
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis CWig: compressed representation of Wiggle/BedGraph format</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">18 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Do</forename>
								<forename type="middle">Huy</forename>
								<surname>Hoang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational and Systems Biology</orgName>
								<orgName type="institution">Genome Institute of Singapore</orgName>
								<address>
									<postCode>138672</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Wing-Kin</forename>
								<surname>Sung</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational and Systems Biology</orgName>
								<orgName type="institution">Genome Institute of Singapore</orgName>
								<address>
									<postCode>138672</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117417</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis CWig: compressed representation of Wiggle/BedGraph format</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="2543" to="2550"/>
							<date type="published" when="2014">18 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu330</idno>
					<note type="submission">Received on March 3, 2014; revised on May 1, 2014; accepted on May 5, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Inanc Birol Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: BigWig, a format to represent read density data, is one of the most popular data types. They can represent the peak intensity in ChIP-seq, the transcript expression in RNA-seq, the copy number variation in whole genome sequencing, etc. UCSC Encode project uses the bigWig format heavily for storage and visualization. Of 5.2 TB Encode hg19 database, 1.6 TB (31% of the total space) is used to store bigWig files. BigWig format not only saves a lot of space but also supports fast queries that are crucial for interactive analysis and browsing. In our benchmark, bigWig often has similar size to the gzipped raw data, while is still able to support $5000 random queries per second. Results: Although bigWig is good enough at the moment, both storage space and query time are expected to become limited when sequencing gets cheaper. This article describes a new method to store density data named CWig. The format uses on average one-third of the size of existing bigWig files and improves random query speed up to 100 times. Availability and implementation: http://</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As the next-generation sequencing (NGS) cost reduces, huge amount of reads can be generated nowadays. After aligning the reads on a reference genome, we can generate the read density, i.e. the number of NGS reads covering each base in the genome. Density data are useful because it can be used to represent the transcript expression in RNA-seq (<ref type="bibr" target="#b9">Hu et al., 2013</ref>), the peak intensity in ChIP-seq (<ref type="bibr" target="#b14">Liu et al., 2011</ref>), the copy number variation in whole genome sequencing (<ref type="bibr" target="#b0">Bock, 2012</ref>), etc. For example,<ref type="figure" target="#fig_0">Figure 1</ref>shows plots of density signals of a ChIP-seq region and a RNA-seq region, respectively. Currently, read density is often represented using the wiggle (wig) format, the bedGraph format or the bigWig format. They all store the densities of NGS reads along the whole reference genome. Wig and bedGraph are uncompressed text formats, thus, are usually huge. BigWig (<ref type="bibr" target="#b12">Kent et al., 2010</ref>) is the compressed form of wig and bedGraph. Its compression approach is to sort and partition the density data into blocks and compress them by gzip. BigWig also supports a few types of queries over any selected region: coverage, max, min, average and standard deviation. These queries facilitate efficient downstream analysis and enable fast visualization of the data. With bigWig format, UCSC genome browser (<ref type="bibr" target="#b11">Karolchik et al., 2014</ref>) can support interactive browsing of density data. In fact, bigWig is one of the most popular track types. In the hg19 browser, $4400 tracks (10% of all hg19 tracks) are bigWig tracks, and they use 1.6TB (it is equivalent to 31% of the total space for all UCSC hg19 tracks). To reduce space and improve query speed, the resolution of the density signals of some UCSC tracks has been reduced, which affects the accuracy. In the future, it is important to reduce the storage space of density data and improve their query speed while maintaining the accuracy of the data. Our project aims to develop an alternative storage format for density signal. Our design is based on careful observations of the data and knowledge of succinct and compressed data structures. For example, we observed that mapping locations of NGS are usually overlapped. Regions with non-zero intensity are often clustered. This fact enables us to reduce the space. Another observation is that the density values of adjacent regions are not independent. Storing the differences between adjacent density values can reduce the size of 80% of the datasets in UCSC hg19. To enable fast queries, we use data structures like SDArray (<ref type="bibr" target="#b15">Okanohara and Sadakane, 2007</ref>) that can compress data while still allowing random access. We also adopt a modified Cartesian tree (<ref type="bibr" target="#b5">Fritz et al., 2011</ref>) that uses linear number of bits and provides constant time min/max query. Similar to UCSC bigWig tool, cWig tool also implements the remote file access feature. In this feature, the program and the data file can be placed in different computers. The program can answer queries by accessing the data file through the HTTP/ HTTPS network protocol. In our experiment using all UCSC hg19 database, the cWig format uses on average one-third of the size of existing bigWig files, and uses much lower space in high resolution data files. In addition, it also improves query speed by 10–100 times depending on the query types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUNDS</head><p>UCSC database stores and displays many types of genomerelated data. They can generally be divided into three groups of formats. Sequence formats: store raw DNA sequences and quality scores. Examples include SAM/BAM (<ref type="bibr" target="#b13">Li et al., 2009</ref>), FASTQ (<ref type="bibr" target="#b1">Cock et al., 2010</ref>) formats. Annotation formats: store information about some biological features (e.g. genes, variants) *To whom correspondence should be addressed. located in a genome. Some popular formats in UCSC are Bed, BigBed (<ref type="bibr" target="#b12">Kent et al., 2010</ref>) and VCF (<ref type="bibr" target="#b3">Danecek et al., 2011</ref>). Some annotation formats are designed to keep different types of features, for example, (<ref type="bibr" target="#b8">Hoffman et al., 2010</ref>) and (<ref type="bibr" target="#b6">Gundersen et al., 2011</ref>). Signal formats: store continuous numerical signal values for each genome bases. Examples include Wiggle, BedGraph and bigWig formats. The sequence and annotation files can be big, but they only require simple queries, i.e. list or count all sequences/annotations in a given region. This query can be solved by adding some index pointers on top of the existing formats. The signal files are structurally simple; however, it requires fast summary operations over some long regions. This article focuses on improving the existing signal formats. The raw density dataset is usually big (measured in Giga bytes per file) and contains a lot of duplicated information. To reduce size, bigWig applies the following compression scheme. It keeps a set of non-overlapping intervals such that the bases in each interval share the same signal value. Intervals with zero intensity or missing values are usually omitted. All intervals are sorted by their starting positions and they are partitioned into blocks of 512 by default. Each block of intervals and their corresponding signal values are compressed using the gzip algorithm in zlib library. To allow partial random access, bigWig stores the starting locations of all blocks using an R-tree-based index (<ref type="bibr" target="#b7">Guttman, 1984</ref>), which is commonly used for geographical data. In addition to the original data, bigWig also stores extra tables to provide fast computation of four summary operations over any query interval. These operations are mean, min/max, coverage and standard deviation. They are crucial for UCSC genome browser visualization function.</p><p>Before we formally define the four operations, we need some additional notations. Let r k be the value at position k of the genome. If there is no value at position k, we denote r k as NaN. Operations that involve NaN are NaN+x=x, NaN Á x=x, 1=0=NaN, min ðNaN; xÞ=x, max ðNaN; xÞ=x, where x is any value (including NaN). For any query range p::q, let N be the number of positions k in p::q, where r k 6 ¼ NaN. The four operations are defined as follows.</p><p>coverageðp; qÞ: Proportion of positions k where r k 6 ¼ NaN, that is, N=ðq À p+1Þ. meanðp; qÞ: The arithmetic mean of the non-NaN values in p::q, that is, 1</p><formula>N X q k=p r k .</formula><p>min valðp; qÞ and max valðp; qÞ: the minimum/maximum value in p::q, that is, min k=p::q fr k g and max k=p::q fr k g. stdevðp; qÞ: The standard deviation of the non-NaN values in p::q, that is,</p><formula>ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 1 N X q k=p r 2 k À meanðp; qÞ 2 r .</formula><p>The extra tables in bigWig file stores precomputed answers of the operations in different zoom levels. For example, zoom level 1 stores answers for regions of length 50 000 bases and zoom level 2 stores answers for regions of length 5000 bases. The precomputed tables are also indexed using R-trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OBSERVATIONS</head><p>This section describes our observations on the bigWig data in UCSC hg19 database. bigWig groups bases that have the same values into intervals instead of storing signal values for each individual base. The problem becomes storing a set of tuples, i.e. ðs i ; e i ; v i Þ where, s i and e i are the start and the end positions of the intervals in a genome; and v i is the signal value of the bases in the interval s i ::e i. As the positions and the values are highly independent across the database, we study them separately in the next two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Observations on interval positions</head><p>This section discusses our observations on the characteristics of the interval data s i ::e i stored in bigWig format. For high-density regions, NGS reads are often overlapped. Once the reads are piled up to generate the coverage data, each high-density region is expected to form a set of consecutive intervals. To illustrate,<ref type="figure" target="#fig_0">Figure 1</ref>shows the density plots of a ChIP-seq region and a RNA-seq region. In both data types, we observed that the position intervals are usually consecutive (i.e. the start of the next interval equals the end of the previous one). To precisely measure this characteristic, we define a measurement called consecutiveness, which is the percentage of intervals in a signal data file that have their start positions equal the end positions of their adjacent intervals. The consecutiveness is zero when no interval stays next to another. It approaches one when all intervals are chained together.<ref type="figure" target="#fig_2">Figure 2a</ref>plots the proportion of bigWig files in UCSC hg19 database based on consecutiveness. We found that 81% of the files have the consecutiveness 40.5. To have a clear picture,<ref type="figure" target="#fig_2">Figure 2b</ref>further shows the relationship between the consecutiveness and the coverage. (Recall that the coverage is the) Intuitively, we expect high coverage files have high consecutiveness. This is actually true as shown in the figure. Most of the Chip-seq data files (highlighted in red oval) are high in both coverage and consecutiveness. However, many RNA-seq files only have high consecutiveness. That means high consecutiveness may be a characteristic of RNA-seq data. Section 4.2 will use this property to reduce the space consumption for storing the positions of the intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Observations on signal values</head><p>This section discusses our observations on signal values in bigWig files. Let v i be the signal value of an interval s i ::e i .<ref type="figure" target="#fig_0">Figure 1</ref>shows that signal values of adjacent intervals are similar for most cases. We suspect that storing the differences (i.e. v i+1 À v i ) may be better than storing the raw signal values (i.e. v i ). To validate this observation, we compare the entropy of raw signals and the entropy of signal differences of adjacent intervals. [Under certain conditions, entropy (<ref type="bibr" target="#b2">Cover and Thomas, 1991</ref>) is the minimum number of bits required to store each element in a sequence of values.]<ref type="figure" target="#fig_3">Figure 3</ref>shows that, among all UCSC bigWig files, the average entropy of raw signals is $4.9 bits, whereas the entropy of differences is around 3.2 bits. This means that, with a suitable compression scheme, storing differences uses less space than storing raw signal values on average. To be more precise, we try to find the list of bigWig tracks, where storing differences is better by computing the discrepancy between the two entropies for each bigWig track.<ref type="figure" target="#fig_3">Figure 3b</ref>shows the histogram plot of the results. We found that 81% of the bigWig tracks (represented by the area under the curve on the right side of the zero line) give smaller entropy when the differences of the adjacent signals values are stored. In other words, we can classify the files into two classes. The first class is smaller by storing differences of the signals. The second class is smaller by storing raw signal values. Our second observation is that certain signal (or difference) values occur more frequently in the bigWig file. To be precise, we define the number of frequent signal (or difference) values in a bigWig file as the minimum number of distinct values whose sum of occurrences makes up 75% of the total number of values in that file.<ref type="figure" target="#fig_4">Figure 4</ref>shows the number of bigWig files that have x frequent signalvalues are usually close to zero. For integer signal files,<ref type="figure" target="#fig_5">Figure 5a</ref>and b show the typical distributions of signal differences. They usually contain one or two peaks in the center. For floating point signal files,<ref type="figure" target="#fig_5">Figure 5c</ref>shows the typical distribution of the signal differences. They often have dense values near zero. We ran a simple classifier on the database and found that of 2627 integer signal files, 1851 files have two peak shape that look like<ref type="figure" target="#fig_5">Figure 5b</ref>, whereas 813 files have shape that are similar to<ref type="figure" target="#fig_5">Figure 5a</ref>. In summary, we have three observations for the signal values.</p><p>More than half of the data is better stored by differences. Most data files have a small set of frequent values. The frequent values are usually small and close to zero. We will use these observations to design schemes for storing signal values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODS</head><p>Using the knowledge from the observations of all bigWig files in UCSC hg19 database, this section presents our storage scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SDArray</head><p>One of the frequently used components in our design is SDArray proposed by (<ref type="bibr" target="#b15">Okanohara and Sadakane, 2007</ref>). It can be seen as a compressed array of increasing integers. We use this data structure for storing both data and index pointers. The advantages of this data structure over the traditional search tree is that, it uses nearly optimal number of bits while still provides O(1) time to access and less than Oð log 2 mÞ time to search (where m is the number of elements). There are a few alternative compressed structures, which have similar properties as described by<ref type="bibr" target="#b17">Raman et al., 2002 and</ref><ref type="bibr" target="#b16">Patrascu, 2008</ref>. SDArray is used because of its speed and simplicity. In addition, it has good compression ratio when the values are not dense, which is commonly observed in our data. The details of SDArray are as follows. Consider an array of nondecreasing nonnegative integers P½1::m. Storing P½1::m explicitly costs mdlog 2 ne bits (where n is the biggest number). SDArray is a compressed data structure storing the array P½1::m and enables constant time access of any element P½i. It also provides an operation called rankðP; xÞ to find the first element P½i that is greater than or equal to x, i.e. rankðP; xÞ=min fi jP½i ! x; i 2 1::mg. Let n=P½m. The SDArray for the array P uses 1:56m+mlog 2 ðn=mÞ+oðmÞ bits and computes rank operation in Oðlog 2 ðmin ðn=m; mÞÞÞ time. This data structure is better than explicit storage when n ) m and m44.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Compression schemes for interval positions</head><p>Consider a set of m position intervals fs i ::e i ji=1::mg. Without loss of generality, assume the intervals are sorted in increasing order of s i. This section describes two alternative schemes (basic scheme and space saving scheme) to store the position intervals. Our two schemes also support random access of the values s i and e i. To implement compatible bigWig operations, our schemes require an operation called find intervalðpÞ that finds the maximal index i, such that s i p, and an operation called cover lenðkÞ that reports the total length of the first k intervals (i.e.</p><formula>X k i=1 ðe i À s i +1Þ).</formula><p>The basic scheme has better access time for the queries, whereas the space saving scheme is more compact when there are many consecutive intervals. CWig uses the space saving scheme, if the consecutiveness (defined in the observation section) is 40.5; otherwise, it uses the basic scheme. Basic scheme: The basic scheme stores the starting positions and interval lengths in two SDArrays: S½1::m and L½1::m+1, respectively, such that S½i=s i , L½0=0 and L½i=</p><formula>X iÀ1 k=1 ðe k À s k Þ. Given S</formula><p>and L, s i and e i equal S½i and S½i+L½i+1 À L½i, respectively. Operation find_interval(p) equals rankðS; pÞ. Operation cover_len(k) equals the value of the k-th entry of L plus k. Hence, all operations take Oðlog 2 ðn=mÞÞ time. The space complexity for this scheme is mð3:12+log 2 ðn=mÞ+ log 2 ðl=mÞÞ+oðmÞ bits, where n=s m , and l is the total length of all intervals (i.e. L½m). This scheme enables efficient query. It also has good space usage when the intervals are sparse (e.g. in RNA-seq datasets). Space saving scheme: By the observations in the previous section, the space saving scheme groups the consecutive intervals into segments to save space. Precisely, we group consecutive intervals ðs i ; e i Þ;. .. ; ðs j ; e j Þ into one segment, if e k =s k+1 for k=i; ::; j À 1. The space saving scheme stores the starting positions of segments, the numbers of intervals in each segment and the lengths of all intervals. Assume that there are g segments, we store: G½1::g is a length-g array, where G½j is the start position of the j-th segment. I c ½1::g+1 is an array such that (I c ½i+1 À I c ½i) equals the number of intervals in the i-th segment. L½1::m+1 contains the prefix sum of the lengths (same as the one in basic scheme).To find the start of the interval i (i.e. the value of s i ), we first compute the segment j that contains the interval i by calculating j=rankðI c ; iÞ, then s i =G½j+L½i À L½I c ½j. The end of the interval, e i =s i +L½i+1 À L½i. function find_interval p j=rankðG; pÞ i=rankðL; ðp À G½jÞ+L½I c ½jÞ if (i5I c ½j+1) then return i else return L½I c ½j+1</p><p>The operation find_interval(p) can be computed using a two-step algorithm. The first step finds the segment nearest to p. Because the intervals inside each segment are consecutive, the second step finds the index of the interval that contains p, using the distance between p and the start of the segment. The operation cover_len(k) equals the value of the k-th entry of L plus k. The space complexity for this scheme is 1:56m+mlog 2 ðl=mÞ+gð3:12+ log 2 ðn=gÞ+log 2 ðm=gÞÞ+oðg+mÞ where l is the total length of the intervals, g is the number of groups and m is the number of intervals. The estimated space requirement is better than the basic scheme when 2g5m. That is when each group on average has more than two intervals (i.e. the consecutiveness is 40.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Compression schemes for signal values</head><p>By the observations in Section 3.2, we design our compression scheme for storing values and the auxiliary data structure to support the required query. The compression has two main stages. The first stage converts the signals into integers and decides whether we need to store the raw signal values or the differences based on the entropy. It also applies some common transformations to make numbers easier for compression. The second stage uses a mixture of methods to compress the integers. Transformations: Let V=fv 1 ; v 2 ;. .. ; v m g denote the signal values. For floating point datasets, we convert all signal values into integers by multiplying with a scale factor. Precisely, we scan all values in V and identify the maximum number of digits after the decimal point; then, every value is multiplied by the same scaling factor f=10. For practical purpose, we keep at most seven fractional decimal digits of precision, which is compatible to the precision level in bigWig format. It is similar to use IEEE's 32-bit floating point numbers for storing signal values. The next step is to decide whether we store the signal values or differences. To make the decision, we compute the entropy of the values and the differences. If the entropy of the values is smaller, we will store the set B=fb i g such that b i =v i f for i=1::n where, f is the scaling factor. Otherwise, we store the set B=fb i g such that b i =ðv i+1 À v i Þf for i=1::n À 1. To avoid the gaps between the numbers introduced by the scaling, we convert B into C such that c i equals the rank of the values of b i in sorted order. Compression: The previous section showed that only a few signal differences have high frequency. Furthermore, many signal differences with high frequency are scattered around zero. To capture this type of distributions, we use two compression methods: Huffman code and Elias delta code. Each method has its own strength and weakness. Elias delta code (<ref type="bibr" target="#b4">Elias, 1975</ref>) is a variable length encoding scheme for positive integers. It represents an integer x in blog xc+2blog 2 blog 2 x+1c c+1 bits. This compression scheme is asymptotically optimal when the numbers are uniformly random in a large range. Huffman code (<ref type="bibr" target="#b10">Huffman, 1952</ref>) is a variable length encoding scheme for a set of symbols (i.e. characters). It encodes each symbol by a new sequence of bits. This compression wastes at most 1 bit per symbol when the probability distribution is known. However, because it needs to store a symbol mapping table, the method is not practical when the number of symbols is large. To encode the set of numbers C from the transformation stage, we use Huffman code to capture the small set of frequent numbers and use Elias delta code for the rest. The details are as follows. We construct a Huffman code with 128 symbols. The most frequent 127 values in C are encoded by 127 Huffman symbols. The remaining values share the 128th Huffman symbol as their prefix and use the delta code values as suffixes. The weights used to build the Huffman symbols are the frequencies of the values. Note that we choose 128 symbols because<ref type="figure" target="#fig_4">Figure 4</ref>showed that most of the files have 5100 frequent values. The signal values V is, therefore, represented by storing the value C, and necessary information to reverse transform from values C to values V (e.g. the factor f, the scheme is raw values or differences, the ranks, the Huffman code table). Auxiliary data structures for queries: We also require a few additional auxiliary data structures and intermediate operations to implement the summary operations defined in Section 2 (i.e. min/max, average and SD). To support the min and max operations, we use Cartesian tree from</p><p>(<ref type="bibr" target="#b5">Fritz et al., 2011</ref>). This structure uses 2m+oðmÞ bits. It supports computation of the minimum/maximum values in any range using O(1) time. Formally, the data structure provides two operations min idxði; jÞ =arg min k2i::j fv k g and max idxði; jÞ=arg max k2i::j fv k g. For the average and SD operations, we need auxiliary data structures to compute two intermediate operations: sum and square sum of the values. The intermediate operations are defined as follows: cover val</p><formula>ðkÞ= X k j=1 ðe j À s j +1Þv j and cover val sqrðkÞ= X k j=1 ðe j À s j +1Þv 2 j for k=1;. .. ; m.</formula><p>To implement operations cover val and cover val sqr, we keep one sampled value in every 64 values of the functions. The sampled values are stored in SDArray for fast access. To compute the values that are not sampled, we jump to the nearest sampled value and sequentially extract ðs j ; e j ; v j Þ to compute the exact sum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Query</head><p>Previous subsections have outlined our storing scheme for the positions and values of the intervals. This section shows how to use these components to support the four summary query operations defined in Section 2. In general, given a query region p::q, the query asks for some summary values (e.g. average, min/max, SD, coverage) of the signal values of the genome positions from p to q. The details are as follows. Coverage query: Given the input region p::q, the coverage query coverage(p,q) computes the proportion of non-NaN bases. Note that the number of non-NaN bases, which equals 1 ðqÀp+1Þ ðq Á coverageð0; qÞ À ðp À 1Þcoverageð0; p À 1ÞÞ. Let j be the largest index such that s j is less than or equal to q (i.e. j=find intervalðqÞ). We have q Á coverageð0; qÞ=cover lenðjÞ À min fe j À s j ; q À s j g+1. Similarly, we can compute ðp À 1Þ Á coverageð0; p À 1Þ using find intervalðp À 1Þ and the interval values. Min/max query: The minimum/maximum of signal values in a query region p::q can be computed in three steps. First, we find the set of intervals fðs i ; e i Þ;. .. ; ðs j ; e j Þg that overlap with the query region p::q. This can be done by computing find intervalðpÞ and find intervalðqÞ. The second step uses operations min idxði; jÞ or max idxði; jÞ to find the index of the minimal/maximal value in constant time. The last step extracts the actual signal values. Mean query:</p><formula>meanðp; qÞ= 1 n X q k=p r k where r i</formula><p>is the value of the i-th base, and n is the number of non-NaN bases, i.e. n=ðq À p+1Þcoverageðp; qÞ.</p><formula>Note that X q k=p r k = X q k=0 r k À X pÀ1 k=0 r k. The value of X q k=0 r k can be computed by (1) let j=find intervalðqÞ and (2) X q k=0 r k =cover valðjÞ+v j ðmin fe j À s j ; q À s i g+1Þ.</formula><p>Similarly, we can compute</p><formula>X pÀ1 k=0 r k .</formula><p>Standard deviation query: stdevðp; qÞ can be computed using the formula ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Remote file access</head><p>Our solution for remote access feature is to use a simple network layer that handles HTTP 1.1 byte ranges and keep-alive protocols. Once a data file is placed under a web server that supports the HTTP protocol (e.g. Apache, Microsoft IIS and nginx), it can be queried from different computer to get any block of data. The implementation also supports HTTPS protocol if OpenSSL library is available. To avoid duplicated data transfer and network protocol overhead, a simple file caching scheme is implemented. Any data requested over the network is read in blocks of 16 KB and stored in a cache file. An additional bit-map file is kept to mark down blocks that have been saved locally. Multiple queries to some close locations are likely to access the same data block, hence, do not incur new network request. In addition, the overhead to start transferring data over the network is high (e.g. in milliseconds). It is more beneficial to transfer data in blocks. To enhance the performance of block transferring and file caching, cWig reorganizes the component data structures to make data access localized. It groups small, fixed size and frequently accessed fields of different data structures into a consecutive segment called 'control segment'. (The segment usually stores the length, counter and metadata of the data structures.) The large and variable length data are stored in another segment of the file. When the data structure is loaded remotely, the data in the control segment is more likely to be transferred in one request and cached; therefore, it helps to reduce the delay between queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT RESULTS</head><p>In this section, we present three sets of experiments. The first set of experiments compares the sizes of bigWig and cWig files. It also compares different alternatives of our design to support our final choice. The second set of experiments compares the speed between bigWig and cWig in one machine. The last set of experiments compares the remote query speed of cWig's and bigWig's tools. We use three datasets for the experiments: full dataset for size measurement, sampled dataset for the speed measurement on one computer and a few selected files for the remote access experiments. The full dataset consists of all bigWig files in UCSC hg19 database ($4400 files). The UCSC bigWig files use a total of 1.6 Terabytes. To have a clear picture, we categorize the files in UCSC into groups by value types (i.e. integer signal versus floating point signal) and by data types (i.e. ChIP-seq, RNA-seq, DNAse, FAIRE and Other). This dataset is used in the section on file size comparison. The sampled dataset is a subset of the full dataset. The files are grouped similarly as the full dataset. However, each group only contains 5–10 sampled files. (The detailed list of files can be found in the Supplementary C.) The sampled datasets are used for running time comparison. Furthermore, three files from UCSC hg19 of different sizes are selected for the remote query speed experiments. Note that the name bigWig, cWig or gzip is used to refer to both the file format and tool/program to access the format. For bigWig, there are a few tools that can create, extract and randomly access the format. We use the latest version of the tool provided by the original authors (in<ref type="bibr" target="#b12">Kent et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">File sizes comparison</head><p>Compare different methods:<ref type="figure">Figure 6</ref>shows results that compare different storage formats for different data types. The methods used in this experiment are (i) bedGraph is the raw text format of the input file, (ii) gzip_bg is the gzip compressed bedGraph format, (iii) bigWig is the method from UCSC, (iv) val_delta is our method that stores the raw signal values using delta code, (v) diff_delta is our method that stores signals by their differences using delta code only and (vi) huff128 and (vii) huff1024 are our methods that store signals by their differences using a mix of Huffman code and delta code. huff128 encodes the most frequent 127 values by unique Huffman symbols, whereas the rest of the values are encoded by delta code. huff1024 is similar to huff128; but the number of Huffman symbols are 1023. For clarity,<ref type="figure">Figure 6</ref>shows only four types of data: ChIP-seq, RNA-seq FAIRE and Other. (For full result, please refer to Supplementary B.) The bars in the background show the relative ratios between the compression schemes. Among our methods, huff128 and huff1024 are consistently better than val-delta and diff-delta. huff128 and huff1024 give similar size. This supports the observations in Section 3.2 that, higher number of Huffman symbols does not improve compression. Based on this experiment, we choose huff128 as our default compression method for cWig format. Compared with bigWig and gzip, our methods use at most half of their sizes. In most of the files, the file sizes of bigWig and gzip are similar because the bigWig uses gzip to compress their main data. However, for high-resolution files, e.g. FAIRE data type, bigWig uses considerably more space than gzip. We found that this space is usually accounted for its indexing structures to support random access and queries. Compare ours and bigWig:<ref type="figure" target="#fig_8">Figure 7</ref>compares the file sizes between cWig and bigWig formats.<ref type="figure" target="#fig_8">Figure 7a</ref>plots the original<ref type="figure">Fig. 6</ref>. This table indicates the mean file sizes for storing ChIP-seq, RNA-seq and Other data types using the raw text format (bedGraph) and six different compression schemes. The bars in the background show the relative ratios between the compression schemes bigWig size versus the reduction that we can achieve.<ref type="figure" target="#fig_8">Figure 7b</ref>is a table that summarizes the ratios based on the data types. It shows that our format is (in average) 3.6 times smaller than bigWig. In particular, cWig is more compressible for high resolution datasets, e.g. FAIRE and DNase. We noticed some users truncate the significant digits of the values to reduce the file sizes of bigWig. We conducted an experiment to investigate its effect on both formats. The detail is included in the Supplementary D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Running time comparison</head><p>Linear compression and extraction:<ref type="figure">Figure 8</ref>shows the average compression/decompression speed for different methods. Because the compression/decompression speed is consistent with the input file size, we only show the average processing time in terms of megabytes per second. The figure shows that bigWig and gzip have similar compression speed. Our program is about two times faster. For decompression speed, our program is $150% faster than bigWig, but slower than gzip. Random queries: This set of experiments measure the query speed of operations coverage, minimum and average for both our tool and bigWig tool. We tested three sets of queries: (i) each query is a random interval. The order of queries is also random.This set is intended to simulate the actual list of queries made by the bioinformaticians). Because the speed of both programs for query types (i) and (ii)</p><p>are not significantly different, we only summarize the speed for query types (i) and (iii). In addition, because the query speed for the three operations in bigWig is similar, we only report the average query speed of bigWig.<ref type="figure">Figure 9</ref>shows that the query speed of our program is $10– 100 times faster than that of bigWig, depending on query type. In our program, coverage queries are much faster than the minimum and the average queries because coverage queries only use the interval position component. The minimum queries are faster than the average queries in sparse files where there are a lot of regions without values. We noticed that there is a big difference in bigWig speed between random queries and real queries. After some investigations, we found that bigWig query speed may be affected by the query interval length. It is slower for shorter intervals. We create a query file that has the same starting positions as the real query file, but increased in the interval lengths. bigWig is much faster when the interval lengths are larger than 1 million bases. Note that the average interval length of the random query in<ref type="figure">Figure 9</ref>is around half the chromosome length, whereas the average interval length of the genes is only 54 783.<ref type="figure">Fig. 8</ref>. Average compression and decompression speed in Megabytes per second (higher is better) with SDs for each method<ref type="figure">Fig. 9</ref>. Average query time in nanoseconds (lower is better) for randomly generated queries and gene region queries</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Remote file access speed</head><p>In this experiment, we measure the query speed in different network conditions. We select three input files of different sizes from UCSC hg19 database. They are called 'small', 'medium' and 'big'. The sizes of the corresponding bigWig files are 824 KB, 98 MB and 5.5 GB, respectively. The sizes of the corresponding cWig files are 414 KB, 35 MB and 1.4 GB, respectively. The query speed is measured in two different network conditions: 'SG' and 'US'. 'SG': the files and the programs are both hosted in Singapore and connected through the Internet. The average round trip time is $100 ms; the bandwidth is $5–10 MB/s. 'US': the programs are in Singapore, and the files are hosted in California, USA. The round trip time is $210 ms, the bandwidth is $300–850 KB/s. Similar to the previous experiment, we use the human genes regions as the query set.<ref type="figure" target="#fig_0">Figure 10</ref>compares the running times of bigWig and cWig under different network conditions and using different input files. (Note that, there is no measurement for big file under 'US' network condition owing to our resource limitation.) In these experiments, the CPU times of both programs are accounted for 510% of the total running times for medium and big input files. The programs spend most of their time waiting for network responses. Our file size significantly helps in the experiments on the medium file. Because cWig file is smaller, the queries on this file get cached in fewer iterations. For small file, the time difference is not significant. Both programs can cache the small file after a few queries. For big file, both programs fail to cache the file, and hence, both methods spend similar amount of time to wait for the network to respond.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>This article proposed the file format for cWig to store signal data. Comparing with bigWig, cWig not only uses lesser space but also provides faster queries. This format should be useful for visualization applications like UCSC genome browser (<ref type="bibr" target="#b11">Karolchik et al., 2014</ref>) and Broad Institute Integrative Genome Viewer (<ref type="bibr" target="#b18">Robinson et al., 2011</ref>) and for Biologists to analyze and discover features in their data. In the future, we would like to extend our idea to represent other types of data [like bigBed (<ref type="bibr" target="#b12">Kent et al., 2010</ref>) and BAM (<ref type="bibr" target="#b13">Li et al., 2009)]</ref>. We also want to consider lossy compression methods to gain better compression over noisy data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts</head><p>of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. (a) A zoom region in ChIP-seq file. (b) A zoomed region in a RNA-seq file. The dotted lines indicate boundaries of two consecutive intervals</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>(or difference) values for all x. Of 4400 bigWig files in UCSC hg19, about 1500 files have less than six frequent raw signal values, and $2500 files have less than six frequent differences values. Most of the files have 560 differences values. We further investigate the distributions of the values in each file. After studying many examples, we found that the frequent</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. (a) Histogram of the datasets based on consecutiveness. (b) Coverage versus consecutiveness in UCSC hg19 bigWig files. The big dotted oval highlights most Chip-seq datasets. The small oval highlights low coverage, but high consecutive datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. (a) Average entropy of raw signals and their differences in UCSC files. (b) Histogram of the entropy of the values minus the entropy of the differences in each file</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Histogram of frequent values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Histogram of signal differences. (a) and (b) are two common histograms observed in integer value signal files. (c) is a common histogram observed in floating point value signal files. In these subfigures, the X-axes are the difference between adjacent signal values shown from –10 to 10. Y-axes show the frequencies of these signal differences. The maximal frequencies shown in (a), (b) and (c) are 0.4, 0.5 and 0.016, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>can be computed from the intermediate queries cover_sum_sqr and find_interval.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><figDesc>(ii) Each query is a random interval. But the list of queries is arranged in increasing order of the start positions. (iii) The query intervals are the confirmed human gene regions. We call this set 'real queries' set. (It contains 76 969 intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.7.</head><figDesc>Fig. 7. Ratio between bigWig file sizes and our file sizes. (a) The compression ratio for all UCSC files whose sizes are56 GB. (The files that are excluded are three FAIRE files and the liver cancer file). (b) The mean of the compression ratio between bigWig and our format for each file type. (The last column represents both integer-value and floating-point-value files. 'All UCSC' row represents all the files types in UCSC. The light scale of the cells of the table is in proportion to the value inside)</figDesc></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">D.Huy Hoang and W.-K.Sung at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">CWig at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> n X q i=p r 2 i À 1 n 2 meanðp; qÞ 2 q , where, r i and n are defined same as above. Using similar approach as the mean query, the sum of squared</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Analysing and interpreting DNA methylation data</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="705" to="719" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">The Sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Cock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1767" to="1771" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Cover</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Thomas</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Wiley</publisher>
			<biblScope unit="page">195</biblScope>
			<pubPlace>New York, NY, USA, Chapter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">The variant call format and VCF tools</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Danecek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2156" to="2158" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Universal codeword sets and representations of the integers</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Elias</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Theory IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="194" to="203" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient storage of high throughput DNA sequencing data using reference-based compression</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H Y</forename>
				<surname>Fritz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="734" to="740" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Identifying elemental genomic track types and representing them uniformly</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gundersen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">494</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">R-trees: a dynamic index structure for spatial searching</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Guttman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1984 ACM SIGMOD International Conference on Management of Data. SIGMOD&apos;84</title>
		<meeting>the 1984 ACM SIGMOD International Conference on Management of Data. SIGMOD&apos;84<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">The genomedata format for storing large-scale functional genomics data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Hoffman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1458" to="1459" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">DiffSplice: the genome-wide detection of differential splicing events with RNA-seq</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Hu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A method for the construction of minimum-redundancy codes</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Huffman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the I.R.E</title>
		<meeting>the I.R.E<address><addrLine>India, India</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1952" />
			<biblScope unit="page" from="1098" to="1102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">The UCSC genome browser database: 2014 update</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Karolchik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="764" to="770" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">BigWig and BigBed: enabling browsing of large distributed datasets</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Kent</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2204" to="2207" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">The sequence alignment/map (SAM) format and SAMtools</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2078" to="2079" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Cistrome: an integrative platform for transcriptional regulation studies</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">83</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Practical entropy-compressed rank/select dictionary</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Okanohara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sadakane</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Workshop on Algorithm Engineering and Experiments</title>
		<imprint>
			<publisher>ALENEX). Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2007" />
			<publisher>ALENEX). Society for Industrial and Applied Mathematics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Succincter In: Foundations of Computer Science</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Patrascu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS&apos;08. IEEE 49th Annual IEEE Symposium</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="305" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Succinct indexable dictionaries with applications to encoding k-Ary trees and multisets</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Raman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms. SODA&apos;02</title>
		<meeting>the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms. SODA&apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Integrative genomics viewer</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Robinson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="24" to="26" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">10. cWig and bigWig remote query time</title>
		<author>
			<persName>
				<surname>Fig</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
	<note>in. seconds</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>