
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Stability of gene rankings from RNAi screens</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-12">. 12 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Juliane</forename>
								<surname>Siebourg</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<addrLine>Mattenstrasse 26</addrLine>
									<postCode>4058</postCode>
									<settlement>Basel, Switzerland</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">SIB Swiss Institute of Bioinformatics</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Gunter</forename>
								<surname>Merdes</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<addrLine>Mattenstrasse 26</addrLine>
									<postCode>4058</postCode>
									<settlement>Basel, Switzerland</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Benjamin</forename>
								<surname>Misselwitz</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Institute of Microbiology</orgName>
								<orgName type="department" key="dep2">Department of Biology</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<addrLine>Wolfgang-Pauli-Strasse 10</addrLine>
									<postCode>8093</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Wolf-Dietrich</forename>
								<surname>Hardt</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Institute of Microbiology</orgName>
								<orgName type="department" key="dep2">Department of Biology</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<addrLine>Wolfgang-Pauli-Strasse 10</addrLine>
									<postCode>8093</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Niko</forename>
								<surname>Beerenwinkel</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<addrLine>Mattenstrasse 26</addrLine>
									<postCode>4058</postCode>
									<settlement>Basel, Switzerland</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">SIB Swiss Institute of Bioinformatics</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Systems biology Stability of gene rankings from RNAi screens</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="1612" to="1618"/>
							<date type="published" when="2012-12">. 12 2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts192</idno>
					<note type="submission">Received on December 21, 2011; revised on March 19, 2012; accepted on April 11, 2012</note>
					<note>Copyedited by: TRJ MANUSCRIPT CATEGORY: ORIGINAL PAPER [19:30 17/5/2012 Bioinformatics-bts192.tex] Page: 1612 1612–1618 Associate Editor: Ivo Hofacker Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Genome-wide RNA interference (RNAi) experiments are becoming a widely used approach for identifying intracellular molecular pathways of specific functions. However, detecting all relevant genes involved in a biological process is challenging, because typically only few samples per gene knock-down are available and readouts tend to be very noisy. We investigate the reliability of top scoring hit lists obtained from RNAi screens, compare the performance of different ranking methods, and propose a new ranking method to improve the reproducibility of gene selection. Results: The performance of different ranking methods is assessed by the size of the stable sets they produce, i.e. the subsets of genes which are estimated to be re-selected with high probability in independent validation experiments. Using stability selection, we also define a new ranking method, called stability ranking, to improve the stability of any given base ranking method. Ranking methods based on mean, median, t-test and rank-sum test, and their stability-augmented counterparts are compared in simulation studies and on three microscopy image RNAi datasets. We find that the rank-sum test offers the most favorable trade-off between ranking stability and accuracy and that stability ranking improves the reproducibility of all and the accuracy of several ranking methods. Availability: Stability ranking is freely available as the R/Bioconductor package staRank at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Genome-wide gene silencing experiments are important in many fields of biology and medicine as they provide a first overview of which genes might play a role for a specific experimental condition. Many screens have been performed to study signaling in model organisms like Drosophila melanogaster (<ref type="bibr" target="#b4">Boutros et al., 2004;</ref><ref type="bibr" target="#b35">Saj et al., 2010</ref>). In infection biology, viruses such as Influenza and HIV (<ref type="bibr" target="#b7">Cherry, 2009;</ref><ref type="bibr" target="#b17">Hao et al., 2008;</ref><ref type="bibr" target="#b18">Karlas et al., 2010;</ref><ref type="bibr" target="#b38">Zhou et al., 2008</ref>) as well as bacteria, including Salmonella, Bartonella and Shigella (<ref type="bibr" target="#b0">Agaisse et al., 2005;</ref><ref type="bibr" target="#b24">Misselwitz et al., 2011;</ref><ref type="bibr" target="#b29">Philips *</ref>To whom correspondence should be addressed<ref type="bibr" target="#b33">Rämet et al., 2002;</ref><ref type="bibr" target="#b34">Reiterer et al., 2011;</ref><ref type="bibr" target="#b37">Truttmann et al., 2011</ref>), have been analyzed to identify the key host genes involved in pathogen entry into the cell. In cancer research, RNA interference (RNAi) screens have been used to study dysregulated signaling pathways and to identify novel drug targets (<ref type="bibr" target="#b1">Berns et al., 2004;</ref><ref type="bibr" target="#b27">Ngo et al., 2006</ref>). In such high-throughput experiments one faces the problem of detecting the typically few relevant variables from a large, highdimensional, noisy dataset. We focus here on data from microscopy image-based RNAi screens (<ref type="bibr" target="#b2">Bickle, 2010</ref>), where genes are knocked down individually by post-transciptional gene silencing. Small interfering RNAs (siRNAs) of 22 base pairs are introduced into a cell, where they induce cleavage and degradation of a target messenger RNA, complementary to the siRNA and thus to the eventual depletion of the respective protein (<ref type="bibr" target="#b12">Fire et al., 1998;</ref><ref type="bibr" target="#b16">Hannon, 2002;</ref><ref type="bibr" target="#b23">Mello and Conte, 2004</ref>). A typical setup for such a microscopy image-based screen consists of several 384-well plates, where each well contains cells with exactly one gene knocked down. There are different strategies for the knock-down, two of which will be covered by different datasets we analyze in Section 4.2. The first is to take replicates of the same biological experiment, meaning that for each gene, the same siRNA knock-down is performed several times. The second strategy uses biologically different experiments per gene. Here, each well for the same gene contains a different type of siRNA targeting the gene (<ref type="bibr" target="#b8">Echeverri et al., 2006</ref>). A third approach is to pool these different siRNAs in one well, each of them in lower concentration (<ref type="bibr" target="#b19">Kittler et al., 2007</ref>). This strategy adresses two main problems of siRNAs. The first is inefficient knock-down of a gene, for example due to inefficient siRNA binding. Secondly, an siRNA can have so called off-target effects, arising from limited binding specificity or other often unknown pharmacological effects (<ref type="bibr" target="#b31">Qiu et al., 2005</ref>). After transfection with siRNAs, the cells are put in the experimental condition to be studied and subsequently they are imaged. The images are processed by an image segmentation and analysis software and the final experimental readout consists of one or more phenotypic measures retrieved from fluorescence signals of stained proteins. In most cases, the goal of a first genome-wide screen is to prioritize genes to select a set of top scoring 'hits' for which a secondary validation experiment is performed. For a 1D readout the usual procedure is to rank the genes by their mean or median readout across replicates. However, to account for the variation among replicates genes can also be ranked according to a test</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stability ranking</head><p>statistic. For example, redundant siRNA activity analysis (RSA) is a ranking method specifically designed for RNAi screens. It ranks all individual siRNAs by readout and then assigns a p-value to each gene based on the rank distribution of all siRNAs targeting it using a hyper-geometric model (<ref type="bibr">König et al., 2007</ref>). After ranking, a threshold is chosen to distinguish between hit and non-hit genes. This threshold can be a fold-change, deviation from the mean, or simply the fraction of top k ranking genes. The number of genes in the final subset will usually be restricted by the capacity of the re-screen and typically contains at most on the order of a few hundred genes. Selecting the optimal genes is a difficult problem, because many data points lie very close to each other and, at the same time, they are subject to considerable noise. Rather than defining hits, we focus here on the gene ranking itself, because (i) we did not find any evidence for two separate groups in the data (such as a bimodal readout distribution), and (ii) in practice, the top k genes will be selected based on available resources. Thus, we assume that each gene has an individual effect and that readout values are drawn from a continuous distribution. A general problem with rankings is that reproducibility is strongly affected by small perturbations of the data and that different ranking criteria can lead to very different results (<ref type="bibr" target="#b11">Fagin et al., 2003</ref>). Since the screens are expensive and time consuming, in a whole-genome setting, only a few samples per gene are available. The analysis is further complicated by high levels of noise resulting, among other factors, from the uncertainty in quantifying image-based readouts and from the above mentioned off-target effects. Thus, the reliability of such gene rankings is a major concern directly affecting the chances of validating primary hits in follow-up experiments. Gene rankings have been considered in the context of identifying differentially expressed genes from microarray data. To quantify the robustness of a ranking, resampling or subsampling methods are often used (<ref type="bibr" target="#b9">Efron, 1979</ref>). For example, to benchmark different statistical tests for their reproducibility in detecting differentially expressed genes, (<ref type="bibr" target="#b32">Qiu et al., 2006</ref>) use a subsampling approach. (<ref type="bibr" target="#b28">Pavlidis, 2003</ref>) apply a jackknife procedure to investigate the number of replicates per gene in a microarray experiment that are needed to obtain stable results. The R package 'Gene Selector' (<ref type="bibr" target="#b3">Boulesteix and Slawski, 2009</ref>) implements several ranking statistics and provides a bootstrap procedure to estimate the robustness of the ranking result. Another way of generating more stable results is learning the optimal ranking statistic for a given dataset based on resampling (<ref type="bibr" target="#b10">Elo et al., 2008;</ref><ref type="bibr" target="#b26">Mukherjee et al., 2005</ref>). The probabilities obtained in this manner can also inform the variable selection procedure. For example, (<ref type="bibr" target="#b25">Mukherjee et al., 2003</ref>) have used bootstrapped p-values from t-tests to select genes more robustly. Hall and<ref type="bibr" target="#b14">Miller (2009)</ref>discuss the consistency of boostrap estimators for rankings. They also model the variability of rankings which they find to be lower at the extremes (<ref type="bibr" target="#b15">Hall and Miller, 2010</ref>). Stability selection is a more general variable selection method based on subsampling to estimate selection probabilities of variables (<ref type="bibr" target="#b22">Meinshausen and Bühlmann, 2010</ref>). For this approach, an upper bound on the expected number of false positives has been derived under certain assumptions. Rank aggregation has also been proposed to improve ranking stability. The 'Gene Selector' package provides aggregation of rankings by, for example, rank averaging or rank product. (<ref type="bibr" target="#b30">Pihur et al., 2009</ref>) propose a genetic algorithm to find an aggregated ranking that minimizes the distance to the individual rankings.</p><p>Their results are quite stable, but a drawback of this method is that it is computationally very expensive and practical only for very small lists of genes. In the presence of multivariate data, the hit selection problem can also be addressed by multivariate approaches like support vector machines (<ref type="bibr" target="#b13">Guyon et al., 2002</ref>) or other classification methods [see (<ref type="bibr" target="#b21">Lai et al., 2006</ref>) and (<ref type="bibr" target="#b36">Stiglic and Kokol, 2010</ref>) for examples]. However, since we have 1D readouts we only consider univariate methods for the rankings. In this article, we compare different ranking methods to identify those that produce the most stable gene lists. We analyze mean, median, t-test and rank-sum test, and quantify their reproducibility. The notion of stable sets, as defined in stability selection, is used to assesses the stability of a ranking. However, a ranking should not only be stable but also as accurate as possible. A constant ranking obtained, for example, by sorting genes alphabetically would be perfectly stable, but estimate biological effects very poorly. Finding an optimal trade-off between accuracy and reproducibility is a major goal when selecting hits in RNAi screening. We introduce stability ranking to improve the stability of any given base ranking method, while maintaining and sometimes improving its level of accuracy, and compare it to rank averaging. The performance of rankings is tested on simulated data and on real data from three image-based RNAi screens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">STABILITY RANKING</head><p>Let G be a set of p genes. For each gene knock-down, an experimental response is measured, called readout. We want to prioritize the genes with significantly altered readouts. For each gene g ∈ G, there are n measurements g 1 ,...,g n , which could either be replicates or correspond to individual siRNAs. Let rk(g) be the true rank of a gene g, S k ={g | rk(g) k} the set of genes that are ranked below a certain cutoff k, and N k ={g | rk(g) &gt; k} the set of genes with ranks above the cutoff. Then the goal is to infer the set of true top k genes, S k , from few noisy observations. As discussed above, we do not optimize the cutoff parameter k, but rather aim at inferring S k for all k ∈{1,...,p}. We follow the stability selection approach (<ref type="bibr" target="#b22">Meinshausen and Bühlmann, 2010</ref>) and let I ∈ 2 {1,...,n} be the random variable for data samples of size n that are drawn with replacement from the set of replicates. For a given ranking method and a fixed cutoff k, the probability for a gene g ∈ G to be in the selected setˆSsetˆ setˆS k (I) is denoted by</p><formula>g k = P[g ∈ ˆ S k (I)]</formula><p>and estimated from a finite sample</p><formula>{i 1 ,...,i m } asˆgasˆ asˆg k = 1/m m j=1 1{g ∈ S k (i j )</formula><p>}, where 1 is the indicator function, which equals 1 if the argument is true and 0 otherwise, and S k (i j ) the set of selected genes based on subsample i j. We regard those genes as stable that are selected with high probability. Formally, for a threshold π ∈ (0,1), we define the stable gene setˆS setˆ setˆS stable</p><formula>k = g ∈ G | ˆ g k π .</formula><p>We fix π = 0.9 throughout the article since the choice of this parameter is not critical, as long as it is not set to very low values (see Supplementary<ref type="figure" target="#fig_4">Fig. S3</ref><ref type="figure">1</ref>. Illustration of stability selection for a specific ranking cutoff k. The cardinality of the stable set at this cutoff provides an estimate for the number of top k genes, that are expected to be among the top k again, when repeating the experiment under the same conditions computing the stable sets for all k ∈{1,...,p} and then ranking the genes by the order in which they enter the stable set:</p><formula>rk stable (g) = ˆ S stable k * , where k * = min k | ˆ g k π .</formula><p>The cardinality of the stable set provides an estimate of the number of hits that can be expected to be validated with probability π when considering the top k * genes in the ranking. By validation we mean here that a gene is again among the top k * genes when repeating the experiment under the same conditions. For noisy datasets, k * can become much larger than the stable set size (<ref type="figure">Fig. 1</ref>). Stability ranking is implemented in the R/Bioconductor package staRank. We apply this procedure to several ranking statistics, including mean and median as well as two statistical tests which account for the variation per gene, namely the t-test as a parametric and the rank-sum test as a non-parametric test. The tests are performed as one sided, two-sample tests comparing the replicates of one gene to the total dataset. For datasets generated by different siRNAs per gene, we also apply RSA ranking (<ref type="bibr">König et al., 2007</ref>). We analyze the stability and accuracy of the original ranking methods and investigate the improvement due to stability ranking in a simulation study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SIMULATION STUDY</head><p>In the absence of evidence for multiple modes in the readout distributions of the RNAi screens we analyzed, in our simulations, we draw knock-down effects for all genes from a unimodal distribution and add individual random noise to it. We simulate datasets from a variety of models. Each model generates datasets of size p×n, where p is the number of genes and n the number of replicates. For each gene, its true effect μ and its observed readouts g i are drawn in a hierarchical fashion from normal distributions as follows:</p><formula>μ ∼ N(0,s 2 )</formula><formula>σ 2 ∼ (α,β) g i ∼ N(μ,σ 2 ), i = 1,...,n.</formula><p>Each model is characterized by the variance among gene effects, s 2 , and the shape α and rate β of the gamma distribution from which the gene-wise variances among replicates are drawn. The gamma distribution has mean m = α/β and variance v = α/β 2. We estimated the parameters s, m and v from the effect and replicate distributions observed in the Drosophila genome-wide</p><p>RNAi screen described below (<ref type="bibr" target="#b35">Saj et al., 2010</ref>). We then varied the parameters around these estimates, which resulted in 24 different models (Supplementary<ref type="figure">Fig. S1</ref>and Supplementary Tables S1 and S2). Each model was used to generate datasets of cardinality n = 2, 3, 4 and 10. To assess reproducibility and accuracy, 300 pairs of datasets are drawn from each model. For each dataset, the different base ranking methods, their stability ranking and their average ranking are computed. Accuracy is assessed by comparing the top k genes from an estimated ranking rk to the true hits S k , whereas the reproducibility of a ranking is defined as the overlap in top k gene sets between the two rankings rk 1 and rk 2 estimated from paired datasets (<ref type="bibr" target="#b26">Mukherjee et al., 2005</ref>),</p><formula>accuracy(k) = |S k ( rk)∩S k |/k reproducibility(k) = |S k ( rk 1 )∩S k ( rk 2 )|/k.</formula><p>Both quality measures take values in<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, where 1 indicates complete agreement among top k gene sets and hence perfect accuracy or reproducibility. The final quantities we report are averages across the pairs of datasets (reproducibility) or across all datasets (accuracy), for the top k/p = 1% or 10% genes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Simulation results</head><p>Using the model described in the previous section, we ran simulations for p = 1000 genes and assessed accuracy and reproducibility of the top 10 (1%) genes, because in practice, usually only a small fraction of hits can be selected for follow-up experiments. In<ref type="figure" target="#fig_2">Figure 2</ref>, reproducibility and accuracy are compared between the original, average and stability rankings for all models. Models with a filled shape showed a significant difference between the two ranking methods (baseline versus stability ranking and aggregated versus stability ranking) at the 0.1% level in a paired t-test after Benjamini–Hochberg correction for multiple testing. For mean and median ranking, we observe an increase in reproducibility for a large group of models, when using stability ranking (<ref type="figure" target="#fig_2">Fig. 2A</ref>and B). Remarkably, stability ranking also increases the accuracy of the ranking (<ref type="figure" target="#fig_2">Fig. 2F</ref>and G). Similarly, for the rank-sum test, reproducibility is improved using stability ranking, although the effect is not as strong, while maintaining the same level of accuracy (<ref type="figure" target="#fig_2">Fig. 2C</ref>and H). The same behavior can be observed for the RSA rankings (<ref type="figure" target="#fig_2">Fig. 2E</ref>and J). By contrast, the t-test shows no difference between the two ranking versions, but accuracy is overall very low (<ref type="figure" target="#fig_2">Fig. 2D</ref>and I). The poor performance might be due to unreliable estimation of the variance from only two to five observations. Thus, non-parametric ranking statistics are preferable for this type of data. Direct comparison of the stability rankings based on mean, median and rank-sum test reveals superior accuracy and reproducibility of the rank-sum test (Supplementary Figs S3 and S4). In general, the performance increases with the width of the effects distribution (see Supplementary Tables S1 and S2, and Supplementary<ref type="figure">Figure S1</ref>for top 10%). A direct comparison of stability ranking and rank averaging shows similar performance (<ref type="figure" target="#fig_2">Fig. 2K</ref>–T) with a slight advantage of stability ranking. For all of the four competitive methods, the stability ranking was significantly better in reproducibility for many more models than the average ranking (43 versus 9 for mean, 36 versus 12 for median, 41 versusThe colors represent the parameters that were used for the mean effect distribution. The different shapes represent the different gamma distributions for the gene variances and the symbol size indicates the number of replicates used. For models that have a filled shape, the two ranking methods (baseline versus stability ranking) showed a significant difference at the 1% level in a paired t-test after Benjamini–Hochberg correction for multiple testing 7 for rank sum and 29 versus 17 for RSA). The accuracy was similar for both aggregated methods, again with a slight advantage for stability ranking (12 versus 0 for mean, 11 versus 0 for median and 2 versus 0 for rank sum).<ref type="figure" target="#fig_4">Figure 3</ref>shows reproducibility and accuracy for one specific model, defined by the parameters s = 1.69, m = 9, v = 61.8 and n = 10. Interestingly, at the very top of the ranking the t-test outperforms the other methods in terms of reproducibility, but at the same time it has the lowest accuracy. The t-test base and stability rankings are almost indistinguishable, whereas for the other methods there is a large difference between the two. Especially for the top-ranked genes, stability ranking improves reproducibility by &gt;10%. For median and mean, this also holds true in terms of accuracy up to the top 25% of the ranking. The most accurate ranking is produced by the rank-sum test, slightly outperforming its stability ranking version. Similar effects can be observed for most of the models. In summary, the rank-sum test offers a good trade-off between accuracy and reproducibility of the ranking. Stability ranking, which can be applied on top of any given ranking method, improves or at least equalizes both accuracy and reproducibility of all ranking methods investigated here. The improvement is the largest if the base ranker does not account for gene-wise variation, such as mean and median ranking, but even the reproducibility of the rank-sum test ranking can be improved and, on average, it is larger then using average ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Application to RNAi datasets</head><p>We apply stability ranking to three RNAi screens, of which one uses four replicates per siRNA, whereas the other two use three to four siRNAs per gene. The first is a whole-genome screen of D.melanogaster cells, which was performed to study signaling of the Notch receptor (<ref type="bibr" target="#b35">Saj et al., 2010</ref>). It consists of 4 identical replicates on ∼12 000 genes each. For each knocked down gene, Notch signaling activity was measured based on the ratio of signal to background fluorescence measurements. We refer to it as the Notch screen. The second dataset comprises a screen of ∼7000 human druggable genes (<ref type="bibr" target="#b24">Misselwitz et al., 2011</ref>). In this experiment, HeLa cells were infected with Salmonella bacteria to study their entry mechanism. For this the infection rate per knock-down is used. This screen was performed using three different siRNAs targeting the same gene. The third dataset is similar to the previous one but wasHere we used all 14 837 genes for which 4 siRNA values were available. We call these screens the druggable (SalD) and the genome-wide (SalGW) Salmonella screen, respectively. For a more detailed description of the datasets, see Datasets section in the Supplementary Material. For all datasets, median, mean, t-test and rank-sum test were used to calculate base and stability rankings. Since they use different siRNAs per gene, for the Salmonella screens, RSA ranking was also performed. The rankings were directed toward down regulation of the Notch receptor and decrease in infection, respectively. In all screens, the rank-sum test produces the most stable rankings, followed by RSA ranking (<ref type="figure" target="#fig_5">Fig. 4</ref>). The t-test has initially the lowest stability. This changes throughout the ranking, but since the top part is the most relevant one, this method appears impractical. As expected, the stability of the Notch screen, which uses replicates, is much higher than for the Salmonella screens, which use different siRNAs per gene.<ref type="figure" target="#tab_1">Table 1</ref>summarizes the stable set sizes for the top 1% and top 10% resulting from the rank-sum rankings for each of the datasets (for the other methods see Supplementary Tables S3–S6). To compare the reproducibility of rankings on the real data, we employed a bootstrap analysis (<ref type="bibr" target="#b9">Efron, 1979</ref>) and resampled the data for each gene with replacement. For each bootstrap run, we used as many values per gene as the original dataset had.<ref type="figure" target="#fig_6">Figure 5A</ref>shows the bootstrapped reproducibility values of the Notch screen for the top 20% of median, t-test and rank-sum test rankings. Overall the reproducibility is very high for most rankings. In particular, the first two ranks show perfect reproducibility for the stability median and stability rank sum. Generally, the stability median rankings and both rank-sum test versions are ∼10% more reproducible than the base median rankings. Above the top 1% the original version is slightly more reproducible. The t-test again fails to recover a stable ranking. For all screens, subsets of genes had been selected, which were followed up on with validation experiments. Selection of genes was based on a combination of the outcome of the primary screen as well as biological expert knowledge. For the rank-sum test,<ref type="figure" target="#tab_1">Table 1</ref><ref type="figure" target="#tab_2">Table 2</ref>. Comparison of the base and stability version of the rank-sum test rankingsummarizes how many of the stable top 1% and top 10% genes were selected for re-screening and how many of these were finally validated (see Supplementary Tables S3–S6 for the other rankings). However, assessing the significance of these results is difficult for two reasons. Firstly, the sets of re-screened genes do not represent i.i.d. random samples, because they are biased by the way they were selected. Secondly, the re-screening experiments were not carried out under the same experimental conditions and therefore may lead to different conclusions. In case of the Notch screen, the primary in vitro screen was validated in vivo. In case of Salmonella, screens were validated using different or only partially overlapping siRNA libraries as compared with the primary screens. For the Notch screen, a total of 233 down regulating genes were re-screened, whereas for Salmonella, 164-infection decreasing genes of the drugable and 119 infection-decreasing genes of the genome-wide screen were chosen for validation. Overall, most of the stable top 1% genes were re-screened. For the Notch screen the stable top 10% genes contained almost all of the re-screened genes, whereas for the other experiments this fraction is reduced to ∼50%. Validation rates vary considerably but tend to be the higher the more stable a screen is. Comparing the top 1% and top 10% of the rank-sum test ranking and its stability counterpart we find that for the base ranker always a few more genes had been chosen for re-screening. Yet, in five out of six cases validation rates were higher when using stability ranking (<ref type="figure" target="#tab_2">Table 2</ref>). The rank-sum test and t-test rankings showed the highest overlaps between base and stability ranking, but for the less similar rankings, the stability rankings had also higher validation rates in most of the cases (Supplementary Tables S7–S10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Siebourg et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stability ranking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We have applied the concept of stability selection to gene rankings to generate more reproducible ordered hit lists for data generated from phenotypic RNAi experiments. We have shown that the robustness of different ranking methods can be very different and that the stable set size can be used as a measure of reproducibility. Since imagebased RNAi screening data tend to be very noisy and sparse, the use of stability ranking can improve stability, especially in the top part of the rankings which is of main interest. In the present study, the ranksum test ranking and its stability ranking version have resulted in the most reproducible hit lists. Stability ranking is very flexible and can be applied to any gene ranking method. It does not only improve ranking statistics that ignore the gene-wise variance, such as mean or median, but it also improved the reproducibility of a statistic like the rank-sum test. Thus, irrespective of the chosen ranking statistic, it appears beneficial to complement the selection of top scoring genes with stable genes to increase validation rates in secondary screens. In principle, the stable sets could also hint at a reasonable cutoffs for hit selection. Analyzing the growth curve of the stable sets for the datasets used in the present study, no such cutoff was be found, but this may be investigated further in future work on different datasets. Funding: SystemsX.ch, the Swiss initiative in systems biology, under IPhd<ref type="bibr">[2009/025]</ref>and RTD<ref type="bibr">[2009/005]</ref>(InfectX), evaluated by the Swiss National Science Foundation. Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.</head><figDesc>Fig. 1. Illustration of stability selection for a specific ranking cutoff k. The cardinality of the stable set at this cutoff provides an estimate for the number of top k genes, that are expected to be among the top k again, when repeating the experiment under the same conditions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Reproducibility (top row) and accuracy (second row) of the simulations. Shown are the results for the top 1% genes in base versus stability ranking using median (A, F), mean (B, G), rank-sum test (C, H), t-test (D, I) and RSA (E, J). The third and forth row (K–T) show the same plots but for the comparison of the aggregated versus the stability ranking. Each plot shows results for one ranking statistic and each symbol in the plots indicates one model. The colors represent the parameters that were used for the mean effect distribution. The different shapes represent the different gamma distributions for the gene variances and the symbol size indicates the number of replicates used. For models that have a filled shape, the two ranking methods (baseline versus stability ranking) showed a significant difference at the 1% level in a paired t-test after Benjamini–Hochberg correction for multiple testing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Copyedited by: TRJ MANUSCRIPT CATEGORY: ORIGINAL PAPER [19:30 17/5/2012 Bioinformatics-bts192.tex] Page: 1616 1612–1618</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Reproducibility (A) and accuracy (B) for the model (s = 1.69,m = 9,v = 61.8,n = 10). Dashed lines represent the base rankings, solid lines the stability versions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. Growth of the stable set of genes as a function of the ranking cutoff k * for the Notch screen (A), the drugable Salmonella screen (B) and the genome-wide Salmonella screen (C). For each of the different ranking statistics, stability selection was performed. The diagonal (gray line) indicates perfect stability</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.5.</head><figDesc>Fig. 5. Bootstrapped reproducibility for the Notch screen as a function of the cutoff k. (A) Shows the top 20% genes and (B) a zoom into the top 50 genes. Dashed lines indicate the base rankings and solid lines the stability versions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>stable k ⊆ ˆ S stable k+1 , i.e. k-stable genes remain k-stable for all k k. Stability ranking is defined by</figDesc><table>). We will use the size of stable sets as a 
measure of ranking stability and we now introduce a novel ranking 
method based on this notion. 
Observe that stable sets are nested, ˆ 
S Copyedited by: TRJ 

MANUSCRIPT CATEGORY: ORIGINAL PAPER 

[19:30 17/5/2012 Bioinformatics-bts192.tex] 
Page: 1614 1612–1618 

J.Siebourg et al. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 1. Screening and validation results for the top 1% and top 10% of the rank-sum test ranking for each of the three RNAi screens</figDesc><table>Gene set 
Total 
Stable 
Re-screened 
Validated, n (%) 

Notch top 1% 
129 
70 
67 
37 (55.2) 
Notch top 10% 
1281 
556 
225 
141 (62.7) 
SalD top 1% 
69 
12 
9 
7 (77.8) 
SalD top 10% 
686 
198 
74 
28 (37.8) 
SalGW top 1% 
148 
6 
5 
2 (40) 
SalGW top 10% 
1478 
111 
51 
6 (11.8) 

Second column indicates the absolute number of genes, third column indicates how 
many of these were stable. Fourth column indicates the part of the stable genes that 
was used in the re-screening experiments and the last column shows how many of them 
were validated. Notch indicates the Notch screen, SalD and SalGW refer to the drugable 
and the genome-wide Salmonella screens. </table></figure>

			<note place="foot">© The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Genome-wide RNAi screen for host factors required for intracellular bacterial infection</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Agaisse</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="page" from="1248" to="1251" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A large-scale RNAi screen in human cells identifies new components of the p53 pathway</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Berns</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">428</biblScope>
			<biblScope unit="page" from="431" to="437" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">The beautiful cell: high-content screening in drug discovery</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bickle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Bioanal. Chem</title>
		<imprint>
			<biblScope unit="volume">398</biblScope>
			<biblScope unit="page" from="219" to="226" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Stability and aggregation of ranked gene lists</title>
		<author>
			<persName>
				<forename type="first">A.-L</forename>
				<surname>Boulesteix</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Slawski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="556" to="568" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Genome-wide RNAi analysis of growth and viability in Drosophila cells</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Boutros</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">303</biblScope>
			<biblScope unit="page" from="832" to="835" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Bioinformatics-bts192.tex] Page</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="30" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Siebourg</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">What have RNAi screens taught us about viral-host interactions?</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Cherry</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Microbiol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="446" to="452" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Minimizing the risk of reporting false positives in large-scale RNAi screens</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">J</forename>
				<surname>Echeverri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Meth</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="777" to="779" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Bootstrap methods: another look at the Jackknife</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Reproducibility-optimized test statistic for ranking genes in microarray studies</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">L</forename>
				<surname>Elo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinform</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="423" to="431" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing top k lists</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Fagin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the 14th Annual ACM-SIAM Symposium on Discrete Algorithms<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Potent and specific genetic interference by double-stranded RNA in Caenorhabditis elegans</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Fire</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="page" from="806" to="811" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using support vector machines</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Guyon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="389" to="422" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">Using the bootstrap to quantify the authority of an empirical ranking. The Annals of Statistics</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3929" to="3959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<monogr>
		<title level="m" type="main">Modeling the variability of rankings. The Annals of Statistics</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2652" to="2677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">RNA interference</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Hannon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">418</biblScope>
			<biblScope unit="page" from="244" to="251" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Drosophila RNAi screen identifies host genes important for influenza virus replication</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">454</biblScope>
			<biblScope unit="page" from="890" to="893" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Genome-wide RNAi screen identifies human host factors crucial for influenza virus replication</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Karlas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">463</biblScope>
			<biblScope unit="page" from="818" to="822" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Genome-scale RNAi profiling of cell division in human tissue culture cells</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kittler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Cell Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1401" to="1412" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A probability-based approach for the analysis of large-scale RNAi screens</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>König</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Meth</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="847" to="849" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">A comparison of univariate and multivariate gene selection techniques for classification of cancer datasets</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">235</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Stability selection</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Meinshausen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bühlmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="417" to="473" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Revealing the world of RNA interference</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">C</forename>
				<surname>Mello</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Conte</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">431</biblScope>
			<biblScope unit="page" from="338" to="342" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">RNAi screen of Salmonella invasion shows role of COPI in membrane targeting of cholesterol and Cdc42</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Misselwitz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">474</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Gene ranking using bootstrapped p-values</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">N</forename>
				<surname>Mukherjee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor. Newslett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Data-adaptive test statistics for microarray data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">N</forename>
				<surname>Mukherjee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="108" to="114" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">A loss-of-function RNA interference screen for molecular targets in cancer</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">N</forename>
				<surname>Ngo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="page" from="106" to="110" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">The effect of replication on gene expression microarray experiments</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Pavlidis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1620" to="1627" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Drosophila RNAi screen reveals CD36 family member required for mycobacterial infection</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Philips</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="page" from="1251" to="1253" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">RankAggreg, an R package for weighted rank aggregation</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Pihur</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">62</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">A computational study of off-target effects of RNA interference</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Qiu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1834" to="1847" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Assessing stability of gene selection in microarray data analysis</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Qiu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Functional genomic analysis of phagocytosis and identification of a Drosophila receptor for E. coli</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Rämet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">416</biblScope>
			<biblScope unit="page" from="644" to="648" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Shigella flexneri type III secreted effector OspF reveals new crosstalks of proinflammatory signaling pathways during bacterial infection</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Reiterer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell. Signal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">A combined ex vivo and in vivo RNAi screen for Notch regulators in Drosophila reveals an extensive Notch interaction network</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Saj</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Cell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="862" to="876" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Stability of ranked gene lists in large microarray analysis studies</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Stiglic</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Kokol</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Biotechnol</title>
		<imprint>
			<biblScope unit="page">616358</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Bartonella henselae engages inside-out and outside-in signaling by integrin β1 and talin1 during invasome-mediated bacterial uptake</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">C</forename>
				<surname>Truttmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cell Sci</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="3591" to="602" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Pt. 21</note>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Genome-scale RNAi screen for host factors required for HIV replication</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell Host Microbe</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="495" to="504" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>