
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis E-MEM: efficient computation of maximal exact matches for very large genomes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015">2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Nilesh</forename>
								<surname>Khiste</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Western Ontario</orgName>
								<address>
									<postCode>N6A 5B7</postCode>
									<settlement>London</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Lucian</forename>
								<surname>Ilie</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Western Ontario</orgName>
								<address>
									<postCode>N6A 5B7</postCode>
									<settlement>London</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">John</forename>
								<surname>Hancock</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Western Ontario</orgName>
								<address>
									<postCode>N6A 5B7</postCode>
									<settlement>London</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis E-MEM: efficient computation of maximal exact matches for very large genomes</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">31</biblScope>
							<biblScope unit="issue">4</biblScope>
							<biblScope unit="page" from="509" to="514"/>
							<date type="published" when="2015">2015</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu687</idno>
					<note type="submission">Received on July 21, 2014; revised on September 25, 2014; accepted on October 14, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Alignment of similar whole genomes is often performed using anchors given by the maximal exact matches (MEMs) between their sequences. In spite of significant amount of research on this problem, the computation of MEMs for large genomes remains a challenging problem. The leading current algorithms employ full text indexes, the sparse suffix array giving the best results. Still, their memory requirements are high, the parallelization is not very efficient, and they cannot handle very large genomes. Results: We present a new algorithm, efficient computation of MEMs (E-MEM) that does not use full text indexes. Our algorithm uses much less space and is highly amenable to parallelization. It can compute all MEMs of minimum length 100 between the whole human and mouse genomes on a 12 core machine in 10 min and 2 GB of memory; the required memory can be as low as 600 MB. It can run efficiently gen-omes of any size. Extensive testing and comparison with currently best algorithms is provided. Availability and implementation: The source code of E-MEM is freely available at:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Maximal exact matches (MEMs) are exact matches between two sequences that cannot be extended either way without introducing mismatches. MEM computation is a fundamental problem in stringology (<ref type="bibr" target="#b9">Gusfield, 1997</ref>) and has important applications in sequence alignment. Closely related genomes are often aligned by using local similarities as anchors (<ref type="bibr" target="#b2">Brudno et al., 2003;</ref><ref type="bibr" target="#b6">Deogun et al., 2004;</ref><ref type="bibr" target="#b10">H € ohl et al., 2002;</ref><ref type="bibr" target="#b14">Kent, 2002;</ref><ref type="bibr" target="#b21">Menconi et al., 2013;</ref><ref type="bibr" target="#b23">Ohlebusch and Abouelhoda, 2006;</ref><ref type="bibr" target="#b25">Schwartz et al., 2000</ref>) and sufficiently long MEMs have been quite successfully used in this respect (<ref type="bibr" target="#b0">Abouelhoda et al., 2004;</ref><ref type="bibr" target="#b1">Bray and Pachter, 2004;</ref><ref type="bibr" target="#b3">Choi et al., 2005;</ref><ref type="bibr" target="#b4">Delcher et al., 1999</ref><ref type="bibr" target="#b5">Delcher et al., , 2002</ref><ref type="bibr" target="#b17">Kurtz et al., 2004</ref>). A theoretically optimal solution, in linear time and space, for the MEM computation problem is easily obtained using suffix trees (<ref type="bibr" target="#b27">Weiner, 1973</ref>). However, suffix trees require large memory and practical implementations use highly engineered suffix trees (<ref type="bibr" target="#b16">Kurtz, 1999</ref>). Suffix arrays were introduced by Manber and Myers (1993) as a space-efficient alternative to suffix trees and have replaced them in most applications. Enhanced suffix arrays were shown to solve all problems suffix trees could solve with the same theoretical complexity (<ref type="bibr" target="#b0">Abouelhoda et al., 2004</ref>). Suffix arrays still use a significant amount of memory, especially with the additional tables required to match the complexity of suffix trees (<ref type="bibr" target="#b0">Abouelhoda et al., 2004</ref>). When whole genomes are aligned, the memory required by the computation of all MEMs may become prohibitively high. The large popularity of whole-genome alignment programs, most notably that of the MUMmer software (<ref type="bibr" target="#b17">Kurtz et al., 2004</ref>), attracted a lot of attention to the MEM computation problem, with the purpose of enabling the alignment of larger genomes within reasonable amount of memory. For example, one of the most reliable such programs, Vmatch (<ref type="bibr" target="#b0">Abouelhoda et al., 2004</ref>), uses enhanced suffix arrays and its memory usage is very high. The idea of sparseness has been already used for suffix trees (K€ arkk€ ainen and<ref type="bibr" target="#b13">Ukkonen, 1996</ref>) and it has been successfully employed for suffix arrays by<ref type="bibr" target="#b15">Khan et al. (2009)</ref>in their sparseMEM program. Their approach relies on indexing only every kth suffix of the given genome sequence (k is called sparseness factor) and is able to find MEMs faster and using less memory than previous approaches. It can serve as a drop-in replacement for the MUMmer3 software package (<ref type="bibr" target="#b17">Kurtz et al., 2004</ref>). The approach of sparseMEM has been enhanced by<ref type="bibr" target="#b26">Vyverman et al. (2013)</ref>with a sparse child array for large sparseness factors and implemented in their essaMEM software. Our tests show that essaMEM is currently the best program for MEM computation in large genomes. Compressed indexes (<ref type="bibr" target="#b22">Navarro and M€ akinen, 2007</ref>) have been used as well.<ref type="bibr" target="#b24">Ohlebusch et al. (2010)</ref>developed backwardMEM that uses a backward search method over a compressed suffix array. Recently, Fernandes and Freitas (2013) employed in slaMEM a new sampled representation of the longest common prefix (LCP) array that works with the backward search method of the FM-Index (<ref type="bibr" target="#b8">Ferragina and Manzini, 2000</ref>). In spite of these advances, MEM computation remains a challenging problem for large genomes. The memory requirements of the current approaches remain high and very large genomes cannot be effectively handled. We present a new algorithm, E-MEM that targets large genome sequences. E-MEM does not use full text indexes. Instead, hash tables are efficiently used in combination with several ideas to speed up the search. Our algorithm uses much less space and is highly amenable to parallelization. For example, it can compute all MEMs of *To whom correspondence should be addressed. ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com minimum length 100 between the whole human and mouse genomes on a 12-core machine in 10 min and 2 GB of memory; the required memory can be as low as 600 MB. It can run efficiently on genomes of any size. Extensive testing and comparison with currently best algorithms is provided. We have used for comparison traditional datasets, such as whole human versus mouse genomes and whole human versus chimp genomes, but also introduced a new test where two species of wheat, Triticum aestivum and Triticum durum are used. It turns out that only E-MEM and Vmatch could handle these genomes. However, Vmatch requires 57 GB whereas E-MEM can use less than 1 GB while being also faster. Our E-MEM software is implemented in C++ and OpenMP, is freely available, and can be used as a stand-alone program or as a drop-in replacement for the MUMmer3 software package (<ref type="bibr" target="#b17">Kurtz et al., 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>Assume we have two genomes, the reference R, of length jRj=n, and the query Q, of length jQj=m. The character of R at position i is R½i and the substring of R starting at position i and ending at j is denoted R½i::j; we have also that R=R½1::n. A k-mer is a string of length k. A maximal exact match (MEM) between R and Q is a match that cannot be extended on either side. Formally, it is a quadruple ðb r ; e r ; b q ; e q Þ such that R½b r ::e r =Q½b q ::e q  and R½b r À 1 6 ¼ Q½b q À 1; R½e r +1 6 ¼ Q½e q +1, if defined; e r À b r +1 is the length of the MEM. The MEM finding problem is: given two sequences R and Q and an integer L, find all MEMs of length at least L between R and Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hashing the reference</head><p>The starting idea of our approach is that, for any MEM ðb r ; e r ; b q ; e q Þ of length L or more between R and Q, there must be a k-mer in R starting at a position that is a multiple of L À k+1 that is completely contained in the MEM, that is, b r jðL À k+1Þ e r À k+1, for some j ! 1. That means, it is sufficient to index all k-mers in the reference that start at positions that are multiples of L À k+1, which significantly reduces the required memory. However, all k-mers of the query genome have to be processed and this must be done very efficiently. Each genome is encoded using two bits per nucleotide and then stored as an array of unsigned 64-bit integers, that is, as blocks of 32 nucleotides. We use k-mers of size 28 or less for technical reasons described below. Each k-mer starting at a position that is a multiple of L À k+1 is computed by a bit-and operation between a mask of 2k 1's and the appropriate elements of the array storing R. All k-mers are hashed using double hashing. In the hash table, each entry stores the value of the k-mer and a list of all positions where the k-mer occurs in R. All numbers are unsigned 64-bit integers, thus able to handle genomes of any size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Searching the query</head><p>As mentioned above, all k-mers in Q need to be considered. However, they are not indexed but simply computed from Q and searched for in the hash table we built for R. Every time a k-mer of Q is found in the hash table, all positions at which it occurs in R are investigated for possible extension. If the extension has length L or more, then it is reported as a MEM. This way all MEMs are found. The idea is now clear but a straightforward implementation is very slow. First, we need a fast way to compute the k-mers of Q. This is done by bit operations; we slide a 64-bit window across Q and each k-mer is computed by a bit-and between the window and a mask of 2k 1's. The window is then updated by shifting its content two bits. Every four shifts, another byte is added, for that reason the k-mer size has to be at most 28. Second, we need to check each extension very fast. Recall that the genome sequences are stored in arrays of 64 bit blocks. The extension is performed in such a way that two 64-bit blocks are compared using only very few bit operations. Third, some MEMs may be rediscovered many times, thus decreasing the speed. In order to avoid MEM rediscovery, we use a data structure, CurrMEMs, that stores the current MEMs. Given the current position j in Q, the current MEMs are those whose query part covers j, that is, all MEMs ðb r ; e r ; b q ; e q Þ such that b q j e q. Any new MEM found is added to CurrMEMs. When the current position j moves past e q , the corresponding MEM is removed from CurrMEMs. MEM rediscovery verification is done as follows. Any time a k-mer w at position j in Q is found in the hash table of R, then, for each position ' in the list of w in the hash table, we check first whether the k-mer pair ðj; j+k À 1Þ; ð'; '+k À 1Þ lies inside an already discovered MEM. For each current MEM, ðb r ; e r ; b q ; e q Þ, we need only check whether j À b q =' À b r. In practice, the number of current MEMs is never very high and thus the algorithm advances very fast through Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Unknown bases</head><p>Genome sequences may contain unknown bases, denoted by N. Our twobit encoding does not allow storing N's so we replace them with random bases. Therefore, we need to eliminate any accidental matches between randomly replaced N's and real bases. Storing the positions of N's would be too space consuming, so we store them as blocks of N's, recording only their beginning and end. During the MEMs discovery process, we check whether any intersection with a block of N's occurred in R or Q. For Q this is very simple, since we know, for the current position in Q, where the closest blocks of N's on both sides are. For R, we need to verify, for each MEM found, that no N position has been included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Reducing the memory further</head><p>So far the algorithm works very well, with little space and time. However, we need to store both sequences R and Q to enable comparison, which gives a lower bound for the required peak memory. In order to avoid this problem and reduce the memory further, we split each of R and Q sequences into D ! 1 subsequences each; D is called division factor. However, we cannot simply cut them into D equal subsequences since this may prevent us from finding some MEMs straddling the borders. The D sequences must overlap. For R (similarly for Q), each subsequence has length '= 1 D ðjRj+ðD À 1ÞLÞ and the overlap between consecutive subsequences is L – 1. This way, any MEM must have at least L bases within a single subsequence and will be discovered. Since we build hash tables on the reference, as explained above, we consider the subsequences of R in order, one at the time, build its hash table, then, for each subsequence of Q, find all MEMs shared by the two subsequences. The time increases since we process each subsequence of Q multiple times, but the space decreases very much with D. A different problem that appears now is that we may discover only parts of the MEMs straddling borders. That is, some of the matches that reach the borders of the subsequences may not be maximal. This happens because we load into memory only one subsequence from each genome, and hence no match can be extended past the end of either subsequence. Matches reaching the ends of the subsequences are stored together in a data structure, MEMext, and processed at the end. If some of these are parts of the same, larger, MEM, then they are merged accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Parallelism</head><p>The above algorithm can be easily parallelized on any number of cores. Each subsequence of the query genome is divided equally into a number of pieces equal to the number of processors. Each processor will then execute the algorithm we have described independently of the others. MEM's straddling these new borders may be discovered more than once and duplicates are removed at the end. Also, each thread has its own CurrMEMs data structure that it has to compute from scratch. Nevertheless, a speed up of up to six times faster is obtained on the 12-core machine that we used for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Very large number of MEMs</head><p>For large genomes that are highly similar, the number of MEMs can be very large. For example, for human and chimp, the number of MEMs is well over a 100 million. Keeping all these MEMs in memory at the same time will reverse all the memory reductions we obtained so far, not to mention a significant amount of time necessary to sort them. To avoid these problems, we store the MEMs in files, sorted according to their starting positions in the query genome. At the end, each file is sorted, duplicates are removed, and MEMs are output in the right order.input: two sequences R and Q and a minimum MEM length L output: all MEMs of length at least L between R and Q 1. choose a division factor</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Pseudocode</head><formula>D 2. split R into R 1 ; R 2 ;. .. ; R D 3. split Q into Q 1 ; Q 2 ;. .. ; Q D 4. for i from 1 to D do 5. encode R i 6. ' L À k+1</formula><p>7. while ð' jR i j À k+1Þ do 8. hash the k-mer at position ' of R i 9. ' '+L À k+1 10. for j from 1 to D do 11. encode Q j 12. for ' from 1 to jQ j j À k+1 do 13. get the k-mer q at position ' in Q j 14. search for k-mers r = q in the hash table of R i 15. for each occurrence of r with extension ! L do 16. check CurrMEMs 17. if ((q, r) discovers a new MEM) then 18. if (MEM at ends of R i or Q j ) then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We have compared E-MEM with several programs, including the top ones: essaMEM (<ref type="bibr" target="#b26">Vyverman et al., 2013</ref>), slaMEM (<ref type="bibr">Fernandes and Freitas, 2013</ref>), sparseMEM (<ref type="bibr" target="#b15">Khan et al., 2009</ref>), and Vmatch (<ref type="bibr" target="#b0">Abouelhoda et al., 2004</ref>). We have also tested backwardMEM (<ref type="bibr" target="#b24">Ohlebusch et al., 2010</ref>) and MUMmer (<ref type="bibr" target="#b17">Kurtz et al., 2004</ref>) but they could not run any of our large tests. The genomes involved in the tests are given in<ref type="figure" target="#tab_1">Table 1</ref>, where we give also their length and number of sequences included in each fasta file. Download information for each genome sequence as well as for the source code of the programs tested is given in the Supplementary Material. Note that the wheat genome has $17 GB, however the available sequence has only 4.3 GB. We performed three tests. The first two are classical problems of large genome alignment: human versus mouse, human versus chimp. We have added two larger genomes of two wheat species: common wheat versus durum wheat. The results are presented in Tables 2–4, respectively. In each table, we include the time andNote: A dash means the program could not run that test, that is, in serial mode, the output was incorrect or empty, whereas the parallel mode was not supported.of all programs were run; details are given in the Supplementary Material. Since we are trying to reduce both time and memory, a trade off is obtained and the results are better seen when time is plotted against memory. We show these plots in<ref type="figure" target="#fig_3">Figures 1</ref>, 2 and 3. For the first two tests, we give two plots for clarity, one for the serial mode, the other for the parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Human versus mouse</head><p>In our first test, the whole human and mouse genomes have 537 491 MEMs of minimum length 100. E-MEM produces much better results than the other programs; see<ref type="figure" target="#tab_2">Table 2</ref>. In serial mode, the smallest memory obtained by the other programs was that of slaMEM, with 3.5 GB. However, slaMEM took 17 h to complete the test. Therefore, the best performance comes from essaMEM, which can use as low as 4 GB of memory, but complete the test in 2.5 h; essaMEM can complete the test in little over one hour but at the cost of increasing the memory to 19 GB. E-MEM can run within as little as 623MB and complete in less than two hours or in half an hour and 4 GB of memory. E-MEM has the best speed up in parallel, between 5 and 6 times on our 12-core machine. The speed up of essaMEM varies between 1.3 and 4.5 times. We note that sparseMEM has speed up comparable to that of E-MEM but the running time in serial mode is one order of magnitude higher. The best result from the competing programs comes again from essaMEM, that has been consistently outperforming the other ones: 23 min and 6 GB or 1 h and 5.4 GB. E-MEM can complete the test in 6 min and 4.7 GB or 10 minutes and less than 2 GB. The time and space are plotted against each other in<ref type="figure" target="#fig_3">Figure 1</ref>. Programs closer to origin are faster and require less memory. The left plot is for serial mode and the right for parallel. The area is very large in the serial plot, due to the large memory requirements of Vmatch and long running times required by slaMEM and sparseMEM. Since the two programs do not run in parallel, the plot giving the time/space values for the parallel testing gives a more clear picture. Only essaMEM, sparseMEM, and E-MEM could run in parallel. The memory required for the same sparseness factor by essaMEM is slightly smaller than that of sparseMEM while essaMEM is much faster than sparseMEM. All three programs trade time for space but the results of E-MEM are much closer to origin than the rest; see<ref type="figure" target="#fig_3">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Human versus chimp</head><p>For our second test, human versus chimp, there are 132 368 058 MEMs of minimum length 100 to be found. This slows down<ref type="figure">Table 3</ref>. The whole picture, given in<ref type="figure" target="#fig_2">Figure 2</ref>is similar with the one for the first test, human versus mouse (<ref type="figure" target="#fig_3">Fig. 1</ref>) except that the difference between the running times is not as large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Two wheat species</head><p>In our last test, we used two wheat genomes that are larger than the mammalian ones used in the previous two tests. Only E-MEM and Vmatch could run this test and the results are presented in<ref type="figure">Table 4</ref>and plotted in<ref type="figure" target="#fig_1">Figure 3</ref>. Note that this figure is slightly different than<ref type="figure" target="#fig_2">Figures 1 and 2</ref>in that both serial and parallel results are presented in the same plot. E-MEM could run this test efficiently; in serial mode it can use less than 1GB of memory and in parallel it requires only 16 min and 2GB of memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>E-MEM provides a practical solution for finding MEMs between arbitrarily large genomes. It uses much less memory than the currently available programs. It is freely available and it can be used as a stand-alone program or as a drop-in replacement for the MUMmer3 software package (<ref type="bibr" target="#b17">Kurtz et al., 2004</ref>). MEMs are good anchors for closely related genomes. Otherwise, approximate matches are more suitable. The approach of E-MEM can be generalized to work with spaced seeds (<ref type="bibr" target="#b19">Ma et al., 2002</ref>) inorder to search efficiently for approximate matches. Highly sensitive multiple spaced seeds (<ref type="bibr" target="#b18">Li et al., 2004</ref>) of large weight are necessary and they can be designed using the approach of Ilie and Ilie (2007) by the SpEED program (<ref type="bibr" target="#b12">Ilie et al., 2011</ref>). The exact matching procedure of index-based algorithms is not well suited for finding approximate matchings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>We bring together the ideas explained above into the pseudocode of the E-MEM algorithm. The main steps are identified. The implementation details have been explained above. E-MEM(R,Q,L)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Table3.</head><figDesc>Homo sapiens versus Pan troglodytes; MEMs of minimum length 100 slightly the E-MEM program since all these MEMs need to be post processed. (The very large number of MEMs is also the reason why the program is slightly slower for D = 1 compared with D = 2.) The details are given in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Homo sapiens versus Pan troglodytes; MEMs of minimum length 100. The left plot is for serial mode, the right for parallel. Note the different scale of the plots</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.1.</head><figDesc>Fig. 1. Homo sapiens versus Mus musculus; MEMs of minimum length 100. The left plot is for serial mode, the right for parallel. Note the different scale of the plots</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Triticum aestivum versus Triticum durum; MEMs of minimum length 100. Both serial and parallel results of E-MEM are plotted</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. Homo sapiens versus Mus musculus; MEMs of minimum length 100</figDesc><table>Program 
Time (s) 
Memory (MB) 
serial 
12 cores 
serial 
12 cores 

essaMEM 
K = 1 
— 
— 
— 
— 
K = 2 
4076 
3107 
19 065 
19 697 
K = 4 
8291 
3174 
11 264 
11 896 
K = 8 
9243 
2069 
7394 
8282 
K = 16 
4437 
1385 
5468 
6394 
K = 32 
6245 
3520 
4508 
5396 
K = 64 
9044 
5119 
4029 
4917 
slaMEM 
62 099 
— 
3480 
— 
sparseMEM 
K = 1 
— 
— 
— 
— 
K = 2 
3845 
2947 
20 182 
20 750 
K = 4 
19 797 
6833 
12 426 
13 250 
K = 8 
58 325 
10 217 
8548 
9327 
K = 16 
50 703 
9169 
6609 
7497 
K = 32 
46 492 
8853 
5640 
6528 
K = 64 
41 396 
9398 
5155 
6043 
Vmatch 
7370 
— 
39 377 
— 
E-MEM 
D = 1 
1792 
324 
3979 
4705 
D = 2 
2241 
392 
2138 
2864 
D = 3 
2864 
505 
1513 
2239 
D = 4 
3266 
596 
1211 
1937 
D = 5 
3900 
699 
1009 
1735 
D = 6 
4327 
799 
884 
1610 
D = 7 
4841 
903 
786 
1512 
D = 8 
5340 
1048 
722 
1448 
D = 9 
5855 
1097 
669 
1395 
D = 10 
6296 
1209 
623 
1349 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 1. Genomes used for testing</figDesc><table>Datasets 
Size (Mbp) 
Sequences 

Homo sapiens (Human) 
3137 
93 
Mus musculus (Mouse) 
2731 
66 
Pan troglodytes (Chimp) 
3218 
24 132 
Triticum aestivum (Common wheat) 
4391 
731 921 
Triticum durum (Durum wheat) 
3229 
5 671 204 </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">N.Khiste and L.Ilie at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Efficient computation of maximal exact matches at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>Performance evaluation has been performed using the facilities of the Shared Hierarchical Academic Research Computing Network (SHARCNET: www.sharcnet.ca) and Compute/Calcul Canada.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Replacing suffix trees with enhanced suffix arrays</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">I</forename>
				<surname>Abouelhoda</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Discrete Algorithms</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="53" to="86" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">MAVID: constrained ancestral alignment of multiple sequences</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Bray</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Pachter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="693" to="699" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast and sensitive multiple alignment of large genomic sequences</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Brudno</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">66</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">GAME: a simple and efficient whole genome alignment method using maximal exact match filtering</title>
		<author>
			<persName>
				<forename type="first">J.-H</forename>
				<surname>Choi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Chem</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="244" to="253" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Alignment of whole genomes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Delcher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2369" to="2376" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast algorithms for large-scale genome alignment and comparison</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Delcher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2478" to="2483" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Emagen: An efficient approach to multiple whole genome alignment</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Deogun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second conference on Asia-Pacific bioinformatics</title>
		<meeting>the second conference on Asia-Pacific bioinformatics</meeting>
		<imprint>
			<publisher>Australian Computer Society, Inc</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">slaMEM: efficient retrieval of maximal exact matches using a sampled LCP array</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Fernandes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">T</forename>
				<surname>Freitas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="464" to="471" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Opportunistic data structures with applications</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ferragina</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Manzini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 41st Annual Symposium on IEEE</title>
		<meeting>. 41st Annual Symposium on IEEE<address><addrLine>Redondo Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="390" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">Algorithms on strings, trees and sequences: computer science and computational biology</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gusfield</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient multiple genome alignment</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>H€ Ohl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="312" to="320" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiple spaced seeds for homology search</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ilie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ilie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2969" to="2977" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">SpEED: fast computation of sensitive spaced seeds</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ilie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2433" to="2434" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Sparse suffix trees</title>
		<author>
			<persName>
				<forename type="first">K€</forename>
				<surname>Arkk€ Ainen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ukkonen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing and Combinatorics</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="219" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Blatthe blast-like alignment tool</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Kent</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="656" to="664" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A practical algorithm for finding maximal exact matches in large sequence datasets using sparse suffix arrays</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Khan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1609" to="1616" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Reducing the space requirement of suffix trees</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kurtz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Practice Exp</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1149" to="71" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Versatile and open software for comparing large genomes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kurtz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">PatternHunter II: Highly sensitive and fast homology search</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bioinformatics Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="417" to="439" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">PatternHunter: faster and more sensitive homology search</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="440" to="445" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Suffix arrays: a new method for on-line string searches</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Manber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Siam J. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="935" to="948" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Mobilomics in saccharomyces cerevisiae strains</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Menconi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Compressed full-text indexes</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Navarro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">Chaining algorithms and applications in comparative genomics In: Handbook of Computational Molecular Biology</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Ohlebusch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">I</forename>
				<surname>Abouelhoda</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Chapman &amp; Hall/CRC, Boca Raton FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Computing matching statistics and maximal exact matches on compressed full-text indexes</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Ohlebusch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">String Processing and Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="347" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Pipmakera web server for aligning two genomic dna sequences</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Schwartz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="577" to="586" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">essaMEM: finding maximal exact matches using enhanced sparse suffix arrays</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Vyverman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="802" to="804" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Linear pattern matching algorithms In: Switching and Automata Theory</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Weiner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference Record of 14th Annual Symposium on IEEE</title>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>