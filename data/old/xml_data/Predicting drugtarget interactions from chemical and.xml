
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Predicting drug–target interactions from chemical and genomic kernels using Bayesian matrix factorization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">18 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Mehmet</forename>
								<surname>Gönen</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information and Computer Science</orgName>
								<orgName type="institution" key="instit1">Helsinki Institute for Information Technology HIIT</orgName>
								<orgName type="institution" key="instit2">Aalto University School of Science</orgName>
								<address>
									<postCode>FI-00076</postCode>
									<settlement>Aalto, Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Systems biology Predicting drug–target interactions from chemical and genomic kernels using Bayesian matrix factorization</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="2304" to="2310"/>
							<date type="published" when="2012">18 2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts360</idno>
					<note type="submission">Received on May 27, 2012; revised on May 27, 2012; accepted on June 18, 2012</note>
					<note>Copyedited by: SK MANUSCRIPT CATEGORY: ORIGINAL PAPER Page: 2304 2304–2310 Associate Editor: Gunnar Ratsch Contact: mehmet.gonen@aalto.fi Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Identifying interactions between drug compounds and target proteins has a great practical importance in the drug discovery process for known diseases. Existing databases contain very few experimentally validated drug–target interactions and formulating successful computational methods for predicting interactions remains challenging. Results: In this study, we consider four different drug–target interaction networks from humans involving enzymes, ion channels, G-protein-coupled receptors and nuclear receptors. We then propose a novel Bayesian formulation that combines dimensionality reduction, matrix factorization and binary classification for predicting drug–target interaction networks using only chemical similarity between drug compounds and genomic similarity between target proteins. The novelty of our approach comes from the joint Bayesian formulation of projecting drug compounds and target proteins into a unified subspace using the similarities and estimating the interaction network in that subspace. We propose using a variational approximation in order to obtain an efficient inference scheme and give its detailed derivations. Finally, we demonstrate the performance of our proposed method in three different scenarios: (i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network. Availability: Software and Supplementary Material are available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The functions of pharmaceutically useful target protein families such as enzymes, ion channels, G-protein-coupled receptors (GPCRs) and nuclear receptors can be modulated by interacting them with drug compounds. Our knowledge about the genomic space of target proteins and the chemical space of drug compounds is piling up as a result of high-throughput experimental projects that analyze the genome and high-throughput chemical compound screening with biological assays. Unfortunately, our knowledge about the relationship between these two spaces remains quite limited * To whom correspondence should be addressed. due to laborious and costly experimental procedures. Existing databases such as ChEMBL (<ref type="bibr" target="#b6">Gaulton et al., 2012</ref>), DrugBank (<ref type="bibr" target="#b16">Knox et al., 2011</ref>), KEGG DRUG (<ref type="bibr" target="#b14">Kanehisa et al., 2012</ref>) and SuperTarget (<ref type="bibr" target="#b11">Hecker et al., 2012</ref>) contain information about a small number of experimentally validated interactions. Hence, successful computational methods for identifying interactions between drug compounds and target proteins make genomic drug discovery significantly efficient and effective. Computational approaches can be used to guide experimentalists towards new predictions and to provide supporting evidence for their experimental results. Traditional computational methods can be grouped into three categories: (i) docking simulations (<ref type="bibr" target="#b5">Cheng et al., 2007;</ref><ref type="bibr" target="#b18">Rarey et al., 1996</ref>), (ii) ligand-based approaches (<ref type="bibr" target="#b3">Butina et al., 2002;</ref><ref type="bibr" target="#b4">Byvatov et al., 2003;</ref><ref type="bibr" target="#b15">Keiser et al., 2007</ref>) and (iii) literature text mining (<ref type="bibr" target="#b30">Zhu et al., 2005</ref>). Docking simulations require structural information of target proteins, which is not mostly available for some protein families such as GPCRs. Ligand-based approaches compare a candidate ligand with the known ligands of a target protein and may not perform well for target proteins with a small number of known ligands. Literature text mining based on keyword search cannot be used to detect unknown interactions and suffers from the redundancy due to non-standard naming practice for drug compounds and target proteins. Recently, there are many machine learning algorithms proposed for predicting drug–target interactions using the chemical properties of drug compounds, the genomic properties of target proteins and the known interaction network (<ref type="bibr" target="#b2">Bleakley and Yamanishi, 2009;</ref><ref type="bibr" target="#b12">Jacob and Vert, 2008;</ref><ref type="bibr" target="#b25">van Laarhoven et al., 2011;</ref><ref type="bibr" target="#b26">Wassermann et al., 2009;</ref><ref type="bibr" target="#b28">Yamanishi et al., 2008</ref><ref type="bibr" target="#b29">Yamanishi et al., , 2010</ref>). The main assumption of these studies is that similar drug compounds are likely to interact with similar target proteins. These similarities between drug compounds and target proteins are often encoded using kernel functions designed specifically for chemical compounds and protein sequences, respectively (<ref type="bibr" target="#b22">Schölkopf et al., 2004</ref>). The most basic statistical approach is to formulate the interaction network inference problem as a binary classification task between drug–target pairs using pairwise kernel functions (<ref type="bibr" target="#b12">Jacob and Vert, 2008;</ref><ref type="bibr" target="#b26">Wassermann et al., 2009</ref>). However, this approach can be computationally quite heavy due to the high number of drug–target pairs. Supervised bipartite graph inference maps drug compounds and target points into a unified space (i.e. pharmacological space) using the chemical and genomic similarities and tries to estimate the interaction network using a distance-based procedure in that subspace (<ref type="bibr" target="#b28">Yamanishi et al., 2008</ref><ref type="bibr" target="#b29">Yamanishi et al., , 2010</ref>). Local models are also used to predict drug–target interaction networks after their successful applications for protein–protein interaction networks, metabolic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernelized Bayesian matrix factorization with twin kernels</head><p>networks and regulatory networks (<ref type="bibr" target="#b2">Bleakley and Yamanishi, 2009</ref>). Instead of using the given interaction network just as the output, integrating a kernel function that considers the given network topology and the kernels calculated using chemical compounds and protein sequences can improve the prediction performance (van<ref type="bibr" target="#b25">Laarhoven et al., 2011</ref>). In this study, we propose a novel Bayesian formulation that combines kernel-based nonlinear dimensionality reduction (<ref type="bibr" target="#b21">Schölkopf and Smola, 2002</ref>), matrix factorization (<ref type="bibr" target="#b25">Srebro, 2004</ref>) and binary classification for predicting drug–target interaction networks using only chemical similarity between drug compounds and genomic similarity between target proteins. Different from previous studies, our proposed method is the first fully probabilistic formulation for drug–target interaction network inference. We show its performance on four benchmark datasets using three experimental scenarios with practical importance: (i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MATERIALS</head><p>In this study, we consider four different drug–target interaction networks from humans, namely, Enzyme, Ion Channel, GPCR and Nuclear Receptor, provided by<ref type="bibr" target="#b28">Yamanishi et al. (2008)</ref>. These datasets are publicly available at http://web.kuicr.kyoto-u.ac.jp/supp/yoshi/drugtarget/. We use these datasets as they are without adding new interactions from source databases.<ref type="bibr" target="#b28">Yamanishi et al. (2008)</ref>use KEGG BRITE (<ref type="bibr" target="#b13">Kanehisa et al., 2006</ref>), BRENDA (<ref type="bibr" target="#b23">Schomburg et al., 2004</ref>), SuperTarget (<ref type="bibr">Günther et al., 2008</ref>) and DrugBank (<ref type="bibr" target="#b27">Wishart et al., 2008</ref>) databases to collect information about the interactions between drug compounds and target proteins.<ref type="figure" target="#tab_1">Table 1</ref>summarizes the datasets in terms of numbers of drug compounds, target proteins and interactions. The set of known drug–target interactions is regarded as 'gold standard' and used to evaluate the performance of our proposed method in the cross-validation experiments as in the previous studies (<ref type="bibr" target="#b2">Bleakley and Yamanishi, 2009;</ref><ref type="bibr" target="#b25">van Laarhoven et al., 2011;</ref><ref type="bibr" target="#b28">Yamanishi et al., 2008</ref><ref type="bibr" target="#b29">Yamanishi et al., , 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Drug–target interaction data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Chemical data</head><p>Chemical structures of drug compounds are extracted from the DRUG and COMPOUND sections in the KEGG LIGAND database (<ref type="bibr" target="#b13">Kanehisa et al., 2006</ref>).<ref type="bibr" target="#b28">Yamanishi et al. (2008)</ref>calculate the structural similarities between drug compounds using SIMCOMP (<ref type="bibr" target="#b10">Hattori et al., 2003</ref>), which represents drug compounds as graphs and calculates a similarity score based on the size of the common substructures between two graphs. Given two drug compounds d i and d k , chemical similarity between them can be found as s c (d i ,d k ) =|d i ∩d k |/|d i ∪d k | and the similarity matrix between all drug compound pairs is denoted as S c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Genomic data</head><p>Aminoacid sequences of target proteins are extracted from the KEGG GENES database (<ref type="bibr" target="#b13">Kanehisa et al., 2006</ref>).<ref type="bibr" target="#b28">Yamanishi et al. (2008)</ref>calculate the sequence similarities between target proteins using a normalized version of Smith–Waterman score (<ref type="bibr" target="#b24">Smith and Waterman, 1981</ref>). Given two target proteins t j and t l , genomic similarity between them can be found as</p><formula>s g (t j ,t l ) = SW(t j ,t l )/ SW(t j ,t j )SW(t l ,t l )</formula><p>, where SW(·,·) gives the canonical Smith–Waterman score and the similarity matrix between all target protein pairs is denoted as S g .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>We mainly consider the problem of predicting new drug–target interactions for out-of-sample drug compounds and/or target proteins that are not in the given interaction network. Our proposed method can also be used to predict unknown interactions of the given network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem formulation</head><p>We are given N d drug compounds denoted as X d ={d 1 ,d 2 ,...,d Nd } and N t target proteins denoted as X t ={t 1 ,t 2 ,...,t Nt }. We are also given a set of known interactions between these two sets as the N d ×N t adjacency matrix denoted as Y, where y i j =+1 if drug compound d i interacts with target protein t j and y i j =−1 otherwise. We can have three different prediction scenarios:</p><p>(i) find interacting target proteins from X t for a new drug compound d , (ii) find interacting drug compounds from X d for a new target protein t and (iii) estimate whether a new drug compound d and a new target protein t are interacting with each other or not. In order to attack these three scenarios with a single unified approach, we formulate the problem as a binary classification task, which requires to estimate whether there is an interaction between a drug compound and a target protein using only the similarities between drug compounds and the similarities between target proteins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Kernelized Bayesian matrix factorization with twin kernels</head><p>In order to obtain an efficient Bayesian algorithm, we formulate a fully conjugate probabilistic model and develop a deterministic variational approximation mechanism for inference. The main idea is to project drug compounds and target proteins into a unified subspace using the kernels calculated from chemical and genomic data, respectively. These lowdimensional representations of drug compounds and target proteins can be used to estimate their interactions.<ref type="figure" target="#fig_0">Figure 1</ref>illustrates the proposed probabilistic model for predicting drug– target interactions from kernels on drug compounds and target proteins with a graphical model. The kernel matrix calculated from drug compounds K d is used to project them into a low-dimensional space using the projection matrix A d. Similarly, the kernel matrix calculated from target proteins K t is used to project them into the same subspace, which is called 'pharmacological space'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.Gönen</head><p>in the previous studies (<ref type="bibr" target="#b28">Yamanishi et al., 2008</ref><ref type="bibr" target="#b29">Yamanishi et al., , 2010</ref>), using the projection matrix A t. The low-dimensional representations of drug compounds and target proteins in the pharmacological space, namely, G d and G t , are used to calculate the interaction scores between them. Finally, the given interaction matrix Y is generated from the interaction score matrix F. The notation we use throughout the rest of the this article is as follows: N d and N t represent the numbers of training drug compounds and target proteins, respectively. R gives the dimensionality of the projected subspace. The N d ×N d kernel matrix for drug compounds is denoted by K d , where the columns of K d by k d,i. The N d ×R matrix of corresponding projection parameters a i d,s and their priors λ i d,s are denoted by A d and d , respectively, where the columns of A d and d by a d,s and λ d,s. The R×N d matrix of projected instances for drug compounds g s d,i are represented as G d , where the columns of G d as g d,i and the rows of</p><formula>λ i d,s ∼ G(λ i d,s ;α λ ,β λ ) ∀(i,s) a i d,s |λ i d,s ∼ N (a i d,s ;0,(λ i d,s ) −1 ) ∀(i,s) g s d,i |a d,s ,k d,i ∼ N (g s d,i ;a d,s k d,i ,σ 2 g ) ∀(s,i) λ j t,s ∼ G(λ j t,s ;α λ ,β λ ) ∀(j,s) a j t,s |λ j t,s ∼ N (a j t,s ;0,(λ j t,s ) −1 ) ∀(j,s) g s t,j |a t,s ,k t,j ∼ N (g s t,j ;a t,s k t,j ,σ 2 g ) ∀(s,j) f i j |g d,i ,g t,j ∼ N (f i j ;g d,i g t,j ,1) ∀(i,j) y i j |f i j ∼ δ(f i j y i j &gt;ν) ∀(i,j)</formula><p>where the interaction scores between the matrices of projected instances and interaction variables are introduced to make the inference procedures efficient (<ref type="bibr" target="#b0">Albert and Chib, 1993</ref>), and the margin parameter ν can be used to resolve the scaling ambiguity issue and to place a low-density region between two classes (interacting versus non-interacting), similar to the margin idea in support vector machines, which is generally used for semi-supervised learning (<ref type="bibr" target="#b17">Lawrence and Jordan, 2005</ref>). N (·;μ,) represents the normal distribution with the mean vector μ and the covariance matrix. G(·;α,β) denotes the gamma distribution with the shape parameter α and the scale parameter β. δ(·) represents the Kronecker delta function that returns 1 if its argument is true and 0 otherwise. We only use the gamma and normal distributions in our probabilistic model. The main reason for choosing these specific distributions is that they allow us to obtain a very efficient inference mechanism easily due to conjugacy between them. Their advantage becomes clear when we explain our inference procedure. When we consider the random variables as deterministic values, the interaction score matrix that corresponds to the decision function values in discriminative methods can be decomposed asThis strategy allows us to make predictions for out-of-sample points using kernel functions.</p><formula>F = G d G t = (A d K d ) (A t K t ) = K d A d A t K t</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Efficient inference using variational approximation</head><p>Exact inference for our probabilistic model is intractable and using a Gibbs sampling approach is computationally expensive (<ref type="bibr" target="#b7">Gelfand and Smith, 1990</ref>). We instead formulate a deterministic variational approximation, which is more efficient in terms of computation time. The variational methods use a lower bound on the marginal likelihood using an ensemble of factored posteriors to find the joint parameter distribution (<ref type="bibr" target="#b1">Beal, 2003</ref>). We can write the factorable ensemble approximation of the required posterior as</p><formula>p(,|K d ,K t ,Y) ≈ q(,) = q( d )q(A d )q(G d )q( t )q(A t )q(G t )q(F)</formula><p>and define each factor just like its full conditional distribution:</p><formula>q( d ) = Nd i=1 R s=1 G(λ i d,s ;α(λ i d,s ),β(λ i d,s )) q(A d ) = R s=1 N (a d,s ;μ(a d,s ),,(a d,s )) q(G d ) = Nd i=1 N (g d,i ;μ(g d,i ),,(g d,i )) q( t ) = Nt j=1 R s=1 G(λ j t,s ;α(λ j t,s ),β(λ j t,s )) q(A t ) = R s=1 N (a t,s ;μ(a t,s ),,(a t,s )) q(G t ) = Nt j=1 N (g t,j ;μ(g t,j ),,(g t,j )) q(F) = Nd i=1 Nt j=1 T N (f i j ;μ(f i j ),,(f i j ),ρ(f i j )) where α(·), β(·), μ(·) and (·)</formula><p>denote the shape parameter, the scale parameter, the mean vector and the covariance matrix for their arguments,</p><formula>respectively. T N (·;μ,,ρ(·)</formula><p>) denotes the truncated normal distribution with the mean vector μ, the covariance matrix and the truncation</p><formula>rule ρ(·) such that T N (·;μ,,ρ(·)) ∝ N (·;μ,) if ρ(·) is true and T N (·;μ,,ρ(·)) = 0 otherwise.</formula><p>We can bound the marginal likelihood using Jensen's inequality:</p><formula>logp(Y|K d ,K t ) ≥ E q(,) [logp(Y,,|K d ,K t )]−E q(,) [logq(,)] (1)</formula><p>and optimize this bound by maximizing with respect to each factor separately until convergence. The approximate posterior distribution of a specific factor τ can be found as</p><formula>q(τ ) ∝ exp(E q({,}\τ ) [logp(Y,,|K d ,K t )]).</formula><p>For our proposed model, thanks to the conjugacy between random variables, the resulting approximate posterior distribution of each factor follows the same distribution as the corresponding factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Inference details</head><p>The approximate posterior distributions of the precision priors for drug compounds can be found as</p><formula>q( d ) = Nd i=1 R s=1 G λ i d,s ;α λ +1/2,(1/β λ + (a i d,s ) 2 /2) −1 (2)</formula><p>Copyedited by: SK</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernelized Bayesian matrix factorization with twin kernels</head><p>where the tilde notation denotes the posterior expectations as usual, i.e.</p><formula>h(τ ) = E q(τ ) [h(τ )]</formula><p>. The approximate posterior distribution of the projection parameters for drug compounds can be found as a product of multivariate normal distributions:</p><formula>q(A d ) = R s=1 N a d,s ;(a d,s )K d (g s d ) /σ 2 g ,</formula><formula>(diag( λ s d )+K d K d /σ 2 g ) −1 (3)</formula><p>and the approximate posterior distribution of the projected instances for drug compounds is also a product of multivariate normal distributions:</p><formula>q(G d ) = Nd i=1 N g d,i ;(g d,i )( A d k d,i /σ 2 g + G t (f i ) ),</formula><formula>(I/σ 2 g + G t G t ) −1. (4)</formula><p>The approximate posterior distributions of the precision priors for target proteins can be found as</p><formula>q( t ) = Nt j=1 R s=1 G λ j t,s ;α λ +1/2,(1/β λ + (a j t,s ) 2 /2) −1 .</formula><formula>(5)</formula><p>The approximate posterior distribution of the projection parameters for target proteins can be found as a product of multivariate normal distributions:</p><formula>q(A t ) = R s=1 N a t,s ;(a t,s )K t (g s t ) /σ 2 g ,</formula><formula>(diag( λ s t )+K t K t /σ 2 g ) −1 (6)</formula><p>and the approximate posterior distribution of the projected instances for target proteins is also a product of multivariate normal distributions:</p><formula>q(G t ) = Nt j=1 N g t,j ;(g t,j )( A t k t,j /σ 2 g + G d f j ),</formula><formula>(I/σ 2 g + G d G d ) −1. (7)</formula><p>The approximate posterior distribution of the interaction scores is a product of truncated normal distributions given as</p><formula>q(F) = Nd i=1 Nt j=1 T N f i j ; g d,i g t,j ,1,f i j y i j &gt;ν (8)</formula><p>where we need to find their posterior expectations to update the approximate posterior distributions of the projected instances for drug compounds and target proteins. Fortunately, the truncated normal distribution has a closedform formula for its expectation. The inference procedure summarized in Algorithm 1 sequentially updates the approximate posterior distributions of the model parameters and the latent variables until convergence, which can be checked by monitoring the lower bound in (1). The first term of the lower bound corresponds to the sum of exponential form expectations of the distributions in the joint likelihood. The second term is the sum of negative entropies of the approximate posteriors in the ensemble. The only non-standard distribution in these terms is the truncated normal distribution used for the interaction scores; nevertheless, the truncated normal distribution has a closed-form formula also for its entropy. In our implementation, the chemical similarity function s c (·,·) is used as the kernel function between drug compounds k d (·,·), which means that the chemical similarity matrix S c is used as the kernel matrix for drug compounds K d. Similarly, the genomic similarity function s g (·,·) is used as the kernel function between target proteins k t (·,·), which means that the genomic similarity matrix S g is used as the kernel matrix for target proteins K t. The provided similarity matrices S c and S g may not be valid kernels (i.e. positive semidefinite), but we use them as they are because our algorithm does not require them to be positive semidefinite. The hyper-parameters (α λ ,β λ ) and σ g are set to (1,1) and 0.1, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Prediction scenarios</head><p>We consider three different scenarios for drug–target interaction prediction. For these scenarios, we can get probabilistic estimates from our Bayesian model but the variances are observed to be very small due to discriminative nature of the model (i.e. modeling the interaction between drug compounds and target proteins by introducing the binary classification part with a large margin strategy just after the matrix factorization part). Hence, we only consider point estimates for simplicity without sacrificing the generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Prediction for a new drug compound</head><p>In the first scenario, we assume that we are given a new drug compound d and our task is to find the set of target proteins from X t that interact with d. We first need to calculate the similarities between d and X d :</p><formula>k d,, = k d (d ,d 1 ) k d (d ,d 2 ) ... k d (d ,d Nd )</formula><p>and these similarities can be used to find the interaction scores for d :</p><formula>f = A d k d,, A t K t = k d,, A d A t K t</formula><p>where positive valued entries indicate that the corresponding target proteins interact with d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Prediction for a new target protein</head><p>In the second scenario, we assume that we are given a new target protein t * and our task is to find the set of drug compounds from X d that interact with t * . We first need to calculate the similarities between t * and X t :</p><formula>k t, * = k t (t * ,t 1 ) k t (t * ,t 2 ) ... k t (t * ,t Nt )</formula><p>and these similarities can be used to find the interaction scores for t * :</p><formula>f * = A d K d A t k t, * = K d A d A t k t, *</formula><p>where positive valued entries indicate that the corresponding drug compounds interact with t * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Joint prediction for a new drug compound and a new target protein</head><p>The third scenario is the hybrid of the first two scenarios and our task is to find whether a new drug compound d and a new target protein t * interact with each other. We can find the interaction score for d and t * as</p><formula>f * = A d k d,, A t k t, * = k d,, A d A t k t, *</formula><p>where a positive value indicates that d and t * interact with each other. Note that d and t * can be a known drug compound and a known target protein, respectively, from the given interaction network in order to predict unknown interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>In order to illustrate the effectiveness of our proposed method, called 'kernelized Bayesian matrix factorization with twin kernels' (KBMF2K), we present the results of three experimental scenarios:</p><p>(i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.Gönen</head><p>Drugs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Exploratory data analysis using low-dimensional projections</head><p>KBMF2K can also be used for exploratory data analysis by displaying low-dimensional projections in addition to predicting interactions. For three different prediction scenarios described earlier, we provide visualizations on Nuclear Receptor dataset due to its small network size. In this set of experiments, we set the subspace dimensionality R = 2 and the margin parameter ν = 0. Given a drug–target interaction network, we want to investigate the interactions of new drug compounds and/or target proteins within that network. We do not include 10% of drug compounds and/or target proteins and their interactions to our training network giving us three different scenarios.<ref type="figure" target="#fig_3">Figure 2</ref>displays the two-dimensional projections of training networks superimposed with the predicted projections for held-out drug compounds and/or target proteins. Provided interactions between drug compounds and target proteins are also shown as dashed lines for training network and thick solid lines for held-out drug compounds and/or target proteins. We would like to point out a couple of important observations from<ref type="figure" target="#fig_3">Figure 2</ref>. First of all, KBMF2K successfully captures bipartite nature of the given interaction networks (i.e. two disjoint node sets) by placing drug compounds and target proteins as clearly separated node groups. Second, we can easily see that the dashed lines (i.e. interactions from training network) connect nearby drug compounds and target proteins. Finally the projections for held-out drug compounds/target proteins are meaningful because they are connected to nearby target proteins/drug compounds. The prediction performance using just two dimensions may not be enough for a reliable system, but these two-dimensional figures can definitely be used for exploratory data analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Predicting interactions for the out-of-sample drug compounds</head><p>To show the performance of KBMF2K in predicting interactions for new drug compounds, we perform experiments on the four benchmark datasets. We exactly follow the experimental procedure of<ref type="bibr" target="#b29">Yamanishi et al. (2010)</ref>in order to have comparable results. For each dataset, drug compounds are split into five subsets of roughly equal size. Each subset is then used in turn as the test set and training is performed on the remaining four subsets. This procedure is repeated five times to obtain robust results. The subspace dimensionality R and the margin parameter ν of KBMF2K are selected from {5,10,15,20,25} and {0,1}, respectively, using the prediction performances on the training sets.<ref type="figure" target="#tab_2">Table 2</ref>gives the average AUC (area under the receiver operating curve) values for<ref type="bibr" target="#b29">Yamanishi et al. (2010</ref>) and KBMF2K. Note that<ref type="bibr" target="#b29">Yamanishi et al. (2010)</ref>also report results with pharmacological similarity between drug compounds. We compare our results with the results obtained using the same similarity measures in our experiments (i.e. chemical similarity for drug compounds and genomic similarity for target proteins). We see that KBMF2K achieves higher average AUC values on all datasets. KBMF2K significantly improves the results on Ion Channel and GPCR datasets by 10.7% and 4.6% respectively.<ref type="figure" target="#fig_5">Figure 3</ref>shows the average AUC values for KBMF2K with changing subspace dimensionality and ν = 0. On Nuclear Receptor dataset, we do not see any effect of the subspace dimensionality possibly due to small size of the interaction network. However, there is a clear increasing trend in AUC with increasing subspace dimensionality for other datasets. On Enzyme and GPCR datasets, we get the best results with R = 25. It is still possible to improve the results on Enzyme dataset by adding more dimensions to the common subspace of drug compounds and target proteins. Instead of using a cross-validation strategy, the intrinsic subspace dimensionality can be found while learning the model parameters using, for example, automatic relevance determination (<ref type="bibr" target="#b18">Neal, 1996</ref>). However, we leave this extension as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernelized Bayesian matrix factorization with twin kernels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Predicting unknown interactions of the given network</head><p>In order to illustrate the performance of KBMF2K in predicting unknown drug–target interactions of the given network, we perform a new set of experiments on the four benchmark datasets. Using the best parameter values for {R,ν} found in the previous experiments, we train KBMF2K with the complete interaction network for each dataset. We rank the non-interacting pairs with respect to their interaction scores and extract the top 100 predicted interactions. We report only the top five predicted interactions for each dataset and give the full lists of predicted interactions as Supplementary material.<ref type="figure" target="#tab_3">Table 3</ref>lists the top five predicted interactions for each dataset. We check these predicted interactions manually from the latest online versions of ChEMBL (<ref type="bibr" target="#b6">Gaulton et al., 2012</ref>), DrugBank (<ref type="bibr" target="#b16">Knox et al., 2011</ref>) and KEGG DRUG (<ref type="bibr" target="#b14">Kanehisa et al., 2012</ref>) databases. We see that 80% of the predictions (16 out of 20) is reported in at least one of these databases. This is a strong evidence for the practical relevance of our method. For example, Enzyme dataset has 2926 interacting and 292554 non-interacting (i.e. not known to interact) drug–target pairs. We pick only the top five predicted interactions and see that four out of these five drug–target pairs are currently reported in at least one database. KBMF2K correctly identifies three and four out of five predicted interactions on Ion Channel and GPCR datasets, respectively. The prediction performance of KBMF2K is even better on Nuclear Receptor dataset. The top five predicted interactions are currently reported in ChEMBL database. We also check the top 10 predicted interactions and see that all of them are reported in ChEMBL database. Note that the predicted interactions that are not reported yet may also exist in reality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>In this study, we consider four different drug–target interaction networks from humans involving enzymes, ion channels, GPCRs and nuclear receptors. We then propose a novel Bayesian formulation that combines kernel-based nonlinear dimensionality reduction (<ref type="bibr" target="#b21">Schölkopf and Smola, 2002</ref>), matrix factorization (<ref type="bibr" target="#b25">Srebro, 2004</ref>) and binary classification for predicting drug–target interaction networks using only chemical similarity between drug compounds and genomic similarity between target proteins. The novelty of our approach comes from the joint Bayesian formulation of projecting drug compounds and target proteins into a unified subspace using the similarities and estimating the interaction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.Gönen</head><p>network in that subspace. Our proposed method is the first fully probabilistic formulation proposed for drug–target interaction network inference. We propose using a variational approximation in order to obtain an efficient inference scheme and give its detailed derivations. The most time-consuming steps of the proposed variational inference mechanism are covariance calculations because we need to perform matrix inversions. The time complexity of the covariance updates for the projection matrices in (3) and (6) is O(RN 3 d ) and O(RN 3 t ), respectively. The time complexity of the covariance updates for the composite components in (4) and (7) is O(R 3 ). The other calculations in these steps can be done very efficiently using matrix– matrix or matrix–vector multiplications. Finding the posterior expectations of the interaction scores in (8) only requires evaluating the standardized normal cumulative distribution function and the standardized normal probability density. In summary, the total time complexity of each iteration in our variational approximation scheme is O(RN 3 d +RN 3 t +R 3 ), which makes our algorithm very efficient compared to standard pairwise kernel approaches that require calculating an N d N t ×N d N t kernel matrix between object pairs and training a kernel-based classifier using this kernel matrix. In order to demonstrate the performance of our proposed method, called 'kernelized Bayesian matrix factorization with twin kernels' (KBMF2K), we use four benchmark datasets containing known drug–target interaction networks, chemical kernels between drug compounds and genomic kernels between target proteins provided by<ref type="bibr" target="#b28">Yamanishi et al. (2008)</ref>. We design three different experimental scenarios with practical importance as follows (i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network. In the first set of results, we show that the resulting low-dimensional projections can be used to predict drug–target interactions and practitioners can use these projections as two-dimensional figures for exploratory data analysis. The remaining sets of results show that our novel probabilistic interpretation obtains better generalization performance than earlier optimization-based approaches. KBMF2K uses one kernel function for chemical similarity and another kernel function calculated on protein sequences for genomic similarity. The performance of our approach can be improved by integrating multiple kernels for both kinds of similarity. In kernelbased methods, this approach is known as 'multiple kernel learning' (<ref type="bibr">Gönen and Alpaydın, 2011</ref>) and our method can be extended towards that direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Graphical model for predicting drug–target interactions from kernels on drug compounds and target proteins</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>where we see that F is factorized using the matrices of projected instances G d and G t. Different from previous Bayesian matrix factorization solutions such as the probabilistic formulations proposed by Salakhutdinov and Mnih (2008a, b), our approach parameterizes the matrices of projected instances in terms of kernel matrices K d and K t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Copyedited by: SK MANUSCRIPT CATEGORY: ORIGINAL PAPER [11:28 17/8/2012 Bioinformatics-bts360.tex] Page: 2308 2304–2310</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Two-dimensional projections of drug compounds and target proteins obtained by KBMF2K on Nuclear Receptor dataset with (A) held-out drug compounds (B) held-out target proteins compounds and (C) held-out drug compounds and target proteins. Provided interactions between drug compounds and target proteins are shown as dashed lines for training network and thick solid lines for held-out drug compounds and/or target proteins</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Interactions reported in ChEMBL, DrugBank and KEGG are marked with C, D and K, respectively. Interactions reported in at least one of these databases are shown in bold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.3.</head><figDesc>Fig. 3. Prediction performance of KBMF2K with changing subspace dimensionality and ν = 0 on the four benchmark datasets in terms of average AUC values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>Copyedited by: SK MANUSCRIPT CATEGORY: ORIGINAL PAPER [11:28 17/8/2012 Bioinformatics-bts360.tex] Page: 2310 2304–2310</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. The drug–target interaction datasets from Yamanishi et al. (2008)</figDesc><table>Dataset 
Drugs 
Targets 
Interactions 

Enzyme 
445 
664 
2926 
Ion Channel 
210 
204 
1476 
GPCR 
223 
95 
635 
Nuclear Receptor 
54 
26 
90 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>G d as g s d. The N t ×N t kernel matrix for target proteins is denoted by K t , where the columns of K t by k t,j. The N t ×R matrix of corresponding projection parameters a j t,s and their priors λ j t,s are denoted by A t and t , respectively, where the columns of A t and t by a t,s and λ t,s. The R×N t matrix of projected instances for target proteins g s t,j are represented as G t , where the columns of G t as g t,j and the rows of G t as g s t. The variance for the entries of G d and G t is represented as σ 2 g. The N d ×N t matrix of interaction scores f i j is represented as F, where the rows of F as f i and the columns of F as f j. The N d ×N t matrix of associated interaction variables is represented as Y, where each element y i j ∈{−1,+1}. As short-hand notations, all priors in the model are denoted by ={ d , t }, where the remaining variables by ={A d ,A t ,G d ,G t ,F} and the hyper-parameters by ζ ={α λ ,β λ }. Dependence on ζ is omitted for clarity throughout this article. The distributional assumptions of our proposed model are defined as</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Algorithm 1 Kernelized Bayesian matrix factorization with twin kernels (KBMF2K) Require: K d , K t , Y, R, α λ , β λ , σ g and ν 1. Initialize q(A d ), q(A t ), q(G d ), q(G t ) and q(F) randomly 2. repeat 3. Update q( d ), q(A d ) and q(G d A d ) and q(A t )</figDesc><table>) using (2), (3) and (4) 

4. 

Update q( t ), q(A t ) and q(G t ) using (5), (6) and (7) 

5. 

Update q(F) using (8) 
6. until convergence 
7. return q(</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 2. Prediction performances of Yamanishi et al. (2010) and KBMF2K on the four benchmark datasets in terms of average AUC values</figDesc><table>Dataset 
Yamanishi et al. (2010) 
KBMF2K 

Enzyme 
0.821 
0.832 
Ion Channel 
0.692 
0.799 
GPCR 
0.811 
0.857 
Nuclear Receptor 
0.814 
0.824 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Table 3.</figDesc><table>The top five predicted interactions on the four benchmark datasets 

Rank Pair 
Annotation 
Rank Pair 
Annotation 

</table></figure>

			<note place="foot">© The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The author thanks Fidan Sümbül for her very useful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Bayesian analysis of binary and polychotomous response data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Albert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Chib</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="669" to="679" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title level="m" type="main">Variational Algorithms for Approximate Bayesian Inference</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Beal</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Supervised prediction of drug–target interactions using bipartite local models</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bleakley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yamanishi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2397" to="2403" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Predicting ADME properties in silico: methods and models</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Butina</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discov. Today</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="83" to="88" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Comparison of support vector machine and artificial neural network systems for drug/nondrug classification</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Byvatov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inf. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1882" to="1889" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Structure-based maximal affinity model predicts smallmolecule druggability</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Cheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="71" to="75" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">ChEMBL: a large-scale bioactivity database for drug discovery</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gaulton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1100" to="1107" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Sampling-based approaches to calculating marginal densities</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Gelfand</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">F M</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="398" to="409" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiple kernel learning algorithms</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gönen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Alpaydın</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2211" to="2268" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">SuperTarget and Matador: resources for exploring drug–target relationships</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Günther</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="919" to="922" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Development of a chemical structure comparison method for integrated analysis of chemical and genomic information in the metabolic pathways</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hattori</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Chem. Soc</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="11853" to="11865" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">SuperTarget goes quantitative: update on drug–target interactions</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Hecker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1113" to="1117" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Protein–ligand interaction prediction: an improved chemogenomics approach</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Jacob</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J.-P</forename>
				<surname>Vert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2149" to="2156" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">From genomics to chemical genomics: new developments in KEGG</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kanehisa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="354" to="357" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">KEGG for integration and interpretation of large-scale molecular data sets</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kanehisa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="109" to="114" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Relating protein pharmacology by ligand chemistry</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Keiser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="197" to="206" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">DrugBank 3.0: a comprehensive resource for &apos;omics&apos; research on drugs</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Knox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1035" to="1041" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised learning via Gaussian processes</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">D</forename>
				<surname>Lawrence</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">I</forename>
				<surname>Jordan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 17</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian Learning for Neural Networks A fast flexible docking method using an incremental construction algorithm</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Neal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Ny</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Rarey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">261</biblScope>
			<biblScope unit="page" from="470" to="489" />
			<date type="published" when="1996" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian probabilistic matrix factorization using Markov chain Monte Carlo</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Salakhutdinov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mnih</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="880" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Salakhutdinov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mnih</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Schölkopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Smola</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<monogr>
		<title level="m" type="main">Kernel Methods in Computational Biology</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Schölkopf</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">BRENDA, the enzyme database: updates and major new developments</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Schomburg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="431" to="433" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Identification of common molecular subsequences</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">F</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Waterman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="195" to="197" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning with Matrix Factorizations Massachusetts Institute of Technology Gaussian interaction profile kernels for predicting drugtarget interaction</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Srebro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Van Laarhoven</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3036" to="3043" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Ligand prediction for orphan targets using support vector machines and various target–ligand kernels is dominated by nearest neighbor effects</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Wassermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inf. Model</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="2155" to="2167" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">DrugBank: a knowledgebase for drugs, drug actions and drug targets</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">S</forename>
				<surname>Wishart</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="901" to="906" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Prediction of drug–target interaction networks from the integration of chemical and genomic spaces</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yamanishi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="232" to="240" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Drug–target interaction prediction from chemical, genomic and pharmacological data in an integrated framework</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yamanishi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="246" to="254" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">A probabilistic model for mining implicit &apos;chemical compoundgene&apos; relations from literature</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Zhu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="251" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>