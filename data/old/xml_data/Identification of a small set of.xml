
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identification of a small set of plasma signalling proteins using neural network for prediction of Alzheimer&apos;s disease</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Swapna</forename>
								<surname>Agarwal</surname>
							</persName>
							<email>agarwal.swapna@gmail.com or swapna_r@isical.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Electronics and Communication Sciences Unit</orgName>
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<postCode>700108</postCode>
									<settlement>Calcutta</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Pradip</forename>
								<surname>Ghanty</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Praxis Softek Solutions Pvt. Ltd</orgName>
								<orgName type="institution" key="instit2">Saltlake Electronic Complex</orgName>
								<address>
									<postCode>700091</postCode>
									<settlement>Calcutta</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Nikhil</forename>
								<forename type="middle">R</forename>
								<surname>Pal</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Electronics and Communication Sciences Unit</orgName>
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<postCode>700108</postCode>
									<settlement>Calcutta</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Identification of a small set of plasma signalling proteins using neural network for prediction of Alzheimer&apos;s disease</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Gene expression</title>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv173</idno>
					<note type="submission">Received on May 26, 2014; revised on February 25, 2015; accepted on March 22, 2015</note>
					<note>*To whom correspondence should be addressed. Associate Editor: Ziv Bar-Joseph Availability and implementation: The FSRBF code is available at https://sites.google.com/site/agar walswapna/publications. Contact: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Alzheimer&apos;s disease (AD) is a dementia that gets worse with time resulting in loss of memory and cognitive functions. The life expectancy of AD patients following diagnosis is $7 years. In 2006, researchers estimated that 0.40% of the world population (range 0.17–0.89%) was afflicted by AD, and that the prevalence rate would be tripled by 2050. Usually, examination of brain tissues is required for definite diagnosis of AD. So, it is crucial to diagnose AD at an early stage via some alternative methods. As the brain controls many functions via releasing signalling proteins through blood, we analyse blood plasma proteins for diagnosis of AD. Results: Here, we use a radial basis function (RBF) network for feature selection called feature selection RBF network for selection of plasma proteins that can help diagnosis of AD. We have identified a set of plasma proteins, smaller in size than previous study, with comparable prediction accuracy. We have also analysed mild cognitive impairment (MCI) samples with our selected proteins. We have used neural networks and support vector machines as classifiers. The principle component analysis, Sammmon projection and heat-map of the selected proteins have been used to demonstrate the proteins&apos; discriminating power for diagnosis of AD. We have also found a set of plasma signalling proteins that can distinguish incipient AD from MCI at an early stage. Literature survey strongly supports the AD diagnosis capability of the selected plasma proteins.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Alzheimer's disease (AD) is the most common form of dementia. According to a cohort longitudinal study, $10–15 persons per 1000 persons per year get dementia of which 5–10 get AD (<ref type="bibr" target="#b2">Bermejo et al., 2008;</ref><ref type="bibr" target="#b3">Carlo et al., 2002</ref>). In AD, an unknown process divides Amyloid Precursor Protein into smaller fragments. One of these fragments gives rise to fibrils of beta-amyloid, which gets deposited outside neurons in dense formation known as senile plaques (<ref type="bibr" target="#b11">Hooper et al., 2005</ref>). Tau protein becomes hyper-phosphorylated and creates neurofibrillary tangles (<ref type="bibr" target="#b10">Hernandez and Avila, 2007;</ref><ref type="bibr" target="#b25">Tiraboschi et al., 2004</ref>). In recent years researchers have devoted great efforts for the development of AD diagnosis tools (<ref type="bibr" target="#b7">German et al., 2007;</ref><ref type="bibr" target="#b13">Hye et al., 2006;</ref><ref type="bibr" target="#b29">Xiao et al., 2005</ref>). Most of the articles have investigated on a small set (two to four) of Cerebro Spinal Fluid (CSF) proteins (<ref type="bibr" target="#b4">Craig-Schapiro et al., 2011;</ref><ref type="bibr" target="#b21">Rentzos et al. 2006;</ref><ref type="bibr" target="#b28">Westin et al., 2012</ref>). Few attempts have been made using serum proteins (<ref type="bibr" target="#b20">Ray et al., 2007</ref>) and using both CSF and serum proteins (<ref type="bibr" target="#b24">Tham et al., 1993</ref>). Some have tried tofind biomarker proteins that can discriminate AD and non-AD patients (<ref type="bibr" target="#b12">Hu et al., 2010</ref>) and some have tried to predict AD from mild cognitive impairment (MCI) patients (<ref type="bibr" target="#b4">Craig-Schapiro et al., 2011</ref>). In the study by<ref type="bibr" target="#b23">Teramoto (2008)</ref>, a semi-supervised distance metric learning using random forests with label propagation is proposed for prediction of AD. In<ref type="bibr" target="#b9">Hansson et al. (2006)</ref>, concentration of T – tau, P À tau 181 and Ab42 in CSF are reported to be associated with future development of AD in patients with MCI.<ref type="bibr" target="#b20">Ray et al. (2007)</ref>have proposed a microarray-based method that has selected 18 blood plasma signalling proteins to classify and predict clinical AD diagnosis. We have used the same dataset and found nine plasma signalling proteins for the same problem with comparable prediction accuracy. We have also found a set of useful plasma signalling proteins that can predict AD from MCI with a better prediction accuracy. The selection of biomarker plasma proteins from a large set of proteins is a feature selection problem. Feature selection methods can be broadly classified as filter methods and wrapper methods. In filter methods, the features are given importance solely depending on the properties of the features themselves. These methods ignore the tool finally used to recognize the patterns. But the utility of a feature depends on the pattern recognition tool being used and the problem being solved. A set of features good for a particular pattern recognition problem and a tool may not be as good for a different pattern recognition tool. The wrapper-based feature selection methods utilize the classifier itself to find the relevance of the feature. Thus, wrapper methods are generally considered better as compared with filter methods (<ref type="bibr" target="#b15">Kohavi and John, 1997</ref>). One of the early filter methods is Relief (<ref type="bibr" target="#b14">Kira and Rendell, 1992</ref>). In Relief, given a feature vector, two more instances of feature vectors are considered; one from the same class and the other from the other class. The weight of a feature is decreased if the value of that feature differs more from the value in the instance of the same class than the value in the instance of the different class and vice versa. Relief was modified into ReliefF by<ref type="bibr" target="#b16">Kononenko et al. (1997)</ref>. KernelPLS (<ref type="bibr" target="#b22">Sun et al., 2014</ref>) is a kernel-based multivariate feature selection method that selects features taking into account possible non-linear relation between features as well as that between features and target. In the study by<ref type="bibr" target="#b22">Sun et al. (2014)</ref>, a partial least square (PLS) algorithm finds a low-dimensional approximation of the input matrix that can explain as close as possible the target vectors. The support vector machine recursive feature elimination (SVMRFE) method (<ref type="bibr" target="#b8">Guyon et al., 2002</ref>) eliminates poor features using an iterative process. It starts with all features and removes one feature at a time based on a feature ranking score that is computed using the coefficients of the weight vector of a linear SVM. At each iteration, the feature with the smallest ranking score is eliminated. In this study, neural networks (NNs) are used for feature selection as well as for classification. We have used both multilayer perceptron (MLP) and radial basis function (RBF) NNs for classification. RBF NNs are used for feature selection in the studies by Basak and Mitra (1999) and Chakraborty and Pal (2008). The Group Feature Selection RBF (GFSRBF) is proposed by<ref type="bibr" target="#b5">Chakraborty and Pal (2008)</ref>for selecting useful groups of features where each feature group corresponds to a sensor. In<ref type="bibr" target="#b18">Pal and Malpani (2012)</ref>, this network has been adapted for feature selection with controlled redundancy. Here, we have adapted GFSRBF for feature selection without any explicit control on redundancy for selection of plasma proteins that can predict clinical AD. Our approach is described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>For diagnosis of AD from plasma samples, we need to identify the plasma proteins that carry AD specific signature. As the initial set of plasma proteins, we consider the set of 120 proteins reported in<ref type="bibr" target="#b20">Ray et al. (2007)</ref>. To select an adequate set of proteins we use a modified RBF NN for feature selection. This is an integrated method where feature selection and system identification are done simultaneously. In this method, a feature attenuator is associated with each feature. For a useful feature, its attenuator allows the feature to get into the network. For an unimportant feature, its attenuator does not allow the feature to affect the network. To verify the AD-specific signature of these selected features (proteins), we subject them to different classifiers. We have also tested if the selected proteins form natural AD and non-AD-specific clusters. We have compared the results with that of Ray et al. (2007) as well as those by two filter methods (ReliefF and kernelPLS) and a wrapper method (SVMRFE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature selection RBF</head><p>Let p be the number of features, c be the number of classes and X be the dataset, X ¼ fx 1 ; x 2 ; :::; x n g &amp; &lt; p with associated output in &lt; c. In general, an RBF network has three layers. Layer 1, which is called input layer, has p nodes. Layer 3, which is called output layer, has c nodes. The architecture of RBF depends on number (let us denote it by h) of nodes present in layer 2, which is called hidden layer or basis function layer. The required value of h depends on the dataset. In an RBF network, each node in the input layer is connected to each node in the hidden layer, and each node in the hidden layer is connected through some weights to each node in the output layer. There is no connection between the nodes in the same layer. Each node in the hidden layer uses a Gaussian basis function, / j ; j ¼ 1; :::; h: / j ðxÞ ¼ expfÀ k x À u j k 2 =r 2 j g;</p><formula>(1)</formula><p>where u j is the centre and r j is the spread of the jth basis function. Note that u and x both are in &lt; p. Let O k be the output of the k th node of the output layer, then</p><formula>O k ¼ X h j¼1 w jk / j ðxÞ; (2)</formula><p>where w jk is the weight between jth node in hidden layer and kth node in output layer. In (2), O k is unbounded as w jk can take any value. For classification problems, desired output lies in<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. So, we add a standard sigmoidal function to each output node.</p><formula>O 0 k ¼ 1=f1 þ exp À X h j¼1 w jk / j ðxÞ g: (3)</formula><p>For classification problem, (3) is used and for regression, (2) is used. We can rewrite (1) as</p><formula>/ j ðxÞ ¼ P p i¼1 expfÀðx i À u ij Þ 2 =r 2 j g ¼ P p i¼1 C i j ; (4)</formula><p>where C i j ¼ exp fÀðx i À u ij Þ 2 =r 2 j g:</p><formula>(5)</formula><p>Value of C i j depends only on the ith feature of the input. To eliminate the features which have derogatory effect on the classification/regression problem, as done in<ref type="bibr" target="#b5">Chakraborty and Pal (2008)</ref>, we design C i j as:</p><formula>C i j ¼ ½expfÀðx i À u ij Þ 2 =r 2 j g 1Àe Àb 2 i : (6)</formula><p>The term, (1 À e Àb 2 i ), is called the feature attenuator. When b i approaches 0, C i j approaches 1 and therefore C i j has almost no effect on / j. When b i is high, the feature attenuator approaches 1 thus there is almost no change to the value of C i j. The value of b i is learnt along with w jk during training through back propagation algorithm. The architecture of the FSRBF is shown in<ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Learning rules</head><p>Let the desired output label associated with a data point be d ¼ ½d 1 ; d 2 :::; d c  T. Thus, the instantaneous error for a data point x is</p><formula>E ¼ 1 2 X c k¼1 ðO 0 k À d k Þ 2 : (7)</formula><p>We use gradient descent technique to learn w jk and b i .</p><p>w jk ðt þ 1Þ ¼ w jk À g w dE=dw jk ðtÞ</p><formula>(8)</formula><p>b i ðt þ 1Þ ¼ b i À g b dE=db i ðtÞ ;</p><formula>(9)</formula><p>where g w and g b are learning rates. For initial assignment of centres to the hidden nodes, we use the k-means clustering of the training dataset. After the k-means clustering, the spread (r) value for each RBF is chosen as the minimum distance between its cluster centre and all the other cluster centres. The connection weights between the hidden layer and the output layer are initialized with random values in [À0.5, 0.5]. When total error on all training samples goes below a predefined tolerance, we terminate the learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dataset</head><p>We have used the same dataset reported inMCI' dataset we mean these three test datasets, respectively. Out of 47 subjects diagnosed with MCI at blood draw, 22 converted to AD within 2–5 years (MCI ! AD), eight converted to OD (MCI ! OD), whereas 17 were still diagnosed as MCI, 4–6 years later (MCI ! MCI) (<ref type="bibr" target="#b20">Ray et al., 2007</ref>). The datasets are available at http://www.nature.com/nm/journal/v13/n11/suppinfo/ nm1653_S1.html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiment design</head><p>We do a 5-fold cross-validation (CV) on the training data for architecture selection for FSRBF. For each fold we run FSRBF 10 times and in each run we initialize the w jk and initial centres of k-means clustering randomly. We take the result averaged over these 10 runs as the final result of that fold, thus decreasing the effect of these random initializations. The number of hidden nodes is varied between 2 and 30. FSRBF is run 10 times on the best architecture selected from the 5-fold CV to get 10 sets of b values. The b values are then averaged over different runs. FSRBF assigns an importance (weight) to each feature during the training in terms of b values. The features are sorted in descending order of the values of b. We need to put a threshold either on the number of features to be selected or on the value of b to select the features. Features for which b value is &lt;0.1135 produce component basis function value &gt; 0.95 even at 2r distance, therefore, do not have much effect on / j (<ref type="bibr" target="#b5">Chakraborty and Pal, 2008</ref>). Here also we choose m features (proteins) which have average b value &gt; 0.1135. To further condense the feature set, we take the feature with the highest average b value and do a 5-fold CV for RBF with different architectures. We increase the number of features by one, i.e. take the two features with highest average b value and again do a 5-fold CV for RBF with different architectures. This process is repeated until 5-fold CV is done on all m features. We select the number of features f 0 for which validation result is the best. This approach is briefly depicted in<ref type="figure" target="#fig_1">Figure 2</ref>. Note that this may not be the only or the best strategy. This is one of the strategies to select a small set of proteins for early detection of AD. Before applying FSRBF on AD data, we test FSRBF on some synthetic datasets with known characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance on synthetic data</head><p>We generate five types of synthetic data. We name them 'A', 'B', 'C', 'D' and 'E'. To test whether the feature selection algorithm can recognize the situation when none of the features carry any class information, we create the dataset A. All the four features of dataset A are assigned random values. The class labels are also assigned randomly to the samples. Therefore, in dataset A, none of the features is important. To test the feature selection algorithm on cases where the classes are linearly separable, we create datasets B and C. We also test the algorithm's efficiency on identifying correlation between features. The first and the second features of dataset C are highly correlated, correlation coefficient being 0.97. We also need to test the cases where the classes are not linearly separable. Therefore, datasets D and E are created. Whereas datasets B and C are linearly separable, dataset D cannot be separated by a single straight line. Dataset D resembles XOR data in appearance. In dataset E, samples belonging to one class surround the other class. Therefore, the classes are not linearly separable. The scatter plots of the datasets are displayed in<ref type="figure" target="#fig_2">Figure 3</ref>. We also test the behaviour of FSRBF with increasing number of noisy features. We compare our results with two state-of-the-art filter methods: kernelPLS (<ref type="bibr" target="#b22">Sun et al., 2014</ref>) and ReliefF (<ref type="bibr" target="#b16">Kononenko et al., 1997</ref>) and a wrapper method SVMRFE (<ref type="bibr" target="#b8">Guyon et al., 2002</ref>) in terms of type I (false positive) and type II (false negative) errors. For dataset A where none of the four features carry class information, FSRBF selects two features incurring type I error, whereas KernelPLS and SVMRFE select all the four features as useful incurring a high type I error. Only ReliefF assigns low weights to all the features resulting in zero type I and type II error. For linearly separable dataset B all feature selection methods select the right feature. For dataset C that contains correlated features, the three methods FSRBF, KernelPLS and ReliefF select all important (including correlated) features. None of the unimportant features get selected even in the presence of 48 noisy features (zero type I and type II errors). Though SVMRFE is able to recognize correlated features, as the number of noisy features increases, SVMRFE tends to select some unimportant features and discards some important features. For dataset D, FSRBF and for dataset E, FSRBF and ReliefF select only the important features (zero error). KernelPLS and ReliefF for dataset D and KernelPLS for dataset E select only some unimportant features discarding both the important features. Therefore, type I and type II errors both become high. As the number of noisy features increases, SVMRFE, for datasets D and E, usually discards one of the important features and selects one of the unimportant features. All the four feature selection methods under consideration assign a numerical importance (b for FSRBF) to each feature. For an ideal feature selection method, it is expected that the important features be assigned the highest weights and therefore the highest ranks even in presence of noisy features. We analyse in<ref type="figure" target="#fig_3">Figure 4</ref>, the change of rank of the two important features of datasets D and E (with nonlinearly separable classes) with increasing number of noisy features for the four competing feature selection methods. We are more interested in datasets D and E as all the four competing methods produce zero error only for linearly separable datasets. The three methods KernelPLS, ReliefF and SVMRFE produce high or moderate type I and type II errors for non-linearly separable datasets D and E whereas FSRBF produces zero type I and type II errors in non-linear cases also. From<ref type="figure" target="#fig_3">Figure 4</ref>it can be seen that ReliefF maintains the highest ranks for both the important features, feature 1 and feature 2, for dataset E, but fails to maintain the same for dataset D. For both the datasets D and E, only FSRBF consistently maintains thehighest ranks (1 and 2) for the two important features, even in presence of noisy features. Note that these results are average over 10 runs of FSRBF, where the network architecture is selected using 5-Fold CV, but in some individual runs FSRBF may not maintain the highest ranks for features 1 and 2. Except for dataset A, FSRBF produces zero error for all the cases. Given the application of feature selection in identifying biomarkers of critical biological phenomena (e.g. existence of diseases like Alzheimer, cancer), it is important that none of the features that carry important class information gets discarded. Our limited experiments with simple synthetic datasets reveal the success of FSRBF in this regard, but this does not mean that this will always be the case with real life datasets. Further results on synthetic datasets can be found in Section 1 of the Supplementary Material. Next we apply FSRBF on AD dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance on AD data</head><p>Our architecture selection scheme suggests an FSRBF with 13 hidden nodes (validation accuracy 90.25%). Therefore, we run FSRBF NN with 13 hidden nodes on AD training data. We have executed FSRBF on an 80 core computing system involving @2.13 GHz Xeon(R) E7-L8867 processors with 512 GB RAM. Note that though the above-mentioned system is a multi-core multiprocessor system we did not explicitly exploit the parallel processing capability of the system. The CPU time (using only single core of a single processor) for one run of FSRBF with 500 iterations for the parameter updates (Equations 8 and 9) is 20.14 s. It is worth noting that there is a natural parallelism in an RBF network. The computations done at the hidden nodes can be done in parallel which can drastically reduce the computation time. Using the average b values obtained after applying the first four steps in<ref type="figure" target="#fig_1">Figure 2</ref>, we find 34 signalling proteins with b value &gt; 0.1135. To condense the feature set further, 5-fold CV on n signalling proteins (sorted according to b values) where n ¼ 1; 2; :::; 34 is performed.<ref type="figure" target="#fig_4">Figure 5a</ref>shows the change of training and validation error with increasing number of signalling proteins. It is seen in<ref type="figure" target="#fig_4">Figure 5a</ref>that validation error is least for nine signalling proteins. We select these nine signalling proteins as our final set of predictors. The selected nine proteins along with their importance in terms of b values averaged over 10 runs of FSRBF are shown in<ref type="figure" target="#fig_4">Figure 5b</ref>. Seven predictors out of these nine are common with 18 predictors reported by<ref type="bibr" target="#b20">Ray et al. (2007)</ref>. The remaining two (marked in bold font in<ref type="figure" target="#fig_4">Fig. 5b</ref>) are new findings with FSRBF. Correlation analysis reveals that the maximum correlation between any two of the nine proteins is 0.39 and five of the nine proteins have high correlation (&gt;0.61) with one or more proteins from the remaining set of 111 proteins. That is FSRBF has selected only one of the several highly correlated and important proteins. The details are given in Section 2 of the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prediction result with the selected proteins</head><p>To test the usefulness of the features selected by FSRBF, we subject the AD dataset with selected features to different classifiers, e.g. RBF, SVM with linear kernel, SVM with RBF kernel and MLP. For selection of an appropriate architecture/hyperparameters for these classifiers, we do a 5-fold CV on the training dataset. Each classifier is trained with the 'train' dataset using both sets of features (nine features found by FSRBF and 18 features found by<ref type="bibr" target="#b20">Ray et al. 2007</ref>) and tested on the four datasets, 'train', 'first test', 'OD' and 'MCI'.These results are depicted in<ref type="figure" target="#fig_5">Figure 6</ref>.<ref type="figure" target="#fig_5">Figure 6</ref>indicates that for most of the classifiers, the set of nine proteins improves the classification accuracies of the MCI dataset (47 samples) into AD and nonAD classes by $4%. On the other hand, for most classifiers, the set of 18 proteins better classifies the OD dataset (11 samples) by $18%. Therefore, when the set of 18 proteins performs better, the improvement in performance appears higher than the cases when the set of nine proteins perform better. But, the OD dataset has only 11 samples and hence $18% better classification amounts to just two extra correct classifications. Moreover, we have identified a much smaller set of uncorrelated proteins which leads to low computational complexity and may result in decreased diagnostic expenses. We draw a heat-map using our nine proteins in<ref type="figure" target="#fig_6">Figure 7</ref>. Observe that most AD samples, shown in blue, form a cluster in the middle and the non-AD samples form two clusters on the two sides. This pattern shows that our nine proteins form AD-specific signature. A heat-map for the 18 proteins identified in<ref type="bibr" target="#b20">Ray et al. (2007)</ref>is shown in Supplementary<ref type="figure" target="#fig_0">Figure S1a</ref>and is compared in Supplementary Section 2 with the heat-map presented in<ref type="figure" target="#fig_6">Figure 7</ref>. To compare the efficiency of FSRBF with that of kernelPLS, ReliefF and SVMRFE, we run them on the same training set (Section 3.2) for AD-specific feature selection. Each feature selection method assigns a numerical value to each feature according to the importance of the feature. For each method we have considered the top 20 features and then identified the features that are common to all four sets. We have found eight such common biomarkers. Of these eight proteins, seven are present in the set of 18 reported in<ref type="bibr" target="#b20">Ray et al. (2007)</ref>. These seven are shown in<ref type="figure" target="#fig_4">Figure 5b</ref>in non-bold font. The biomarker FAS which is selected by FSRBF as the ninth important feature, but not reported in<ref type="bibr" target="#b20">Ray et al. (2007)</ref>, is also selected by ReliefF, kernelPLS and SVMRFE. For the next set of experiments, we train the classifiers with the train set of 83 samples and test the performance on the first test set of 81 samples (Section 3.2).<ref type="figure" target="#fig_7">Figure 8</ref>compares the performances of the features selected by different methods. Different metrics: recall/sensitivity, specificity, precision and F-score have been used for performance comparison. These metrics are plotted against increasing number of features as selected by different feature selection methods. The classifier used is SVM with linear kernel. We choose LIBSVM implementation of SVM with default value (0.5) of the<ref type="figure" target="#fig_8">Figure 9</ref>shows the experimental results in terms of F-score. Note that high F-score indicates both high sensitivity and high precision. For 14 proteins identified by<ref type="bibr" target="#b20">Ray et al. (2007)</ref>, addition of TGF-b and FAS increases the F-score. It is observable that each of the proteins MCP-3, PARC, ICAM, IGFBP-6 and IL11 (feature indices 5, 8, 14, 15 and 16, respectively, in<ref type="figure" target="#fig_8">Fig. 9</ref>) identifies all the samples as non-AD, resulting in zero sensitivity and thus no F-score. TGF-b and FAS, when added to each of these five proteins, results in a significant F-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">PCA and Sammon mapping of selected proteins</head><p>To further analyse the characteristics of the selected nine proteins, we perform principal component analysis (PCA). Experiments show that for our nine proteins, 92.69% variance is concentrated in seven principal components (PCs) whereas, for 18 proteins, 91.12% variance is concentrated in nine PCs.<ref type="figure" target="#fig_0">Figure 10a</ref>shows the scatter plot of the first test dataset in 2D principal domain of our nine proteins and Supplementary<ref type="figure" target="#fig_1">Figure S2</ref>shows similar scatter plots for the train set and the rest two test sets: OD and MCI. For a fair comparison, Supplementary<ref type="figure" target="#fig_1">Figure S2</ref>also shows similar scatter plots in 2D principal space for the 18 proteins reported by<ref type="bibr" target="#b20">Ray et al. (2007)</ref>. The two figures reveal that clustering capability of both the protein sets (nine and 18) is comparable. Since we have used non-linear architecture for selection of plasma signalling proteins, linear PCA may not reflect the appropriate discriminating power of the selected predictors. So, we have also explored non-linear Sammon mapping. The 2D Sammon projection of the first test set using nine signalling proteins and that of the 18 signalling proteins (reported by<ref type="bibr" target="#b20">Ray et al., 2007</ref>) are shown in<ref type="figure" target="#fig_0">Figure 10b</ref>and Supplementary<ref type="figure" target="#fig_2">Figure S3</ref>, respectively. For the sake of completeness, the 2D Sammon projections of the training set and the remaining two test sets, OD and MCI, using our nine signalling proteins as well as using the set of 18 signalling proteins (reported in<ref type="bibr" target="#b20">Ray et al., 2007</ref>) are also shown in Supplementary<ref type="figure" target="#fig_2">Figure S3</ref>. In the two scatter plots of<ref type="figure" target="#fig_0">Figure 10</ref>, especially in<ref type="figure" target="#fig_0">Figure 10b</ref>, two distinct clusters corresponding to AD and non-AD samples can be observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Identifying incipient AD from MCI samples</head><p>The last columns of the bar-graphs in<ref type="figure" target="#fig_5">Figure 6</ref>, and Supplementary<ref type="figure" target="#fig_1">Figure S2d</ref>and h, show that both the set of nine and the set of 18 signalling proteins are not good enough to identify those pre-symptomatic individuals with MCI who will eventually suffer from AD. To identify the bio-markers that can single out the MCI patients who will gradually convert to AD, we do the feature selection experiments afresh on the MCI data. Since limited numbers (47) of samples are available, we do the experiments in 10 folds. First, the set of 47 MCI data samples is divided into 10 parts say, D 1 ; D 2 ; :::; D 10. We use each D i as the test data and the remaining data T i ¼ [ j6 ¼i D j as the training data. We perform 10-fold CV on T i to choose the architecture with the highest validation accuracy. Once the architecture for T i is selected, FSRBF is run on T i 10 times with different initializations and tested on D i as test data. So we get 10 sets of b values for each D i. So for 10 iterations, we get a total of 100 sets of b values. The features (signalling proteins) for which b value is &gt;0.1135, are chosen from each set. Then we select 29 signalling proteins for which frequency count is &gt;50. The frequency of the selected signalling proteins in these 100 sets of b values is shown in<ref type="figure" target="#fig_0">Figure 11</ref>. Note that this set of 29 proteins is not necessarily the minimal set of plasma proteins that carry AD specific signature in MCI patients. The frequency of occurrence of these proteins being more that 50 in 100 runs of FSRBF indicates that these proteins may carry important AD specific signature in MCI patients. A heat-map along with a dendrogram constructed using 'correlation' distance and 'average' linkage for the 29 proteins is shown in Supplementary<ref type="figure">Figure</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Biological relevance of the selected proteins</head><p>In Section 4, we notice that seven of our nine proteins selected from AD 'train' set are the same as those reported in<ref type="bibr">Ray</ref>shows that different subsets of this set of 29 proteins are found to play significant roles in different biological processes that are related to AD and/or other neurological brain disorders. This is discussed in detail in Section 3 of the Supplementary Material. Some regulatory protein interaction networks for different biological processes created using gene mania online (http://www. genemania.org/) and defined by the 29 plasma proteins are shown in Supplementary<ref type="figure" target="#fig_4">Figure S5</ref>. The result of DAVID query (http://david. abcc.ncifcrf.gov/conversion.jsp) for specific biological processes controlled by the indicated 29 proteins is shown in Supplementary<ref type="figure" target="#fig_5">Figure S6</ref>. Literature further reveals that many of the 29 proteins as listed in<ref type="figure" target="#fig_0">Figure 11</ref>are mentioned to play important roles either in distinguishing AD and non-AD disorders or brain injury or related diseases. For example, in connection with dementia/AD we find mention of IFGBP-2 in<ref type="bibr" target="#b24">Tham et al. (1993)</ref>;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pros and cons of FSRBF</head><p>Although we have used FSRBF for discovering genetic markers for AD, the FSRBF algorithm described in Section 3.1 is a general algorithm for feature selection, which judiciously combines the feature selection process and the universal function approximation capability of RBF NN. Therefore, FSRBF can be used for any feature selection task including biological data as well as data where classes are not linearly separable. FSRBF can also be used for function approximation type problems. While selecting features, FSRBF exploits the non-linear interactions among features and also that between the features and the target outputs. This is a unique advantage of FSRBF and that is why it can yield better results compared with several filter-based methods. However, the results of FSRBF depend on the initialization and this dependence may become more prominent when we have many correlated features because FSRBF cannot control the level of redundancy among the set of selected features. Moreover, since the present version of FSRBF uses Euclidean distance in the activation function of the hidden layer nodes, if the data are in really very high dimension, FSRBF may not yield the most desired results. For such datasets a hierarchical version of FSRBF may be developed, which we plan to investigate in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this study, we have used FSRBF, an adapted version of the GFSRBF neural network for selection of plasma signalling proteins that can predict clinical AD. Compared with a state-of-the-art method, FSRBF finds a smaller set of plasma proteins exhibiting comparable power in discriminating Alzheimer's patients from NDC. FSRBF is also found to be very effective in finding a set of plasma signalling proteins that can distinguish incipient AD from MCI. The biological relevance of the selected proteins in AD and MCI is discussed. The utility of the selected proteins is further established using PCA, heat-map and Sammon projections. FSRBF is a general purpose tool and can be used for finding markers for other diseases as well as for non-biological numeric data. Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Architecture of FSRBF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Overview of the approach: F ½f  and C ½f  represent feature count and the highest validation accuracy, H½f  represents number of hidden nodes for C ½f </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Scatter plots of the synthetic datasets. Datasets A, B and C are four variate and the fourth feature is important. Datasets D and E are two variate and both the features are important for classification. The panels (a), (b) and (c) plot the first versus the fourth feature of the datasets A, B and C, respectively. Panels (d) and (e) plot the first versus the second feature of the datasets D and E, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. Change of feature rank assigned by FSRFB, kernelPLS, ReliefF and SVMRFE with increasing number of noisy features. Rank 1 stands for the most important feature and rank 50 for the least important feature. The panels (a), (b), (c) and (d) show the change of rank of the first (important) feature of the dataset D, the second (important) feature of the dataset D, the first (important) feature of the dataset E and the second (important) feature of the dataset E, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.5.</head><figDesc>Fig. 5. (a) Change of training and validation error with increasing number of signalling proteins. (b) The feature importance values (b) of the nine plasma proteins suggested by FSRBF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.6.</head><figDesc>Fig. 6. Performance comparison in terms of classification accuracy % of the nine signalling proteins selected by FSRBF with 18 signalling proteins reported by Ray et al. (2007) using (a) RBF, (b) SVM with linear kernel, (c) SVM with RBF kernel and (d) MLP classifiers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.7.</head><figDesc>Fig. 7. Heat-map of AD training set with our nine selected plasma proteins. The numbers at the bottom of the heat-map represent indices of data samples in the train set. Data sample numbers 1–43 are AD data and from 44 to 83 are non-AD data samples. For ease of understanding, blue numbers represents AD samples and black non-AD samples. The dendrograms shown are constructed using 'correlation' distance and 'average' linkage. The arrangement of the coloured data sample indices, as ordered by the bottom up clustering, reveals that the samples are efficiently clustered into AD and non-AD categories. The names of the proteins are shown on the right of the heat-map (Color version of this figure is available at Bioinformatics online.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.8.</head><figDesc>Fig. 8. Performance comparison of FSRBF, kernelPLS, ReliefF and SVMRFE. (a) Sensitivity, (b) specificity, (c) precision and (d) F-score</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.9.</head><figDesc>Fig. 9. Performance increase of each of the 18 signalling proteins suggested by Ray et al. (2007) by addition of the two newly selected plasma proteins, TGF-b and FAS. The numbers along the horizontal axis show the index of each individual feature in the set of 18 signalling proteins. The dashed line shows the F-score for each of the 18 signalling proteins individually. The solid line indicates the F-score when TGF-b and FAS are added to each of the 18 signalling proteins</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><figDesc>S1b. To visualize how the MCI data are distributed in this 29-dimensional feature space, we have performed PCA and have plotted the 47 MCI data in the domain spanned by top two PCs in Supplementary Figure S4a. The corresponding Sammon plot is shown in Supplementary Figure S4b. Supplementary Figure S4a and b clearly show that the selected 29 proteins naturally form clusters for AD and non-AD specific signatures in MCI samples. Figure 12 depicts the performance versus number of proteins graph for the 29 selected proteins. Observe that the F-score becomes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.10.</head><figDesc>Fig. 10. Scatter plot of 'first test' data using nine selected proteins in (a) 2D principal space and after (b) Sammon mapping to 2D space</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig.11.</head><figDesc>Fig. 11. Frequency count of the features selected for prediction of AD from MCI</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig.12.</head><figDesc>Fig. 12. Performance of the plasma proteins that carry AD specific signature in MCI patients and are selected by FSRBF. The vertical axis represents performance percentage in terms of sensitivity, specificity, precision and F-score</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><figDesc>et al. (2007). To further investigate the biological significance of the two newly selected proteins, TGF-b and FAS, we manually search PubMed and other research articles. Craig-Schapiro et al. (2011) indicate FAS, and Lee et al. (2010) and Town et al. (2008) indicate TGF-b 3 as important for discriminating AD from non-AD samples. Peress and Perillo (1995) have noticed strikingly selective staining of Hirano bodies produced by TGF-b 3. Note that patients with AD are found to have more Hirano bodies than normal persons in the same age group. We also search through integrative multi-species prediction (http://imp.princeton.edu/) interactive web server and find that FAS is related to the protein TNF for AD. These findings strengthen the idea that FAS and TGF-b are important biomarkers for AD. We have reported a set of 29 plasma proteins in Section 4.5 that can single out the MCI patients who will gradually convert to AD. Of these 29 proteins, eight are reported as carrying AD specific signature in Ray et al. (2007). These eight proteins are marked in bold in Figure 11. Of the set of 29 proteins, seven (IL-11, IL-1a, GCSF, TNF-a, RANTES, TGB-b and FAS) are also present in the set of nine proteins. Literature survey</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><figDesc>Eotaxin-3 in Westin et al. (2012), Craig-Schapiro et al. (2011), Hu et al. (2010); IL-12 in Tobinick and Gross (2008), Rentzos et al. (2006); IGFBP-4 in Beilharz et al. (1993); VEGF-B in Eriksson (2013) and TNF-a in Tobinick and Gross (2008). These facts show that the set of 29 plasma proteins suggested by FSRBF may carry AD-specific signature in MCI patients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2505 Bioinformatics, 31(15), 2015, 2505–2513 doi: 10.1093/bioinformatics/btv173 Advance Access Publication Date: 26 March 2015 Original Paper</figDesc><table></table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">S.Agarwal et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Feature selection using radial basis function networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Basak</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mitra</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="297" to="302" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Differential expression of insulin-like growth factor binding proteins (IGFBP) 4 and 5 mRNA in the rat brain after transient hypoxic-ischemic injury</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">J</forename>
				<surname>Beilharz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Brain Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="209" to="215" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Incidence and subtypes of dementia in three elderly populations of central Spain</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">F</forename>
				<surname>Bermejo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurol. Sci</title>
		<imprint>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page" from="63" to="72" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Incidence of dementia, Alzheimer&apos;s disease, and vascular dementia in Italy. The ILSA Study</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Carlo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Geriatr. Soc</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="41" to="48" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Multiplexed immunoassay panel identifies novel CSF biomarkers for Alzheimer&apos;s disease diagnosis and drognosis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Craig-Schapiro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">18850</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Selecting useful groups of features in a connectionist framework</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Chakraborty</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">R</forename>
				<surname>Pal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="381" to="396" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Targeting VEGF-b regulation of fatty acid transporters to modulate human diseases</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Eriksson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">383</biblScope>
			<biblScope unit="page">112</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Serum biomarkers for Alzheimer&apos;s disease: prot discovery</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">C</forename>
				<surname>German</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Pharmacother</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="383" to="389" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using support vector machines</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Guyon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="389" to="422" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Association between CSF biomarkers and incipient Alzheimer&apos;s disease in patients with mild cognitive impairment: a follow-up study</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Hansson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Neurol</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="228" to="234" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Hernandez</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Avila</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Taopathies. Cell. Mol. Life Sci</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="2219" to="2233" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Roles of proteolysis and lipid rafts in the processing of the amyloid precursor protein and prion protein</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">M</forename>
				<surname>Hooper</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochem. Soc. Trans</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="335" to="338" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Novel CSF biomarkers for Alzheimers disease and mild cognitive impairment</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">T</forename>
				<surname>Hu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Neuropatholica</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="669" to="678" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Proteome-based plasma biomarkers for Alzheimer&apos;s disease</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hye</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="3042" to="3050" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">The feature selection problem: traditional methods and a new algorithm</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kira</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">A</forename>
				<surname>Rendell</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="129" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Wrappers for feature subset selection</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kohavi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>John</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="273" to="324" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Overcoming the myopia of inductive learning algorithms with RELIEFF</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Kononenko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="39" to="55" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">TGF-b induces TIAF1 self-aggregation via type II receptor-independent signaling that leads to generation of amyloid b plaques in Alzheimer&apos;s disease</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell Death Dis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">110</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Redundancy-constrained feature selection with radial basis function networks</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">R</forename>
				<surname>Pal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Malpani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WCCI 2012 IEEE World Congress on Computational Intelligence</title>
		<meeting>the WCCI 2012 IEEE World Congress on Computational Intelligence<address><addrLine>Brisbane, Australia, doi</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06-10" />
			<biblScope unit="page" from="10" to="1109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Differential expression of TGF-beta 1, 2 and 3 isotypes in Alzheimer&apos;s disease: a comparative immunohistochemical study with cerebral infarction, aged human and mouse control brains</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">S</forename>
				<surname>Peress</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Perillo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neuropathol. Exp. Neurol</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="802" to="811" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Classification and prediction of clinical Alzheimer&apos;s diagnosis based on plasma signaling proteins</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ray</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1359" to="1362" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Interleukin-12 is reduced in cerebrospinal fluid of patients with Alzheimer&apos;s disease and frontotemporal dementia</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Rentzos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurol. Sci</title>
		<imprint>
			<biblScope unit="volume">249</biblScope>
			<biblScope unit="page" from="110" to="114" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A kernel-based multivariate feature selection method for microarray data classification</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">102541</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Prediction of Alzheimer&apos;s diagnosis using semi-supervised distance metric learning with label propagation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Teramoto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Chem</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="438" to="441" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Insulin-like growth factors and insulin-like growth factor binding proteins in cerebrospinal fluid and serum of patients with dementia of the Alzheimer type</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Tham</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neural Transm. Park. Dis. Dement. Sect</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="165" to="176" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">The importance of neuritic plaques and tangles to the development and evolution of AD</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tiraboschi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1984" to="1989" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Rapid cognitive improvement in Alzheimer&apos;s disease following perispinal etanercept administration</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">L</forename>
				<surname>Tobinick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Gross</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neuroinflammation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="10" to="1186" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Blocking TGF-Smad2/3 innate immune signaling mitigates Alzheimer-like pathology</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Town</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="681" to="687" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">CCL2 is associated with a faster rate of cognitive decline during early stages of Alzheimer&apos;s disease</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Westin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">30525</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Proteomic patterns: their potential for disease diagnosis</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Xiao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Cell. Endocrinol</title>
		<imprint>
			<biblScope unit="volume">230</biblScope>
			<biblScope unit="page" from="96" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<monogr>
		<title level="m" type="main">Neural network for prediction of Alzheimer&apos;s disease</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>