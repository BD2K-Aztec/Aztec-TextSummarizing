
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gene expression Model-based clustering of microarray expression data via latent Gaussian mixture models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">. 21 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Paul</forename>
								<forename type="middle">D</forename>
								<surname>Mcnicholas</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics &amp; Statistics</orgName>
								<orgName type="institution">University of Guelph</orgName>
								<address>
									<postCode>N1G2W1</postCode>
									<settlement>Guelph</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Thomas</forename>
								<forename type="middle">Brendan</forename>
								<surname>Murphy</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">School of Mathematical Sciences</orgName>
								<orgName type="institution">University College Dublin</orgName>
								<address>
									<addrLine>Dublin 4</addrLine>
									<settlement>Belfield</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gene expression Model-based clustering of microarray expression data via latent Gaussian mixture models</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="2705" to="2712"/>
							<date type="published" when="2010">. 21 2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq498</idno>
					<note type="submission">Received on October 31, 2009; revised on August 11, 2010; accepted on August 26, 2010</note>
					<note>[13:22 6/10/2010 Bioinformatics-btq498.tex] Page: 2705 2705–2712 Associate Editor: Martin Bishop Availability: The reduced, preprocessed data that were analysed are available at www.paulmcnicholas.info Contact: pmcnicho@uoguelph.ca</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: In recent years, work has been carried out on clustering gene expression microarray data. Some approaches are developed from an algorithmic viewpoint whereas others are developed via the application of mixture models. In this article, a family of eight mixture models which utilizes the factor analysis covariance structure is extended to 12 models and applied to gene expression microarray data. This modelling approach builds on previous work by introducing a modified factor analysis covariance structure, leading to a family of 12 mixture models, including parsimonious models. This family of models allows for the modelling of the correlation between gene expression levels even when the number of samples is small. Parameter estimation is carried out using a variant of the expectation–maximization algorithm and model selection is achieved using the Bayesian information criterion. This expanded family of Gaussian mixture models, known as the expanded parsimonious Gaussian mixture model (EPGMM) family, is then applied to two well-known gene expression data sets. Results: The performance of the EPGMM family of models is quantified using the adjusted Rand index. This family of models gives very good performance, relative to existing popular clustering techniques, when applied to real gene expression microarray data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Model-based clustering</head><p>Cluster analysis methods are used to find subgroups in a population. Clustering is of particular interest when analysing gene expression data because it can be used to find subgroups that are well distinguished by their expression profiles. A number of clustering techniques are commonly used including agglomerative hierarchical, divisive hierarchical, k-means, k-medoids and modelbased clustering. Model-based clustering is a technique for estimating group membership based on parametric finite mixture models. The density of a parametric finite mixture model can be * To whom correspondence should be addressed.</p><formula>written f (x | π 1 ,...,π G ,θ 1 ,...,θ G ) = G g=1 π g r(x | θ g ), where π g ∈[0,1], such that G g=1 π g = 1</formula><p>, is the probability of membership of subpopulation g, and r(x | θ g ) is the density of a multivariate random variable X with parameters θ g. Overviews of finite mixture models are given by McLachlan and Peel (2000a) and Frühwirth-Schnatter (2006). In the model-based clustering literature, the finite Gaussian mixture model is most commonly used (examples include<ref type="bibr" target="#b8">Fraley and Raftery, 2002;</ref><ref type="bibr" target="#b22">McLachlan et al., 2002;</ref><ref type="bibr" target="#b27">McNicholas and</ref><ref type="bibr">Murphy, 2008, 2010</ref>). The density of a finite Gaussian mixture model is given by,</p><formula>f (x | ϑ) = G g=1 π g φ(x | µ g , g ),</formula><formula>(1)</formula><p>where φ(x | µ g , g ) is the density of a multivariate Gaussian random variable X with mean µ g and covariance matrix g ,</p><formula>and ϑ = (π 1 ,...,π G ,µ 1 ,...,µ G , 1 ,..., G</formula><p>). Note that the Gaussian mixture model has been used within the bioinformatics literature for purposes other than clustering: for example,<ref type="bibr" target="#b24">McLachlan et al. (2006)</ref>apply a two-component mixture model to detect differential gene expression. Gaussian mixture models offer an advantage over other commonly used approaches because the covariance structure can potentially account for correlation between expression levels within an expression profile. Consequently, these models are more flexible than k-means or hierarchical clustering which commonly use Euclidean distance. However, due to the high-dimensional nature of expression data, additional structure needs to be assumed for the covariance matrices, so that the model can be fitted in high-dimensional settings. The MCLUST (<ref type="bibr" target="#b8">Fraley and Raftery, 2002</ref>) approach to model-based clustering, which utilizes eigendecomposed covariance matrices, can only be applied to clustering expression profiles if a diagonal covariance structure is assumed;<ref type="bibr" target="#b37">Yeung et al. (2001)</ref>were able to cluster genes using MCLUST but not expression profiles. By assuming a highly parsimonious but nondiagonal covariance structure, it is possible to cluster expression profiles while allowing for correlation between gene expressions. In general, a structure like that given in Equation (1) can be used to model such data. Then the parameters, and hence group memberships, can be estimated using some variant of the expectation–maximization (EM) algorithm (<ref type="bibr" target="#b5">Dempster et al., 1977</ref>).</p><formula>C C C g = +ψI p C C U g = + C U C g = +ψ g I p C U U g = + g U C C g = g g +ψI p U C U g = g g + U U C g = g g +ψ g I p U U U g = g g + g C, constrained; U, unconstrained.</formula><p>The covariance matrices g can be decomposed to allow the construction of more parsimonious models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Parsimonious Gaussian mixture models</head><p>The factor analysis model (<ref type="bibr" target="#b33">Spearman, 1904</ref>) assumes that a p-dimensional random vector X i can be modelled using a q-dimensional vector of latent factors U i , where q p. The model can be written X i = µ+U i + i , where is a p×q matrix of factor weights, the latent variables U i ∼ N (0,I q ) and i ∼ N (0,), where is a p×p diagonal matrix. Therefore, the marginal distribution of X i is N (µ, +). To illustrate the implications of the covariance matrix attached to this marginal distribution, = +, suppose that X ij and X ik are expression levels from a sample X i. Then, Cov(X ij ,</p><formula>X ik ) = σ jk = q s=1 λ js λ ks for j = k, and Var(X ij ) = σ jj = q s=1 λ 2 js +ψ qq .</formula><p>Hence, the matrix models the covariance between expression levels, and a combination of the and matrices models the variance of expression levels. The factor analysis model allows for the modelling of a high-dimensional non-diagonal covariance matrix with a low number of parameters.<ref type="bibr" target="#b11">Ghahramani and Hinton (1997)</ref>proposed a mixture of factor analysers model given by the finite Gaussian mixture model in Equation (1), with g = g g +. McLachlan and<ref type="bibr" target="#b21">Peel (2000b)</ref>used the more general covariance structure g = g g + g .<ref type="bibr" target="#b34">Tipping and Bishop (1999)</ref>proposed the mixtures of probabilistic principal component analysers model, for which the component covariance matrix is g = g g +ψ g I p .<ref type="bibr" target="#b25">McNicholas and Murphy (2008)</ref>further generalized the factor analysis covariance structure by including the possibility of imposing the constraints:</p><formula>g = , g = and g = ψ g I p .</formula><p>The result of imposing, or not, each of these three constraints is the family of eight parsimonious Gaussian mixture models (PGMMs) that are described in<ref type="figure" target="#tab_1">Table 1</ref>. Each member of this family of models has a number of covariance parameters that is linear in data dimensionality. This is one of the reasons that this family of models is particularly well suited to the analysis of high-dimensional data. The constraints allow for assuming common structure in the component covariance matrix g , if appropriate. By assuming common covariance structure, a more parsimonious model can be used and this can be estimated in a more stable manner. The PGMM family has another significant advantage that is particularly important in applications involving high-dimensional data. When running the alternating expectation-conditional maximization (AECM) algorithm (<ref type="bibr" target="#b29">Meng and van Dyk, 1997</ref>) for these models, it is advantageous to make use of the Woodbury identity (<ref type="bibr" target="#b36">Woodbury, 1950</ref>) to avoid inverting any non-diagonal p×p matrices. Given an n×n matrix A, an n×k matrix H, a k ×k matrix C and a k ×n matrix V, the Woodbury identity states that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Modified factor analysis covariance structure</head><p>The factor analysis covariance structure (cf.<ref type="bibr" target="#b21">McLachlan and Peel, 2000b</ref>) can be further parameterized by writing g = ω g g , where ω g ∈ R + and g = diag{δ 1 ,δ 2 ,...,δ p } such that | g |=1, for g = 1,2,...,G. The resulting covariance structure g = g g +ω g g shall be known as the modified factor analysis covariance structure. Now, this covariance structure can be used within the model-based clustering framework, opening up the possibility of models that are more parsimonious than their PGMM counterparts. Specifically, constraints can be imposed on the parameters g , ω g and g leading to the 12 Gaussian mixture models illustrated in<ref type="figure" target="#tab_2">Table 2</ref>. The family of models in<ref type="figure" target="#tab_2">Table 2</ref>will be referred to as the expanded PGMM (EPGMM) family hereafter.<ref type="figure" target="#tab_2">Table 2</ref>contains a total of four new, parsimonious, models when compared with<ref type="figure" target="#tab_1">Table 1</ref>. Notably, all 12 members of the EPGMM family have a number of covariance parameters that is linear in the dimensionality of the data. Furthermore, the identities given in Equations (3 and 4) can be used for all 12 models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Parameter estimation for the EPGMM family</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Introduction Estimation</head><p>of the model parameters, via the AECM algorithm, is analogous to that of the PGMM parameter estimation procedure described by McNicholas and Murphy (2008). The estimates for the eight pre-existing models are obtained from the PGMM estimates by writing</p><formula>g =| g | 1/p g /| g | 1/p , and then setting ω g =| g | 1/p and g = g /| g | 1/p .</formula><p>However, the derivation of the maximum likelihood estimates of the model parameters for the new models, requires the method of Lagrange multipliers (Lagrange, 1788). Parameter estimates for the CCUU model are derived in Section 2.2.2 and derivations for the other three new models are given at the end of said section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">AECM algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based clustering of microarray expression data</head><formula>g = g = ω g = ω g = I p C C C C CCC g = +ωI p [pq−q(q−1)/2]+1 C C U C CUC g = +ω g I p [pq−q(q−1)/2]+G U C C C UCC g = g g +ωI p G[pq−q(q−1)/2]+1 U C U C UUC g = g g +ω g I p G[pq−q(q−1)/2]+G C C C U CCU g = +ω [pq−q(q−1)/2]+p C C U U – g = +ω g [pq−q(q−1)/2]+[G+(p−1)] U C C U UCU g = g g +ω G[pq−q(q−1)/2]+p U C U U – g = g g +ω g G[pq−q(q−1)/2]+[G+(p−1)] C U C U – g = +ω g [pq−q(q−1)/2]+[1+G(p−1)] C U U U CUU g = +ω g g [pq−q(q−1)/2]+Gp U U C U – g = g g +ω g G[pq−q(q−1)/2]+[1+G(p−1)] U U U U UUU g = g g +ω g g G[pq−q(q−1)/2]+Gp C, constrained, U, unconstrained.</formula><p>incomplete, or are treated as incomplete. In the expectation step (E-step), the expected value of the complete-data log-likelihood (Q, say) is computed, where the complete-data is the missing data plus the observed data. Then in the maximization step (M-step), Q is maximized with respect to the model parameters. In the expectation-conditional maximization (ECM) algorithm (<ref type="bibr" target="#b28">Meng and Rubin, 1993</ref>), the M-step is replaced by a number of conditional maximization (CM) steps. The AECM algorithm (<ref type="bibr" target="#b29">Meng and van Dyk, 1997</ref>) is an extension of the ECM algorithm that permits different specification of the complete-data at each stage. Extensive details on the EM algorithm and variants thereof are given by McLachlan and Krishnan (2008). Since there are two sources of missing data for the EPGMM family, the group memberships and the latent factors, the AECM algorithm is used for parameter estimation. We shall use z ig to denote the group membership of sample i, so that z ig = 1 if sample i is in group g and z ig = 0 otherwise. At the first stage of the algorithm, the complete-data are (x i ,z ig ) and in the E-step the z ig are replaced by their expected values</p><formula>E[Z ig | ˆ π g , ˆ µ g , ˆ g , ˆ g , ˆ ω g ]= ˆ π g φ(x i | ˆ µ g , ˆ g , ˆ g , ˆ ω g ) G h=1ˆπh=1ˆ h=1ˆπ h φ(x i | ˆ µ h , ˆ h , ˆ h , ˆ ω h ) ,</formula><p>to give the expected value of the complete-data log-likelihood, Q 1 say. In the interest of brevity, the expected value of Z ig will be denotedˆzdenotedˆ denotedˆz ig herein. The function Q 1 is then maximized in the CM-step to givê</p><formula>µ g = n i=1ˆzi=1ˆ i=1ˆz ig x i /n g andˆπandˆ andˆπ g = n g /n, where n g = n i=1ˆzi=1ˆ i=1ˆz ig and n = G g=1 n g .</formula><p>At the second stage, the complete-data is (x i ,z ig ,u ig ) and in the E-step the z ig are replaced byˆzbyˆ byˆz ig and the sufficient statistics for the factors U ig are replaced by</p><formula>E[U ig | x i ,µ g , g ,ω g , g ]=β g (x i −µ g ), E[U ig U ig | x i ,µ g , g ,ω g , g ]= I q −β g g +β g (x i −µ g )(x i −µ g ) β g ,</formula><p>respectively, where</p><formula>β g = g ( g g +ω g g ) −1 , to give Q 2 .</formula><p>The CM-step at this second stage will depend on the model. Consider the CCUU model, so that g = and g =. In this case, the expected complete-data log-likelihood Q 2 (,ω g ,) can be written</p><formula>C + 1 2 G g=1 n g plogω −1 g +log| −1 |−ω −1 g tr −1 S g +2ω −1 g tr −1ˆβ−1ˆ −1ˆβ g S g −ω −1 g tr −1 g ,</formula><p>where C is constant with respect to , ω g and ,</p><formula>and g = I q − ˆ β g ˆ + ˆ β g S g ˆ β g .</formula><p>To maximize Q 2 with respect to , ω g and , it is necessary to use the method of Lagrange multipliers. First, form the Lagrange</p><formula>function L(,ω g ,,κ) = Q(,ω g ,)−κ(||−1)</formula><p>. Note that we use κ to denote the Lagrange multiplier to avoid confusion with the elements of the matrix. Differentiating L with respect to , ω −1 g , −1 and κ, respectively, gives the following score functions.</p><formula>S 1 (,ω g ,,κ) = ∂L ∂ = G g=1 n g ω g −1 S g ˆ β g − −1 g ,</formula><formula>S 2 (,ω g ,,κ) = ∂L ∂ω −1 g = n g 2 pω g − tr −1 S g +2tr −1ˆβ−1ˆ −1ˆβ g S g − tr −1 g ,</formula><formula>S 3 (,ω g ,,κ) = ∂L ∂ −1 = 1 2 G g=1 n g −ω −1 g S g +2ω −1 g ( ˆ β g S g ) −ω −1 g g +κ||, S 4 (,ω g ,,κ) = ∂L ∂κ =||−1.</formula><p>Note that S 4 is included for completeness only and solving</p><formula>S 4 ,ω g ,</formula><p>,κ = 0 just returns the constraint ||=1. Now, solving</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.D.McNicholas and T.B.Murphy</head><formula>S 1 ( ˆ new , ˆ ω g , ˆ ,κ) = 0 givesˆnew givesˆ givesˆnew = ⎡ ⎣ G g=1 n g ˆ ω g S g ˆ β g ⎤ ⎦ ⎡ ⎣ G g=1 n g ˆ ω g g ⎤ ⎦ −1 , and solving S 2 ( ˆ new ,( ˆ ω g ) new , ˆ ,κ) = 0 gives ( ˆ ω g ) new = 1 p trˆ−1 trˆ trˆ−1 S g −2ˆnewˆβ−2ˆ −2ˆnew−2ˆnewˆ −2ˆnewˆβ g S g + ˆ new g ( ˆ new ) .</formula><formula>Solving diag{S 3 ( ˆ new ,( ˆ ω g ) new , ˆ new ,κ)}=0 leads tô tô new = 1 n+2κ diag G g=1 n g ( ˆ ω g ) new S g −2ˆnewˆβ−2ˆ −2ˆnew−2ˆnewˆ −2ˆnewˆβ g S g + ˆ new g ( ˆ new )</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ButˆnewButˆ</head><p>Butˆnew is a diagonal matrix with | ˆ new |=1, therefore</p><formula>n+2κ = ⎛ ⎝ p j=1 ξ j ⎞ ⎠ 1 p ,</formula><p>where ξ j is the j-th element along the diagonal of the matrix</p><formula>G g=1 n g ( ˆ ω g ) new S g −2ˆnewˆβ−2ˆ −2ˆnew−2ˆnewˆ −2ˆnewˆβ g S g + ˆ new g ( ˆ new ) .</formula><p>Therefore, it follows that</p><formula>κ = 1 2 ⎡ ⎢ ⎣ ⎛ ⎝ p j=1 ξ j ⎞ ⎠ 1 p −n ⎤ ⎥ ⎦.</formula><formula>(5)</formula><p>The derivations for the other three new models are similar. The estimates in the UCUU case arêarê</p><formula>new g = S g ˆ β g −1 g ,</formula><formula>( ˆ ω g ) new = 1 p trˆ−1 trˆ trˆ−1 S g − ˆ −1ˆnew−1ˆ −1ˆnew g ˆ β g S g , ˆ new = 1 n+2κ diag ⎧ ⎨ ⎩ G g=1 n g ( ˆ ω g ) new S g − ˆ new g ˆ β g S g ⎫ ⎬ ⎭ ,</formula><p>where κ is as defined in Equation (5) but, in this case, ξ j is the j-th element along the diagonal of the matrix</p><formula>G g=1 n g ( ˆ ω g ) new S g − ˆ new g ˆ β g S g .</formula><p>In the CUCU case, the estimate for is derived in a row-by-row fashion asˆλ</p><formula>asˆ asˆλ new i = r i ⎛ ⎝ G g=1 n g ˆ δ g(i) g ⎞ ⎠ −1 , for i = 1</formula><p>,...,p where r i is the i-th row of the matrix</p><formula>G g=1 (n g / ˆ δ g(j) )S g ˆ β g , andˆδandˆ andˆδ g(i)</formula><p>is the i-th element along the diagonal of the matrixˆgmatrixˆ matrixˆg. The other estimates are</p><formula>( ˆ ω) new = 1 p G g=1ˆπ g=1ˆ g=1ˆπ g trˆ−1 trˆ trˆ−1 g S g −2ˆnewˆβ−2ˆ −2ˆnew−2ˆnewˆ −2ˆnewˆβ g S g − ˆ new g ( ˆ new ) , ˆ new g = n g ( ˆ ω) new n g +2κ g diag S g −2ˆnewˆβ−2ˆ −2ˆnew−2ˆnewˆ −2ˆnewˆβ g S g + ˆ new g ( ˆ new ) , κ g = n g 2 ⎡ ⎢ ⎣ 1 ( ˆ ω) new ⎛ ⎝ p j=1 ξ gj ⎞ ⎠ 1 p −1 ⎤ ⎥ ⎦,</formula><p>where ξ gj is the j-th element along the diagonal of the matrix</p><formula>S g −2ˆnewˆβ−2ˆ −2ˆnew−2ˆnewˆ −2ˆnewˆβ g S g + ˆ new g ( ˆ new ) .</formula><p>In the UUCU case, the parameter estimates are given byˆnew byˆ</p><formula>byˆnew g = S g ˆ β g −1 g ,</formula><formula>( ˆ ω) new = 1 p G g=1ˆπ g=1ˆ g=1ˆπ g trˆ−1 trˆ trˆ−1 g (S g − ˆ new g ˆ β g S g ) , ˆ new g = 1 ( ˆ ω) new 1+2κ g /n g diag S g − ˆ newˆβnewˆ newˆβ g S g ,</formula><p>and κ g is as in the CUCU case but with ξ gj given by the j-th element along the diagonal of the matrix</p><formula>S g − ˆ newˆβnewˆ newˆβ g S g .</formula><p>Note that the predicted clustering for each member of the EPGMM family is given by the maximum a posteriori (MAP) classification. That is, the posterior predicted component membership of tissue i is the value of g for whichˆzwhichˆ whichˆz ig is the greatest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Convergence and model selection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Convergence criterion</head><p>Aitken's acceleration (<ref type="bibr" target="#b0">Aitken, 1926</ref>) is used in the analyses herein to estimate the asymptotic maximum of the log-likelihood at each iteration. This allows a decision to be made about whether or not a given AECM algorithm has converged. Aitken's acceleration at iteration t is given by</p><formula>a (t) = l (t+1) −l (t) l (t) −l (t−1) , where l (t+1) , l (t) and l (t−1)</formula><p>are the log-likelihood values from iterations t +1, t and t −1, respectively. The asymptotic estimate of the log-likelihood at iteration t +1 is given by</p><formula>l (t+1) ∞ = l (t) + 1 1−a (t) (l (t+1) −l (t) )</formula><p>(<ref type="bibr">Böhning et al., 1994</ref>). Herein, the stopping criterion proposed by<ref type="bibr" target="#b26">McNicholas et al. (2010)</ref>is used, so that the algorithm can be stopped when l</p><formula>(t+1)</formula><p>∞ −l (t) &lt;&lt;. More specifically, = 0.1 is used. Note that this criterion is very similar to that proposed by<ref type="bibr" target="#b17">Lindsay (1995)</ref>, who suggested stopping when l</p><formula>(t+1) ∞ −l (t+1) &lt;&lt;.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Model selection</head><p>The Bayesian information criterion (BIC<ref type="bibr" target="#b32">Schwarz, 1978</ref>) is used to select the best member of the EPGMM family, in terms of both model and number of factors. Note that the BIC can also be used to select the number of mixture components (cf.<ref type="bibr" target="#b7">Fraley and Raftery, 1999;</ref><ref type="bibr" target="#b25">McNicholas and Murphy, 2008</ref>) but this is not necessary for the analyses herein since we fix G = 2. For a model with parameters θ , the BIC is<ref type="bibr">, 1974</ref>), the integrated completed likelihood (ICL;<ref type="bibr" target="#b3">Biernacki et al., 2000</ref>) and clustering stability (cf. von<ref type="bibr" target="#b35">Luxburg, 2009</ref>). However, we found that the BIC gave a quick solution and generally good clustering results.<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>analysed two microarray gene expression data sets—one on leukaemia data and another on colon tissue samples—using the EMMIX-GENE approach. The first stage of this approach focuses on data reduction where, initially, one-and twocomponent mixtures of t-distributions are fitted to the data. Then a gene is retained only if two conditions are satisfied. One of these conditions is that the minimum cluster size exceeds some prespecified threshold a 1. The other condition concerns the result of a likelihood ratio test, or tests. First, the hypothesis H 0 : G = 1 is tested against H 1 : G = 2 and the gene is retained if −2logλ&gt;a 2 ,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ANALYSES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dimensionality reduction</head><formula>(6)</formula><p>where λ is the likelihood ratio statistic. However, if the condition in Equation (6) is not met then the hypothesis H 0 : G = 2 is tested against H 1 : G = 3 and the gene is retained if the same condition is satisfied, with the same a 2 , for this test statistic λ and at least two of the three components contain at least a 1 tissues. When fitting the two-and three-component mixture models for this purpose, starting values for the component memberships are defined randomly or by using starting values based on k-means clustering results. This whole process represents the first stage of the EMMIX-GENE approach and can be carried out using the select-genes software that accompanies<ref type="bibr" target="#b23">McLachlan et al. (2004)</ref>. For the analyses herein, the select-genes software is used with thresholds a 1 = a 2 = 8, as in<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>, and 50 random and 50 k-means starts.<ref type="bibr" target="#b12">Golub et al. (1999)</ref>presented data on two forms of acute leukaemia: acute lymphoblastic leukaemia (ALL) and acute myeloid leukaemia (AML). Affymetrix arrays were used to collect measurements for 7129 genes on 72 tissues. There were a total of 47 ALL tissues and 25 with AML. The data were sourced from the web site accompanying<ref type="bibr" target="#b23">McLachlan et al. (2004,</ref>www.maths.uq.edu.au/∼gjm/emmix-gene/) and so they had been preprocessed (<ref type="bibr" target="#b6">Dudoit et al., 2002;</ref><ref type="bibr" target="#b22">McLachlan et al., 2002</ref>) as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Leukaemia data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The data</head><p>(1) Genes with expression less than 100 or greater than 16 000 were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">The EPGMM approach</head><p>Treating this as a clustering problem where the form of leukaemia is unknown, all 12 members of the EPGMM family (<ref type="figure" target="#tab_2">Table 2</ref>) were fitted to these data for G = 2, q = 1,...,6 and 10 different random starting values for thê z ig. The BIC for the best q for each of the 12 members of the EPGMM family is given in<ref type="figure" target="#tab_3">Table 3</ref>. The best of these models, in terms of BIC, was a CCUC model with q = 3 latent factors. The chosen model has a nondiagonal covariance structure where the covariance between pairs of genes is equal across different clusters but the variance of each gene is unequal across different clusters (Section 1.2). The MAP classifications arising from the parameter estimates associated with this model are given in<ref type="figure" target="#tab_4">Table 4</ref>; only five tissue samples were misclassified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Hierarchical clustering, k-means, k-medoids and MCLUST</head><p>In addition to the EPGMM technique, several other techniques were applied to these data using the R software (R Development Core Team, 2010). Agglomerative hierarchical clustering was used, with Euclidean distance and three different linkage methods: complete, average and single. The k-means (cf.<ref type="bibr" target="#b13">Hartigan and Wong, 1979</ref>) and k-medoids techniques were also used. In the latter case, the partitioning around medoids (PAM; cf.<ref type="bibr" target="#b15">Kaufman and Rousseeuw, 1990</ref>, Chapter 2) algorithm was used. Finally, in order to compare our model-based clustering approach to the well-established MCLUST approach, we used the mclust package (<ref type="bibr" target="#b7">Fraley and Raftery, 1999</ref>) for the R software. The results, which are summarized in<ref type="figure" target="#tab_5">Table 5</ref>, give the Rand and adjusted Rand indices as measures of class agreement. The Rand index (<ref type="bibr" target="#b30">Rand, 1971</ref>) is based on pairwise agreements and<ref type="figure" target="#tab_5">Table 5</ref>disagreements, and the adjusted Rand index (<ref type="bibr" target="#b14">Hubert and Arabie, 1985</ref>) is effectively the Rand index corrected for random chance. These indices reveal that the best of the non-model-based approaches was k-means clustering, with an adjusted Rand index of 0.187. In fact, k-means clustering narrowly outperformed mclust on these data, but the EPGMM model with the greatest BIC (CCUC, q = 3) was the best model overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.D.McNicholas and T.B.Murphy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">The EMMIX-GENE approach McLachlan et al. (2002)</head><p>analysed the same data using the EMMIX-GENE approach with four random and four k-means starts in the first stage, which reduced the number of genes to 2015. In the second stage, a mixture of 40 normal distributions with isotropic covariance structure was fitted to the 2015 genes. Two of these groups (Groups 1 and 3) provided clusterings that were most similar to the type of leukaemia—of course, in a real clustering scenario this could not be established. A two-component mixture of factor analysers, with q = 6 factors, was fitted to the data using the genes from Groups 1 and 3, respectively. Using the genes from Group 1 led to the misclassification of 13 tissues and using those from Group 3 led to the misclassification of six tissues. Note that<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>did not specify how many different random starts were used but, based on other analyses, it seems likely that 50 random and 50 k-means starts were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Two other approaches</head><p>In addition to the EMMIX-Gene approach,<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>used two other approaches to cluster the leukaemia tissues. In both cases, the first stage was identical to that described in Section 3.2.4. The first alternative approach was to cluster the tissues based on the 40 fitted group means and the top 50 of the 2015 genes. Fitting a two-component mixture of factor analysers with q = 8 factors to these data, using 50 random and 50 k-means starts, led to the misclassification of just one tissue. The second alternative approach was to base the analysis on the top 50 genes. Fitting a two-component mixture of factor analysers, with q = 8 factors to these data, using 50 random and 50 k-means starts, led to the misclassification of 10 tissues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.6">Comments</head><p>The EPGMM approach gave very good clustering performance when applied to the leukaemia data. This approach used 10 random starts and led to the misclassification of just five tissues. This performance far exceeds that of agglomerative hierarchical clustering, k-means clustering, PAM and MCLUST. In fact, the best of all of these techniques had an adjusted Rand index of 0.187, while the best EPGMM model had an adjusted Rand index of 0.738. Although, in one instance, one of theIn this latter case, the choice of the number of clusters (40) was validated in some sense by the fact that two of the groups give classifications that were similar to the true leukaemia type. In fact, as mentioned by<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>, an objective technique for choosing this number is not possible since genes cannot be assumed to be independently distributed within a tissue sample. Furthermore, it is quite likely that the number of factors q was selected, in each case, to give the best classification. This could be done objectively, as in Section 3.2.2, using the BIC. Finally, any comparison between the EPGMM approach and the approaches of<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>would have to be taken in context with the fact that different subsets of the 3731 genes are used in each case.<ref type="bibr" target="#b2">Alon et al. (1999)</ref>presented gene expression data on 62 colon tissue samples, of which 40 were tumours and the remaining 22 were normal. Affymetrix arrays were used to collect measurements for 6500 gene expressions on all 62 tissues. Following<ref type="bibr" target="#b2">Alon et al. (1999) and</ref><ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>, only the 2000 genes with the highest minimal intensity are focused upon. The data were again sourced from the web site mentioned in Section 3.2.1 and, this time, the only preprocessing was the taking of natural logarithms, followed by normalization. Application of the select-genes software, with the settings specified in Section 3.1, led to the reduction of the number of genes from 2000 to just 461.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Colon data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">The data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">The EPGMM approach</head><p>Treating this as a clustering problem where the type of tissue is unknown, all 12 members of the EPGMM family (<ref type="figure" target="#tab_2">Table 2</ref>) were fitted to these data for G = 2, q = 1,...,10 and 10 different random starting values for thê z ig. The BIC for the best q for each of the 12 members of the EPGMM family is given in<ref type="figure" target="#tab_6">Table 6</ref>. The best of these models, again in terms of BIC, was a CCUC model with q = 6 latent factors; the covariance structure in this model is the same as that chosen for the leukaemia data (Section 3.2.2). The MAP classifications given by the parameter estimates associated Page: 2711 2705–2712with this model are given in<ref type="figure" target="#tab_7">Table 7</ref>; only five tissue samples were misclassified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based clustering of microarray expression data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Hierarchical clustering, k-means, k-medoids and MCLUST</head><p>In addition to the EPGMM technique, the methods used in Section 3.2.3 were run on these colon data using the R software. The results, which are summarized in<ref type="figure" target="#tab_8">Table 8</ref>, suggest that the best of the non-model-based approaches was PAM, with an adjusted Rand index of 0.218. This time, mclust outperformed k-means clustering but PAM outperformed mclust. The EPGMM model with the greatest BIC (CCUC, q = 6) was the best model, misclassifying just five tissues based on 10 random starts.<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>Using various techniques,<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>found five different clusterings of these data. However, none of these clusterings corresponded to the tissue type. While, once again, the EPGMM results are not directly comparable with those of<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>, it is interesting to look at the second best of the EPGMM models. The second best of the EPGMM models, in terms of BIC, was a CCUU model with q = 7 latent factors. Note that this is one of the four new models that were introduced herein and, again, this model has equal covariance between pairs of genes; however, the variance structure is more complex than for the CCUC model. The MAP classification given by the parameter estimates associated with this CCUU model do not separate tumour from normal tissue. However, they are similar to what<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>call C 1 , in that they seem sensible when one considers that there was a change of protocol during the experiment (<ref type="bibr" target="#b10">Getz et al., 2000;</ref><ref type="bibr" target="#b22">McLachlan et al., 2002</ref>). Specifically, tissues 1–11 and 41–51 were all extracted from the first 11 patients using a poly detector, while the remaining samples were taken from the other patients using total extraction of RNA. Looking at the tissues by extraction method, rather than by tissue type, leads to the estimated classifications given in<ref type="figure" target="#tab_9">Table 9</ref>; only eight of the tissues were misclassified by this CCUU model when the data are considered by extraction method.The results from applying the other methods to the colon data (cf.<ref type="figure" target="#tab_8">Table 8</ref>), can also be viewed in terms of extraction method, rather than tissue type. These results are given, along with our best CCUU model, in<ref type="figure" target="#tab_0">Table 10</ref>. From this table, it is clear that our CCUU model gives the best clustering performance of all of the approaches. Furthermore, the hierarchical (complete and average linkage), k-means, and mclust clustering results are all better when viewed in terms of extraction method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Correspondence with</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">Comments</head><p>The EPGMM approach gave very good clustering performance when applied to the colon data. Our approach led to the misclassification of just five tissues, when these data were viewed by tissue type. This performance far exceeded that of all of the other techniques that were used—in fact, the performance of these other approaches was surprisingly poor, with only PAM giving better than random classifications (cf.<ref type="figure" target="#tab_8">Table 8</ref>). This phenomenon is partly explained when one looks at the classifications by extraction method, rather than by tissue type (cf.<ref type="figure" target="#tab_0">Table 10</ref>). In this case, only one method performed worse than random, which might suggest that techniques such as k-means clustering and MCLUST were picking up extraction method more-so than tissue type. That said, the performance of these methods was only slightly better than random which suggests that the restrictive cluster shapes imposed by kmeans clustering and MCLUST were not at all suited to the data. On the other hand, the best of the new EPGMM models gave the based clustering performance, misclassifying just eight samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>The EPGMM family of models has been shown to give good clustering performance when applied to gene expression microarray data. These applications, concerning leukaemia and colon tissue data, respectively, were conducted as genuine clustering examples. That is, no information on the true tissue classification was used for parameter estimation or model selection. In fact, this information was only used to assess the performance of the selected model. In this context, the clustering performance of the EPGMM family can be looked upon favourably. Moreover, the performance of the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.D.McNicholas and T.B.Murphy</head><p>EPGMM family on both data sets far exceeded that of a number of popular clustering techniques, including agglomerative hierarchical clustering and k-means clustering. However, like the techniques of<ref type="bibr" target="#b22">McLachlan et al. (2002)</ref>, the EPGMM family relies on multiple random starts. In addition to the obvious drawback of the sensitivity of results to the starting values, there is the computation time that is required. Furthermore, there is no guarantee that increasing the number of random starts will lead to better clustering results. This is due, in the main, to the fact that models with greater BIC do not necessarily give better clustering performance. This phenomenon has been observed previously and work into finding better model selection techniques is ongoing. That said, the EPGMM family did perform well in the analyses in Section 3, based on random starting values and using the BIC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>The EPGMM family of mixture models has been introduced and used for the model-based clustering of gene expression microarray data. This family of models is an extension of the PGMM family of models which, in turn, is an extension of the mixtures of factor analysers model. The EPGMM family of models are very well suited to the analysis of high-dimensional data. The reason for this suitability is 3-fold. First, each member of the EPGMM family has a number of covariance parameters that is linear in the data dimensionality. Second, as shown herein, the Woodbury identity can be used to avoid the inversion of any non-diagonal p×p matrices, leading to efficient computation. Thirdly, as shown by<ref type="bibr" target="#b26">McNicholas et al. (2010)</ref>in the context of the PGMM family, these models are 'trivially parallelizable', opening up the possibility of even more efficient parameter estimation using parallel computing. The EPGMM family was applied to two well-known gene expression microarray data sets. In both cases, the EPGMM family performed well and gave much better clusterings than several popular clustering techniques. Herein, we took G = 2 for all of the analysis but future work will focus on the selection of G.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>The EM algorithm is an iterative technique for finding maximum likelihood estimates when data are Page: 2707 2705–2712</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>[13:</head><figDesc>22 6/10/2010 Bioinformatics-btq498.tex] Page: 2708 2705–2712</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Page: 2709 2705–2712 Model-based clustering of microarray expression data given by BIC = 2l(x, ˆ θ)−mlogn, where l(x, ˆ θ) is the maximized log-likelihood, ˆ θ is the maximum likelihood estimate of θ, m is the number of free parameters in the model and n is the number of observations. The effectiveness of the BIC for choosing the number of factors in a factor analysis model has been established by Lopes and West (2004), while McNicholas et al. (2010) provide practical evidence that the BIC performs well in choosing the number of factors for the PGMM family of models. A number of other model selection criteria could be used including the Akaike information criterion (AIC; Akaike</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>.</head><figDesc>Summary results for all of the clustering techniques that were applied to the leukaemia data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1. The covariance structure of each parsimonious Gaussian mixture model—note that the UCU, UUC and UUU models previously existed under different names, as described in Section 1.2 g = g = Isotropic Covariance structure</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>(A+HCV) −1 = A −1 −A −1 H(C −1 +VA −1 H) −1 VA −1. (2) Setting H = , V = , A = and C = I q in Equation (2) gives ( + ) −1 = −1 − −1 (I q + −1 ) −1 −1. (3)</figDesc><table>Now, the left-hand side of Equation (3) involves inversion of a 
p×p matrix, but the right-hand side leaves only diagonal and q×q 
matrices to be inverted. This is a major computational advantage 
when modelling expression data, since q p. A related identity for 
the determinant of the covariance matrix is given by 

| +|=||/|I q − ( +) −1 |. 
(4) 

Equations (3 and 4) are used by McLachlan and Peel (2000b) for the 
mixtures of factor analysers model and by McNicholas and Murphy 
(2008) and McNicholas et al. (2010) for the PGMM family. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2. The covariance structure, number of covariance parameters and nomenclature for each member of the EPGMM family, along with the name of the equivalent member of the PGMM family where applicable EPGMM nomenclature PGMM equivalent Covariance structure Number of covariance parameters</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 3. The BIC for the best q for each of the 12 members of the EPGMM family for the leukaemia data</figDesc><table>Model 
q 
BIC 
Model 
q 
BIC 

CCCC 
3 
−411 646.50 
CCUC 
3 
−411 566.29 

UCCC 
1 
−416 954.56 
UCUC 
1 
−416 803.57 

CCCU 
4 
−414 615.22 
CCUU a 
5 
−413 207.29 

UCCU 
1 
−423 354.79 
UCUU a 
1 
−422 089.38 

CUCU a 
4 
−413 966.90 
CUUU 
5 
−413 978.04 

UUCU a 
1 
−423 933.46 
UUUU 
1 
−423 532.04 

a One of the four new models. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 4.</figDesc><table>Estimated group membership for the best EPGMM model for the 
leukaemia data 

1 
2 

ALL 
42 
0 
AML 
5 
25 

(2) Genes with expressions satisfying max/min≤5 and 
max−min≤500 were removed. 

(3) The natural logarithm was taken. 

Following this preprocessing, a total of 3731 genes remained. This 
number was further reduced to 2030 following application of the 
select-genes software (cf. Section 3.1). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 6. The BIC for the best q for each of the 12 members of the EPGMM family for the colon data</figDesc><table>Model 
q 
BIC 
Model 
q 
BIC 

CCCC 
4 
−79 085.73 
CCUC 
6 
−70 937.72 

UCCC 
3 
−77 267.65 
UCUC 
3 
−77 268.16 

CCCU 
8 
−71 064.11 
CCUU a 
7 
−71 063.71 

UCCU 
3 
−77 310.19 
UCUU a 
4 
−77 532.97 

CUCU a 
8 
−71 609.10 
CUUU 
8 
−71 631.35 

UUCU a 
2 
−78 458.83 
UUUU 
2 
−78 306.33 

a One of the four new models. 

approaches of McLachlan et al. (2002) returned a better predicted 
classification, it is difficult to make a direct comparison to the 
EPGMM approach. This difficulty arises because the EPGMM 
approach is a genuine clustering approach, while the methods 
described in Sections 3.2.4 and 3.2.5 assumed, to some extent, 
knowledge of the truth. This knowledge was clearly used in the 
analyses described in Section 3.2.4 but was used in a less obvious 
fashion in the analyses given in Section 3.2.5. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 7.</figDesc><table>Estimated group membership for the best EPGMM model for the 
colon data 

1 
2 

Tumour 
37 
3 
Normal 
2 
20 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Table 8.</figDesc><table>Summary results for all of the clustering techniques that were 
applied to the colon data 

BIC 
Rand index Adjusted Rand index 

Hierarchical (complete) – 
0.497 
−0.018 

Hierarchical (average) 
– 
0.526 
−0.005 

Hierarchical (single) 
– 
0.526 
−0.014 

k-means 
– 
0.494 
−0.016 

PAM 
– 
0.611 
0.218 
MCLUST (VII) 
−81 124.36 0.500 
−0.006 

EPGMM (CCUC, q = 6) −70 937.72 0.849 
0.697 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>Table 9.</figDesc><table>Estimated group membership for the second best EPGMM model 
for the colon data 

1 
2 

Poly detector 
19 
3 
Total extraction of RNA 
5 
35 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><figDesc>Table 10.</figDesc><table>Summary results, by extraction method, for all of the clustering 
techniques that were applied to the colon data 

BIC 
Rand index Adjusted Rand index 

Hierarchical (complete) – 
0.518 
0.024 
Hierarchical (average) 
– 
0.545 
0.035 
Hierarchical (single) 
– 
0.526 
−0.014 

k-means 
– 
0.526 
0.048 
PAM 
– 
0.581 
0.158 
MCLUST (VII) 
−81 124.36 0.526 
0.045 
EPGMM (CCUU, q = 7) −71 063.71 0.772 
0.542 

</table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2705 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors gratefully acknowledge the insightful and helpful comments of three anonymous reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">On Bernoulli&apos;s numerical solution of algebraic equations</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Aitken</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. Edinb</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="289" to="305" />
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Akaike</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Alon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="6745" to="6750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Assessing a mixture model for clustering with the integrated completed likelihood</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Biernacki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="719" to="725" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">The distribution of the likelihood ratio for mixtures of densities from the one-parameter exponential family</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Böhning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Inst. Stat. Math</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="373" to="388" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">P</forename>
				<surname>Dempster</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Comparison of discrimination methods for the classification of tumors using gene expression data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dudoit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">MCLUST: software for model-based cluster analysis</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Fraley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Raftery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Classif</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="297" to="306" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Model-based clustering, discriminant analysis, and density estimation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Fraley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Raftery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="611" to="631" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">Finite Mixture and Markov Switching Models</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Frühwirth-Schnatter</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Coupled two-way clustering analysis of gene microarray data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Getz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="12079" to="12084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">The EM algorithm for factor analyzers</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Ghahramani</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<pubPlace>Toronto</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">R</forename>
				<surname>Golub</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="531" to="537" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A k-means clustering algorithm</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Hartigan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hubert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Arabie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Classif</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<monogr>
		<title level="m" type="main">Finding Groups in Data: An Introduction to Cluster Analysis</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Kaufman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Rousseeuw</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Méchanique Analitique</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Lagrange</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chez le Veuve Desaint</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Mixture models: theory, geometry and applications</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">G</forename>
				<surname>Lindsay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSFCBMS Regional Conference Series in Probability and Statistics</title>
		<meeting><address><addrLine>Hayward, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Mathematical Statistics</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian model assessment in factor analysis</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">F</forename>
				<surname>Lopes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>West</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sin</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="41" to="67" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Krishnan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>The. EM Algorithm and Extensions. 2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Finite Mixture Models</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Peel</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Mixtures of factor analyzers</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Peel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Machine Learning</title>
		<editor>P. Langley</editor>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="599" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A mixture model-based approach to the clustering of microarray expression data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="412" to="422" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">Analyzing Microarray Gene Expression Data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Wiley</publisher>
			<pubPlace>Hoboken, New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">A simple implementation of a normal mixture approach to differential gene expression in multiclass microarrays</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1608" to="1615" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Parsimonious Gaussian mixture models</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Mcnicholas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">B</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="285" to="296" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Model-based clustering of longitudinal data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Mcnicholas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">B</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can. J. Stat</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="153" to="168" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Serial and parallel implementations of model-based clustering via parsimonious Gaussian mixture models</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Mcnicholas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="711" to="723" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation via the ECM algorithm: a general framework</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<forename type="middle">L</forename>
				<surname>Meng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">B</forename>
				<surname>Rubin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="267" to="278" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">The EM algorithm — an old folk song sung to a fast new tune (with discussion)</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<forename type="middle">L</forename>
				<surname>Meng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Van Dyk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="511" to="567" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">M</forename>
				<surname>Rand</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Development</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Core</forename>
				<surname>Team</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Schwarz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">The proof and measurement of association between two things</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Spearman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Psychol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="72" to="101" />
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Mixtures of probabilistic principal component analysers</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">E</forename>
				<surname>Tipping</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="443" to="482" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Clustering stability: an overview. Found</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Von Luxburg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="235" to="274" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<monogr>
		<title level="m" type="main">Inverting Modified Matrices. Statistical Research Group, Memorandum Report no. 42</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Woodbury</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
			<pubPlace>Princeton, New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Model-based clustering and data transformations for gene expression data</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">Y</forename>
				<surname>Yeung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="977" to="987" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>