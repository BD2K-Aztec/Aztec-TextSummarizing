
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ccSVM: correcting Support Vector Machines for confounding factors in biological data classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Limin</forename>
								<surname>Li</surname>
							</persName>
							<email>limin.li@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning and Computational Biology Research Group</orgName>
								<orgName type="institution">Max Planck Institutes Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an 710049</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Barbara</forename>
								<surname>Rakitsch</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning and Computational Biology Research Group</orgName>
								<orgName type="institution">Max Planck Institutes Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Karsten</forename>
								<surname>Borgwardt</surname>
							</persName>
							<email>karsten.borgwardt@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Machine Learning and Computational Biology Research Group</orgName>
								<orgName type="institution">Max Planck Institutes Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ccSVM: correcting Support Vector Machines for confounding factors in biological data classification</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="page" from="342" to="348"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr204</idno>
					<note>[20:21 6/6/2011 Bioinformatics-btr204.tex] Page: i342 i342–i348 BIOINFORMATICS Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Classifying biological data into different groups is a central task of bioinformatics: for instance, to predict the function of a gene or protein, the disease state of a patient or the phenotype of an individual based on its genotype. Support Vector Machines are a wide spread approach for classifying biological data, due to their high accuracy, their ability to deal with structured data such as strings, and the ease to integrate various types of data. However, it is unclear how to correct for confounding factors such as population structure, age or gender or experimental conditions in Support Vector Machine classification. Results: In this article, we present a Support Vector Machine classifier that can correct the prediction for observed confounding factors. This is achieved by minimizing the statistical dependence between the classifier and the confounding factors. We prove that this formulation can be transformed into a standard Support Vector Machine with rescaled input data. In our experiments, our confounder correcting SVM (ccSVM) improves tumor diagnosis based on samples from different labs, tuberculosis diagnosis in patients of varying age, ethnicity and gender, and phenotype prediction in the presence of population structure and outperforms state-of-the-art methods in terms of prediction accuracy. Availability: A ccSVM-implementation in MATLAB is available from</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Several of the most intensively studied problems in computational biology are classification tasks: for instance, predicting the function of a gene, the disease state of a patient, the reaction of a patient to a therapy and the phenotype of an individual based on its genotype. The abstract task is to predict the class y of an biological subject based on its features x. Emerging and existing high-throughput technologies allow us to measure the features of genes, proteins and individuals at an unprecedented resolution and scale, and the hope is that this rich knowledge will lead to ever more accurate data classification. One of the most prominent and most successful classification algorithms are Support Vector Machines (SVMs) (<ref type="bibr" target="#b6">Cortes and Vapnik, 1995;</ref><ref type="bibr" target="#b20">Schölkopf and Smola, 2002</ref>). They are based on the idea to separate objects from two classes by means of a hyperplane; new test objects are then predicted to belong to one of these two classes depending on which half-space they are * To whom correspondence should be addressed. located in. Their popularity is due to several reasons: first, SVMs have shown excellent prediction accuracy in many studies (<ref type="bibr" target="#b16">Noble, 2006</ref>). Second, SVMs can be directly applied to structured data, such as strings (<ref type="bibr" target="#b12">Leslie et al., 2002</ref>) or graphs (<ref type="bibr" target="#b2">Borgwardt et al., 2005</ref>), which are abundant in bioinformatics. Third, SVMs allow for straightforward data integration of several data types (<ref type="bibr" target="#b11">Lanckriet et al., 2004</ref>). However, SVMs suffer from one limitation: it is unclear how to correct for confounding variables in SVM predictions. According to Meinert (<ref type="bibr" target="#b14">Meinert and Tonascia, 1986</ref>), a confounder is defined as a variable which is related to two factors of interest, and which falsely obscures or accentuates the relationship between them. In this article, we present an SVM which can correct for observed confounding variables. The detrimental effects of confounders are observable in many classification tasks in molecular biology, as illustrated by the following two examples: one may want to predict the phenotypes of plants based on their genotype, typically represented by single nucleotide polymorphisms that represent sequence variation in an individual. In this task, population structure, that is systematic ancestry differences between plants with different phenotypes, may have a confounding effect on the prediction (<ref type="bibr" target="#b19">Price et al., 2010</ref>). For instance, if there is a correlation between population structure and phenotype, the classifier may rely on SNPs that correlate with population structure, and subsequently, its predictions may be wrong on datasets from different geographic origins where the phenotype–population correlation is less pronounced or not present. Another example is drug treatment response in patients from gene expression profiles. Confounding factors may be the age, the gender or the ethnicity of the patients, each of which may correlate with the treatment response and the expression levels of certain genes (<ref type="bibr" target="#b8">Holsboer, 2008</ref>). When predicting on patients with different age, sex or ethnic background, the learnt classifier may poorly generalize. Our goal in this article is to define a confounder-correcting Support Vector Machine (ccSVM) that removes the confounding side information to the largest extent possible. To achieve this, we strive to make the classifier base its prediction on features that do not correlate with the confounding variable. The remainder of this article is structured as follows. In Section 2, we present the ccSVM (Section 2.3), and the classifier (Section 2.1) and the statistical dependence measure (Section 2.2) it is based upon. We prove that the ccSVM can be computed highly efficiently with existing software packages in Section 2.4. In Section 3, we show that our method improves upon several state-of-the-art classifiers in tumor diagnosis (Section 3.3), tuberculosis diagnosis (Section 3.4)<ref type="bibr">[20:21 6/6/2011 Bioinformatics-btr204.tex]</ref>Page: i343 i342–i348</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ccSVM</head><p>and plant phenotype prediction (Section 3.5). In Section 4, we summarize our findings and give an outlook to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ccSVM APPROACH</head><p>We first introduce the SVM (Section 2.1) and the Hilbert-Schmidt Independence Criterion (HSIC) (Section 2.2), that is the measure of statistical dependence that we use to then define our confoundercorrecting SVM (Section 2.3). In Section 2.4, we show how to efficiently solve the ccSVM optimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SVMs</head><p>SVMs are supervised learning methods (<ref type="bibr" target="#b20">Schölkopf and Smola, 2002;</ref><ref type="bibr" target="#b24">Vapnik and Chervonenkis, 1974</ref>) that are widely used in molecular biology (<ref type="bibr" target="#b21">Schölkopf et al., 2004</ref>). The SVM takes a set of input data with corresponding class labels, and predicts to which class a new input belongs. Suppose we are given the data</p><formula>(x 1 ,y 1 ),··· ,(x m ,y m )</formula><p>, where x i is an observation and y i is its class label (+1 or −1). The original SVM assumes the data are separable by a hyperplane and obtains this hyperplane by maximizing the margin, that is the minimum distance between the hyperplane and points from each class. Once the hyperplane is learnt from the training data, it can be used to predict the class label of new test points. Suppose the hyperplane is in the form of f (x) = w T x+b, then the model is as follows: min w∈R n ,b∈R</p><formula>||w|| 2 (1)</formula><p>subject to y i (w,x i +b) ≥ 1</p><formula>(2)</formula><p>By considering the case when data are non-separable, a soft margin SVM was proposed to punish the training errors as follows (<ref type="bibr" target="#b6">Cortes and Vapnik, 1995</ref>):</p><formula>min w∈R n ,b∈R,ξ∈R m ||w|| 2 +C m i=1 ξ i (3) subject to y i (w,x i +b) ≥ 1−ξ i ξ i ≥ 0,</formula><formula>(4)</formula><p>where C determines the trade-off between margin maximization and training errors minimization, and ξ i is the term by which the object x i violates the inequality (2). Once w and b are obtained, one can predict the class label for a new observation x by the decision function: sgn(w T x+b). The dual problem of (3) is</p><formula>max α ⎧ ⎨ ⎩ − 1 2 m i=1 m j=1 y i y j α i α j x T i x j + m i=1 α i ⎫ ⎬ ⎭ (5)</formula><p>under the constraints of m i=0 y i α i = 0,</p><formula>0 ≤ α i ≤ C, for i = 1,...,m (6)</formula><p>The Karush–Kuhn–Tucker conditions (<ref type="bibr" target="#b10">Kuhn and Tucker, 1951</ref>) imply that w =</p><formula>n i=1 y i α i x i .</formula><p>Thus, after we obtain α i by solving (5), the decision function will be sgn</p><formula>m i=1 y i α i x T i x+b .</formula><p>The kernel trick is to replace x T i x j by k(x i ,x j ) = φ(x i ) T φ(x j ) in (5), where k(x,x ) is a kernel function such that its discretization K ij = k(x i ,x j ) is a positive definite matrix. The decision function can then be represented as sgn</p><formula>m i=1 y i α i k(x i</formula><p>,x)+b .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">HSIC</head><p>The HSIC is a measure of statistical independence (<ref type="bibr" target="#b7">Gretton et al., 2005</ref>). Intuitively, HSIC can be thought of as a squared correlation coefficient between two random variables x and z computed in feature spaces F and G. In more detail, let x be a random variable from the domain X and z a random variable from the domain Z. Let F and G be feature spaces on X and Z with associated kernels k : X ×X → R and l : Z ×Z → R. If we draw pairs of samples (x,z) and (x ,z ) from x and z according to a joint probability distribution p (x,z) , then the HSIC can be computed in terms of kernel functions via:</p><formula>HSIC(p (x,z) ,F,G) = E x,x ,z,z [k(x,x )l(z,z )] (7) +E x,x [k(x,x )]E z,z [l(z,z )] −2E x,z [E x [k(x,x )]E z [l(z,z )]], (8)</formula><p>where E is the expectation operator. The empirical estimator of HSIC for a finite sample of points X and Z from x and z with p (x,z) was shown in<ref type="bibr" target="#b7">Gretton et al. (2005)</ref>to be HSIC((X,Z),F,G) ∝ tr(KHLH),</p><formula>(9)</formula><p>where tr is the trace of the products of the matrices, H is a centering matrix</p><formula>H ij = δ (i,j) − 1 m (where δ (i,j) = 1 if i = j and δ (i,j) = 0 otherwise), K and L</formula><p>are the kernel matrices on the two random variables of size m×m and m is the number of observations. The larger HSIC, the more likely it is that X and Z are not independent from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The ccSVM</head><p>Via HSIC we can now define an SVM that can use side information to avoid confounding. Suppose m samples with their feature vectors (x 1 ,...,x m ), class labels (y 1 ,...,y m ) and side information (z 1 ,...,z m ) are given. x i is a n-dimensional column vector representing the features of sample i, y i ∈{−1,+1} is the class label for x i and z i is the some kind of side information on object i, e.g. region, country, age, gender, lab membership or population structure. L ∈ R m×m is a predefined kernel matrix which is generated based on a kernel l on the side information, that is L ij = l(z i ,z j ). We call L the side information kernel matrix. We propose to obtain a classifier by minimizing the following objective function: min</p><formula>subject to y i (w,x i +b) ≥ 1 K ij ==w x i ,w x j ,</formula><formula>(11)</formula><p>where represents the element-wise product of two vectors. The objective function includes two terms. To minimize the first term is to maximize the classifier margin, as in a standard SVM. The second term tr(KHLH) is the HSIC, which measures the independence between two kernels, the reweighted kernel matrix K and side information kernel matrix L. Here the reweighted kernel K is the kernel after reweighting each feature by its weight in w. To minimize HSIC is to make the dependence between the reweighted kernel matrix and the side information kernel matrix as small as possible. In other words, besides maximizing the margin, the ccSVM also tries to weaken the effect of the side information on the weight vector w of the classifier. It rewards solutions in which the input data—after being reweighted by weight vector w—are as independent as possible from the side information, thereby favoring a solution that does not rely on the side information. A constant λ&gt;0 determines the trade-off between margin maximization and dependence minimization. Note that in practice, a separating hyperplane may not exist. A possible soft margin classifier can be obtained by minimizing the following objective function:</p><formula>min w∈R n ,b∈R,ξ∈R m ||w|| 2 +λtr(KHLH)+C m i=1 ξ i (12) subject to y i (w,x i +b) ≥ 1−ξ i K ij ==w x i ,w x j ξ i ≥ 0.</formula><formula>(13)</formula><p>Two constants C and λ determine the trade-off among margin maximization, dependence minimization and training error minimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Transformation into SVM problem with rescaled input</head><p>Next, we show how to solve the ccSVM optimization problem (12) by rescaling the input of a standard SVM. For this purpose, we denote HLH by˜Lby˜ by˜L, and we define</p><formula>w = (w 1 ,...,w n ) T and x i = (x 1i ,...,x ni ) T .</formula><p>Then HSIC in (12) can be written as</p><formula>tr(KHLH) = tr(K ˜ L) = m i,j=1˜L j=1˜ j=1˜L ij w x i ,w x j = m i,j=1˜L j=1˜ j=1˜L ij n k=1 w 2 k x ki x kj = n k=1 w 2 k m</formula><formula>n k=1 w 2 k l k</formula><p>Thus, the objective function in (12) becomes</p><formula>n k=1 w 2 k +λ n k=1 w 2 k l k +C m i=1 ξ i = n k=1 w 2 k (1+λl k )+C m i=1 ξ i Let˜w Let˜ Let˜w k = w k 1+λl k (15) and˜x and˜ and˜x ki = x ki √ 1+λl k (16)</formula><p>for k = 1,...,n. Denote˜wDenote˜</p><formula>Denote˜w = ( ˜ w 1 ,..., ˜ w n ) T and˜xand˜ and˜x i = (˜ x 1i ,..., ˜ x ni ) T .</formula><p>Then the optimization problem (12) becomes:</p><formula>miñ miñ w∈R n ,b∈R,ξ∈R m ||˜w||||˜ ||˜w|| 2 +C m i=1 ξ i (17) subject to y i ( ˜ w, ˜ x i +b) ≥ 1−ξ i ξ i ≥ 0.</formula><formula>(18)</formula><p>Interestingly, the optimization problem (17) with the constraints in (18) is the standard SVM, which can be solved using libsvm (<ref type="bibr" target="#b5">Chang and Lin, 2001</ref>) or other SVM software. Thus, in order to solve the ccSVM problem (12), one only needs to first rescale each feature according to the formula (16) and then solve a standard SVM problem (17). Note that Equation (17) uses a linear kernel˜Xkernel˜ kernel˜X T ˜ X, where˜Xwhere˜ where˜X = (˜ x 1 ,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>In our experiments, we examine three different applications of the ccSVM in bioinformatics: microarray cross-platform comparability on a simulated dataset, disease outcome prediction with correction for various kinds of side information and phenotype prediction with population structure correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parameter selection</head><p>There are two parameters in the ccSVM model (12): λ and C. We choose the parameters based on cross-validation on the training dataset only. We split all the training data into several (for example, 5) folds, and each time we take 1-fold as test set and the others as training set. We first set λ = 0 and select the C by which we can get the best average area under curve (AUC) using a standard SVM. C can take one of the values in</p><formula>{2 −8 ,2 −4 ,2 −2 ,1,2 2 ,2 4 ,2 8 }.</formula><p>Then we fix C in the ccSVM, and select the λ such that it gives the best average AUC in the ccSVM. λ is chosen from the values {10 −8 ,10 −4 ,10 −2 ,1,10 2 ,10 4 ,10 8 }. This parameter selection is performed on the training dataset only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison partners</head><p>We compare the ccSVM to the following comparison partners:</p><p>@BULLET Standard SVM: we use linear kernel K SVM = X T X in the standard SVM,</p><formula>where X = (x 1 ,...,x m ) ∈ R n×m .</formula><p>@BULLET (K+L)SVM: we integrate the side information with the original features by simply concatenating X and L. Thus, the number of features are n+m, where n is the number of original features,@BULLET Confounder correcting logistic regression (ccLR): we consider the following logistic model</p><formula>ln p 1−p = β 0 +β 1 x 1 +···+β n x n +u 1 l 1 +···+u m l m ,</formula><p>where p is the probability of a sample being in one class (e.g. the positive class), β i and u i are parameters, x i are the original features and l i are the side features included in L.<ref type="bibr" target="#b9">Kang et al. (2010)</ref>applied a related mixed-model approach to correct for population structure in genome-wide association studies. In contrast to our approach, they are interested in quantitative phenotypes. In our experiments, besides standard logistic regression with maximum likelihood, a sparse Bayesian logistic regression model BLogReg (<ref type="bibr" target="#b4">Cawley and Talbot, 2006</ref>) is also used to estimate the parameters β i and u i. ccLR with these two parameter estimation methods are denoted as ccLR(ML) and ccLR(BR), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Microarray cross-platform comparability</head><p>In this experiment, we compared the sensitivity of the ccSVM to a standard SVM on a microarray dataset which consists of samples from two different labs. A synthetic dataset was also generated to compare the ccSVM and standard SVM. Data: P.<ref type="bibr" target="#b25">Warnat et al. (2005)</ref>compared two studies on acute myeloid leukemia (AML):<ref type="bibr" target="#b3">Bullinger et al. (2004) and</ref><ref type="bibr" target="#b23">Valk et al. (2004)</ref>. The dataset Bullinger consists of 52 patients, and the dataset Valk of 97 patients. Both datasets share gene expression levels for n = 7102 genes. The prediction task is to differentiate between cancerous and normal tissue. The experiments of<ref type="bibr">Bullinger et al.</ref>were carried out on a cDNA platform while Valk et al. used oligonucleotide microarrays. Besides the real data, we also generated a synthetic dataset based on Bullinger and Valk: we picked randomly half of the genes and centered them to zero mean for each gene and each dataset separately, and kept the other half genes uncentered. The centered genes have no correlation with the lab membership while many of the uncentered genes have a strong correlation. Hence, difference in mean expression level seems to distinguish the expression values from these two labs. We defined the side information matrix L ∈ R m×m by the lab membership. L ij = 1 if patient i and patient j belong to the same lab, and L ij = 0 if the two patients belong to different labs. Experimental setting: we first did 50 times 5-fold random crossvalidation on the real data using the ccSVM and SVM, and report their average AUCs, standard errors and t-test P-values. For the ccSVM, we split the data randomly into 5-folds. We used 4-foldsfor training and 1-fold for testing. Then we fixed the parameters λ and C as explained in Section 3.1 with 4-fold cross-validation. With the obtained parameters, we trained the ccSVM on the training set and predicted on the test objects. The experiment was repeated five times until each fold served as test dataset once. For standard SVM and pcaSVM, we used the same experimental protocol, but we only needed to train C from the training data. We then explored how the ccSVM corrects the normalized weight vector based on the synthetic data. We trained on a subset of the pooled Bullinger and Valk dataset. We determined the parameter C according to the experimental protocol outlined in Section 3.1 and fixed λ = 1. Therefore, we split the training set into 3-folds. With these optimized parameters, we trained our ccSVM jointly over all training objects and predicted on the test dataset. For training the standard SVM, we used the same experimental protocol. Results: for the real data, we obtain an average AUC value of 0.911 ± 0.002 for the ccSVM and an AUC value of 0.822 ± 0.003 for the standard SVM. The P-value of the t-test is 4.8e-40. This result shows that our method is superior to the standard SVM. For the synthetic data, we can see from<ref type="figure" target="#fig_1">Figure 1</ref>that the ccSVM assigns large weights to genes that weakly correlate with the lab membership while the standard SVM assigns the weights without paying attention to the correlation to the lab membership.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Disease outcome prediction with various confounding factors</head><p>In this experiment, we analyzed the ability of the ccSVM to predict active tuberculosis based on blood transcriptional profiles. We used ethnicity, age and gender as confounding information. Data: we obtained the dataset from<ref type="bibr" target="#b1">Berry et al. (2010)</ref>. It includes 103 blood samples from patients with active tuberculosis and 40 blood samples from healthy controls. The transcriptional signature of the blood samples were measured in a subsequent microarray experiment with n = 48 803 gene expression levels. We used three different confounding factors: ethnicity, gender and age. For ethnicity, we defined the information matrix as i345follows: L ij = 1 if the patient i and j belong to the same ethnic group, L ij = 0 if they do not. For gender, we defined L similarly: L ij = 1 if the patient i and j have the same gender, L ij = 0 if the patients have different gender. We used a Gaussian kernel for age as side information. Experimental setting: for the ccSVM, standard SVM, pcaSVM and (K+L)SVM, we used the same experimental setting as described in Section 3.3. We again utilized the same experimental design for ccLR, but instead of setting the parameters (λ,C), we determined the parameters β 0 ,...,β n and u 1 ,...,u m. We ran 50 times random 5-fold cross-validation for standard SVM, pcaSVM,(K+L)SVM and ccSVM, and reported their corresponding average AUCs and standard errors. We also performed a t-test between the 50 AUCs of competing partners and 50 AUCs of ccSVM, and recorded the P-values. As ccLR and BLogReg did not work well, we performed logistic regression with maximum likelihood estimation in 10 times 5-fold cross-validation and reported the averaged AUC. Results:<ref type="figure" target="#tab_1">Table 1</ref>shows the prediction results for random cross-validation. Regarding the AUC values, ccSVMs with side information of ethnicity and age are slightly better than the other SVM approaches, while ccSVM with gender as side information works similar with the other SVMs. The logistic regression approach is not able to classify the data correctly regardless of which side information is used. Weight vector analysis: we examined the weight vector of the ccSVM to get a further understanding for its improved performance. Specifically, we trained on four ethnic groups and then used it to predict on a fifth. In<ref type="figure" target="#fig_3">Figure 2</ref>, we plot the averaged absolute correlation coefficients between membership in one ethnicity (African) and the expression levels of the 10 000 top ranked genes. We can observe that the ccSVM assigns the largest weights to genes that do not correlate with the confounder, while the standard SVM is unaware of the confounder and puts large weight on the features that correlate with the confounding variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Li et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Phenotype prediction with population structure correction</head><p>In this experiment, we assessed the performance of the ccSVM in comparison to the standard SVM, (K+L)SVM, pcaSVM and ccLR on phenotype prediction from SNP data in Arabidopsis thaliana. Data : we used data from the genome-wide association study in A.thaliana conducted by<ref type="bibr" target="#b0">Atwell et al. (2010)</ref>. The dataset consists of m = 177 samples and n = 216 130 single nucleotide polymorphisms (SNPs). An SNP is a fixed position in the genome which exists in two different variations between individuals. We examined five binary phenotypes, namely the presence and absence of chlorosis at 22 @BULLET C (PID:169), of anthocyanin at 16 @BULLET C (PID:171)and at 22 @BULLET C (PID:172) and of leaf roll at 10 @BULLET C (PID:176) and at 22 @BULLET C (PID:178). We used population structure as side information and computed a side information kernel matrix L ∈ R m×m. Population structure is defined by the different allele frequencies between subpopulations. If the phenotype prevalence also differs between these subpopulations, it can lead to spurious associations between the phenotype and SNPs that are associated with a subpopulation in which one phenotype is prevalent (<ref type="bibr" target="#b13">Marchini et al., 2004</ref>). Each entry L ij is here defined as the number of common SNPs between sample i and sample j. Experimental setting: for this experiment, we used the same experimental setting as described in Subsection 3.4. Results: prediction results are reported in<ref type="figure" target="#tab_2">Table 2</ref>. For all the phenotypes except leaf roll at 22 @BULLET C (PID:178), ccSVM yields better AUC values than the state-of-the-art competitors. Regarding the P-values, we see that the improvement of our method against standard SVM, pcaSVM and (K+L)SVM is significant for the phenotypes chlorosis at 22 @BULLET C (PID:169), anthocyanin at 16 @BULLET C (PID:171), anthocyanin at 22 @BULLET C (PID:172) and leaf roll at 10 @BULLET C (PID:176). Weight vector analysis: in<ref type="figure" target="#fig_5">Figure 3</ref>, we compare the normalized weight vectors obtained by ccSVM and standard SVM for two phenotypes by looking at one representative each. We first pick up the top 100 features selected by standard SVM, and then see how the ccSVM corrects the weights of these features. When the ccSVM curve is lower than the standard SVM curve (negative peak),Chlorosis at 22°C standard SVM ccSVMit means that the corresponding SNPs are likely to be correlated with the confounder and ccSVM weights them down for classification. The SNPs whose weights are scaled up (positive peaks) are less correlated with the confounding side information. We can see from the figure that both parameter λ and the number of negative peaks increases from the top to the bottom. This implies the confounding information increases from top to bottom. For the phenotype anthocyanin at 16 @BULLET C (PID:171), the top figure shows that there are almost no large negative peaks in the ccSVM curve. This implies there are few spurious associations for the ccSVM to correct. For the phenotype chlorosis at 22 @BULLET C (PID:169), we can see that ccSVM scales all SNPs down which the standard SVM assigns large weights to. It is likely that they are all correlated with the confounding variable. Functional investigation: we did further analysis for the phenotype chlorosis at 22 @BULLET C (PID:169). In order to do this, we used the complete dataset as training set and determined λ and C via cross-validation as described in Section 3.1. First, we selected the top 500 SNPs from the weight vector of ccSVM; these are the SNPs that correspond to the 500 largest absolute entries in the weight vector. After normalizing these entries in both weight vectors, we selected all SNPs which were upscaled<ref type="figure" target="#tab_3">Table 3</ref>. Summary of ccSVM results for the presence or absence of chlorosis at 22 @BULLET C (PID:169)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i346</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ccSVM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Li et al.</head><p>The results are shown in<ref type="figure" target="#tab_3">Table 3</ref>. pen-3-1 mutants show a chlorosis response after being attacked by Erysiphe cichoracearum. It is assumed that the gene PEN3 contributes to defense at the cell wall and intracellularly (<ref type="bibr" target="#b22">Stein et al., 2006</ref>). The mos6 mutants suppress snc1 resistance and hence exhibit enhanced disease susceptibility to virulent pathogens (<ref type="bibr" target="#b17">Palma et al., 2005</ref>). The gene CDR1 is known to be involved in disease resistance signaling (<ref type="bibr" target="#b26">Xia et al., 2004</ref>), and ahg2-1 mutants have an elevated resistance to bacterial pathogens (<ref type="bibr" target="#b15">Nishimura et al., 2009</ref>). In total, 9 of the 217 upscaled SNPs are close to candidate genes. Out of 216 130 genome-wide SNPs, 3959 are in close proximity to candidate genes. Hence, SNPs near candidate genes are significantly enriched among the SNPs upscaled by the ccSVM (P = 0.020, α = 0.05, Binomial n = 217,p = 3959 216130 ).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Genes are sorted according to the weight vector of the ccSVM (blue dashed line) and according to the weight vector of the standard SVM (green line). The correlation coefficient between each gene expression level and lab membership is calculated. The averaged absolute correlation coefficient of the top i genes is plotted for gene i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Gene expression levels are sorted according to the weight vector of ccSVM (blue dashed line) and according to the weight vector of standard SVM (green line). The correlation coefficient between each gene expression level and ethnic origin (African) is calculated. The averaged absolute correlation coefficient of the top i genes is plotted for gene i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>C 0.590 ± 0.005 0.568± 0.005 1.2e-03 0.570± 0.004 2.1e-03 0.560± 0.004 2.1e-06 0.571± 0.012 0.571± 0.003 172 Anthocyanin at 22 @BULLET C 0.628 ± 0.003 0.610± 0.003 2.7e-05 0.610± 0.004 1.2e-04 0.576± 0.003 1.8e-21 0.613± 0.004 0.552± 0.004 176 Leaf Roll at 10 @BULLET C 0.720 ± 0.002 0.695 ± 0.003 2.6e-09 0.697 ± 0.003 3.8e-08 0.653 ± 0.003 3.3e-31 0.691 ± 0.010 0.550± 0.003 178 Leaf Roll at 22 @BULLET C 0.587 ± 0.007 0.575± 0.006 1.8e-01 0.591 ± 0.005 6.0e-01 0.580 ± 0.006 4.1e-01 0.573± 0.006 0.476± 0.008</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.3.</head><figDesc>Fig. 3. SNPs are sorted by their absolute weight of the standard SVM. The green line shows the weights of the standard SVM, the blue dashed line shows the weights of ccSVM. Both weight vectors are normalized. The Arabidopsis phenotypes are shown in the following order (from top to bottom): anthocyanin at 16 @BULLET C (PID:171, λ = 10 −2 ), chlorosis at 22 @BULLET C (PID:169, λ = 10 8 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>i,j=1˜L j=1˜ j=1˜L ij x ki x kj (14) Let l k = i,j ˜ L ij x ki x kj , then (14) is equal to:</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>˜ x m ) ∈ R n×m. While the rescaling step (16) does not lend itself to kernelization, one can kernelize (17) and (18) by replacing˜xreplacing˜ replacing˜x T i ˜ x j by φ(˜ x i ) T φ(˜ x j ) in its dual problem.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>X is σ and its corresponding eigenvector is v, then define the PCA correction kernel K PCA = K SVM −σvv T. pcaSVM means that we use a standard SVM with kernel matrix K PCA .</figDesc><table>i344 

at :: on August 30, 2016 

http://bioinformatics.oxfordjournals.org/ 

Downloaded from 

[20:21 6/6/2011 Bioinformatics-btr204.tex] 

Page: i345 i342–i348 

ccSVM 

and m is the number of side features. The linear kernel will be 
K (K+L)SVM = K SVM +L T L. (K+L)SVM means that we use a 
standard SVM with kernel matrix K (K+L)SVM . 

@BULLET pcaSVM: we consider the first component from principle 
component analysis (PCA) to be most related to the side 
information, and then weaken the side-effect by removing 
it from the kernel matrix. Price et al. (2006) used a 
similar approach to correct for stratification in genome-wide 
association studies. Suppose the largest eigenvalue of K SVM = 
X T </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 1. AUC and P-values for ccSVM, standard SVM, pcaSVM, (K+L)SVM and ccLR for the three different confounding variables on the Tuberculosis dataset</figDesc><table>Side information 
AUC ccSVM 
AUC SVM 
p SVM 
AUC pcaSVM 
p pcaSVM 
AUC (K+L)SVM 
p (K+L)SVM 
AUC ccLR(ML) 

Ethnicity 
0.955 ± 0.002 
0.939 ± 0.003 

6.3e-05 
0.933± 0.003 

3.6e-09 
0.942± 0.003 
1.2e-04 
0.499 
Age 
0.967 ± 0.002 
3.8e-12 
1.5e-18 
0.943 ± 0.002 
4.0e-16 
0.499 
Gender 
0.938 ± 0.003 
2.8e-01 
6.2e-01 
0.941 ± 0.003 
1.7e-01 
0.499 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>Table 2. AUC and P-values for ccSVM, standard SVM, pcaSVM, (K+L)SVM and ccLR for the five different Arabidopsis phenotypes</figDesc><table>PID Phenotype 
AUC ccSVM 
AUC SVM 
p SVM 
AUC pcaSVM 
p pcaSVM AUC (K+L)SVM p (K+L)SVM AUC ccLR(ML) AUC ccLR(BR) 

169 Chlorosis at 22 @BULLET C 
0.658 ± 0.004 0.623± 0.004 8.3e-10 0.625± 0.004 6.4e-09 0.574± 0.004 2.2e-28 
0.632± 0.006 0.523± 0.004 
171 Anthocyanin at 16 @BULLET </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [20:21 6/6/2011 Bioinformatics-btr204.tex] Page: i344 i342–i348</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [20:21 6/6/2011 Bioinformatics-btr204.tex] Page: i346 i342–i348</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Page: i347 i342–i348</note>

			<note place="foot" n="4"> DISCUSSION In this article, we have defined the ccSVM, an SVM with correction for confounding side information. In our experiments, it outperforms several state-of-the-art classifiers with confounder correcting schemes for disease diagnosis in humans and for phenotype prediction in A.thaliana. Our work extends the advantages of SVMs in data integration: while there is lot of work on SVMs for optimally combining several informative sources of data for a joint prediction (Lanckriet et al., 2004), there was no approach for correcting SVMs for observed confounding factors so far. The ccSVM closes this gap. This is of particular importance for bioinformatics, as side information on confounders is abundant in most classification tasks on biological data. It remains to be discovered if SVMs can be corrected for hidden, unobserved confounders as well, as these tend to frequently occur in gene expression phenotypes. Correcting for these hidden confounders may be one way to further improve the accuracy of our predictions. On the biological level, our work will focus on applications of the ccSVM to binary phenotype prediction in plant genetics and in personalized medicine. The latter includes improved disease diagnosis, prognosis and therapy outcome prediction for human patients. One challenge we will tackle here is how to optimally account for several confounding factors, that is learning their weights relative to each other to further improve phenotype prediction.</note>

			<note place="foot">i348 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors would like to thank Richard Neher for fruitful discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict</head><p>of Interest: none declared.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i347</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Genome-wide association study of 107 phenotypes in Arabidopsis thaliana inbred lines</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Atwell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">465</biblScope>
			<biblScope unit="page" from="627" to="631" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">An interferon-inducible neutrophil-driven blood transcriptional signature in human tuberculosis</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Berry</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">466</biblScope>
			<biblScope unit="page" from="973" to="977" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">M</forename>
				<surname>Borgwardt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Use of gene-expression profiling to identify prognostic subclasses in adult acute myeloid leukemia</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Bullinger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="page" from="1605" to="1616" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Gene selection in cancer classification using sparse logistic regression with bayesian regularization</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Cawley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Talbot</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2348" to="2355" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName>
				<forename type="first">C.-C</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C.-J</forename>
				<surname>Lin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001-03-03" />
		</imprint>
	</monogr>
	<note>last. accessed</note>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Cortes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Vapnik</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="273" to="297" />
		</imprint>
	</monogr>
	<note>Support. vector networks. Machine Learn</note>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Measuring statistical dependence with Hilbert-Schmidt norms</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gretton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Algorithmic Learning Theory</title>
		<meeting>Algorithmic Learning Theory</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="63" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">How can we realize the promise of personalized antidepressant medicines?</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Holsboer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="638" to="646" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Variance component model to account for sample structure in genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">M</forename>
				<surname>Kang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="348" to="354" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonlinear programming</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">W</forename>
				<surname>Kuhn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">W</forename>
				<surname>Tucker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Berkeley Symposium on Mathematical Statistics and Probabilistics</title>
		<meeting>the 2nd Berkeley Symposium on Mathematical Statistics and Probabilistics<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1951" />
			<biblScope unit="page" from="481" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A statistical framework for genomic data fusion</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lanckriet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2626" to="2635" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">The spectrum kernel: A string kernel for SVM protein classification</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Leslie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac. Symp. Biocomput</title>
		<imprint>
			<biblScope unit="page" from="564" to="575" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">The effects of human population structure on large genetic association studies</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="512" to="517" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">Clinical trials: design, conduct, and analysis. Monographs in Epidemiology and Biostatistics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Meinert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Tonascia</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">ABA hypersensitive germination2-1 causes the activation of both abscisic acid and salicylic acid responses in Arabidopsis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Nishimura</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plant Cell Physiol</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="2112" to="2122" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">What is a support vector machine? Nat</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Noble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biotech</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1565" to="1567" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">An importin alpha homolog, MOS6, plays an important role in plant innate immunity</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Palma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1129" to="1135" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Principal components analysis corrects for stratification in genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Price</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="904" to="909" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">New approaches to population stratification in genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Price</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="459" to="463" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Schölkopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Smola</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, London, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">Kernel Methods in Computational Biology</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Schölkopf</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Arabidopsis PEN3/PDR8, an ATP binding cassette transporter, contributes to nonhost resistance to inappropriate pathogens that enter by direct penetration</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plant Cell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="731" to="746" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Prognostically useful gene-expression profiles in acute myeloid leukemia</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Valk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="page" from="1617" to="1628" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title level="m" type="main">Theory of Pattern Recognition</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Vapnik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Chervonenkis</surname>
			</persName>
		</author>
		<editor>Russian]. Nauka, Moscow. [German Translation: W. Wapnik &amp; A. Tscherwonenkis</editor>
		<imprint>
			<date type="published" when="1974" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>Theorie. der Zeichenerkennung. Akademie</note>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Cross-platform analysis of cancer microarray data improves gene expression based classification of phenotypes</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Warnat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">265</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">An extracellular aspartic protease functions in Arabidopsis disease resistance signaling</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Xia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO J</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="980" to="988" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>