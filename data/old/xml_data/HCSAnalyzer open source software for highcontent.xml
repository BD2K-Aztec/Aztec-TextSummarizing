
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining HCS-Analyzer: open source software for high-content screening data correction and analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Arnaud</forename>
								<surname>Ogier</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Cellular Differentiation and Toxicity Prediction</orgName>
								<orgName type="institution">Institut Pasteur Korea</orgName>
								<address>
									<addrLine>696 Sampyeong-dong, Bundang-gu, Seongnam-si, Gyeonggi-do</addrLine>
									<postCode>463-400</postCode>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Thierry</forename>
								<surname>Dorval</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Cellular Differentiation and Toxicity Prediction</orgName>
								<orgName type="institution">Institut Pasteur Korea</orgName>
								<address>
									<addrLine>696 Sampyeong-dong, Bundang-gu, Seongnam-si, Gyeonggi-do</addrLine>
									<postCode>463-400</postCode>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining HCS-Analyzer: open source software for high-content screening data correction and analysis</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS APPLICATIONS NOTE</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="issue">14</biblScope>
							<biblScope unit="page" from="1945" to="1946"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts288</idno>
					<note type="submission">Received on March 6, 2012; revised on May 8, 2012; accepted on May 9, 2012</note>
					<note>Copyedited by: TRJ MANUSCRIPT CATEGORY: APPLICATIONS NOTE [10:52 18/6/2012 Bioinformatics-bts288.tex] Page: 1945 1945–1946 Associate Editor: Martin Bishop Supplementary Information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: High-throughput screening is a powerful technology principally used by pharmaceutical industries allowing the identification of molecules of interest within large libraries. Originally target based, cellular assays provide a way to test compounds (or other biological material such as small interfering RNA) in a more physiologically realistic in vitro environment. High-content screening (HCS) platforms are now available at lower cost, giving the opportunity for universities or research institutes to access those technologies for research purposes. However, the amount of information extracted from each experiment is multiplexed and hence difficult to handle. In such context, there is an important need for an easy-to-use, but still powerful software able to manage multidimensional screening data by performing adapted quality control and classification. HCS-analyzer includes: a user-friendly interface specifically dedicated to HCS readouts, an automated approach to identify systematic errors potentially occurring during screening and a set of tools to classify, cluster and identify phenotypes of interest among large and multivariate data. Availability: The application, the C# .Net source code, as well as detailed documentation, are freely available at the following URL:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>High-content screening (HCS) can be seen as an extension of highthroughput screening when multiplexing readout. This technology usually relies on complex biological systems such as cells. Combined with novel automated imaging platforms, this technology currently allows acquisition of a huge amount of experimental data. Followed by image analysis, this approach performs the extraction of high-dimensional signatures called phenotypes. Here we propose an open source front end interface dedicated to analyze high-dimensional data generated during HCS campaigns. We embedded Weka<ref type="bibr" target="#b3">[Hall et al. (2009)]</ref>, Alglib (http://www. alglib.net/) and Accord (http://accord-net.origo.ethz.ch) open source scientific libraries and created a link to the KEGG database soap server (http://www.kegg.jp/kegg). In a very easy and efficient way, * To whom correspondence should be addressed. the users can import screening datasets, visualize them, evaluate and correct potential biases (edge effect, dispensing effect, etc.), cluster and classify the data, all in a supervised or unsupervised mode. In the case of siRNA screening, gene and pathway information can be extracted, as well as pathways frequency. In addition, one can export the results and generate a report including tables, graphs and annotated images. Thus, our application is well suited for analysis of complex HCS data. This method can be used to further develop high-level plugins, taking advantage of statistical and mathematical toolboxes which can be shared within the community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FEATURES</head><p>HCS-Analyzer has been designed to follow a regular screening analysis pipeline. The software provides six distinct steps: load and display, data quality control, dimensionality reduction, data normalization, classification or clustering, and lastly, export results (<ref type="figure" target="#fig_1">Fig. 1</ref>). Importing data loads commonly used file formats such as comma-separated values .csv, .mtr<ref type="bibr" target="#b5">[Makarenkov et al. (2006)]</ref>, and regular .txt files (Supplementary Figs. S1–S3). The users can select different parameters they want to load and visualize. Current Plate displays the selected array of data. In this mode, the users can design the assay by selecting controls and defining classes (e.g. for a supervised classification). Dimensionality Reduction performs feature selection. Two approaches are available: supervised, where the reduced dimensions are those separating the most efficiently defined classes (depending on criteria); or unsupervised, where only one class is required. In the context of phenotypic screening, the feature selection represents not only a pre-process for classification but may also lead to a better understanding of the biological mechanism(s) of action involved. Systematic Error Identification and Correction achieves an automated quality evaluation on the active plates. A survey of existing methods can be found in<ref type="bibr" target="#b2">Dragiev et al. (2011)</ref>. We implemented here a novel approach to automatically identify systematic errors each plate is potentially subjected to. The algorithm is split into two distinct steps. The first one performs an automated uni-dimensional K-Means clustering based on each descriptor readout. For this purpose, a signature related to the plate geometry is associated to each well previously clustered. Typically, this signature includes distance to the edges, distance to the center, column index and row index. In a normal case, those parameters should not be influenced by any of the clustering methods. Finally, a C4.5 classifier learning step is performed on those data. If successful, the tree is automatically analyzed to provide the user a comprehensive feedback identifying the systematic error. Two correction methodsAnalyzer provides a user-friendly way for designing screening plates and for applying iteratively all the regular screening processes. For siRNA screening, the application is also linked to the KEGG database, allowing automated pathway analysis. A special effort has been made when designing the import and export controls to make these steps as flexible as possible. Graphs allow the assessment of the screening quality such as Z-factors evolution during the screening. A new algorithm has been developed to automatically identify systematic errors. After phenotype identification, the user can check the readout distribution using various scatter points or graphs are proposed, the B-score<ref type="bibr" target="#b0">[Brideau et al. (2003)</ref>] and the diffusionbased model<ref type="bibr" target="#b1">[Carralot et al. (2012)]</ref>. Plates can also be rejected based on Z-score in one dimension. Normalization normalizes the readouts of the different plates to reach a data consistency required for hit identification. This step is not mandatory with some classification approaches, typically when the learning step is performed plate by plate. Classification and Clustering automatically classifies and identifies the phenotype(s) of interest in a multivariate way. The classification can be operated in a supervised (Support vector machine, Neural network, K-nearest neighbors, random forest) or unsupervised manner (K-Means, Expectation maximization, Hierarchical). The clustering and classification automatically updates the classes, and if a tree-based algorithm has been chosen, the graph can be displayed and exported. Report Export generates a complete report of most of the performed operations as well as a description of the screening properties. Finally, the application also includes a module to generate artificial realistic multidimensional screening data [Kwan and<ref type="bibr" target="#b4">Birmingham (2010)</ref>], allowing the validation of additionally developed algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CONCLUSION</head><p>The stand-alone software presented here aims to simplify the process of correcting and analyzing multivariate screening datasets. The full C# source code is available as well as a plugin sample (Supplementary<ref type="figure">Fig. S4</ref>), allowing the user to adapt or to extend the currently provided version of the application. A tutorial as well as visual documentation can be downloaded at the same URL. Further development of the application is expected to adapt the software to evolving community requirements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Copyedited by: TRJ MANUSCRIPT CATEGORY: APPLICATIONS NOTE [10:52 18/6/2012 Bioinformatics-bts288.tex] Page: 1946 1945–1946 A.Ogier et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Schematic illustration of HCS-Analyzer features. HCS-Analyzer provides a user-friendly way for designing screening plates and for applying iteratively all the regular screening processes. For siRNA screening, the application is also linked to the KEGG database, allowing automated pathway analysis. A special effort has been made when designing the import and export controls to make these steps as flexible as possible. Graphs allow the assessment of the screening quality such as Z-factors evolution during the screening. A new algorithm has been developed to automatically identify systematic errors. After phenotype identification, the user can check the readout distribution using various scatter points or graphs</figDesc></figure>

			<note place="foot">© The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We gratefully acknowledge Ministry Of Education, Science And Technology (MEST) Korea, Gyonggido and KISTI. We wish to thank H. K. Moon for fruitful discussions and technical support, and Dr V. Makarenkov and Dr P. Dragiev for the B-score implementation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved statistical methods for hit selection in high-throughput screening</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brideau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="634" to="647" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A novel specific edge effect correction method for RNA interference screenings</title>
		<author>
			<persName>
				<forename type="first">J.-P</forename>
				<surname>Carralot</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="261" to="268" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Systematic error detection in experimental high-throughput screening</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Dragiev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">The weka data mining software: An update; sigkdd explorations</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hall</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Noisemaker: simulated screens for statistical assessment</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Kwan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Birmingham</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2484" to="2485" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Hts-corrector: software for the statistical analysis and correction of experimental high-throughput screening data</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Makarenkov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1408" to="1409" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>