
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An automated workflow for parallel processing of large multiview SPIM recordings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Christopher</forename>
								<surname>Schmied</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute of Molecular Cell Biology and Genetics</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Peter</forename>
								<surname>Steinbach</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute of Molecular Cell Biology and Genetics</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tobias</forename>
								<surname>Pietzsch</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute of Molecular Cell Biology and Genetics</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Stephan</forename>
								<surname>Preibisch</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute of Molecular Cell Biology and Genetics</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">HHMI Janelia Research Campus</orgName>
								<address>
									<settlement>Ashburn</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Max Delbr√º ck Center for Molecular Medicine</orgName>
								<orgName type="institution">Berlin Institute for Medical Systems Biology</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Pavel</forename>
								<surname>Tomancak</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute of Molecular Cell Biology and Genetics</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An automated workflow for parallel processing of large multiview SPIM recordings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv706</idno>
					<note type="submission">Received on 30 July 2015; revised on 13 November 2015; accepted on 25 November 2015</note>
					<note>Bioimage informatics *To whom correspondence should be addressed. Associate Editor: Robert Murphy Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Selective Plane Illumination Microscopy (SPIM) allows to image developing organisms in 3D at unprecedented temporal resolution over long periods of time. The resulting massive amounts of raw image data requires extensive processing interactively via dedicated graphical user interface (GUI) applications. The consecutive processing steps can be easily automated and the individual time points can be processed independently, which lends itself to trivial paralleliza-tion on a high performance computing (HPC) cluster. Here, we introduce an automated workflow for processing large multiview, multichannel, multiillumination time-lapse SPIM data on a single workstation or in parallel on a HPC cluster. The pipeline relies on snakemake to resolve dependencies among consecutive processing steps and can be easily adapted to any cluster environment for processing SPIM data in a fraction of the time required to collect it. Availability and implementation: The code is distributed free and open source under the MIT license</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The duration and temporal resolution of 3D fluorescent imaging of living biological specimen is limited by the amount of laser light exposure the sample can survive. Selective Plane Illumination Microscopy (SPIM) alleviates this by illuminating only the imaged plane thus reducing photo damage dramatically. Additionally, SPIM achieves fast acquisition rates due to sensitive wide-field detectors and sample rotation enables complete coverage of large, nontransparent specimen. Taken together, SPIM allows imaging of developing organisms in toto at single cell resolution with unprecedented temporal resolution over long periods of time (<ref type="bibr" target="#b4">Huisken et al., 2004;</ref><ref type="bibr" target="#b5">Keller et al., 2008</ref>). This powerful technology produces massive, terabyte size datasets that need computationally expensive and time-consuming processing before analysis. Existing software solutions implemented in Fiji (<ref type="bibr" target="#b9">Preibisch et al., 2010</ref><ref type="bibr" target="#b10">Preibisch et al., , 2014</ref><ref type="bibr" target="#b13">Schmied et al., 2014</ref>; Preibisch, unpublished (https://github.com/fiji/SPIM_Registration)) or in ZEISS ZEN black are performing chained processing steps on a single computer and require user inputs via a GUI. As the spatial and temporal resolution of the light sheet data increase, such approaches become inconvenient since processing can take days. In controlled experiments, SPIM image processing is robust enough to be automated and key steps are independent from time point to time point. HPC is inherently designed for such time V C The Author 2015. Published by Oxford University Press.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1112</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.comconsuming and embarrassingly parallel tasks that require no user interaction. Therefore, we developed an automated workflow with minimum user interaction that is easily scalable to multiple datasets or time points on a cluster. In combination with the appropriate computing resources it enables for the first time processing of SPIM data that is faster than the total acquisition time required for collecting the raw images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Processing workflow</head><p>The Fiji SPIM processing pipeline uses Hierarchical Data Format (HDF5) as data container for the originally generated TIFF or CZI files by custom made (<ref type="bibr" target="#b8">Pitrone et al., 2013</ref>) or commercial SPIM microscopes (<ref type="figure" target="#fig_0">Fig. 1A</ref>and B). Following format conversion, multiview registration aligns the different acquisition angles (views) within each time point (<ref type="figure" target="#fig_0">Fig. 1C</ref>), and subsequent time-lapse registration stabilizes the recording over time (Preibisch et al., 2010) (<ref type="figure" target="#fig_0">Fig.  1D</ref>). Fusion combines the registered views of one time point into a single volume by averaging or multiview deconvolution (<ref type="bibr" target="#b9">Preibisch et al., 2010</ref><ref type="bibr" target="#b10">Preibisch et al., , 2014</ref>) (<ref type="figure" target="#fig_0">Fig. 1E</ref>and F). The result is a set of HDF5 files containing registered and fused multiview SPIM data that can be examined locally or remotely using the BigDataViewer (<ref type="bibr" target="#b7">Pietzsch et al., 2015</ref>). All steps are implemented as plugins (<ref type="bibr" target="#b9">Preibisch et al., 2010</ref><ref type="bibr" target="#b10">Preibisch et al., , 2014</ref><ref type="bibr" target="#b7">Pietzsch et al., 2015</ref>; Preibisch, unpublished (https://github. com/fiji/SPIM_Registration)), in the open-source platform Fiji (<ref type="bibr" target="#b11">Schindelin et al., 2012</ref>). We use these plugins by executing them from the command line as Fiji beanshell scripts (Supplementary<ref type="figure" target="#fig_0">Fig.  1</ref>). To overcome the legacy dependency of Fiji on the GUI we encapsulate it in a virtual framebuffer (xvfb) that simulates a monitor in the headless cluster environment (Supplementary<ref type="figure" target="#fig_0">Fig. 1</ref>). To map and dispatch the workflow logic to a single workstation or on a HPC cluster, we use the automated workflow engine snakemake (K√∂ ster and<ref type="bibr" target="#b6">Rahmann, 2012</ref>). The workflow is defined using a Snakefile containing the name, input and output file names of each of the processing steps and python code calling the beanshell scripts (Supplementary<ref type="figure" target="#fig_0">Fig. 1</ref>). Upon invocation, the snakemake rule engine resolves the dependencies between individual processing steps based on the input files required and the output files produced during the workflow. It also creates the command that fits the input/output rule description and the template command as defined in the Snakefile. Most importantly, if single tasks on individual files are discovered to be independent, they are invoked in parallel (Supplementary<ref type="figure">Fig. 2</ref>). Each instance of snakemake for one dataset is independent and thus the workflow can be applied simultaneously to multiple dataset. The required parameters for processing are collected by the user during GUI processing of an exemplary time point and entered into a .yaml configuration file (Supplementary List 1). The workflow is executed by passing the .yaml file to snakemake on the command line (Supplementary<ref type="figure" target="#fig_0">Fig. 1</ref>). Importantly, from the user perspective the launching of the pipeline on a HPC cluster and on a local workstation appears identical and require a single command (Supplementary List 2). If the parameters are chosen correctly and the local or HPC resources are sufficient (Supplementary<ref type="figure">Table 1</ref>and 2) no further action from the user is necessary. Snakemake supports multiple back ends to perform the command dispatch: local, cluster and Distributed Resource Management Application API (DRMAA) (K√∂ ster and<ref type="bibr" target="#b6">Rahmann, 2012</ref>). The local back end creates a new sub shell and calls the command(s) required. The cluster back end is a general interface to HPC batch systems based on string substitution. DRMAA specifies a system library that interfaces all common batch systems based on a generalized task model, thus multiple batch systems are supported through one interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We compared the performance of the pipeline on a 175 GB, single channel SPIM recording of a Drosophila embryo consisting of 90 time points and 5 views, processed either on a single computer or on a HPC cluster (Supplementary<ref type="figure">Table 1</ref>). The processing using average fusion takes almost precisely one day on a single powerful computer. In contrast, using the full cluster resource the dataset can be processed in 1 h 31 min, which represents a 16-fold speedup in processing. Since the time-lapse covers 23 h of Drosophila embryonic development the processing becomes real time with respect to the acquisition. Using deconvolution on a cluster with only 4 GPUs (Supplementary<ref type="figure">Table 1</ref>) still brings a more than 3-fold speed up (Supplementary<ref type="figure">Table 3</ref>). A dataset of 2.2 TB in size with 715 time points (<ref type="bibr" target="#b13">Schmied et al., 2014</ref>) would take an estimated week to process on a single computer. Using this method, the processing is reduced to only 13 h with typical cluster workload from other users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and outlook</head><p>The biologist's goal is to analyze, for instance, cellular behavior using time-lapse SPIM recordings. The steps between data acquisition and analysis are of rather technical interest. Our pipelineleverages HPC to reduce the notoriously difficult and time-consuming SPIM data processing to a single autonomous command. Similar pipelines have been developed (<ref type="bibr" target="#b1">Amat et al., 2015</ref>), however in our case the reliance on an open source platform (Fiji) allows us to execute the processing in parallel without any software associated costs. It is also possible to incorporate new algorithms from the Fiji ecosystem into the pipeline (Schmid and Huisken, 2015 and see Supplementary Note). Future improvements of the workflow will provide greater accessibility to novice users by using the UNICORE GUI framework (<ref type="bibr" target="#b0">Almond and Snelling, 1999</ref>). Ultimately, we aim for a completely unsupervised automated processing similar to grid computing practiced in fields facing similar big data challenges such as particle physics and molecular simulation (<ref type="bibr" target="#b2">Bird, 2011;</ref><ref type="bibr" target="#b3">Gesing et al., 2012)</ref></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Automated workflow for multiview processing. Workflow for SPIM image processing (A‚ÄìE) using parallelization (B, C and E). Shown on the right yz slices in the BigDataViewer of a Drosophila embryo expressing histone H2Av-mRFPruby raw (A) registered (C) and deconvolved (E). Results of deconvolution with xy , xz and xz slices through the fused volume of the same embryo (F). Scale bars represent 50 lm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Bioinformatics, 32(7), 2016, 1112‚Äì1114 doi: 10.1093/bioinformatics/btv706 Advance Access Publication Date: 1 December 2015 Applications Note</figDesc><table></table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">C.Schmied et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Stephan Janosch for valuable discussions and Akanksha Jain for testing the workflow. We thank the computer services of the MPI-CBG for their great general support and specifically Oscar Gonzalez, the members of the scientific computing facility and light microscopy facility.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">UNICORE: Uniform access to supercomputing as an element of electronic commerce</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Almond</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Snelling</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">613</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient processing and analysis of large-scale light-sheet microscopy data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Amat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1679" to="1696" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Computing for the Large Hadron Collider</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Bird</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Nucl. Part. Sci</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="99" to="118" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A single sign-on infrastructure for science gateways on a use case for structural bioinformatics</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gesing</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Grid Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="769" to="790" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Optical Sectioning Deep Inside Live Embryos by Selective Plane Illumination Microscopy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Huisken</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="page" from="1007" to="1009" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Reconstruction of zebra-fish early embryonic development by scanned light sheet microscopy</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Keller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="page" from="1065" to="1069" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Snakemake‚Äìa scalable bioinformatics workflow engine</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>K√∂ Ster</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Rahmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2520" to="2522" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">BigDataViewer: visualization and processing for large image data sets</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pietzsch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="481" to="483" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">OpenSPIM: an open-access light-sheet microscopy platform</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">G</forename>
				<surname>Pitrone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="598" to="599" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Software for bead-based registration of selective plane illumination microscopy data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Preibisch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="418" to="419" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient Bayesian-based multiview deconvolution</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Preibisch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="645" to="648" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Fiji: an open-source platform for biological-image analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schindelin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="676" to="682" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Real-time multi-view deconvolution</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Schmid</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Huisken</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="3398" to="3400" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Open-source solutions for SPIMage processing</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Schmied</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Imag. Cell Biol</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="505" to="529" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>