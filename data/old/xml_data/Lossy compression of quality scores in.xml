
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequence analysis Lossy compression of quality scores in genomic data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Rodrigo</forename>
								<surname>Cá</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Alistair</forename>
								<surname>Moffat</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Andrew</forename>
								<surname>Turpin</surname>
							</persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing and Information Systems</orgName>
								<orgName type="laboratory">NICTA Victoria Research Laboratory</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Associate Editor: Inanc Birol</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sequence analysis Lossy compression of quality scores in genomic data</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">15</biblScope>
							<biblScope unit="page" from="2130" to="2136"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu183</idno>
					<note type="submission">Received on October 7, 2013; revised on February 18, 2014; accepted on April 2, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Next-generation sequencing technologies are revolutionizing medicine. Data from sequencing technologies are typically represented as a string of bases, an associated sequence of per-base quality scores and other metadata, and in aggregate can require a large amount of space. The quality scores show how accurate the bases are with respect to the sequencing process, that is, how confident the sequencer is of having called them correctly, and are the largest component in datasets in which they are retained. Previous research has examined how to store sequences of bases effectively; here we add to that knowledge by examining methods for compressing quality scores. The quality values originate in a continuous domain, and so if a fidelity criterion is introduced, it is possible to introduce flexibility in the way these values are represented, allowing lossy compression over the quality score data. Results: We present existing compression options for quality score data, and then introduce two new lossy techniques. Experiments measuring the trade-off between compression ratio and information loss are reported, including quantifying the effect of lossy representations on a downstream application that carries out single nucleotide poly-morphism and insert/deletion detection. The new methods are dem-onstrably superior to other techniques when assessed against the spectrum of possible trade-offs between storage required and fidelity of representation. Availability and implementation: An implementation of the methods described here is available at https://github.com/rcanovas/</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Genome sequencing methods have evolved at the same astonishing rate as computing technology. Next-generation devices parallelize the process, producing billions of sequences (reads) (<ref type="bibr" target="#b0">Ansorge, 2009;</ref><ref type="bibr" target="#b4">Church, 2006;</ref><ref type="bibr" target="#b16">Mardis, 2008;</ref><ref type="bibr" target="#b18">Myllykangas et al., 2012</ref>) and generating file sizes potentially in the terabyte range, at costs that are decreasing on a yearly basis. Each read is a fragment of data extracted from the processing of a single genome, represented as a string of bases. As well, a number of metadata fields are associated with each read. Some of these fields are more expensive to store than the sequence of bases.</p><p>The mechanics of effectively storing and querying this information are fundamental to the field of bioinformatics (<ref type="bibr" target="#b11">Giancarlo et al., 2009</ref>). Several standard formats to store genome data have been adopted, each aiming to be easy to manipulate and parse using text-processing tools such as Perl and Python. The most common are the FASTA and FASTQ formats (<ref type="bibr" target="#b5">Cock et al., 2010</ref>) and the SAM/BAM formats (<ref type="bibr" target="#b15">Li et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Quality scores</head><p>We consider the problem of effectively representing the quality scores of a genome sequence. Quality scores are typically stored as a Phred-scaled base error probability (<ref type="bibr" target="#b9">Ewing and Green, 1998</ref>), calculated as À10 Á log 10 Prfbase is wrongg Ä Å . These are then typically scaled (Phred þ 33 or Phred þ 64) so that they can be represented as printable ASCII characters.<ref type="figure" target="#tab_1">Table 1</ref>shows examples for Phred þ 33, the scheme assumed in examples in this article. The probability that a base in a given position is wrong can be computed in different ways, and depends on the hardware and software that are used in the sequencer.<ref type="figure" target="#fig_0">Figure 1</ref>shows an example of a short sequence of bases together with the corresponding quantized quality assessments. The higher the quality value, the lower the probability that the base at that position has been incorrectly called. For example, in<ref type="figure" target="#fig_0">Figure 1</ref>, the first nucleotide of the sequence has a quality value equal to 70 (the symbol 'F' in the ASCII alphabet), which means that there is an estimated probability of approximately 10 Àð70À33Þ=10 % 0:02% that the corresponding 'A' has been incorrectly sequenced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Compression</head><p>We consider two different compression modalities: lossless and lossy. Each has advantages and disadvantages, depending on the importance of the information that is stored and on the eventual use of the data. Lossless compression is the most common approach. It ensures that the decompressed data are exactly the same as the original, meaning that the compressed version must contain sufficient information for the decompresser to generate a byte stream identical to the one that was input to the compressor. Lossy compression mechanisms store an approximate representation of the input, trading loss in fidelity of reproduction for enhanced compression effectiveness. Lossy compression is typically only applied to signals that were originally continuous, for which the digital form of the signal already incorporates an element of quantization-generated approximation, such as image and sound data.</p><p>If lossy compression is being considered, the maximum degree of information loss that can be tolerated needs to be specified as an input to the compressor. That requirement presupposes that a measure of loss has been defined, taking as its inputs two data sequences of the type being represented and providing (using some meaningful unit) a numeric score that summarizes the degree to which they differ.<ref type="figure" target="#tab_2">Table 2</ref>shows some of the measures that can be applied to pairs of '-element strictly positive sequences (<ref type="bibr" target="#b3">Cha, 2007</ref>). In all of them, if the two sequences are identical, the score is low (0, or, in the case of Max:Min Distance, 1); when the two sequences are different, the measure is higher. For example, for the two ' ¼ 6-element sequences X ¼ h70, 69, 70, 71, 69, 73i and Y ¼ h70, 70, 70, 70, 70, 73i, the Mean Manhattan Distance is 0.5. The measures shown in<ref type="figure" target="#tab_2">Table 2</ref>will be used in Sections 3 and 4 to evaluate, and in some cases control, the accuracy of lossy compression regimens for quality score sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Bit encodings</head><p>Once the set of symbols to be coded has been determined, the compressor encodes each symbol into a bit sequence. A fixedlength binary code or variable-length prefix-free code is used to represent the symbols contained in the data, with the choice dependent on the probability distribution that arises over the set of symbols. The simplest variable-length code is Unary, which represents a non-negative number x as x 1-bits, followed by a 0-bit. Unary has the advantage of being able to represent arbitrarily large values, but requires as many bits as the value being coded. The Elias Gamma code is more complex, but also more effective, with a value x represented as the concatenation of the length of the binary representation of x in Unary, and the binary representation of x þ 1, omitting its most significant bit (<ref type="bibr" target="#b8">Elias, 1975</ref>). The Golomb code also consists of a Unary/ Binary combination, but makes use of a parameter b, with the unary component storing the quotient q ¼ x=b Ä Å , and a minimallength binary component storing the remainder r ¼ x À bÁq. The parameter b is chosen according to the characteristics of the set of x values to be stored.<ref type="figure" target="#tab_3">Table 3</ref>shows examples of these codes, covering the first six integers. Note that the 3-bit Binary code is limited to inputs 0 x58 and assumes that all of the symbols have equal probability; the Unary, Gamma and Golomb codes assume that the symbol probabilities are non-increasing and place no upper limit on the values x that can be represented. If the symbol probabilities are not non-increasing as the distance from the origin increases, a permutation table can be used so that monotonicity can be maintained. Moffat and<ref type="bibr" target="#b17">Turpin (2002)</ref>describe all of these mechanisms in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Subsequent applications</head><p>One use of sequence data is to identify locations of variation from a specified reference sequence. These variations can assist with the determination of the genotype for each individual at each site, allowing, for example, the study of diseases (<ref type="bibr" target="#b19">Nielsen et al., 2011</ref>). The process of finding variations is known as single nucleotide polymorphism (SNP) and insert/deletion (indel) detection. The normal output of this process is a set of SNPs and indels, stored in a standard format such as variant call format (VCF) (<ref type="bibr" target="#b6">Danecek et al., 2011</ref>). Each line in a VCF file represents a different variation, storing its position and allele in the reference genome, plus the bases related to the variation, a computed quality score and extra information about the variation. We use comparisons between generated VCF files as an applied evaluation of the effect that lossy compression of quality scores has on sequence data use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS APPROACHES</head><p>The SLIMGENE tool presented by<ref type="bibr" target="#b13">Kozanitis et al. (2010)</ref>was one of the first methods for independent compression of quality</p><formula>P ' i¼1 jX i À Y i j</formula><p>Max : Min DistanceðX, YÞ max<ref type="bibr">(2011)</ref>observed that the quality sequences were quasi-random with mild dependence on score position, that some sequences finish with several '#' characters and also that there can be strong local correlations within individual records. In their proposal, a bit flag is stored per sequence to indicate whether the sequence is prefixed by a string of hashes. The hash prefix is removed and the rest of the sequence is stored using a Huffman code. They also proposed storing a modified version of the quality sequence, where equal consecutive values are stored as runs. For example, the sequence 'FFEGGGGGFHHFFFDE' shown in<ref type="figure" target="#fig_0">Figure 1</ref>would be transformed to 'FEGFHFDE', plus a list 1,0,4,0,1,2,0,0 of run-lengths. The new sequence and the vector of run-lengths are then stored using Huffman codes.<ref type="bibr" target="#b22">Wan et al. (2012)</ref>examine several compression methods for compressing the quality field, and propose a new mechanism in which quality scores are transformed into a bin number, with each bin representing an interval. They present three lossy transformations: UniBinning, Truncating and LogBinning. The UniBinning approach creates uniform splits across the error probability distribution, that is, if the parameter is four (and two-bit Binary codes will be used), the first bin spans all quality values corresponding to error probabilities between 0 and 25%. The Truncating transformation separates all the quality values independently, creating a special bin for the l largest values, with l being a user-defined parameter. The LogBinning transformation is similar to UniBinning, but with the bins formed according to the logarithms of the probabilities, by constructing equal-sized segments according to quality values. After applying a binning transformation, Wan et al. form groups of k mapped quality values into a block, and prefix the block with a header containing some local information, depending on the lossless method used. Their MinShifting transformation stores the minimum quality value q min of each block, and the k values q of the block are each replaced by q À q min before being coded. The FreqOrdering transformation permutes all the quality values in each block according to their frequency, so that the most commonly occurring values are assigned the shortest codes when Gamma or Golomb are used. The third option considered by<ref type="bibr">Wan et al. is GapTranslating, in which</ref>all the values of a block are changed to the difference-values presented by Kozanitis et al. Finally, after a lossy transformation and then a lossless mapping, Wan et al. use one of the coding regimens summarized in Section 1.3.<ref type="bibr" target="#b20">Ochoa et al. (2013)</ref>describe the QualComp tool, which compresses quality scores based on the assumption that they are drawn from a Gaussian distribution (<ref type="bibr" target="#b14">Lapidoth, 1997</ref>) parameterized by the position of the quality value in the quality read, assuming that there is a mean and standard deviation for each position i 2 ½1, ' in the read. The mean and covariance matrix of the quality scores are extracted from the entire input, and singular value decomposition is applied to the covariance matrix to recover standard deviations to be used as parameters of the Gaussian. Once those parameters are decided, they are stored for use by the decoder, and used to derive the number of bits used to encode each quality value, by minimizing the mean square error of a rate distortion problem. This optimization problem is parameterized by a user input, which is the total number of output bits the quality scores can consume, expressed as a rate r. The solution to the problem specifies, for position i in a read, the number of bits, i , that should be used to encode the quality value in position i. For each quality value, if it is to be coded in i bits, the Gaussian for that position is split into 2 i regions of equal probability, and a bit pattern selected to indicate the region in which the quality value lies. The decoder reads in the Gaussian parameters and r, performs the optimization to recover the i values and then emits a representative corresponding to the region specified by each code word. Other approaches compress the quality scores depending on information of the read sequences.<ref type="bibr" target="#b21">Tembe et al. (2010)</ref>describe a simple lossless compression technique over the sequence and the quality fields, combining all distinct pairs of genomic base and respective quality value, and then using a Huffman code. That is, the DNA sequence and quality scores of an alignment are represented by a joint sequence of code words, one per each hbase, qualityi pair.<ref type="bibr">Janin et al. (2013)</ref>present a lossy compression scheme based on the premise that, if a base in a read can be predicted by the context of the read, then the base and the respective quality need not be stored. To compute predictions, they use the Burrows–Wheeler transform (<ref type="bibr" target="#b1">Burrows and Wheeler, 1994</ref>) and a longest common prefix array, together with a userdefined minimum context length. We also consider CRAM format files (<ref type="bibr" target="#b10">Fritz et al., 2011</ref>). These files are generated using CRAMTOOLS, a suite of Java programs and interfaces that compress DNA sequence and quality data stored in SAM/BAM format, making use of an external reference genome. Sequences are stored as a difference relative to the external reference, and hence the external reference genome must be provided each time compression or decompression is undertaken. Several lossy options for storing quality scores are provided in the CRAMTOOLS suite. We explored three combinations: Preserve, Bin-Preserve and Match-Bin-Preserve. The Preserve mode only stores quality scores for reads whose mapping quality scores are higher than a user-defined threshold. The other two approaches are variations of Preserve, in which the prefix Bin means that the quality scores are stored using eight bins like Wan</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>We now present a lossy compression approach based on localized properties of the quality scores, following the lead established by<ref type="bibr" target="#b13">Kozanitis et al. (2010)</ref>. The new algorithms represent quality scores by separating them into blocks of variable size, where all the values contained in each block comply with a chosen parameter p according to some measure criterion. For each block, we store its length and a representative value. The representative value also depends on which measure is used. For example, if Mean Manhattan Distance (<ref type="figure" target="#tab_2">Table 2</ref>) is used as the fidelity measure, blocks must be formed such that none of the values in each block are more than p from the corresponding representative value. That is, one possible configuration allows blocks to span a range of up to 2p þ 1 different quality scores, with the midpoint of each block's range taken as the representative value. Generalizing from this starting point, the use of other measures, or other values of p, results in different blocks being formed and hence different amounts of space being required for the set of quality scores, with different degrees of approximation to the original values.1: Representatives ½  2: RunLengths ½  3: block ½  4: block len 0 5: for i ¼ 0 ! ' À 1 do 6: if FulfillCriteriaðblock È quality½i, pÞ then 7: block block È quality½i 8: block len block len þ 1 9: else 10:Algorithm 1 describes the proposed process, with '<ref type="bibr">[]</ref>' used to represent the empty list, and with the 'È' operator used to append a single value to a list of the same type of object. To determine the block boundaries, a left-to-right greedy search is undertaken, seeking to make each block as long as possible, consistent with the constraints imposed by the chosen fidelity criterion and the chosen fidelity limit p. Method FulfillCriteria determines whether it is possible to include the next quality value in the current block, or whether it is necessary to start a new block; method CalculateRepresentative computes the best representative value for a given block, given that at least one valid representative exists. For example, if the measurement metric being used is Mean Manhattan Distance, then FulfillCriteriaðqvals, pÞ is implemented by computing</p><formula>max i qvals½i À min i qvals½i 2p</formula><p>where the range of i is 0 i5jqvalsj. Within a set that meets this criterion, the value rep ¼ ðmax i qvals½iÞ þ ðmin i qvals½iÞ 2 guarantees that the Mean Manhattan Distance for the whole sequence will be not greater than p. For any given block, there may also be other integer values rep0 for which</p><formula>max i jqvals½i À rep 0 j p</formula><p>and in that case, method CalculateRepresentative is free to use a secondary criterion, such as minimizing the average distance between the selected representative and the block's values. We call this option—in which Mean Manhattan Distance is used in both FulfillCriteria and CalculateRepresentative—the P-Block mechanism and control it with the parameter p.<ref type="figure" target="#fig_2">Figure 2</ref>illustrates the application of P-Block to the example sequence. As a second example of how Algorithm 1 might be instantiated, if a given upper bound r must be guaranteed using the Max:Min Distance metric, then FulfillCriteria ðqvals, rÞ needs to check if an integral rep exists such that ðmax i qvals½iÞ=rep5r and rep=ðmin i qvals½iÞ5r. This R-Block approach, parameterized by a maximum ratio r, recognizes that it may be preferable to be more precise in representing low quality scores (when the base is assessed as being more likely to be in error) than high ones. After either of these transforms has been applied to an alignment, the k elements in the Representatives array are stored as a minimum and maximum, followed by k values relative to that range, using a Binary code of log 2 ðmax k Representatives½k À min k Representatives½k þ 1Þ AE Ç bits per value. The k values in the RunLengths array are stored using the Gamma code. When p or r is sufficiently large, only one value is stored for each read, covering every quality value in that alignment. In related work, we have examined compression techniques for the other components of SAM/BAM-format files (Ca´novas<ref type="bibr" target="#b2">Ca´novas and Moffat, 2013</ref>), including the bases, and added a small index thatallows decoding to commence at every 500th read. The space used to store the index information is a small fraction of the total space required, and the functionality that it offers is not part of the experimentation that is reported here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION</head><p>We compare the quality scores of the original file against the quality scores in a reconstructed file using different approaches and a range of fidelity measures (<ref type="figure" target="#tab_2">Table 2</ref>). The fidelity of a mechanism is computed by averaging all of the per-read scores generated for that measure. The quality scores associated with a version of the NA12878 genome are the primary test file used. In particular, we work with reads that were associated with chromosome 20 (That is, we extracted the quality score fields from the file NA12878.Hi.WGS.bwa.cleaned.recal.hg19.20.bam fetched from https://usegalaxy.org/library_common/browse_library?show_deleted¼False&amp;cntrller¼library&amp;use_panels¼False &amp;id¼f9ba60baa2e6ba6d.). To further validate our results, we also take genome HG01477 from the 1000 Genomes Project (ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/), using the reads that were aligned with chromosome 11; those results are presented in the Supplementary Material.<ref type="figure" target="#tab_4">Table 4</ref>gives details of two files of sequence quality values. As part of the processing pipeline used in the experimentation, we also made use of reference chromosomes chr11 and chr20 (Accessed from ftp://ftp.ncbi.nlm.nih.gov/sra/ reports/Assembly/GRCh37-HG19_Broad_variant/). The implementations explored include Wan et al.'s LogBinning and UniBinning, the QualComp mechanisms and our P-Block and R-Block approaches. We also include the CRAMTOOLS lossy models, in recognition of their extensive use in data repositories such as the 1000 Genomes Project. To establish a benchmark for lossless compression, results for GZip –9 are also included.<ref type="figure" target="#fig_4">Figure 3a</ref>shows the various trade-offs measured when fidelity is assessed using Mean Manhattan Distance;<ref type="figure" target="#fig_4">Figure 3b</ref>shows the same trade-off, but with the vertical scale changed to Max:Min Distance; and<ref type="figure" target="#fig_4">Figure 3c</ref>likewise, but with fidelity measured using Mean Squared Error. Each of the implementations provides a trade-off 'knob' that adjusts the balance between fidelity and compression rate. The graphs are plotted using QualComp rates r ¼ {0,0.5,1,2}; P-Block parameters p ¼ {1,2,4,8,16,32}; R-Block ratios r ¼ 1 þ {0.05,0.1,0.2,0.4,0.8,1.6,3.2,6.4}; UniBinning thresholds b ¼ {80,100}; and LogBinning thresholds b ¼ {5,10,20,30,40,60}. For CRAM, lower bound mapping qualities of 40, 50 and 60 were used with the Preserve, Bin-Preserve and MatchBin-Preserve modes. The three components of<ref type="figure" target="#fig_4">Figure 3</ref>show that the QualComp, P-Block and R-Block approaches outperform the other methods. The new approaches are particularly well suited to the Max:MinNote: The columns show the size of the sequence of extracted quality scores as ASCII bytes, the number of reads, the length of each read and the entropy (H 0 , in bits per quality score) of the quality sequence. Distance, as was the intention, while Ochoa et al.'s QualComp offers good performance when fidelity is quantified using Mean Squared Error. Worth noting is that QualComp offers a further modality, allowing the quality file to be separated into c clusters and QualComp applied to each cluster separately. The results obtained via this approach did not result in any appreciable difference in performance. We also analyze the effect of lossy compression of quality scores on a downstream application. For each lossy file generated, we compute its VCF (see Section 1.4) and compare it with the VCF generated from the original file. To compare two VCF files, we use the methodology of<ref type="bibr" target="#b20">Ochoa et al. (2013)</ref>and define a true positive (TP) as a variation that is found in both VCF files, a true negative as a location at which neither file records a variation, a false negative as a variation that is only found in the VCF of the lossless file and a false positive (FP) as a variation that is found only in the VCF of the lossy file. The TP values are further separated into half and equal TP, where equality is registered if the same variation is found in both VCF files, and half is registered if a variation is found in the same position in both files, but the type of variation is not exactly the same. In all our experiments the amount of 'half TP' was no higher than 0.004% of the total TP value, and they were included in the FP count without affecting the results. From these values the precision and recall of the processed sequence can be computed, given by Precision ¼ TP=ðTP þ FPÞ and Recall ¼ TP=ðTP þ FNÞ, respectively; they in turn can be combined into a single statistic known as an F-Score by combining them as F-Score ¼ 2ÁPrecisionÁRecall=ðPrecision þ RecallÞ.<ref type="figure" target="#tab_5">Table 5</ref>provides precision and recall scores for a selected range of methods applied to NA12878.chr20.qual, together with the F-Scores computed from them;<ref type="figure" target="#fig_6">Figure 4</ref>plots F-Score as a function of compressed size, clearly illustrating the superiority of the new approaches. Similar results were obtained using the HG01477.chr11.qual file, included in the Supplementary Material. As<ref type="figure" target="#fig_6">Figure 4</ref>and<ref type="figure" target="#tab_5">Table 5</ref>illustrate, our two approaches outperform other techniques, that is, for a given level of precision or recall, the P-Block and R-Block methods allow more compact storage of quality values than do other mechanisms. For example, if 99.0% in both precision and recall is regarded as being a minimum threshold for having high-confidence in the outcomes, then of the methods compared, P-Block with p ¼ 4 generates the most compact representation. The 563 MB required for the quality values in that configuration is less than one-third of the space required by the lossless GZip approach.<ref type="figure" target="#fig_6">Figure 4</ref>and<ref type="figure" target="#tab_5">Table 5</ref>also include an additional point, labeled OneQual, showing what would happen if no quality scores at all were stored, and every quality value was assumed to be the average quality score from the input sequence. Note that the different methods all have comparable encoding and decoding speeds, and we do not compare them on that basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>We have described and measured the performance of a range of lossy compression techniques for quality scores. The QualComp approach, and our two new methods, offer superior trade-off options when fidelity is assessed according to the measures in<ref type="figure" target="#tab_2">Table 2</ref>. Our new approaches outperformed QualComp in the Max:Min Distance criterion—a measure that is well-suited, we believe, to bioinformatics applications. Our experiments also quantified the extent to which use of lossy compression affected the performance of a typical downstream application of genetic data, and demonstrate that variation detection can still be reliably carried out, even with relatively compact storage of the quality scores.The approaches described here make use of sequentially greedy generation of blocks. One interesting question that we have not yet examined is whether mechanisms for globally optimal block construction will make a measurable difference in overall outcomes. Another area that we have not yet fully explored is the coding mechanisms used for the block representatives and for the block lengths; it may be that tailored codes (rather than Binary and Gamma) can offer further space savings once the particular characteristics of the data streams are taken into account. We are also interested in quantifying the effect that lossy compression has on other downstream applications of genetic sequencing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors thank Idoia Ochoa-Alvarez for her assistance with QualComp; Vadim Zalunin for helping with the CRAMTOOLS usage; and Wei Shi and Jan Schro¨derSchro¨der for sharing their knowledge of the area. Finally, we thank the anonymous referees for their careful input.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Example of a sequence and quality components. The value of each quality score is also shown</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm1:</head><figDesc>Inputs quality½0. .. ' À 1 and a threshold p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Quality values being formed into blocks consistent with a Mean Manhattan Distance guarantee (the approach used in the P-Block transformation) when p ¼ 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Fidelity versus space trade-offs for the quality sequence NA12878.chr20.qual. In the case of P-Block and R-Block, low values of the parameter give points in the top left; as the parameter is increased, the distance measure decreases and the space increases. (a) Average Mean Manhattan Distance. (b) Average Max:Min Distance. (c) Average Mean Squared Error</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>The rows are ordered by increasing compressed size; scores 499% are highlighted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.4.</head><figDesc>Fig. 4. Effect of lossy compression techniques on the quality of VCF computation for NA12878.chr20.qual. Each line represents a different lossy compression method; higher lines represent more desirable methods</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><figDesc>Funding: NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Center of Excellence program. This work was also funded by the Australian Research Council under the Future Fellowship scheme. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 2. Examples of fidelity measures between strictly positive numeric vectors X and Y of length ' [adapted from Cha (2007)]</figDesc><table>Measure 
Function 

Mean Manhattan DistanceðX, YÞ 

1 
' 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Example quality scores using Phred þ 33</figDesc><table>Letter 
Quality value 
Estimated error probability (%) 

( 
40 
20 
7 
55 
0.6 
F 
70 
0.02 
U 
85 
0.0006 
d 
100 
0.00002 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 3. Examples of Binary, Unary, Gamma and Golomb codes for the integers 0–6, assuming that values x ! 0 are to be coded</figDesc><table>Integer 
Binary 
Unary 
Gamma 
Golomb 

0 
0 0 0 
0 
0 
0 0 
1 
001 
10 
10 0 
0 10 
2 
010 
110 
10 1 
0 11 
3 
011 
1110 
110 00 
10 0 
4 
100 
11110 
110 01 
10 10 
5 
101 
111110 
110 10 
10 11 
6 
110 
1111110 
110 11 
110 0 

Note: The Binary code shown here uses 3 bits per integer (and hence has an upper 
limit of x ¼ 7); the Golomb code is constructed using b ¼ 3. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 4. Test sequences: quality scores were extracted from two SAM files, NA12878.chr20.qual, and HG01477.chr11.qual</figDesc><table>File 
Size (MB) Reads 
Read length H 0 

NA12878.chr20.qual 5017.98 
51 585 658 101 
3.384 
HG01477.chr11.qual 617.22 
6 407 925 100 
3.937 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 5. Recall and precision percentages for VCF outputs generated after different lossy methods are applied to the quality scores in the file NA12878.chr20.qual</figDesc><table>Method 
Size 
(MB) 

Variations 
found 

Precision Recall F-Score 

OneQual, q ¼ ' ?' ¼ 63 
0.0 83 859 
97.7 
95.2 96.4 
R-Block, ¼ 4.2 
138.7 86 971 
98.3 
99.3 98.8 
P-Block, p ¼ 16 
141.5 87 172 
98.3 
99.6 99</table></figure>

			<note place="foot">ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> i &apos; maxðXi, YiÞ minðXi, YiÞ Mean Squared ErrorðX, YÞ 1 &apos; P &apos; i¼1 ðX i À Y i Þ 2 Chebyshev DistanceðX, YÞ max 1 i &apos; jX i À Y i j Soergel DistanceðX, YÞ P &apos; i¼1 jXiÀYij P &apos; i¼1 maxðXi, YiÞ Lorentzian DistanceðX, YÞ P &apos; i¼1 log 2 ð1 þ jX i À Y i jÞ Note: Scores of zero indicate that X and Y are identical except for the Max:Min measure, where one is the minimum value.</note>

			<note place="foot">Lossy compression of quality scores at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">R.Cá novas et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Next-generation DNA sequencing techniques</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ansorge</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="195" to="203" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A block-sorting lossless data compression algorithm</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Burrows</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Wheeler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital Equipment Corporation Systems Research Center</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Practical compression for multi-alignment genomic files</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Ca´novasca´novas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Moffat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 36th Australasian Computer Science Conference</title>
		<meeting>36th Australasian Computer Science Conference<address><addrLine>Adelaide, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Comprehensive survey on distance/similarity measures between probability density functions</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Cha</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Math. Models Methods Appl. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="300" to="307" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Genomes for all</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">M</forename>
				<surname>Church</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Am</title>
		<imprint>
			<biblScope unit="volume">294</biblScope>
			<biblScope unit="page" from="46" to="54" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">The Sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Cock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1767" to="1771" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">The variant call format and VCFtools</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Danecek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2156" to="2158" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Compression of DNA sequence reads in FASTQ format</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Deorowicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Grabowski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="860" to="862" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Universal codeword sets and representations of the integers</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Elias</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="194" to="203" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Base-calling of automated sequencer traces using Phred.II. Error probabilities</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Ewing</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Green</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="186" to="194" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient storage of high throughput DNA sequencing data using reference-based compression</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H</forename>
				<surname>Fritz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="734" to="740" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Textual data compression in computational biology: a synopsis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Giancarlo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1575" to="1586" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Adaptive reference-free compression of sequence quality scores</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Janin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="24" to="30" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Compressing genomic sequence fragments using SLIMGENE</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kozanitis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual International Conference on Research in Computational Molecular Biology</title>
		<meeting>the 14th Annual International Conference on Research in Computational Molecular Biology</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="310" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">On the role of mismatch in rate distortion theory</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lapidoth</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tran. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="38" to="47" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">The sequence alignment/map format and SAMtools</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2078" to="2079" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Next-generation DNA sequencing methods</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Mardis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Genomics Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="387" to="402" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<monogr>
		<title level="m" type="main">Compression and Coding Algorithms</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Moffat</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Turpin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title level="m" type="main">Overview of sequencing technology platforms</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Myllykangas</surname>
			</persName>
		</author>
		<editor>Rodrı´guezRodrı´guez-Ezpeleta,N. et al. Bioinformatics for High Throughput Sequencing</editor>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="11" to="25" />
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Genotype and SNP calling from next-generation sequencing data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Nielsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="443" to="451" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">QualComp: a new lossy compressor for quality scores based on rate distortion theory</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ochoa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">187</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">G-SQZ: compact encoding of genomic sequence and quality data</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Tembe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2192" to="2194" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Transformations for the compression of FASTQ quality scores of next-generation sequencing data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Wan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="628" to="635" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>