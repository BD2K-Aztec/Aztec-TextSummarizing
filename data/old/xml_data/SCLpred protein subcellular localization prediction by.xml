
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequence analysis SCLpred: protein subcellular localization prediction by N-to-1 neural networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1920">. 20 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Catherine</forename>
								<surname>Mooney</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Informatics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Medicine and Medical Science</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Complex and Adaptive Systems Laboratory</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Conway Institute of Biomolecular and Biomedical Science</orgName>
								<orgName type="institution" key="instit2">University College Dublin</orgName>
								<address>
									<settlement>Belfield</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yong-Hong</forename>
								<surname>Wang</surname>
							</persName>
							<affiliation key="aff4">
								<orgName type="department">Biophysics Institute</orgName>
								<orgName type="institution">Hebei University of Technology</orgName>
								<address>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Gianluca</forename>
								<surname>Pollastri</surname>
							</persName>
							<email>gianluca.pollastri@ucd.ie</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Informatics</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Complex and Adaptive Systems Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sequence analysis SCLpred: protein subcellular localization prediction by N-to-1 neural networks</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="page" from="2812" to="2819"/>
							<date type="published" when="1920">. 20 2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr494</idno>
					<note type="submission">Received on June 17, 2011; revised on August 5, 2011; accepted on August 22, 2011</note>
					<note>[11:09 20/9/2011 Bioinformatics-btr494.tex] Page: 2812 2812–2819 Associate Editor: Burkhard Rost Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Knowledge of the subcellular location of a protein provides valuable information about its function and possible interaction with other proteins. In the post-genomic era, fast and accurate predictors of subcellular location are required if this abundance of sequence data is to be fully exploited. We have developed a subcellular localization predictor (SCLpred), which predicts the location of a protein into four classes for animals and fungi and five classes for plants (secreted, cytoplasm, nucleus, mitochondrion and chloroplast) using machine learning models trained on large non-redundant sets of protein sequences. The algorithm powering SCLpred is a novel Neural Network (N-to-1 Neural Network, or N1-NN) we have developed, which is capable of mapping whole sequences into single properties (a functional class, in this work) without resorting to predefined transformations, but rather by adaptively compressing the sequence into a hidden feature vector. We benchmark SCLpred against other publicly available predictors using two benchmarks including a new subset of Swiss-Prot Release 2010_06. We show that SCLpred surpasses the state of the art. The N1-NN algorithm is fully general and may be applied to a host of problems of similar shape, that is, in which a whole sequence needs to be mapped into a fixed-size array of properties, and the adaptive compression it operates may shed light on the space of protein sequences. Availability: The predictive systems described in this article are publicly available as a web server at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With the recent advances in high-throughput sequencing technology, there has been a rapid increase in the availability of sequence information. To fully exploit, this information sequences need to be annotated quickly and accurately, which has led to the development of automated annotation systems. A major step toward determining the function of a protein is determining its subcellular localization (SCL). Knowledge of the location of the protein sheds light not only on where it might function but also what other proteins it might interact with, as, in order to interact, proteins must inhabit * To whom correspondence should be addressed. the same location or physically adjacent compartments, at least temporarily. There is a growing gap between the number of proteins that have reliable SCL annotations and the number of known protein sequences. Experimental approaches to SCL prediction are timeconsuming and expensive, whereas computational methods can provide fast and increasingly accurate localization predictions. There are various different mechanisms by which a protein is directed to a particular location in the cell, and there are many possible compartments in which eukaryotic proteins may be located. Some nuclear proteins have a nuclear localization signal (NLS), which may occur anywhere in the sequence (<ref type="bibr" target="#b14">Cokol et al., 2000</ref>). Most secreted, mitochondrial and chloroplastic proteins have N-terminal cleavable peptides (SP, mTP and cTP), but many proteins have no known motif (<ref type="bibr" target="#b18">Emanuelsson, 2002;</ref><ref type="bibr" target="#b26">Nair and Rost, 2005</ref>), and many are known not to have N-terminal peptides (<ref type="bibr" target="#b8">Bendtsen et al., 2004a</ref>). Even in these cases, the information contained in a protein sequence may be sufficient to predict the protein's location in the cell, given that residue and k-residue frequencies correlate with locations (<ref type="bibr" target="#b18">Emanuelsson, 2002;</ref><ref type="bibr">Rost, 2003, 2005;</ref><ref type="bibr" target="#b28">Nakashima and Nishikawa, 1994</ref>). There are many methods for the prediction of SCL that can be roughly divided into two groups: homology or knowledgebased, which rely on similarity to another sequence of known location, or other known information about the sequence or similar sequences, for example WoLF PSORT (<ref type="bibr" target="#b21">Horton et al., 2007</ref>) or SherLoc (<ref type="bibr" target="#b31">Shatkay et al., 2007</ref>); and de novo or ab initio, sequencebased methods, which may use evolutionary information in the form of multiple sequence alignments (MSAs), but do not depend on similarity to sequences of known location, for example BaCelLo (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>). We predict SCL for eukaryotes only, which we divide into animals, plants and fungi. There are many potential classes of subcellular localization, and different prediction systems sometimes use different class subdivisions, ranging from 3 (<ref type="bibr" target="#b11">Bóden and Hawkins, 2005;</ref><ref type="bibr">Emanuelsson et al., 2000;</ref><ref type="bibr" target="#b20">Hawkins and Bóden, 2006</ref>) up to more than 10 classes (<ref type="bibr" target="#b21">Horton et al., 2007</ref>). Here, similarly to BaCelLo (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>), to which we directly compare our results, we consider four subcellular localizations for animals and fungi and five for plants: nucleus, cytoplasm, mitochondrion, chloroplast and secreted. In a first series of tests, we adopt essentially the same experimental setting as in (<ref type="bibr" target="#b13">Casadio et al., 2008</ref>) and (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>), to which we compare our predictor. We then take a further step by developing new, redundancy reduced training and testing sets starting with Swiss-Prot Release<ref type="bibr">[11:09 20/9/2011 Bioinformatics-btr494.tex]</ref>Page: 2813 2812–2819</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Protein subcellular localization prediction</head><p>2010_06 (<ref type="bibr" target="#b12">Boeckmann et al., 2003</ref>) and benchmark SCLpred on these sets against six state-of-the-art, publicly available predictors of SCL: BaCelLo, LOCtree, SherLoc, Protein Prowler, TARGETp and WoLF PSORT, which we briefly describe in the following sections. BaCelLo: BaCelLo (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>) uses a hierarchy of binary support vector machines (SVMs) to predict SCL for eukaryotes into four classes for animals and fungi and five for plants: secreted, cytoplasm, nucleus, mitochondrion and chloroplast. BaCelLo is trained on a non-redundant set of sequences from SwissProt 48. Predictions are made from the full sequence, from the N-and C-terminal regions and evolutionary information. BaCelLo is available at http://gpcr.biocomp.unibo.it/bacello/. LOCtree: LOCtree (<ref type="bibr" target="#b26">Nair and Rost, 2005</ref>) uses binary SVMs to predict SCL. Three versions of the predictor are available, for plants, non-plants and prokaryotes. For prokaryotes, predictions are dived into three classes: secreted, periplasm and cytoplasm. For eukaryotes, predictions are divided into six classes: extracellular space, nucleus, cytoplasm, chloroplast, mitochondrion and other organelles. LOCtree is trained on a redundancy reduced subset of Swiss-Prot 40. Predictions are made from the full sequence, a 50-residue N-terminal region, predicted secondary structure and the output of SIGNALp (for eukaryotes). LOCtree is available at http://www.predictprotein.org/. SherLoc: SherLoc (<ref type="bibr" target="#b31">Shatkay et al., 2007</ref>) uses SVM that integrate sequence and text-based features. There are three predictors (animal, fungi, plant) which predict 10 locations for animals and fungi: cytoplasm, endoplasmic reticulum, extracellular, Golgi, lysosome, mitochondrion, nucleus, peroxisome, plasma membrane, vacuole and an extra class, chloroplast, for plants. The predictors are trained on sequences extracted from Swiss-Prot 42. http://wwwbs.informatik.uni-tuebingen.de/Services/SherLoc/. TargetP: TargetP (<ref type="bibr">Emanuelsson et al., 2000</ref>) uses a feed-forward neural network for the prediction of plant and non-plant SCL into three and four classes, respectively, based on the N-terminal sequence. The prediction is based on the presence of a chloroplast transit peptide (cTP), a mitochondrial targeting peptide (mTP) or a secretory pathway signal peptide (SP). TargetP is available at http://www.cbs.dtu.dk/services/TargetP/. Protein Prowler: Protein Prowler (<ref type="bibr" target="#b11">Bóden and Hawkins, 2005;</ref><ref type="bibr" target="#b20">Hawkins and Bóden, 2006</ref>) is based on the ideas behind TargetP and trained on a subset of Swiss-Prot 37 and 38. The predictor uses neural networks and SVMs specialized for the prediction of plants or nonplants and predicts into the following classes: secretory pathway, mitochondrion, chloroplast and other. Protein Prowler is available at http://pprowler.itee.uq.edu.au/. WoLF PSORT: WoLF PSORT (<ref type="bibr" target="#b21">Horton et al., 2007</ref>) is a version of the PSORT family of SCL predictors for the prediction of eukaryotic proteins based on their sequence. Based on a number of features (residue composition, presence of known sorting signal and target peptides, etc.), WoLF PSORT uses a k-nearest neighbor classifier, comparing these features to other Swiss-Prot-annotated proteins, resulting in a ranked list of up to 12 possible locations: chloroplast, cytosol, cytoskeleton, endoplasmic reticulum, extracellular, Golgiapparatus, lysosome, mitochondrion, nuclear, peroxisome, plasma membrane and vacuolar membrane. WoLF PSORT is available at http://wolfpsort.org/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MATERIALS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets</head><p>The first dataset that we use to train and test SCLpred is the dataset used by<ref type="bibr">Pierleoni</ref>, respectively, have a 'SUBCELLULAR LOCATION'. We remove membrane proteins and sequences that have nonexperimental qualifiers (Potential, Probable, By similarity), leaving 16 406, 3339 and 7116 sequences, respectively. We internally redundancy reduce each of these sets using an all-against-all BLAST (<ref type="bibr" target="#b4">Altschul et al., 1997</ref>) search (with e = 10 −3 ) removing any sequence with a hit with &gt;30% sequence identity to any other sequence in the set. All the sequences added to SwissProt earlier than 2009 in the set are used as a training set (2010_06 training set). Sequences added to Swiss-Prot in 2009 or later are used for testing, as these sequences have &lt;30% sequence similarity to any sequences used to train any of the predictors tested in this article. We refer to as the 2009+ test set.<ref type="figure" target="#tab_2">Table 2</ref>shows the number of sequences per class for each of the three kingdoms in these new training (2010_06 training set) and test sets (2009+ test set). The BaCelLo datasets are available on the BaCelLo website: http://gpcr.biocomp.unibo.it/bacello/dataset.htm and the SCLpred datasets are available upon request from the authors. MSAs are extracted from uniref90 (<ref type="bibr" target="#b33">Suzek et al., 2007</ref>) from February 2010 containing 6 464 895 sequences. The alignments are generated by three runs of PSI-BLAST with parameters b = 3000 (maximum number of hits) and e = 10 −3 (expectation of a random hit).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Predictive architecture: N1-NN</head><p>We call the model that we describe in this work N-to-1 Neural Network or N1-NN. The model is based and on our framework to design Neural Networks for structured data (<ref type="bibr" target="#b5">Baldi and Pollastri, 2003;</ref><ref type="bibr" target="#b34">Walsh et al., 2009</ref>). The aim of the model is to map a sequence of variable length N into a single property or fixed-width array of properties. Other models transform/compress the sequence into a fixed number of descriptors (or into descriptors of pairwise relations between sequences) beforehand, and they then map these descriptors into the property of interest. These descriptors are Page: 2814 2812–2819. In some cases whole sections of the sequence are directly taken into account (again, typically the termini, where some signals are to be found), but even in this case the size of this section needs to be fixed and decided beforehand. In N1-NN, instead, we do not compress all the information of a sequence into a handful of predefined features (e.g. k-mer frequencies, sequence length, etc.). Rather, we decide beforehand only how many features we want to compress a sequence into. If these features are stored in a vector</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.Mooney et al.</head><formula>f = (f 1 ,...,f h )</formula><p>, and if we represent the i-th residue in the sequence as r i , then f is obtained as:</p><formula>f = k N i=1 N (h) (r i−c ,...,r i+c ) (1)</formula><p>where N (h) is a non-linear function, which we implement by a two-layered feed-forward Neural Network with h non-linear output units (the sequenceto-feature network). N (h) is replicated N times (N being the sequence length), and k is a normalization constant. The feature vector f is obtained by combining information coming from all windows of 2c+1 residues in the protein. If c = 20, as in all the tests in this article, the motifs have a length of 41 residues. The feature vector f thus obtained is mapped into the property of interest o (for instance, cellular component class), as follows:</p><formula>o = N (o) (f ) (2)</formula><p>where N (o) is a non-linear function that we implement by a second twolayered feed-forward neural network (the feature-to-output network). The whole neural network (the cascade of N replicas of the sequence-to-feature vector network and one feature-to-output network) is itself a feed-forward neural network, and thus can be trained by gradient descent via the backpropagation algorithm. As there are N copies of N (h) for a sequence of length N, there will be N contributions to the gradient for this network, which are added together. A graphical representation of N-to-1 NN is shown in<ref type="figure" target="#fig_0">Fig. 1</ref>. The feature vector f is a compression of the sequence into h real-valued descriptors. These descriptors are automatically determined/learned in order to minimize the output error, hence to be most informative to predict the property of interest. Although there is a daunting number of possible motifs of length 2c+1, the model does not need to count them or represent them all. Only a relatively small number of free parameters is available to represent all the motifs in a sequence. This prevents overparametrization and model fitting problems that arise when one counts frequencies of n-mers as soon as n &gt; 2−3. If training is successful, only (soft) motifs relevant to the task at hand are represented in f. Thus, f is effectively a compressed version of the sequence into a fixed-size array. The compression is property driven, meaning that different predictive targets generally induce different representations of a sequence. The number of free parameters in the overall N1-NN can be controlled by: the number of units in the hidden layer of the sequence-to-feature network</p><formula>N (h) (), N H f ;</formula><p>the number of hidden units in the feature-to-output networknetwork (only three represented for simplicity) process all the (overlapping) motifs of a predefined length in a sequence. The vectorial outputs f k of these networks are added up, and the resulting feature vector f is input to the N (o) network to produce the localization prediction.</p><formula>N (o) (), N H o ;</formula><p>the number of hidden states in the feature vector f , which is also the number of output units in the sequence-to-feature network, N f. Given that only one instance of the sequence-to-feature network (i.e. only one set of free parameters) is replicated for all positions in the sequence, and there is only one feature-to-output network, the overall number of free parameters N p of the N1-NN is:</p><formula>N p = (N i +1)N H f +(N H f +1)N f +(N f +1)N H o +(N H o +1)N o (3)</formula><p>where N i is the size of the input vector representing one residue (including its context) and N o is the number of output classes. The number of free parameters can be controlled by N H f , N f and N H o , while N o is governed by the property being predicted, and N i depends on the input representation and, importantly, by the size of the motifs being considered<ref type="bibr">[</ref>Training: for each training experiment (i.e. training on the BaCelLo training set and training on the 2010_06 training set), we implement three predictors, one for each of the three kingdoms of animals, fungi and plants. Each training is conducted by 10-fold cross-validation, i.e. 10 different sets of training runs are performed in which a different tenth of the overall set is reserved for testing. The 10 tenths are roughly equally sized, disjoint and their union covers the whole set. For each training, the 9/10 of the set that are not reserved for testing are split into a validation set (1/10 of the overall set) and a proper training set. Given that some classes are far less numerous than others, in order to rebalance the training set we repeat the number of instances in the various classes until we have roughly the same number of examples in each of them. Examples in the testing and validation sets are not replicated. The training set is used to learn the free parameters of the network by gradient descent, while the validation set is used to monitor the training process. For each different architecture, we run three trainings, which differ only in the training versus validation split. Excluding different validation sets ensures that the resulting models are different, which yields larger gains when ensembling them. During preliminary experiments (run on the BaCelLo plant training set split into 2/3 for training and 1/3 for testing), we tested N H o values of 6, 8 and 10, which all yielded similar performances. When choosing a motif size, we considered that the average size for known signal peptides in eukaryotes is ∼20 residues (<ref type="bibr" target="#b9">Bendtsen et al., 2004b</ref>), and 35–40 is an upper size bound for most known signals and NLS (<ref type="bibr" target="#b9">Bendtsen et al., 2004b;</ref><ref type="bibr" target="#b14">Cokol et al., 2000</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Protein subcellular localization prediction</head><p>It should be noted that, since all (overlapping) motifs of length 2c+1 are considered by an N-to-1 NN, it is not strictly necessary for 2c+1 to cover all motif sizes, because signal larger than 2c+1 is still input to an N-to-1 NN as all its overlapping substrings of length 2c+1, although this may lead to the loss of some positional information. During preliminary experiments, we tested c values of 10 and 15, which performed marginally less well than c = 20. We kept N H f and N f fixed at 10 in all experiments. During the final cross-validations, we use exactly the same architecture for all sets and all kingdoms, in which N H f = N f = N H o = 10 and c = 20. All trainings are also identical in that the weights in the networks are updated every 10 examples (proteins) and 2000 epochs of training are performed, which brings the training error to near zero in all cases. In all cases, we save networks at epochs 1800, 1900 and 2000, ensemble average them and evaluate them on the corresponding test set. Saving the models that perform best on validation yields very similar results. The final results for each 10-fold cross-validation (different kingdoms, BaCelLo and 2010_06 training sets) are the average of the results on each test set. When testing on an independent set from the one used during training (BaCelLo for training and BaCelLo_2008 for testing, 2010_06 for training and 2009+ for testing), we ensemble-combine all the models from all cross-validation folds of the best architecture. Training is performed by gradient descent on the error, which we model as the relative entropy between the target class and the output of the network. The overall output of the network [output layer of N (o) (</p><p>)] is implemented as a softmax function, while all internal squashing functions are implemented as hyperbolic tangents. The examples are shuffled between epochs. We use a momentum term of 0.9. Although this does not significantly affect the final results, it speeds up overall training times by a factor 10. The learning rate is kept fixed at 0.2 throughout the training. Training one model on a state of the art core took between 8 h and 4 days, depending on the size of the training set. Predicting the localization of an average-sized protein from the sequence and MSA takes less than a second, in fact running BLAST to generate MSA is far costlier (minutes) than obtaining the actual prediction from an ensemble of N-to-1 NN. Evaluating performance: to evaluate the performance of SCLpred against other predictors, we use the following global indices:</p><formula>GC = ij (z ij −e ij ) 2 e ij N(K −1) Q = i z ii ij z ij (4)</formula><p>where: @BULLET z ij : the number of sequences of class i predicted to be in class j. @BULLET e ij : the number of sequences of class i expected to be predicted in class j by chance. @BULLET N: the number of sequences. @BULLET K: the number of classes.</p><p>To measure performances for a given class i we use:</p><formula>Spec = TP TP+FP Sens = TP TP+FN FPR = FP FP+TN MCC = TP×TN−FP×FN (TP+FP)(TP+FN)(TN+FP)(TN+FN) (5)</formula><formula>v =i j =i z jv. @BULLET False negatives (FN): j =i z ij .</formula><p>We emphasize performances based on GC [see<ref type="bibr" target="#b7">Baldi et al. (2000)</ref>for more details], as this index minimizes the effect of class sizes. For some of the experiments, we extract performances of other predictors from the literature, hence not all indices are reported at all times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head><p>In previous tests, BaCelLo (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>) was shown to outperform the following publicly available methods for the prediction of the subcellular localization: LOCtree (<ref type="bibr" target="#b26">Nair and Rost, 2005</ref>), PSORT II (<ref type="bibr" target="#b27">Nakai and Horton, 1999</ref>), SubLoc (<ref type="bibr" target="#b22">Hua and Sun, 2001</ref>), ESLpred (<ref type="bibr" target="#b10">Bhasin and Raghava, 2004</ref>), LOCSVMpsi (<ref type="bibr" target="#b35">Xie et al., 2005</ref>), SLP-local (<ref type="bibr" target="#b23">Matsuda et al., 2005</ref>), Protein Prowler (<ref type="bibr" target="#b11">Bóden and Hawkins, 2005</ref>), TARGETp (<ref type="bibr">Emanuelsson et al., 2000</ref>), PredoTar (<ref type="bibr" target="#b32">Small et al., 2004</ref>) and pTARGET (<ref type="bibr" target="#b19">Guda and Subramaniam, 2005</ref>). In<ref type="figure" target="#tab_3">Table 3</ref>, we show the performance of SCLpred compared with BaCelLo on the BaCelLo training set (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>). Both predictors are assessed by 10-fold cross-validation on the same set. Overall SCLpred is far more accurate for animals (Q 82% versus 74% and GC 72% versus 67%) and fungi (Q 75% versus 70% and GC 67% versus 66%) while the accuracy for plants (Q) is the same (68%), but GC is still considerably higher for SCLpred (63% versus 59%).<ref type="figure" target="#tab_4">Table 4</ref>shows the accuracy of the same version of SCLpred tested on the BaCelLo_2008 test dataset from<ref type="bibr" target="#b13">Casadio et al. (2008)</ref>compared with the other five SCL predictors tested on the same dataset<ref type="bibr">[results from Casadio et al. (2008)]</ref>. Notice that two of the predictors (Protein Prowler and TARGETp) use a different class assignment ('easier' as comprised by fewer classes) and are thus not directly comparable to SCLpred. The results refer to versions of the various predictors that were trained on datasets extracted from Swiss-Prot release 48 or earlier. Since the BaCelLo_2008 test set Page: 2816 2812–2819<ref type="figure" target="#tab_4">Table 4</ref>. Results for SCLpred, trained on the BaCelLo training set from Swiss-Prot 48 (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>), compared with BaCelLo (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>), LOCtree (<ref type="bibr" target="#b26">Nair and Rost, 2005</ref>), WoLF PSORT (<ref type="bibr" target="#b21">Horton et al., 2007</ref>), Protein Prowler (<ref type="bibr" target="#b20">Hawkins and Bóden, 2006</ref>) and TARGETp (<ref type="bibr">Emanuelsson et al., 2000</ref>Tested on the BaCelLo_2008 test set (see text). Results for the predictors other than SCLpred from<ref type="bibr" target="#b13">Casadio et al. (2008)</ref>. Results in italics are for predictors using a fewer classes, hence not directly comparable to SCLpred. For these predictors 'Other' is the class of proteins that cannot be classified as mitochondrion, secreted or chloroplast based on the presence of a known SP, mTP or cTP. Deviations are ±2 for both GC and Q for Fungi and ±1 for Plant and Animal. These are for our predictor (SCLpred). We have no access to the raw data for the other predictors as these are obtained from the literature and were not reported. is extracted from Swiss-Prot release 54 and redundancy reduced against Swiss-Prot 48, there is no significant overlap between the training sets of any predictors in the table and the BaCelLo_2008 test set. For animals we obtain a Q of 85% and GC of 81%, higher than the second best predictor that is directly comparable (WoLF PSORT, with 81 and 75%, respectively). SCLpred also performs better than the two predictors that are not directly comparable on the two classes that are common (mitochondrion and secreted). On fungi, SCLpred has the best Q (60% versus BaCelLo's 59%) and the second best GC (57% versus WoLF PSORT's 59%). On plants, SCLpred has by far the highest GC (58% versus BaCelLo's 46%) and the joint highest Q (76%, again with BaCelLo). It should be noted that BaCelLo was optimized for balanced class accuracies (<ref type="bibr" target="#b30">Pierleoni et al., 2006</ref>), that is, to maximize average class sensitivity (nQ measure). Based on nQ, SCLpred still outperforms BaCelLo on both the BaCelLo and BaCelLo_2008 set for animal proteins (by 2.3 and 6.2%, respectively), BaCelLo fares better on fungi (by 4.5 and 2%), while on plants BaCelLo does better on the BaCelLo training set (by 4.6%) and SCLpred on the BaCelLo_2008 test set (by 2.2%). Overall BaCelLo shows a more balanced sensitivity across classes than SCLpred, although in the case of animal proteins this is at a lower average level. We repeat the experiments on a new training set extracted from the 2010_06 release of Swiss-Prot, which is approximately twice the size of the BaCelLo set for all three kingdoms. The accuracy of this new version of SCLpred is shown in<ref type="figure" target="#tab_5">Table 5</ref>. On animal and fungi, overall performances are lower, in absolute value, to those obtained on the BaCelLo set. We attribute this to the more balanced nature of the 2010_06 training set, which is thus intrinsically 'harder'. Assigning proteins randomly to classes with a probability proportional to class frequencies yields a Q measure 3% higher on the<ref type="bibr">BaCelLo</ref><ref type="figure" target="#tab_5">Table 5</ref>proteins as fixed-size arrays) induced by different output targets (functional classes, protein folds/families), to determine whether they are satisfactory representations toward protein comparison, and whether they yield insights into the structure of the protein space. SCLpred is available as part of our web servers for protein sequence annotation. Up to 32 768 residues can be handled in a single submission. The servers are freely available for academic users at http://distill.ucd.ie/distill/. Predictions are obtained by an ensemble of all models trained on the 2010_06 training set (as in<ref type="figure">Table 6</ref>). Linux binaries and the benchmarking sets are freely available for academic users upon request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.Mooney et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Protein subcellular localization prediction</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. An N-to-1 Neural Network. N copies of the N (h) network (only three represented for simplicity) process all the (overlapping) motifs of a predefined length in a sequence. The vectorial outputs f k of these networks are added up, and the resulting feature vector f is input to the N (o) network to produce the localization prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>2c+1 in Equation (1)]. The input at each residue is coded as a letter out of an alphabet of 25. Beside the 20 standard amino acids, B (aspartic acid or asparagine), U (selenocysteine), X (unknown), Z (glutamic acid or glutamine) and. (gap) are considered. The input presented to the networks is the frequency of each of the 24 non-gap symbols, plus the total frequency of gaps in each column of the MSA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>[11:09 20/9/2011 Bioinformatics-btr494.tex] Page: 2815 2812–2819</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Chlo0.</head><figDesc>68 0.79 0.76 0.73 Cyto 0.58 0.54 0.41 0.65 0.46 0.39 0.39 0.60 0.39 0.36 0.47 0.52 Mito 0.77 0.74 0.66 0.76 0.72 0.78 0.72 0.81 0.49 0.34 0.54 0.51 Nucl 0.83 0.85 0.85 0.65 0.83 0.82 0.85 0.67 0.83 0.76 0.76 0.72 Secr 0.93 0.93 0.91 0.91 0.86 0.85 0.85 0.94 0.89 0.85 0.65 0.85</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>animal training set than on the 2010_06 set (33.1% versus 30.1%) and 6.3% higher on fungi (41.3% versus 35.0%). Always predicting the most numerous class yields a 9% higher Q Page: 2817 2812–2819</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>.</head><figDesc>SCLpred, trained and tested in 10-fold cross-validation on the 2010_06 training set Animals Fungi Plants Spec Sens MCC Spec Sens MCC Spec Sens MCC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Number of sequences per class for each of the three kingdoms in the BaCelLo training set and the BaCelLo_2008 test set</figDesc><table>BaCelLo training set 
BaCelLo_2008 test set 

Animals Fungi Plants Animals Fungi Plants 

Cytoplasm 
439 
211 
58 
846 
331 
102 
Mitochondrion 
188 
188 
67 
241 
104 
38 
Nucleus 
1166 
711 121 
979 
256 
99 
Secreted 
804 
88 
41 
722 
26 
18 
Chloroplast 
204 
1345 

Total 
2597 
1198 491 
2788 
717 
1602 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. Number of sequences per class for each of the three kingdoms in the 2010_06 training set and the 2009+ test set</figDesc><table>2010_06 training set 
2009+ test set 

Animals Fungi Plants Animals Fungi Plants 

Cytoplasm 
1364 
890 
133 
20 
34 
8 
Mitochondrion 
315 
413 
81 
5 
19 
7 
Nucleus 
1830 
1150 
259 
25 
36 
54 
Secreted 
1584 
111 
98 
68 
15 
8 
Chloroplast 
523 
29 

Total 
5095 
2564 
1094 
118 
104 
106 

typically frequencies of residues or k-mers, sometimes computed separately 
on different parts of the sequence [e.g. around the termini, as in (Pierleoni 
et al., 2006)]</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 3. Results for BaCelLo [from Pierleoni et al. (2006)] and SCLpred, trained and tested in 10-fold cross-validation on the BaCelLo training set (Pierleoni et al., 2006), extracted from Swiss-Prot 48 SCLpred BaCelLo SCLpred BaCelLo SCLpred BaCelLo Spec Sens Spec Sens Spec Sens Spec Sens Spec Sens Spec Sens</figDesc><table>Animals 
Fungi 
Plants 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="0">.67 0.71 on the BaCelLo set compared with 2010_06 for animals (44.9% versus 35.9%) and 14.4% higher for fungi (59.3% versus 44.9%). Moreover, in both kingdoms the class which is overrepresented in the 2010_06 set compared with BaCelLo is cytoplasm (26.8% versus 16.9% of the examples for animal, 34.7% versus 17.6% of the examples for fungi), which in all out tests is the hardest to predict. Hence not only is 2010_06 more challenging because of its distribution of examples, but also because it contains a higher proportion of difficult instances. On plants, Q is higher on the 2010_06 training than on the BaCelLo training set (71% versus 68%) while GC is lower (58% versus 63%). This is the result of a larger chloroplast class (which is well predicted) in 2010_06, and of the mitochondrion class being only 7% of the 2010_06 set (versus 14% in BaCelLo), which results in infrequent predictions for this class. While the improvement on the much larger chloroplast class dominates in terms of Q measure, the reduction of performances on mitochondrion dominates with respect to GC, which weighs all classes equally. Overall it should be noted that, because of different class composition, it is hard to compare Q and GC measures across different datasets, and different predictors should always be ranked on the same dataset, as we do throughout this article. We then test the version of SCLpred trained on the 2010_06 set on the 2009+ dataset (a subset of Swiss-Prot 2010_06 with &lt;30% sequence similarity to the training set, described in Section 2.1). We compare its accuracy with BaCelLo, SherLoc, WoLF PSORT, Protein Prowler and TARGETp (Table 6). Results for TARGETp and Protein Prowler are based on three class predictions for animals and fungi, and four for plants, whereas for WoLF PSORT and SherLoc prediction is possible for more four/five classes. For WoLF PSORT, we count any proteins predicted as &apos;vacu&apos;, &apos;lyso&apos;, &apos;E.R.&apos;, &apos;golg&apos; or &apos;plas&apos; as secreted, and any &apos;cyto&apos;, &apos;cysk&apos;, &apos;cyto_nucl&apos; as cytoplasmic and any &apos;nucl&apos; or &apos;cyto_nucl&apos; as nuclear. For SherLoc, any sequences predicted as &apos;extracellular&apos;, &apos;ER&apos;, &apos;vacuolar&apos;, &apos;peroxisomal&apos;, &apos;Golgi&apos; or &apos;plasma&apos; are counted as secreted. On 2009+, SCLpred again performs best of all predictors. On animals, Q is 89%, more than 20% better than the second best directly comparable predictor (BaCelLo, with 66.3%), and over 10% better than predictors using one less class. GC, at 79%, is also 10% higher than BaCelLo, and higher than that of the two predictors with one less class. On fungi, both Q and GC (72% and 69%) are the highest of all four class predictors, and similar to those obtained by the three class predictors. On plants, again Q (at 80%) is by far the highest (SherLoc in this case being the second best five class predictor at 68%), and GC (66%) is at least 9% higher than all other five class predictors, and only lower than Protein Prowler&apos;s (69%) which tackles the simpler four class problem. In this case, SCLpred also outperforms BaCelLo by nQ on all three kingdoms. 4 CONCLUSION AND FUTURE WORK As the amount of sequence information churned out by experimental methods keeps expanding at an ever-increasing pace, it is crucial to develop and make available fast and accurate computational methods to make sense of it. SCL prediction is a step toward bridging the gap between a protein sequence and the protein&apos;s function and can provide information about potential protein–protein interactions and insight into possible drug targets and disease processes. As different SCL predictors are specialized for prediction into different classes and number of classes, and as some predictors are more accurate than others at prediction into any one class, this information can be exploited to lead to more accurate overall consensus predictions, especially if the predictors are diverse in their behavior. In this article, we have developed a new method for SCL prediction (SCLpred) based on a novel Neural Network architecture (N1-NN). The architecture can map a sequence of any length into a set of individual properties for the whole sequence. We have developed three kingdom specific predictors for animals, fungi and plants and predict into four classes for animals and fungi (nucleus, cytoplasm, mitochondrion and the secreted) and an additional fifth class for plants (chloroplast). We have trained SCLpred in 10-fold cross-validation on large non-redundant subsets of annotated proteins from Swiss-Prot 2010_06 and benchmarked it against five other state-of-the-art SCL prediction servers on an independent set of recently annotated proteins. SCLpred performs favorably on these benchmarks, often by consistent margins, and we expect that its prediction accuracy will continue to improve with frequent retrainings to take advantage of larger, more diverse, datasets of annotated proteins as they become available, and as our understanding of the underlying biological mechanisms improves. We expect larger datasets to be especially beneficial to our models, as these incorporate information from the whole sequence and normally have a higher number of free parameters than the alternatives. In this work, we have used the primary sequence and multiple sequence alignments as inputs to the network. Additional residuelevel information may be included, such as predicted secondary structure, solvent accessibility, location of binding sites, etc. Incorporating diverse information into the input to SCLpred is one of our future directions of investigation, as is the inclusion of putative homology to &apos;templates&apos; or proteins of known localization/structure [e.g. by techniques similar to those in Mooney and Pollastri (2009)]. In this work, we predict subcellular localizations into a small number of classes (four for animal and fungi, five for plants), to allow the comparison of our novel algorithms against a a number of existing predictors, and direct comparison against BaCelLo in particular, which has been shown as one of the best-performing ab initio systems to date. We are currently testing our methods on a wider set of localization classes, as well as different functional tasks. A further direction of research is studying the space of f vectors (i.e. compressed, property-driven representations of whole</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank the authors of BaCelLo for making their datasets publicly available, Dr Andrea Pierleoni for assistance with the BaCelLo predictions and Tatyana Goldberg for providing LOCtree predictions. We wish to acknowledge UCD IT Services for the provision of computational facilities and support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>btr494. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2818" />
			<biblScope unit="page" from="2812" to="2819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Mooney</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName>
				<surname>Pierleoni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Table 6. Results for SCLpred, trained on the 2010_06 set, compared with BaCelLo SherLoc WoLF PSORT Protein Prowler (Hawkins and Bóden, 2006) and TARGETp (Emanuelsson et al</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>SCLpred. BaCelLo LOCtree SherLoc Protein Prowler TARGETp WoLF PSORT</note>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Results in italics are for predictors using fewer of classes, hence not directly comparable to SCLpred. For these predictors &apos;Other&apos; is the class of proteins that cannot be classified as mitochondrion, secreted or chloroplast based on the presence of a known SP, mTP or cTP. Deviations for both GC and Q are ±4 for Plant and Fungi and ±3 for Animal Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3389" to="3402" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>Tested. on the 2009+ set</note>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">The principled design of large-scale recursive neural network architectures – DAG-RNNs and the protein structure prediction problem</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Baldi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Pollastri</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="575" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Assessing the accuracy of prediction algorithms for classification: an overview</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Baldi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="412" to="424" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Feature-based prediction of non-classical and leaderless protein secretion</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bendtsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="349" to="356" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Improved prediction of signal peptides: Signalp 3.0</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bendtsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">340</biblScope>
			<biblScope unit="page" from="783" to="795" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">ESLpred: SVM-based method for subcellular localization of eukaryotic proteins using dipeptide composition and PSI-BLAST</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bhasin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Raghava</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="414" to="419" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Prediction of subcellular localization using sequencebiased recurrent networks</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bóden</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hawkins</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2279" to="2286" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">The Swiss-Prot protein knowledgebase and its supplement TrEMBL in 2003</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Boeckmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="365" to="370" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">The prediction of protein subcellular localization from sequence: a shortcut to functional genome annotation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Casadio</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Funct. Genomic Proteomic</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="63" to="73" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Finding nuclear localization signals</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Cokol</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO Reports</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="411" to="415" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">20</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2819" to="2812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Predicting subcellular localization of proteins based on their N-terminal amino acid sequence</title>
		<author>
			<persName>
				<forename type="first">O</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">300</biblScope>
			<biblScope unit="page" from="1005" to="1016" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Protein. subcellular localization prediction Emanuelsson</note>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting protein subcellular localisation from amino acid sequence information</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Emanuelsson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="361" to="376" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">pTARGET: a new method for predicting protein subcellular localization in eukaryotes</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Guda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Subramaniam</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3963" to="3969" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Detecting and sorting targeting peptides with recurrent networks and support vector machines</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hawkins</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bóden</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bioinformatics Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">WoLF PSORT:protein localization predictor</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Horton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="585" to="587" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Support vector machine approach for protein subcellular localization prediction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Hua</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Sun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="721" to="728" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A novel representation of protein sequences for prediction of subcellular location using support vector machines</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Matsuda</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2804" to="2813" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Beyond the twilight zone: Automated prediction of structural properties of proteins by recursive neural networks and remote homology information</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Mooney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Pollastri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="181" to="190" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Better prediction of sub-cellular localization by combining evolutionary and structural information</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Nair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Rost</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="917" to="930" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Mimicking cellular sorting improves prediction of subcellular localization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Nair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Rost</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="page" from="85" to="100" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">PSORT: a program for detecting the sorting signals of proteins and predicting their subcellular localization</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Nakai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Horton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Biochem. Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="34" to="35" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<monogr>
		<title level="m" type="main">Discrimination of intracellular and extracellular proteins using amino acid composition and residue-pair frequencies</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Nakashima</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Nishikawa</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page" from="54" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">BaCelLo: a balanced subcellular localization predictor</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Pierleoni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">422</biblScope>
			<biblScope unit="page" from="408" to="416" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Sherloc: high-accuracy prediction of protein subcellular localization by integrating text and protein sequence data</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shatkay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1410" to="1417" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Predotar: a tool for rapidly screening proteomes for N-terminal targeting sequences</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Small</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteomics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1581" to="1590" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Uniref: comprehensive and non-redundant uniprot reference clusters</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Suzek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1282" to="1288" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Recursive neural networks for undirected graphs for learning molecular endpoints</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Walsh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Pattern Recognition in Bioinformatics Lecture Notes in Bioinformatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">5780</biblScope>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">LOCSVMPSI: a web server for subcellular localization of eukaryotic proteins using SVM and profile of PSI-BLAST</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Xie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>