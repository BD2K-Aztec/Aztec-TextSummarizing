
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Deviance residuals-based sparse PLS and sparse kernel PLS regression for censored data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015">2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Philippe</forename>
								<surname>Bastien</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">L&apos;Or eal Recherche &amp; Innovation</orgName>
								<address>
									<postCode>93601</postCode>
									<settlement>Aulnay-sous-Bois</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Fr</forename>
								<surname>Ed Eric Bertrand</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 7501</orgName>
								<orgName type="institution" key="instit1">IRMA</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Labex IRMIA</orgName>
								<orgName type="institution" key="instit4">Universit e de Strasbourg</orgName>
								<address>
									<postCode>67084</postCode>
									<settlement>Strasbourg Cedex</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Nicolas</forename>
								<surname>Meyer</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">INSERM EA3430</orgName>
								<orgName type="laboratory">Laboratoire de Biostatistique</orgName>
								<orgName type="institution">Labex IRMIA</orgName>
								<address>
									<addrLine>Facult e de M edecine de Strasbourg</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Associate Editor: Igor Jurisica</orgName>
								<orgName type="institution">Universit e de Strasbourg</orgName>
								<address>
									<postCode>67085</postCode>
									<settlement>Strasbourg Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Myriam</forename>
								<surname>Maumy-Bertrand</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 7501</orgName>
								<orgName type="institution" key="instit1">IRMA</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Labex IRMIA</orgName>
								<orgName type="institution" key="instit4">Universit e de Strasbourg</orgName>
								<address>
									<postCode>67084</postCode>
									<settlement>Strasbourg Cedex</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Deviance residuals-based sparse PLS and sparse kernel PLS regression for censored data</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">31</biblScope>
							<biblScope unit="issue">3</biblScope>
							<biblScope unit="page" from="397" to="404"/>
							<date type="published" when="2015">2015</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu660</idno>
					<note type="submission">Received on August 29, 2013; revised on September 13, 2014; accepted on October 1, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: A vast literature from the past decade is devoted to relating gene profiles and subject survival or time to cancer recurrence. Biomarker discovery from high-dimensional data, such as transcrip-tomic or single nucleotide polymorphism profiles, is a major challenge in the search for more precise diagnoses. The proportional hazard regression model suggested by Cox (1972), to study the relationship between the time to event and a set of covariates in the presence of censoring is the most commonly used model for the analysis of survival data. However, like multivariate regression, it supposes that more observations than variables, complete data, and not strongly correlated variables are available. In practice, when dealing with high-dimensional data, these constraints are crippling. Collinearity gives rise to issues of over-fitting and model misidentification. Variable selection can improve the estimation accuracy by effectively identifying the subset of relevant predictors and enhance the model interpretability with parsimonious representation. To deal with both collinearity and variable selection issues, many methods based on least absolute shrinkage and selection operator penalized Cox proportional hazards have been proposed since the reference paper of Tibshirani. Regularization could also be performed using dimension reduction as is the case with partial least squares (PLS) regression. We propose two original algorithms named sPLSDR and its non-linear kernel counterpart DKsPLSDR, by using sparse PLS regression (sPLS) based on deviance residuals. We compared their predicting performance with state-of-the-art algorithms on both simulated and real reference benchmark datasets. Results: sPLSDR and DKsPLSDR compare favorably with other methods in their computational time, prediction and selectivity, as indicated by results based on benchmark datasets. Moreover, in the framework of PLS regression, they feature other useful tools, including biplots representation, or the ability to deal with missing data. Therefore, we view them as a useful addition to the toolbox of estimation and prediction methods for the widely used Cox&apos;s model in the high-dimensional and low-sample size settings. Availability and implementation: The R-package plsRcox is available on the CRAN and is maintained by Fr ed eric Bertrand. http://cran.r-project.org/web/packages/plsRcox/index.html.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Lasso penalized Cox proportional hazards regression</head><p>L 1 penalized Cox regression was first suggested by<ref type="bibr" target="#b57">Tibshirani, 1997</ref>, as an extension of its variable selection procedure called least absolute shrinkage and selection operator (Lasso) (<ref type="bibr" target="#b56">Tibshirani, 1996</ref>). Since then many developments in the framework of generalized Lasso have appeared.<ref type="bibr" target="#b15">Efron et al., 2004</ref>, described a highly efficient procedure called LARS for Least Angle Regression for variable Selection, which can be slightly modified to provide solution for the Lasso.<ref type="bibr" target="#b26">Gui and Li, 2005</ref>, taking advantage of the close connection between LARS and Lasso proposed a solution to the Cox–Lasso procedure in the setting of high-dimensional data, combining LARS path inside each Newton approximation. However, the iterative reweighted least squares strategy used by the LARS–Cox procedure for handling survival endpoints undo much of the computational efficiency of the LARS–Lasso procedure. Segal, 2006, described an estimation strategy that restores the computational efficiency of the LARS–Lasso procedure. He showed that the expression to be minimized in the Cox–Lasso procedure of Tibshirani could be approached by the deviance residuals sum of squares. He then performed the original LARS-Lasso algorithm on those specific residuals.<ref type="bibr" target="#b43">Park and Hastie, 2007</ref>, using results from the LARS algorithm, proposed a L 1-regularization path algorithm for generalized linear models based on the predictor-corrector method of convex optimization that they applied to the Cox proportional hazards model. Their algorithm exploits the near piece-wise linearity of the coefficients to approximate the solution at different constraints, then numerically maximizes the likelihood for each constraint via a Newton iteration initialized at the approximation.<ref type="bibr" target="#b52">Sohn et al., 2009</ref><ref type="bibr">, extended the Kim et al., 2008</ref>, coordinatewise gradient Lasso algorithm to the Cox proportional hazard model. Following quite the same ideas, Goeman, 2010, described a full gradient Lasso algorithm. Unlike the algorithm of Sohn et al., it does not update a single coordinate at a time, but uses the full gradient at each step and can switch to a Newton–Raphson algorithm to speedup its convergence when it gets close to the optimum. Both methods are gradient based and therefore scalable to high-dimensional data because they do not require matrix inversion. Tibshirani, 2009, proposed uniCox, *To whom correspondence should be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>y</head><p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint<ref type="bibr" target="#b61">Wang et al., 2009</ref>, which yields sparsity at both group and individual feature levels to select groups and predictors within a group, for example, genes within a pathway.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">PLS regression</head><p>Prediction in high-dimensional and low-sample size settings already arose in chemistry in the eighties. Partial least squares (PLS) regression, that can be viewed as a regularization method based on dimension reduction, was developed as a chemometric tool in an attempt to find reliable predictive models with spectral data (<ref type="bibr" target="#b54">Tenenhaus, 1998;</ref><ref type="bibr" target="#b63">Wold et al., 1983</ref>). Nowadays, the difficulty encountered with the use of genomic or proteomic data for classification or prediction, using large matrices, is of comparable nature. It was thus natural to use PLS regression principles in this new context. The method starts by constructing latent components, using linear combinations of the original variables, which are then used as new descriptors in standard regression analysis. Different from the principal components analysis (PCA), this method makes use of the response variable in constructing the latent components. The PLS regression can be viewed as a regularized approach searching the solution in a subspace named Krylov space giving biased regression coefficients but with lower variance. In the framework of censored genomic data, the PLS regression operates a reduction of the dimensionality of the gene's space oriented toward the explanation of the hazard function. It allows transcriptomic signatures correlated to survival to be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">PLS–Cox regression</head><p>Garthwaite, 1994, showed that PLS regression could be obtained as a succession of simple and multiple linear regressions. Tenenhaus, 1999, proposed a fairly similar approach but one that could cope with missing data by using the principles of the Nipals algorithm (<ref type="bibr" target="#b62">Wold, 1966</ref>). As a result, Tenenhaus suggested that PLS regression be extended to logistic regression (PLS–LR) by replacing the succession of simple and multiple regressions by a succession of simple and multiple logistic regressions in an approach much simpler than that developed by Marx, 1996. By using this alternative formulation of the PLS regression,<ref type="bibr" target="#b6">Bastien and Tenenhaus, 2001</ref>, extended the PLS regression to any generalized linear regression model (PLS–GLR) and to the Cox model (PLS–Cox) as a special case. Further improvements have then been described (<ref type="bibr" target="#b5">Bastien et al., 2005</ref>) in the case of categorical descriptors with model validation by bootstrap resampling and variable selection using hard thresholding. Since then many developments in the framework of PLS and Cox regressions have appeared in the literature.<ref type="bibr" target="#b42">Nguyen and Rocke, 2002</ref>, directly applied PLS regression to survival data and used the resulting PLS components in the Cox model for predicting survival time. However, such a direct application did not really generalize PLS regression to censored survival data, as it did not take into account the failure time in the dimension reduction step. Based on a straightforward generalization of Garthwaite, 1994, presented a solution, partial Cox regression, quite similar to the one proposed by Bastien and Tenenhaus, using different weights to derive the PLS components but not coping with missing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">PLSDR</head><p>Following Segal, 2006, who suggested initially computing the null deviance residuals and then using these as outcomes for the LARS-Lasso algorithm, Bastien, 2008, proposed PLSDR, an alternative in high-dimensional settings using deviance residuals-based PLS regression. This approach is advantageous by both its simplicity and its efficiency because it only needs to carry out null deviance residuals using a simple Cox model without covariates and use these as outcome in a standard PLS regression. The final Cox model is then carried out on the m-retained PLSDR components. Moreover, following the principles of the Nipals algorithm, weights, loadings and PLS components are computed as regression slopes. These slopes may be computed even when there are missing data: let t hi =x h1;i w h =w 0 h w h the value of the PLS component for individual i, with descriptors matrix X and covariance weights matrix W, t hi represents the slope of the OLS line without constant term related to the cloud of points ðw h ; x h1;i Þ. In such case, in computing the h th PLS component, the denominator is computed only on the data available also for the denominator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">sPLS</head><p>Recently, Chun and Keles, 2010, provided both empirical and theoretical results showing that the performance of PLS regression was ultimately affected by the large number of predictors. In particular, a higher number of irrelevant variables leads to inconsistent coefficient estimates in the linear regression setting. There is a need to filter the descriptors as a preprocessing step before PLS fit. However, commonly used variables filtering approaches are all univariate and ignore correlation between variables. To solve these issues, Chun and Keles proposed 'sparse PLS regression', which promotes variables selection within the course of PLS dimension reduction. sPLS has the ability to include variables that variable filtering would select in the construction of the first direction vector. Moreover, it can select additional variables, i.e. variables that become significant once the response is adjusted for other variables in the construction of the subsequent direction vectors. This is the case of 'proxy genes' acting as suppressor variables that do not predict the outcome variable directly but improve the overall prediction by enhancing the effects of prime genes despite having no direct predictive power, Magidson and Wassmann, 2010.where M=X 0 YY 0 X:</p><p>When Y = X, the objective function coincides with that of sPCA (<ref type="bibr" target="#b30">Jolliffe et al., 2003</ref>). However, in that case, Jolliffe et al. pointed out that the solution tends not to be sparse enough and the problem is not convex. To solve these issues,<ref type="bibr">Chun</ref>This formulation promotes exact zero property by imposing L 1 penalty onto a surrogate of the direction vector c instead of the original direction w while keeping w and c close to each other. The L 2 penalty takes care of the potential singularity of M. Moreover, they demonstrated that for univariate PLS, y regressed on X, the first direction vector of the sparse PLS algorithm was obtained by soft thresholding of the original PLS direction vector: jZj À 2 +signðZÞ; where Z=X 0 y=jjX 0 yjj 2 :</p><p>To inherit the property of the Krylov subsequences, which is known to be crucial for the convergence of the algorithm (<ref type="bibr" target="#b33">Kr€ amer, 2007</ref>), the thresholding phase is followed by a PLS regression on the previously selected variables. The algorithm is then iterated with y replaced by y À X ^ , the residuals of the PLS regression based on the variables selected from the previous steps. The sPLS algorithm leads therefore to sparse solutions by keeping the Krylov subsequence structure of the direction vectors in a restricted X space, which is composed of the selected variables. The thresholding parameter and the number of hidden components are tuned by cross-validation. sPLS has connections to other variable selection algorithms including the elastic net method (<ref type="bibr" target="#b66">Zou and Hastie, 2005</ref>) and the threshold gradient method (<ref type="bibr" target="#b20">Friedman and Popescu, 2004</ref>). The elastic net algorithm deals with the collinearity issue in variable selection problem by incorporating the ridge regression method into the LARS algorithm. In a way, sPLS handles the same issue by fusing the PLS technique into the LARS algorithm. sPLS can also be related to the threshold gradient method in that both algorithms use only thresholded gradient and not the Hessian. However, sPLS achieves fast convergence by using conjugate gradient. Hence, LARS and sPLS algorithms use the same criterion to select active variables in the univariate case. However, the sPLS algorithm differs from LARS in that sPLS selects more than one variable at a time and uses the conjugate gradient method to compute coefficients at each step. The computational cost for computing coefficients at each step of the sPLS algorithm is less than or equal to the computational cost of computing step size in LARS, as conjugate gradient methods avoid matrix inversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6">sPLSDR and DKsPLSDR</head><p>In this article, we propose two new algorithms, named sPLSDR and DKsPLSDR, by using sPLS or its non-linear kernel counterpart DKsPLS instead of PLS in the PLSDR algorithm. We show them as efficient sparse regularized alternatives based on dimension reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Cox proportional hazards model</head><p>The model assumes the following hazard function for the occurrence of an event at time t in the presence of censoring:</p><formula>ðtÞ= 0 ðtÞ exp ð 0 XÞ;</formula><p>where 0 ðtÞ is an unspecified baseline hazard function, the vector of the regression coefficients and X=ðX 1 ; :::; X p Þ a n by p matrix of features with x i =ðx i1 ; :::; x ip Þ the covariate vector for the i th individual. The event could be death or cancer relapse. Based on the available data, the Cox's partial likelihood can be written as follows:</p><formula>PLðÞ= Y k2D exp ð 0 x k Þ X j2Rk exp ð 0 x j Þ ;</formula><p>where D is the set of indices of the events and R k denotes the set of indices of the individuals at risk at time t k. The goal is to find the coefficients ^ , which maximize the log partial likelihood function</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>lðÞ=log PLðÞ:</head><p>The vector ^ is the solution of the equation:</p><formula>uðÞ= @l @ =0</formula><p>with uðÞ the vector of efficient scores. However, there is no explicit solution and the minimization is generally accomplished using the Newton–Raphson procedure. An estimate of the vector of parameters at the ðk+1Þ th cycle of the iterative procedure is as follows:</p><formula>^ k+1 = ^ k +I À1 ð ^ k Þuð ^ k Þ</formula><p>where IðÞ= À @ 2 l @@ 0 is the observed information matrix. The process can be started by taking ^ 0 =0 and iterated up to convergence, i.e. when the change in the log likelihood function is small enough. When the iterative procedure has converged, the variance-covariance matrix of the parameter estimates can be approximated by the inverse of the observed information matrix I À1 ð ^ Þ. When p4n, there is no unique ^ to maximize this log partial likelihood function. Even when p n, covariates could be highly correlated and regularization may still be required to reduce the variances of the estimates and to improve the predictive performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deviance residuals</head><p>For the Cox model with no time-dependent explanatory variables and at most one event per patient, the martingale residuals for the i th subject with observation time t i and event status i , where i =0 if t i is a censored time, and i =1 otherwise is as follows:</p><formula>^ M i = i À ^ E i = i À ^ " 0 ðt i Þ exp ð ^ 0 x i Þ</formula><p>with ^ " 0 ðt i Þ the estimated cumulative hazard function at time t i. Martingale residuals are highly skewed. The deviance residuals d i are a normalized transform of the martingale residuals. For the Cox model, the deviance residuals (<ref type="bibr" target="#b12">Collett, 1994</ref>) amount to the form:</p><formula>d i =signð ^ M i Þ Á 2 À ^ M i À i log i À ^ M i n o h i 1=2 Á</formula><p>The sign function is to ensure that the deviance residuals have the same sign as the martingale residuals. Martingale residuals take values between À1 and 1. The square root shrinks large negative martingale residuals, while the logarithmic transformation expands toward +1 martingale residuals that are close to 1. As such, the deviance residuals are more symmetrically distributed around zero than the martingale residuals. The deviance residual is a measure of excess of death and can therefore be interpreted as a measure of hazard. Moreover, Segal showed that the expression to be minimized in step 3 of the Cox–Lasso procedure of Tibshirani can be approximated, in a first order Taylor-series approximation sense, by the deviance residual sum of squares: ðz À XÞ 0 Aðz À X Þ % RSSð ^ DÞ with = 0 X; = @l @ ; A= À @ 2 l @ 0 , and z=+A À :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The sPLSDR algorithm</head><p>The sPLSDR algorithm involves the following steps: 1. Cox model without covariates to derive the null deviance residuals d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Computation of the sPLS components by using</head><p>the sPLS regression with the null deviance residuals as outcome.</p><p>a. Set ^ PLS =0; =fg, k = 1, y 1 =d. b. While ðk KÞ.</p><p>(1) w=ðjzj À =2Þ + signðzÞ where z=X 0 y 1 =jjX 0 y 1 jj 2 .</p><p>(2) Update as fi : ^ w i 6 ¼ 0g [ fi : ^ PLS i 6 ¼ 0g</p><p>(3) Fit PLS with X by using the k number of latent components.</p><p>(4) Update ^ PLS by using the new PLS estimates of the direction vectors and update y 1 and k through</p><formula>y 1 y 1 À X ^ PLS and k k+1.</formula><p>3. Cox model on the m-retained sPLSDR components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The DKsPLSDR algorithm</head><p>In the case of very many descriptors, PLS regression being invariant by orthogonal transformation (De Jong and ter<ref type="bibr" target="#b14">Braak, 1994</ref>), an even faster procedure could be derived by replacing the X matrix by the matrix of principal components Z ðXX 0 =ZZ 0 Þ. This could be viewed as the simple form of linear kernel PLS regression algorithms, which have been proposed in the nineties (<ref type="bibr" target="#b38">Lindgren et al., 1993;</ref><ref type="bibr" target="#b44">R€ annar et al., 1994</ref>) to solve computational problems posed by large matrices in chemometrics. The objective of these methods was to obtain PLS components by working on a condensed matrix of a considerably smaller size than the original one. Moreover, in addition to dramatically reducing the size of the problem, non-linear pattern in the data could also be analyzed using non-linear kernel. Rosipal and Trejo, 2001, proposed a non-linear extension of PLS regression using kernels. Assuming a non-linear transformation of the input variables fx i g n i=1 into a feature space F, i.e. a mapping È : x i 2 R N °ðx i Þ 2 F, their goal was to construct a linear PLS regression model in F. They derived an algorithm named KPLS for Kernel PLS by performing the PLS regression on ÈðXÞ. It amounts to replacing, in the expression of PLS components, the product XX 0 by ÈðXÞÈðXÞ 0 using the so-called kernel trick, which allows the computation of dot products in high-dimensional feature spaces using simple functions defined on pairs of input patterns: Èðx i ÞÈðx j Þ 0 =Kðx i ; x j Þ. This avoids having to explicitly calculate the coordinates in the feature space, which could be difficult for a highly dimensional feature space. By using the kernel functions corresponding to the canonical dot product in the feature space, non-linear optimization can be avoided and simple linear algebra can be used.<ref type="bibr" target="#b8">Bennett and Embrecht, 2003</ref>, proposed to perform PLS regression directly on the kernel matrix K instead of ÈðXÞ. DKPLS corresponds to a low rank approximation of the kernel matrix. Moreover,<ref type="bibr" target="#b53">Tenenhaus et al. (2007)</ref>3. Computation of the PLS components by using the DKsPLS algorithm with the null deviance residuals as outcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Cox model on the m-retained DKsPLSDR components.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BENCHMARKING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Implementation</head><p>We benchmarked the new sPLSDR and DKsPLSDR algorithms against the following existing ones: coxpath (<ref type="bibr" target="#b43">Park and Hastie, 2007</ref>), coxnet (<ref type="bibr" target="#b50">Simon et al., 2011</ref>), PLS-Cox (<ref type="bibr" target="#b6">Bastien and Tenenhaus, 2001</ref>), autoPLS-Cox (PLS-Cox with a hard-thresholding approach and automatic selection of the maximal number of components,<ref type="bibr" target="#b5">Bastien et al., 2005</ref>), LARS-LassoDR (<ref type="bibr" target="#b49">Segal, 2006</ref>), Cox-PLS (<ref type="bibr" target="#b42">Nguyen and Rocke, 2002</ref>), PLSDR (<ref type="bibr" target="#b4">Bastien, 2008</ref>), DKPLSDR (<ref type="bibr" target="#b4">Bastien, 2008</ref>), uniCox (<ref type="bibr" target="#b58">Tibshirani, 2009</ref>) and glcoxph (<ref type="bibr" target="#b52">Sohn et al., 2009</ref>). More insights on the implementation of these algorithms are given in the Supplementary Information. We made several wrappers for the Cox-PLS, LARS-LassoDR, PLSDR, sPLSDR, DKPLSDR and DKsPLSDR and had to implement in the R language PLS-Cox, and hence autoPLS-Cox, which is PLS-Cox with hard thresholding of the non-significant explanatory variables at a given level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prediction evaluation</head><p>We propose to use the time-dependent receiver-operator characteristics (ROC) curve for censored data (<ref type="bibr" target="#b29">Heagerty and Zheng, 2005</ref>) to assess how well the model predicts survival. Let sensitivity and specificity be the following: sensitivity ðc; t=XÞ=PðX4c=ðtÞ=1Þ specificity ðc; t=XÞ=PðX c=ðtÞ=0Þ with X a predictor score function and ðtÞ the event indicator at time t. Sensitivity measures the expected fraction of subjects with a marker greater than c among the subpopulation of individuals who die at time t, whereas specificity measures the fraction of subjects with a marker less than or equal to c among those who survive beyond time t. Using the true-and false-positive rate functions, TP t ðcÞ=sen sitivityðc; tÞ and FP t ðcÞ=1 À specificityðc; tÞ allows the ROC curve to be written as follows:</p><formula>ROC t ðpÞ=TP t ððFP t Þ À1 ðpÞÞ; with ðFP t Þ À1 ðpÞ= inf c fc : FP t ðcÞ pg:</formula><p>The area under the ROC curves (AUC), which measures the probability that a marker value for a randomly selected case exceeds the marker value for a randomly selected control, is particularly useful for comparing the discriminatory capacity of different potential biomarkers. A larger AUC at time t based on the risk score function X indicates better predictability of time to event at time t as measured by sensitivity and specificity at time t. A typical complexity with survival data is that observations may be censored. Two ROC curve estimators are proposed that can accommodate censored data (<ref type="bibr" target="#b28">Heagerty et al., 2000</ref>). A simple estimator is based on using the Kaplan–Meier (KM) estimator for each possible subset X4c. However, this estimator does not guarantee the necessary condition that sensitivity and specificity are monotone in X. An alternative estimator that does guarantee monotonicity is based on a nearest-neighbor estimator (NNE) for the bivariate distribution function of (X, T), where T represents survival time (<ref type="bibr" target="#b0">Akritas, 1994</ref>). Moreover, it is a semiparametric efficient estimator and the censoring process is allowed to depend on the diagnostic marker X, whereas the Kaplan–Meier estimator assumes that the censoring process does not depend on X (<ref type="bibr" target="#b0">Akritas, 1994</ref>). We provide benchmark results for both the KM and NNE estimators.<ref type="bibr" target="#b35">Langfelder et al. (2013)]</ref>, using either no link or a linear one between the response and the predictors. We divided each of these 600 datasets into a learning set, of 7/10 (70) of the observations, used for estimation, and a test set, of 3/10 (30) of the observations, used for evaluation or testing of the prediction capability of the estimated model. This choice was made to stay between the 2:1 scheme of<ref type="bibr">Bøvelstad et al. (2007)</ref>; Lambert-Lacroix and Letu e (2011); van<ref type="bibr" target="#b59">Wieringen et al. (2009)</ref>; and the 9:1 scheme of Li (2006). The division between learning and test sets was balanced using the caret package according to both the response value and censor rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Real datasets Eight datasets</head><p>were used to benchmark the models:<ref type="bibr" target="#b1">Alizadeh et al., 2000;</ref><ref type="bibr" target="#b7">Beer et al., 2002;</ref><ref type="bibr" target="#b9">Bhattacharjee et al., 2001;</ref><ref type="bibr" target="#b22">Garber et al., 2001;</ref><ref type="bibr" target="#b41">Metzeler et al., 2008;</ref><ref type="bibr" target="#b45">Romain et al., 2010;</ref><ref type="bibr" target="#b46">Rosenwald et al., 2002 and</ref><ref type="bibr" target="#b60">Wang et al., 2005</ref>. The variability of their numbers of subjects and variables, see<ref type="figure" target="#tab_1">Table 1</ref>, makes their use as benchmarks more insightful. The allelotyping set of<ref type="bibr" target="#b45">Romain et al., 2010</ref>, is a new benchmark set, whereas the other seven are commonly used ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Simulated datasets</head><p>Cross-validation techniques [either CV partial likelihood criterion (CVLL) or van Houwelingen CV partial likelihood criterion (vHCVLL)] were recommended for several of our benchmark methods by their authors. We followed these recommendations. For the Cox-PLS, PLSDR, sPLSDR, DKPLSDR and DKsPLSDR, we used the iAUCSurvROC criterion, for the LARS-LassoDR the vHCVLL and for PLS-Cox and autoPLS-Cox the iAUCSH. Simulation results confirmed these as relevant cross-validation criteria (Supplementary Figs S3 and S4). To assess the goodness of fit and prediction accuracy of all the methods, we selected four indices of various kind: the coefficient (R 2 XO) proposed by Xu and O'Quigley (1999) (a R 2-like measure and a likelihood-based approach), the CGH by Gonen and Heller (2008) (an improved version of the C index<ref type="bibr" target="#b27">Harrell et al., 1996</ref>), the iAUCsurvROC (a ROC-based approach used by<ref type="bibr" target="#b37">Li, 2006</ref>) and the integrated weighted Schmid Score (iSSw,<ref type="bibr" target="#b48">Schmid et al., 2011</ref>, an integrated robust prediction error and a distancebased approach). The simulations lead to some advantage for the models featuring components (<ref type="figure" target="#fig_3">Fig. 1</ref>and Supplementary Figs S6–S8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Real datasets</head><p>For every dataset and every method, we selected the parameters by applying the same cross-validation techniques as in Section 4.1. The test and train groups were commonly used ones whenever available or else randomly chosen ones. All the scripts used to perform these analyses will be provided as demos in an updated version of the plsRcox package. The datasets will be available as direct downloads on a dedicated academic Web site.We compared the survival prediction accuracy, using the iAUCsurvROC criterion, of all the methods over two periods starting from 0 and with two different (near or far) end times. These were chosen separately for every dataset as the first quartile (Q 1 ) and the third quartile (Q 3 ) of the empirical distribution of the survival time. This is tantamount to finding models for making accurate survival prognostics either at an earlier or at a later time. The results are displayed on graphical outputs to point out which is the best method for predicting survival. For instance, the graphical output for comparing the methods' accuracy for predicting the survival at an early time (½0;<ref type="figure" target="#fig_6">Figure 3</ref>. All of them show better predictive performance for both sPLSDR and DKsPLSDR algorithms. All graphical outputs are given in Supplementary information (Supplementary Figs S11–S26. We summed up all the results (Supplementary Tables S3–S6 in Tables 2 and 3 where the methods are ranked by decreasing iAUC. We used bold fonts for the new sPLSDR and DKsPLSDR algorithms and italic for the first R implementation of existing techniques (Cox-PLS, PLS-Cox, autoPLS-Cox, PLSDR, DKPLSDR) by Bastien and Tenenhaus (2001) and Bastien (2008). These results show steady better predictive performance for the sPLSDR and DKsPLSDR algorithms as well as for the uniCox one. Yet, uniCox failed on the Dataset 2 (<ref type="bibr" target="#b7">Beer et al., 2002</ref>), for both ½0; Q 1  and ½0; Q 3  intervals, even after several tries with random training sets. Variable selection results were analyzed for the Romain et al., 2010 dataset (Supplementary Table S11, and Supplementary Figs S26 and S27). In our view, variable selection is a topic in itself and especially its robustness with respect to several criteria including censorship or missingness patterns as well as noise or resampling. We will focus on these issues in a subsequent article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Overall, DKsPLSDR and, even more, sPLSDR compare favorably with the benchmark methods on both simulated and real datasets.</p><p>In the simulation study, sPLSDR turned out to be the best method to recover the linear link according to the ISSw performance measure and for the three simulation schemes (<ref type="figure" target="#fig_3">Fig. 1</ref>, Linear link row panel). More generally in that setting, the models featuring components had better performance measures than the LASSO and elastic net-based ones. Similar results can be observed for the iAUCSurvROC criterion (Supplementary<ref type="figure">Fig. S8</ref>, Linear link row panel) with lesser advantage to sPLSDR and DKsPLSDR. In both cases, simulations study show that neither sPLSDR or DKsPLSDR tend to wrongly recover a link between the response and the explanatory variable when there is none (Supplementary Figs S1 and S8, No link row panel), whereas LASSO and elastic net-based methods do for the factorial simulation scheme and the iAUCSurvROC criterion (Supplementary<ref type="figure">Fig. S8</ref>, no link row panel). Whatever the real dataset, the overall patterns of the sPLSDR and DKsPLSDR algorithms follow the general patterns of predictability of the benchmark methods, e.g. a low increase in predictability for the Metzeler dataset or a global step-wise decrease on the Romain datasets. These patterns suggest that the performances of the different methods may depend on the real but unknown data dimension. The sPLSDR or DKsPLSDR almost always rank among the 1 to 4 best methods with higher predictability, often being even 1st or 2nd, both on short and long term predictions (see Tables 2 and 3). This is particularly true in cases where a large predictability heterogeneity is to be noted among the benchmark algorithms, such as for the Garber and the Wang datasets. Last but not least, sPLSDR and DKsPLSDR not only automatically handle missing data, the study of the robustness of these two algorithms to the amount and type of missing databeing beyond the scope of this article, but also provide nice data exploration tools such as biplots representation of individuals and descriptors, by projecting the dataset on the first sPLS components (see<ref type="figure">Fig. 4</ref>). In a word, we view sPLSDR and DKsPLSDR as a useful addition to the toolbox of estimation and prediction methods for the widely used Cox's model in the high-dimensional and low-sample size settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>and Keles provided an efficient implementation of sPLS based on the LARS algorithm by generalizing the regression formulation of sPCA of Zou et al., 2006: min w;c Àw 0 Mw+ð1 À Þðc À wÞ 0 Mðc À wÞ+ 1 jjcjj 1 + 2 jjcjj 2 subject to w 0 w=1; where M=X 0 YY 0 X:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>demonstrated that, for one-dimensional output response, PLS of ÈðXÞ (KPLS) is equivalent to PLS on K 1=2 (DKPLS). Using previous works, it becomes straightforward to derive a nonlinear Kernel sPLSDR algorithm by replacing in the sPLSDR algorithm the X matrix by a kernel matrix K. The main kernel functions are the linear kernel (Kðu; vÞ=5u; v4) and the Gaussian kernel (Kðu; vÞ=exp ðÀjju À vjj 2 2 =2 2 Þ). However, non-linear kernel (sparse) PLS regression loses the explanation with the original descriptors unlike linear kernel PLS regression, which could limit the interpretation of the results. The DKsPLSDR algorithm involves the following steps: 1. Computation of the kernel matrix. 2. Cox model without covariates to derive the null deviance residuals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3.3.1</head><figDesc>Simulated datasets We performed a simulation study (summed up in Supplementary Table S1) to evaluate the methods by simulating 100 datasets with exponential survival distribution and 40% censored rate (100 observations Â 1000 genes) according to three different simulation types [cluster by Bair et al. (2006), factorial by Kaiser and Dickman (1962) and Fan et al. (2002) or eigengene by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Q 1  interval) for the Dataset 8 of Wang et al., 2005 is shown on Figure 2. As for survival prediction at a later time (½0; Q 3  interval), results for Dataset 5 of Metzeler et al., 2008 are displayed on</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.1.</head><figDesc>Fig. 1. Methods performance evaluation according to the integrated weighted Schmid Score, a distance-based integrated robust prediction error</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.3.</head><figDesc>Fig. 3. Dataset 5: Survival prediction over a long period (½0; Q 3 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.2.</head><figDesc>Fig. 2. Dataset 8: Survival prediction over a short period (½0; Q 1 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>First Authors. a Cox univariate shrinkage method, assuming that the features are independent in each risk set, in the spirit of the univariate soft thresholding solution for the Lasso in linear regression when the features are independent. More recently, Simon et al., 2013, proposed coxnet, a fast path-wise algorithm for the Cox's model regularized by convex combination of L 1 and L 2 penalties, named Elastic Net by Zou and Hastie, 2005. Their algorithm uses cyclical coordinate descent extending the work of Friedman et al., 2010, with early reference from the shooting algorithm of Fu, 1998. Other, though non-exhaustive, regularized Cox regression procedures include the smoothly clipped absolute deviation of Fan and Li, 2002, the adaptive Lasso of Zhang and Lu, 2007, the Dantzig selector of Antoniadis et al., 2010, the Sure and Iterative Sure Independence Screening of Fan et al. (2010) or the hierarchically penalized Cox regression of</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Datasets' structure</figDesc><table>Nbr. 
Dataset 
Number 
of rows 

Number 
of columns 

Pct. uncensored 

1 
Alizadeh 
40 
4026 
45.0 
2 
Beer 
86 
7129 
72.1 
3 
Bhattacharjee 
125 
3171 
42.4 
4 
Garber 
22 
3171 
36.4 
5 
Metzeler 
242 
44 754 
38.0 
6 
Romain 
117 
39 
77.8 
7 
Rosenwald 
240 
7399 
42.5 
8 
Wang 
286 
22 283 
62.6 </table></figure>

			<note place="foot">ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">P.Bastien et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Deviance residuals based sparse PLS at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors are grateful to the referees for their very helpful comments. They also wish to thank Caroline Chaigne and Claude Bouillon who assisted in the proofreading of the manuscript.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Nearest neighbor estimation of a bivariate distribution under random censoring</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">G</forename>
				<surname>Akritas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1299" to="1327" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Alizadeh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="403" to="503" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">The Dantzig selector in Cox&apos;s proportional hazards model</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Antoniadis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand. Stat. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="531" to="552" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Prediction by supervised principal components</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Bair</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="119" to="137" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Deviance residual based PLS regression for censored data in high dimensional data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bastien</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemom. Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="78" to="86" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">PLS generalised linear regression</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bastien</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="17" to="46" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">PLS generalised linear regression, Application to the analysis of life time data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bastien</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tenenhaus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLS and Related Methods, Proceedings of the PLS&apos;01 International Symposium. CISIA-CERESTA Editeur</title>
		<meeting><address><addrLine>Montreuil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Gene-expression profiles predict survival of patients with lung adenocarcinoma</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">G</forename>
				<surname>Beer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="816" to="824" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">An optimization perspective on kernel partial least squares regression</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">P</forename>
				<surname>Bennett</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Embrecht</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Learn. Theory</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="page" from="227" to="250" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Classification of human lung carcinomas by mRNA expression profiling reveals distinct adenocarcinoma sub-classes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bhattacharjee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 98</title>
		<meeting>. Natl Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="13790" to="13795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Predicting survival from microarray data – a comparative study</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">M</forename>
				<surname>Bøvelstad</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2080" to="2087" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Sparse partial least squares regression for simultaneous dimension reduction and variable selection</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Chun</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Keles</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="3" to="25" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Modelling Survival Data in Medical Research</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Collett</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Regression models and life tables</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Cox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="187" to="220" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Comments on the PLS kernel algorithm</title>
		<author>
			<persName>
				<forename type="first">De</forename>
				<surname>Jong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ter Braak</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="169" to="174" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Least angle regression</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="407" to="451" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">SAS for Monte Carlo Studies: A Guide for Quantitative Researchers</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Fan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SAS publishing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">High-dimensional variable selection for Cox&apos;s proportional hazards model</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Borrowing Strength</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="70" to="86" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Variable selection for Cox&apos;s proportional hazards model and frailty model</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="74" to="99" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">A note on the group lasso and a sparse group lasso</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Gradient directed regularization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">E</forename>
				<surname>Popescu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Working Paper</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Penalized regression: the bridge versus the LASSO</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Fu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="397" to="416" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Diversity of gene expression in adenocarcinoma of the lung</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Garber</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 98</title>
		<meeting>. Natl Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="13784" to="13789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">An interpretation of partial least squares</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">H</forename>
				<surname>Garthwaite</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="122" to="127" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">L 1 Penalized estimation in the cox proportional hazards model</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Goeman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometric. J</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="70" to="84" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Concordance probability and discriminatory power in proportional hazards regression</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gonen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Heller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="1809" to="2005" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Penalized Cox regression analysis in the high-dimensional and low-sample size settings, with application to microarray gene expression data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gui</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3001" to="3008" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing error</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">E</forename>
				<surname>Harrell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Med</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="361" to="387" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Time-dependent ROC curves for censored survival data and a diagnostic marker</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Heagerty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="337" to="344" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Survival model predictive accuracy and ROC curves</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Heagerty</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Zheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="page" from="61" to="92" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">A modified principal component technique based on the lasso</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Jolliffe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="531" to="547" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Sample and population score matrices and sample correlation matrices from an arbitrary population correlation matrix</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">F</forename>
				<surname>Kaiser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Dickman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="179" to="182" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">A gradient-based optimization algorithm for lasso</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="994" to="1009" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">An overview on the shrinkage properties of partial least squares regression</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Kr€ Amer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="249" to="273" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<monogr>
		<title level="m" type="main">Partial least squares and cox model with application to gene expression</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lambert-Lacroix</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Letu E</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>VIPhaseVI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">When is hub gene selection better than standard metaanalysis?</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Langfelder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">61505</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Partial cox regression analysis for high-dimensional microarray gene expression data</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gui</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="208" to="215" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Survival prediction of diffuse large-B-cell lymphoma based on both clinical and gene expression information</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="466" to="471" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">The kernel algorithm for PLS</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Lindgren</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="45" to="59" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">The role of proxy genes in predictive models: an application to early detection of prostate cancer</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Magidson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Wassmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Statistical Meetings Proceedings</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<publisher>American Statistical Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2739" to="2753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Iteratively reweighted partial least squares estimation for generalized linear regression</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">D</forename>
				<surname>Marx</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="374" to="381" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">An 86-probe-set gene-expression signature predicts survival in cytogenetically normal acute myeloid leukemia</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">H</forename>
				<surname>Metzeler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Blood</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="4193" to="4201" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Partial least squares proportional hazard regression for application to DNA microarray survival data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">V</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rocke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1625" to="1632" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">L 1 regularization path algorithm for generalized linear models</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">Y</forename>
				<surname>Park</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="659" to="677" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">A PLS kernel algorithm for data sets with many variables and fewer objects. Part I: theory and algorithm</title>
		<author>
			<persName>
				<forename type="first">R€</forename>
				<surname>Annar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="111" to="125" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">Allelotyping identification of genomic alterations in rectal chromosomally unstable tumors without preoperative treatment</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Romain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cancer</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">561</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rosenwald</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">346</biblScope>
			<biblScope unit="page" from="1937" to="1947" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b47">
	<analytic>
		<title level="a" type="main">Kernel partial least squares regression in reproducing kernel hilbert space</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Rosipal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">J</forename>
				<surname>Trejo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="97" to="123" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b48">
	<analytic>
		<title level="a" type="main">A robust alternative to the Schemper-Henderson estimator of prediction error</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Schmid</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="524" to="535" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b49">
	<analytic>
		<title level="a" type="main">Microarray gene expression data with linked survival phenotypes: diffuse large-Bcell lymphoma revisited</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Segal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="268" to="285" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b50">
	<analytic>
		<title level="a" type="main">Regularization paths for cox&apos;s proportional hazards model via coordinate descent</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Simon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b51">
	<analytic>
		<title level="a" type="main">A sparse-group Lasso</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Simon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="231" to="245" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b52">
	<analytic>
		<title level="a" type="main">Gradient lasso for cox proportional hazards model</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Sohn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1775" to="1781" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b53">
	<analytic>
		<title level="a" type="main">Kernel logistic PLS: a tool for supervised nonlinear dimensionality reduction and binary classification</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Tenenhaus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="4083" to="4100" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b54">
	<monogr>
		<title level="m" type="main">La r egression PLS</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tenenhaus</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>Technip, Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b55">
	<analytic>
		<title level="a" type="main">La regression logistique PLS</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tenenhaus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the32èmes journ ees de Statistique de la Soci et e franc¸aise de Statistique.Fè s</title>
		<meeting>the32èmes journ ees de Statistique de la Soci et e franc¸aise de Statistique.Fè s</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="721" to="723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b56">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the Lasso</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b57">
	<analytic>
		<title level="a" type="main">The lasso method for variable selection in the Cox model</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Med</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="385" to="395" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b58">
	<analytic>
		<title level="a" type="main">Univariate shrinkage in the cox model for high dimensional data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b59">
	<analytic>
		<title level="a" type="main">Survival prediction using gene expression data: a review and comparison</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Van Wieringen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1590" to="1603" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b60">
	<analytic>
		<title level="a" type="main">Gene-expression profiles to predict distant metastasis of lymph-node-negative primary breast cancer</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page" from="671" to="679" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b61">
	<analytic>
		<title level="a" type="main">Hierarchically penalized Cox regression with grouped variables</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="307" to="322" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b62">
	<monogr>
		<title level="m" type="main">Estimation of principal components and related models by iterative least squares</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wold</surname>
			</persName>
		</author>
		<editor>Krishnaiah,P.R.</editor>
		<imprint>
			<date type="published" when="1966" />
			<publisher>Multivariate Analysis. Academic Press</publisher>
			<biblScope unit="page" from="391" to="420" />
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b63">
	<analytic>
		<title level="a" type="main">The multivariate calibration problem in chemistry solved by the PLS method</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wold</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding Conference Matrix Pencils</title>
		<editor>Ruhe,A. and Ka˚strømKa˚strøm,B.</editor>
		<meeting>eeding Conference Matrix Pencils<address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1982" />
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b64">
	<analytic>
		<title level="a" type="main">A R 2 type measure of dependence for proportional hazards models</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Xu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Quigley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Nonparametr. Stat</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="83" to="107" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b65">
	<analytic>
		<title level="a" type="main">Adaptive lasso for Cox&apos;s proportional hazards model</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">H</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="691" to="703" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b66">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b67">
	<analytic>
		<title level="a" type="main">Sparse principal component analysis</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="265" to="286" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>