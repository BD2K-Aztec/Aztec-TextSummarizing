
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian consensus clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">20 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Eric</forename>
								<forename type="middle">F</forename>
								<surname>Lock</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistical Science</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<forename type="middle">B</forename>
								<surname>Dunson</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistical Science</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alfonso</forename>
								<surname>Valencia</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Human Genetics</orgName>
								<orgName type="institution">Duke University Medical Center</orgName>
								<address>
									<postCode>27710</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bayesian consensus clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="page" from="2610" to="2616"/>
							<date type="published" when="2013">20 2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt425</idno>
					<note type="submission">Systems biology Advance Access publication August 28, 2013 Received on April 3, 2013; revised on June 18, 2013; accepted on July 18, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Contact: Eric.Lock@duke.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: In biomedical research a growing number of platforms and technologies are used to measure diverse but related information, and the task of clustering a set of objects based on multiple sources of data arises in several applications. Most current approaches to multi-source clustering either independently determine a separate clustering for each data source or determine a single &apos;joint&apos; clustering for all data sources. There is a need for more flexible approaches that simultaneously model the dependence and the heterogeneity of the data sources. Results: We propose an integrative statistical model that permits a separate clustering of the objects for each data source. These separate clusterings adhere loosely to an overall consensus clustering, and hence they are not independent. We describe a computationally scal-able Bayesian framework for simultaneous estimation of both the consensus clustering and the source-specific clusterings. We demonstrate that this flexible approach is more robust than joint clustering of all data sources, and is more powerful than clustering each data source independently. We present an application to subtype identification of breast cancer tumor samples using publicly available data from The Cancer Genome Atlas. Availability: R code with instructions and examples is available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation</head><p>Several fields of research now analyze multisource data (also called multimodal data), in which multiple heterogeneous datasets describe a common set of objects. Each dataset represents a distinct mode of measurement or domain. While the methodology described in this article is broadly applicable, our primary motivation is the integrated analysis of heterogeneous biomedical data. The diversity of platforms and technologies that are used to collect genomic data, in particular, is expanding rapidly. Often multiple types of genomic data, measuring various biological components, are collected for a common set of samples. For example, The Cancer Genome Atlas (TCGA) is a large-scale collaborative effort to collect and catalog data from several genomic technologies. The integrative analysis of data from these disparate sources provides a more comprehensive understanding of cancer genetics and molecular biology. Separate analyses of each data source may lack power and will not capture intersource associations. At the other extreme, a joint analysis that ignores the heterogeneity of the data may not capture important features that are specific to each data source. Exploratory methods that simultaneously model shared features and features that are specific to each data source have recently been developed as flexible alternatives (<ref type="bibr" target="#b11">Lock et al., 2013;</ref><ref type="bibr" target="#b12">Lo¨fstedtLo¨fstedt and Trygg, 2011;</ref><ref type="bibr" target="#b18">Ray et al., 2012;</ref><ref type="bibr" target="#b28">Zhou et al., 2012</ref>). The demand for such integrative methods motivates a dynamic area of statistics and bioinformatics. This article concerns integrative clustering. Clustering is a widely used exploratory tool to identify similar groups of objects (for example, clinically relevant disease subtypes). Hundreds of general algorithms to perform clustering have been proposed. However, our work is motivated by the need for an integrative clustering method that is computationally scalable and robust to the unique features of each data source. In Section 3.3, we apply our integrative clustering method to mRNA expression, DNA methylation, microRNA expression and proteomic data from TCGA for a common set of breast cancer tumor samples. These four data sources represent different but highly related and dependent biological components. Moreover, breast cancer tumors are recognized to have important distinctions that are present across several diverse genomic and molecular variables. A fully integrative clustering approach is necessary to effectively combine the discriminatory power of each data source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Related work</head><p>Most applications of clustering multisource data follow one of two general approaches:</p><p>(1) Clustering of each data source separately, potentially followed by a post hoc integration of these separate clusterings.</p><p>(2) Combining all data sources to determine a single 'joint' clustering.</p><p>Under approach (1), the level of agreement between the separate clusterings may be measured by the adjusted Rand index (<ref type="bibr" target="#b7">Hubert and Arabie, 1985</ref>) or a similar statistic. Furthermore, consensus clustering (also called ensemble clustering) can be used to determine an overall partition of the objects that agrees the most with the source-specific clusterings. Several objective *To whom correspondence should be addressed functions and algorithms to perform consensus clustering have been proposed [for a survey see<ref type="bibr" target="#b15">Nguyen and Caruana (2007)]</ref>. Most of these methods do not inherently model uncertainty, and statistical models assume that the separate clusterings are known in advance (<ref type="bibr" target="#b26">Wang et al., 2010</ref><ref type="bibr" target="#b25">Wang et al., , 2011</ref>). Consensus clustering is most commonly used to combine multiple clustering algorithms, or multiple realizations of the same clustering algorithm, on a single dataset. Consensus clustering has also been used to integrate multisource biomedical data (Cancer Genome Atlas Network, 2012). Such an approach is attractive in that it models source-specific features, yet still determines an overall clustering, which is often of practical interest. However, the two stage process of performing entirely separate clusterings followed by post hoc integration limits the power to identify and exploit shared structure (see Section 3.2 for an illustration of this phenomenon). Approach (2) effectively exploits shared structure, at the expense of failing to recognize features that are specific to each data source. Within a model-based statistical framework, one can find the clustering that maximizes a joint likelihood. Assuming that each source is conditionally independent given the clustering, the joint likelihood is the product of the likelihood functions for each data source. This approach is used by<ref type="bibr" target="#b10">Kormaksson et al. (2012)</ref>in the context of integrating gene expression and DNA methylation data. The iCluster method (<ref type="bibr" target="#b14">Mo et al., 2013;</ref><ref type="bibr" target="#b23">Shen et al., 2009</ref>) performs clustering by first fitting a Gaussian latent factor model to the joint likelihood; clusters are then determined by K-means clustering of the factor scores. Rey and Roth (2012) propose a dependency-seeking model in which the goal is to find a clustering that accounts for associations across the data sources. More flexible methods allow for separate but dependent source clusterings. Dependent models have been used to simultaneously cluster gene expression and proteomic data (<ref type="bibr" target="#b20">Rogers et al., 2008</ref>), gene expression and transcription factor binding data (<ref type="bibr" target="#b21">Savage et al., 2010</ref>) and gene expression and copy number data (<ref type="bibr" target="#b27">Yuan et al., 2011</ref><ref type="bibr" target="#b9">). Kirk et al. (2012</ref>describe a more general dependence model for two or more data sources. Their approach, called Multiple Dataset Integration (MDI), uses a statistical framework to cluster each data source while simultaneously modeling the pairwise dependence between clusterings.<ref type="bibr" target="#b22">Savage et al. (2013)</ref>use MDI to integrate gene expression, methylation, microRNA and copy number data for glioblastoma tumor samples from TCGA. The pairwise dependence model does not explicitly model adherence to an overall clustering, which is often of practical interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Finite Dirichlet mixture models</head><p>Here we briefly describe the finite Dirichlet mixture model for clustering a single dataset, with the purpose of laying the groundwork for the integrative model given in Section 2.2. Given data X n for N objects (n ¼ 1,. .. , N), the goal is to partition these objects into at most K clusters. Typically X n is a multidimensional vector, but we present the model in sufficient generality to allow for more complex data structures. Let fðX n jÞ define a probability model for X n given parameter(s). For example, f may be a Gaussian density defined by the mean and variance ¼ ð, 2 Þ. Each X n is drawn independently from a mixture distribution with K components, specified by the parameters 1 ,. .. , K. Let C n 2 f1,. .. , Kg represent the component corresponding to X n , and k be the probability that an arbitrary object belongs to cluster k: k ¼ PðC n ¼ kÞ: Then, the generative model is X n $ fðÁj k Þ with probability k :</p><p>Under a Bayesian framework, one can put a prior distribution on Å ¼ ð 1 ,. .. , K Þ and the parameter set Â ¼ ð 1 ,. .. , K Þ. It is natural to use a Dirichlet prior distribution for Å. Standard computational methods such as Gibbs sampling can then be used to approximate the posterior distribution for Å, Â and C ¼ ðC 1 ,. .. , C N Þ. The Dirichlet prior is characterized by a K-dimensional concentration parameter of positive reals. Low prior concentration (for example, k 1) will allow some of the estimated k to be small, and therefore N objects may not represent all K clusters. Letting K ! 1 gives a Dirichlet process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Integrative model</head><p>We extend the Dirichlet mixture model to accommodate data from M sources X 1 ,. .. , X M. Each data source is available for a common set of N objects, where X mn represents data m for object n. Each data source requires a probability model f m ðX n j m Þ parametrized by m. Under the general framework presented here, each X m may have disparate structure. For example, X 1n may give an image where f 1 defines the spectral density for a Gaussian random field, while X 2n may give a categorical vector where f 2 defines a multivariate probability mass function. We assume there is a separate clustering of the objects for each data source, but that these adhere loosely to an overall clustering. Formally, each X mn n ¼ 1,. .. , N is drawn independently from a K-component mixture distribution specified by the parameters m1 ,. .. , mK. Let L mn 2 f1,. .. , Kg represent the component corresponding to X mn. Furthermore, let C n 2 f1,. .. , Kg represent the overall mixture component for object n. The source-specific clusterings L m ¼ ðL m1 ,. .. , L mN Þ are dependent on the overall clustering C ¼ ðC 1 ,. .. , C N Þ:</p><formula>PðL mn ¼ kjC n Þ ¼ ðk, C n , m Þ</formula><p>where m adjusts the dependence function. The data X m are independent of C conditional on the source-specific clustering L m. Hence, C serves only to unify L 1 ,. .. , L M. The conditional model is</p><formula>PðL mn ¼ kjX mn , C n , mk Þ / ðk, C n , m Þf m ðX mn j mk Þ:</formula><p>Throughout this article, we assume has the simple form</p><formula>ðL mn , C n , m Þ ¼ m ifC n ¼ L mn 1Àm KÀ1 otherwise ð1Þ</formula><p>where m 2 ½ 1 K , 1 controls the adherence of data source m to the overall clustering. More simply m is the probability that L mn ¼ C n. So, if m ¼ 1, then L m ¼ C. The m are estimated from the data together with C and L 1 ,. .. , L m. In practice we estimate each m separately, or assume that 1 ¼. .. ¼ M and hence each data source adheres equally to the overall clustering. The latter is favored when M ¼ 2 for identifiability reasons. More complex models that permit dependence of the m s are also potentially useful. Let k be the probability that an object belongs to the overall cluster k: k ¼ PðC n ¼ kÞ:</p><p>We assume a Dirichlet() prior distribution for Å ¼ ð 1 ,. .. , K Þ. The probability that an object belongs to a given source-specific cluster follows directly:</p><formula>PðL mn ¼ kjÅÞ ¼ k m þ ð1 À k Þ 1 À m K À 1 : ð2Þ</formula><p>Moreover, a simple application of Bayes rule gives the conditional distribution of C:</p><formula>PðC n ¼ kjL, Å, Þ / k Y M m¼1 ðL mn , k, m Þ,</formula><p>where is defined as in (1). The number of possible clusters K is the same for L 1 ,. .. , L M and C. The link function naturally aligns the cluster labels, as cases in which the clusterings are not well aligned (a permutation of the labels would give better agreement) will have low posterior probability. The number of clusters that are actually represented may vary, and generally the sourcespecific clusterings L m will represent more clusters than C, rather than vice versa. This follows from Equation (2) and is illustrated in Section 2 of the Supplementary Material. Intuitively if object n is not allocated to any overall cluster in data source m (i.e. L mn = 2C), then X mn does not conform well to any overall pattern in the data.<ref type="figure" target="#tab_1">Table 1</ref>summarizes the mathematical notation used for the integrative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Marginal forms</head><p>Integrating over the overall clustering C gives the joint marginal distribution of L 1 ,. .. , L M :</p><formula>PðfL mn ¼ k m g M m¼1 jÅ, Þ / X K k¼1 k Y M m¼1 ðk m , k, m Þ: ð3Þ</formula><p>Under the assumption that 1 ¼. .. ¼ M the model simplifies:</p><formula>PðfL mn ¼ k m g M m¼1 jÅ, Þ / X K k¼1 k U tk ð4Þ</formula><p>where t k is the number of clusters equal to k and U ¼ ðKÀ1Þ1 1À1 ! 1. This marginal form facilitates comparison with the MDI method for dependent clustering. In the MDI model ij 40 control the strength of association between the clusterings L i and L j :</p><formula>PðfL mn ¼ k m g M m¼1 j ~ Å, ÈÞ / Y M m¼1 ~ mkm Y fi5jjki¼kjg ð1 þ ij Þ ð 5Þ</formula><p>where ~ mk ¼ PðL mn ¼ kÞ. For K ¼ 2 and ~ 1Á ¼ ~ 2Á , it is straightforward to show that (4) and (5) are functionally equivalent under a parameter substitution (see Section 3 of the Supplementary Material). There is no such general equivalence between the models for K42 or M42, regardless of restrictions on ~ Å and È. This is not surprising, as MDI gives a general model of pairwise dependence between clusterings rather than a model of adherence to an overall clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Estimation</head><p>Here we present a general Bayesian framework for estimation of the integrative clustering model. We use a Gibbs sampling procedure to approximate the posterior distribution for the parameters introduced in Section 2.2. The algorithm is general in that we do not assume any specific form for the f m and the parameters mk. We use conjugate prior distributions for m , Å and (if possible) mk .</p><formula>m $ TBetaða m , b m , 1 K Þ</formula><p>, the Betaða m , b m Þ distribution truncated below by 1 K. By default we choose a m ¼ b m ¼ 1, so that the prior for m is uniformly distributed between 1 K and 1. Å $ Dirichletð 0 Þ. By default we choose 0 ¼ ð1, 1,. .. , 1Þ, so that the prior for Å is uniformly distributed on the standard ðM À 1Þ-simplex.</p><p>The mk have prior distribution p m. In practice, one should choose p m so that sampling from the conditional posterior p m ð mk jX m , L m Þ is feasible.</p><p>Markov chain Monte Carlo (MCMC) proceeds by iteratively sampling from the following conditional posterior distributions:</p><formula>Â m jX m , L m $ p m ð mk jX m , L m Þ for k ¼ 1,. .. , K. L m jX m , Â m , m , C $ PðkjX mn , C n , mk , m Þ for n ¼ 1,. .. , N, where PðkjX mn , C n , Â m Þ / ðk, C n , m Þf m ðX mn j mk Þ: m jC, L m $ TBetaða m þ m , b m þ N À m , 1 K Þ, where m is the number of samples n satisfying L mn ¼ C n. CjL m , Å, $ PðkjÅ, fL mn , m g M m¼1 Þ for n ¼ 1,. .. , N, where PðkjÅ, fL mn , m g M m¼1 Þ / k Y M m¼1 ðk, L mn , m Þ</formula><p>ÅjC $ Dirichletð 0 þ Þ, where k is the number of samples allocated to cluster k in C.</p><p>This algorithm can be suitably modified under the assumption that 1 ¼. .. ¼ M (see Section 1.2 of the Supplementary Material). Each sampling iteration produces a different realization of the clusterings C, L 1 , Á Á Á , L m , and together these samples approximate the posterior distribution for the overall and source-specific clusterings. However, a point estimate may be desired for each of C, L 1 , Á Á Á , L m to facilitate interpretation of the clusters. In this respect, methods that aggregate over the MCMC iterations to produce a single clustering, such as that described in Dahl (2006), can be used. It is possible to derive a similar sampling procedure using only the marginal form for the source-specific clusterings given in Equation (3). However, the overall clustering C is also of interest in most applications. Furthermore, incorporating C into the algorithm can actually improve computational efficiency dramatically, especially if M is large. As presented, each MCMC iteration can be completed in O(MNK) operations. If the full joint marginal distribution of L 1 ,. .. , L M is used the computational burden increases exponentially with M (this presents a bottleneck for the MDI method). For each iteration, C n is determined randomly from a distribution that gives higher probability to clusters that are prevalent in fL 1n ,. .. , L mn g. In this sense, C is determined by a random consensus clustering of the source-specific clusterings. Hence, we refer to this approach as Bayesian consensus clustering (BCC). BCC differs from traditional consensus clustering in three key aspects.</p><p>(1) Both the source-specific clusterings and the consensus clustering are modeled in a statistical way that allows for uncertainty in all parameters.</p><p>(2) The source-specific clusterings and the consensus clustering are estimated simultaneously, rather than in two stages. This permitsWe have developed software for the R environment for statistical computing (R Development Core Team, 2012) to perform BCC on multivariate continuous data using a Normal-Gamma conjugate prior distribution for cluster-specific means and variances. Full computational details for this implementation are given in Section 1.1 of the Supplementary Material. This software is open source and may be modified for use with alternative likelihood models (e.g. for categorical or functional data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Choice of K</head><p>One can infer the number of clusters in the model by specifying a large value for the maximum number of clusters K, for example K ¼ N. The number of clusters realized in C and the L m may still be small. However, we find that this is not the case for high-dimensional structured data such as that used for the genomics application in Section 3.3. The model tends to select a large number of clusters even if the Dirichlet prior concentration parameters 0 are small. The number of clusters realized using a Dirichlet process increases with the sample size; hence, if the number of mixture component is indeed finite, the estimated number of clusters is inconsistent as N ! 1 (<ref type="bibr" target="#b13">Miller and Harrison, 2013</ref>). This is undesirable for exploratory applications in which the goal is to identify a small number of interpretable clusters. Alternatively, we consider a heuristic approach that selects the value of K that gives maximum adherence to an overall clustering. For each K, the estimated adherence parameters m 2 ½ 1 K , 1 are mapped to the unit interval by the linear transformation</p><formula>Ã m ¼ K m À 1 K À 1 :</formula><p>We then select the value of K that results in the highest mean adjusted adherence</p><formula>" Ã ¼ 1 M X M m¼1 Ã m :</formula><p>This approach will generally select a small number of clusters that reveal shared structure across the data sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Accuracy of ^</head><p>We find that with reasonable signal the m can generally be estimated with accuracy and without substantial bias. To illustrate, we generate simulated datasets X 1 : 1 Â 200 and X 2 : 1 Â 200 as follows:</p><p>(1) Let C define two clusters, where C n ¼ 1 for n 2 f1,. .. , 100g and C n ¼ 2 for n 2 f101,. .. , 200g.</p><p>(2) Draw from a Uniform(0.5,1) distribution.</p><formula>(3) For m ¼ 1, 2 and n ¼ 1,. .. , 200, generate L mn 2 f1, 2g with probabilities PðL mn ¼ C n Þ ¼ and PðL mn 6 ¼ C n Þ ¼ 1 À .</formula><p>(4) For m ¼ 1, 2, draw values X mn from a Normal(1.5,1) distribution if L mn ¼ 1 and from a NormalðÀ1:5, 1Þ distribution if L mn ¼ 2.</p><p>We generate 100 realizations of the above simulation, and estimate the model via BCC for each realization. We assume 1 ¼ 2 in our estimation and use a uniform prior; further computational details are given in Section 4 of the Supplementary Material.<ref type="figure">Figure 1</ref>displays ^ , the best estimate for both 1 and 2 , versus the true for each realization. The point estimate displayed is the mean over MCMC draws, and we also display a 95% credible interval based on the 2.5–97.5 percentiles of the MCMC draws. The estimated ^ are generally close to the true , and the credible interval contains the true value in 91 of 100 simulations. See Section 4 of the Supplementary Material for a more detailed study, including a simulation illustrating the effect of the prior distribution on ^ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Clustering accuracy</head><p>To illustrate the flexibility and advantages of BCC in terms of clustering accuracy, we generate simulated data sources X 1 and X 2 as in Section 3.1 but with Normal(1,1) and Normal(À1,1) as our mixture distributions. Hence, the signal distinguishing the two clusters is weak enough so that there is substantial overlap within each simulated data source. We generate 100 simulations and compare the results for four model-based clustering approaches:</p><p>(1) Separate clustering, in which a finite Dirichlet mixture model is used to determine a clustering separately for X 1 and X 2 .</p><p>(2) Joint clustering, in which a finite Dirichlet mixture model is used to determine a single clustering for the concatenated data ½X 0</p><formula>1 X 0 2  0 .</formula><p>(3) Dependent clustering, in which we model the pairwise dependence between each data source, in the spirit of MDI.</p><p>(4) Bayesian consensus clustering.</p><p>The full implementation details for each method are given in Section 5 of the Supplementary Material.<ref type="figure">1</ref>. Estimated ^ versus true for 100 randomly generated simulations. For each simulation, the mean value ^ is shown with a 95% credible interval</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian consensus clustering</head><p>We consider the relative error for each model in terms of the average number of incorrect cluster assignments:</p><formula>Source error ¼ P M m¼1 P N n¼1 1f ^ L mn 6 ¼ L mn g MN , Overall error ¼ P N n¼1 1f ^ C n 6 ¼ C n g N ,</formula><p>where 1 is the indicator function. For joint clustering, the source clusters b L m are identical. For separate and dependent clustering, we determine an overall clustering by maximizing the posterior expected adjusted Rand index (<ref type="bibr" target="#b5">Fritsch and Ickstadt, 2009</ref>) of the source clusterings. The relative error for each clustering method with M ¼ 2 and M ¼ 3 sources is shown in<ref type="figure" target="#fig_1">Figure 2</ref>. Smooth curves are fit to the results for each method using LOESS local regression (<ref type="bibr" target="#b1">Cleveland, 1979</ref>) and display the relative clustering error for each method as a function of. Not surprisingly, joint clustering performs well for % 1 (perfect agreement) and separate clustering performs well when % 0:5 (no relationship). BCC and dependent clustering learn the level of cluster agreement, and hence serve as a flexible bridge between these two extremes. Dependent clustering does not perform as well with M ¼ 3 sources, as the pairwise dependence model does not assume an overall clustering and therefore has less power to learn the underlying structure for M42.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Application to genomic data</head><p>We apply BCC to multisource genomic data on breast cancer tumor samples from TCGA. For a common set of 348 tumor samples, our full dataset includes RNA gene expression (GE) data for 645 genes. DNA methylation (ME) data for 574 probes. miRNA expression (miRNA) data for 423 miRNAs. Reverse phase protein array (RPPA) data for 171 proteins.</p><p>These four data sources are measured on different platforms and represent different biological components. However, they all represent genomic data for the same sample set and it is reasonable to expect some shared structure. These data are publicly available from the TCGA Data Portal. See http://people.duke. edu/%7Eel113/software.html for R code to completely reproduce the following analysis, including instructions on how to download and process these data from the TCGA Data Portal. Breast cancer is a heterogeneous disease and is therefore a natural candidate for clustering. Previous studies have foundanywhere from 2 (<ref type="bibr" target="#b4">Duan, 2013</ref>) to 10 (<ref type="bibr" target="#b2">Curtis et al., 2012</ref>) distinct clusters based on a variety of characteristics. In particular, 4 comprehensive sample subtypes were previously identified based on a multisource consensus clustering of the TCGA data (<ref type="bibr">Cancer Genome Atlas Network, 2012</ref>). These correspond closely to the well-known molecular subtypes Basal, Luminal A, Luminal B and HER2. These subtypes were shown to be clinically relevant, as they may be used for more targeted therapies and prognosis. We use the heuristic described in Section 2.5 to select the number of clusters for BCC, with intent to determine a clustering that is well-represented across the four genomic data sources. We select K ¼ 3 clusters, and posterior probability estimates were converted to hard clusterings via Dahl (2006) to facilitate comparison and visualization.<ref type="figure">Table 2</ref>shows a matching matrix comparing the overall clustering C with the comprehensive subtypes defined by TCGA, as well as summary data for the BCC clusters. The TCGA and BCC clusters show different structure but are not independent (P-value 50:01; Fisher's exact test). BCC cluster 1 corresponds to the Basal subtype, which is characterized by basal-like expression and a relatively poor clinical prognosis. BCC cluster 2 is primarily a subset of the Luminal A samples, which are genomically and clinically heterogeneous. DNA copy number alterations, in particular, are a source of diversity for Luminal A.<ref type="figure">Table 2</ref>). For comparison, those Luminal A samples that were not included in Cluster 2 had a substantially higher average FGA of 0:17 AE 0:02. Cluster 3 primarily includes those samples that are receptor (estrogen and/or progesterone) positive and have higher FGA. These results suggest that copy number variation may contribute to breast tumor heterogeneity across several genomic sources.<ref type="figure">Figure 3</ref>provides a point-cloud view of each dataset given by a scatter plot of the first two principal components. The overall and source-specific cluster index is shown for each sample, as well as a point estimate and $95% credible interval for the adherence parameter. The GE data has by far the highest adherence to the overall clustering ( ¼ 0:91); this makes biological sense, as RNA expression is thought to have a direct causal relationship with each of the other three data sources. The four data sources show different sample structure, and the sourcespecific clusters are more well-distinguished than the overall clusters in each plot. However, the overall clusters are clearly represented to some degree in all four plots. Hence, the flexible, yet integrative, approach of BCC seems justified for these data. Further details regarding the above analysis are given in Section 6 of the Supplementary Material. These include the prior specifications for the model, charts that illustrate mixing over the MCMC draws, a comparison of the source-specific clusterings L mn to source-specific subtypes defined by TCGA, clustering heatmaps for each data source and short-term survival curves for each overall cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>This work was motivated by the perceived need for a general, flexible and computationally scalable approach to clustering multisource biomedical data. We propose BCC, which models both an overall clustering and a clustering specific to each data source. We view BCC as a form of consensus clustering, with advantages over traditional methods in terms of modeling uncertainty and the ability to borrow information across sources. The BCC model assumes a simple and general dependence between data sources. When an overall clustering is not sought, or when such a clustering does not make sense as an assumption, a more general model of cluster dependence (such as MDI) may be more appropriate. Furthermore, a context-specific approach may be necessary when more is known about the underlying dependence of the data. For example, Nguyen and Gelfand (2011) exploit functional covariance models for timecourse data to determine overall and time-specific clusters. Our implementation of BCC assumes the data are normally distributed with cluster-specific mean and variance parameters. It is straightforward to extend this approach to more complex clustering models. In particular, models that assume clusters exist on a sparse feature set (<ref type="bibr" target="#b24">Tadesse et al., 2005</ref>) or allow for more general covariance structure (<ref type="bibr" target="#b6">Ghahramani and Beal, 1999</ref>) are growing in popularity. While we focus on multisource biomedical data, the applications of BCC are potentially widespread. In addition to multisource data, BCC may be used to compare clusterings from different statistical models for a single homogeneous dataset.Note: Summary data includes 5-year survival probabilities using the Kaplan–Meier estimator, with 95% confidence interval; mean fraction of the genome altered (FGA) using threshold T ¼ 0:5, with 95% confidence interval; receptor status for estrogen (ER), progesteron (PR) and human epidermal growth factor 2 (HER2); and copy number status for amplification at sites 8p11 and 8q23 and deletion at sites 5q13 and 16q23.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian consensus clustering</head><p>Funding: National Institute of Environmental Health Sciences (NIEHS) (R01-ES017436). Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.</head><figDesc>Fig. 1. Estimated ^ versus true for 100 randomly generated simulations. For each simulation, the mean value ^ is shown with a 95% credible interval</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Source-specific and overall clustering error for 100 simulations with M ¼ 2 and M ¼ 3 data sources, shown for joint clustering, separate clustering, dependent clustering, BCC and BCC using the true. A LOESS curve displays clustering error as a function of for each method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>On independent datasets Curtis et al. (2012) and Jo¨nssonJo¨nsson et al. (2010) identify a subgroup of Luminal A that is characterized by fewer copy number alterations and a more favorable clinical prognosis (clusters IntClust 3 and Luminalsimple, respectively). As a measure of copy number activity, we compute the fraction of the genome altered (FGA) as described in Cancer Genome Atlas Network (2012) Supplementary Section VII (with threshold T ¼ 0.50) for each BCC cluster. Clusters 1 and 3 had an FGA above 0.2, while Cluster 2 had an FGA of 0.10 (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1. Notation</figDesc><table>N 
Number of objects 
M 
Number of data sources 
K 
Number of clusters 
X m 
Data source m 
X mn 
Data for object n, source m 
f m 
Probability model for source m 
mk 
Parameters for f m , cluster k 
p m 
Prior distribution for mk 
C n 
Overall cluster for object n 
k 
Probability that C n ¼ k 
L mn 
Cluster specific to X mn 

Dependence function for C n and L mn 
m 
Probability that L mn ¼ C n 

E.F.Lock and D.B.Dunson </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. BCC cluster versus TCGA comprehensive subtype matching matrix and summary data for BCC clusters</figDesc><table>BCC cluster 

1 
2 
3 

TCGA subtype 
1 (Her2) 
13 
6 
20 
2 (Basal) 
66 
2 
4 
3 (Lum A) 
3 
80 
78 
4 (Lum B) 
0 
3 
73 

5-year survival 
0.67 AE 0.20 
0.94 AE 0.08 
0.81 AE 0.11 
FGA 
0.22 AE 0.04 
0.10 AE 0.02 
0.20 AE 0.02 
ERþ 
13% 
92% 
94% 
PRþ 
7% 
86% 
75% 
HER2þ 
15% 
12% 
18% 
8p11 amplification 
32% 
19% 
42% 
8q24 amplification 
79% 
39% 
67% 
5q13 deletion 
61% 
3% 
14% 
16q23 deletion 
19% 
66% 
61% 

</table></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Bayesian consensus clustering at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Comprehensive molecular portraits of human breast tumours</title>
	</analytic>
	<monogr>
		<title level="j">Cancer Genome Atlas Network. Nature</title>
		<imprint>
			<biblScope unit="volume">490</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust locally weighted regression and smoothing scatterplots</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Cleveland</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="829" to="836" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Curtis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="page" from="346" to="352" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Model-Based Clustering for Expression Data via a Dirichlet Process Mixture Model</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dahl</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Metasignatures identify two major subtypes of breast cancer</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Duan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CPT Pharmacom. Syst. Pharmacol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Improved criteria for clustering based on the posterior similarity matrix</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Fritsch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ickstadt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Anal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="367" to="391" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Variational inference for bayesian mixtures of factor analysers</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Ghahramani</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Beal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">A</forename>
				<surname>Solla</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 12, [NIPS Conference</title>
		<meeting><address><addrLine>Denver, Colorado, USA ; Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1999-11-29" />
			<biblScope unit="page" from="449" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hubert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Arabie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Classif</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Genomic subtypes of breast cancer identified by arraycomparative genomic hybridization display distinct molecular and clinical characteristics</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Jo¨nssonjo¨nsson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Breast Cancer Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Bayesian correlated clustering to integrate multiple datasets</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Kirk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3290" to="3297" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Integrative model-based clustering of microarray methylation and expression data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kormaksson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1327" to="1347" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Joint and Individual Variation Explained (JIVE) for integrated analysis of multiple data types</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Lock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="523" to="542" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Onplsa novel multiblock method for the modelling of predictive and orthogonal variation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Lo¨fstedtlo¨fstedt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Trygg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="441" to="455" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">A simple example of dirichlet process mixture inconsistency for the number of components. arXiv preprint</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">T</forename>
				<surname>Harrison</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Pattern discovery and cancer gene identification in integrated cancer genomic data</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Mo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="4245" to="4250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Caruana</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Consensus clusterings. In: Proceedings of the 7th IEEE International Conference on Data Mining (ICDM 2007)</title>
		<meeting><address><addrLine>Omaha, Nebraska, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007-10-28" />
			<biblScope unit="page" from="607" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The Dirichlet labeling process for clustering functional data</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Gelfand</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sin</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1249" to="1289" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Development</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Core</forename>
				<surname>Team</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title level="m" type="main">Bayesian joint analysis of heterogeneous data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ray</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Preprint</note>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Copula mixture model for dependency-seeking clustering</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Rey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Roth</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning (ICML-12). ICML&apos;12</title>
		<editor>Langford,J. and Pineau,J.</editor>
		<meeting>the 29th International Conference on Machine Learning (ICML-12). ICML&apos;12<address><addrLine>New York, NY, Omnipress</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="927" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Investigating the correspondence between transcriptomic and proteomic expression profiles using coupled cluster models</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Rogers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2894" to="2900" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Discovering transcriptional modules by bayesian data integration</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">S</forename>
				<surname>Savage</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="158" to="167" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<monogr>
		<title level="m" type="main">Identifying cancer subtypes in glioblastoma by combining genomic, transcriptomic and epigenomic data. arXiv preprint</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">S</forename>
				<surname>Savage</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Integrative clustering of multiple genomic data types using a joint latent variable model with application to breast and lung cancer subtype analysis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2906" to="2912" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Bayesian variable selection in clustering high-dimensional data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">G</forename>
				<surname>Tadesse</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="602" to="617" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Bayesian cluster ensembles</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Anal. Data Mining</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="54" to="70" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonparametric bayesian clustering ensembles</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<meeting><address><addrLine>Berlin-Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="435" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Patient-specific data fusion defines prognostic cancer subtypes</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yuan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1002227</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<monogr>
		<title level="m" type="main">Common and individual features analysis: beyond canonical correlation analysis Arxiv preprint arXiv</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1212" to="3913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">PCA plots for each data source Sample points are colored by overall cluster; cluster 1 is black, cluster 2 is red and cluster 3 is blue. Symbols indicate source-specific cluster; cluster 1 is indicated by filled circles, cluster 2 is indicated by plus signs and cluster 3 is</title>
		<author>
			<persName>
				<surname>Fig</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
	<note>indicated. by asterisks E.F.Lock and D.B.Dunson</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>