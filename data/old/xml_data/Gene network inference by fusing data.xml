
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gene network inference by fusing data from diverse distributions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Marinka</forename>
								<surname>Zitnik</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer and Information Science</orgName>
								<orgName type="institution">University of Ljubljana</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Bla≈æ</forename>
								<surname>Zupan</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer and Information Science</orgName>
								<orgName type="institution">University of Ljubljana</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Molecular and Human Genetics</orgName>
								<orgName type="institution">Baylor College of Medicine</orgName>
								<address>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gene network inference by fusing data from diverse distributions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv258</idno>
					<note>*To whom correspondence should be addressed. Supplementary information: Supplementary information is available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Markov networks are undirected graphical models that are widely used to infer relations between genes from experimental data. Their state-of-the-art inference procedures assume the data arise from a Gaussian distribution. High-throughput omics data, such as that from next generation sequencing, often violates this assumption. Furthermore, when collected data arise from multiple related but otherwise nonidentical distributions, their underlying networks are likely to have common features. New principled statistical approaches are needed that can deal with different data distributions and jointly consider collections of datasets. Results: We present FUSENET, a Markov network formulation that infers networks from a collection of nonidentically distributed datasets. Our approach is computationally efficient and general: given any number of distributions from an exponential family, FUSENET represents model parameters through shared latent factors that define neighborhoods of network nodes. In a simulation study, we demonstrate good predictive performance of FUSENET in comparison to several popular graph-ical models. We show its effectiveness in an application to breast cancer RNA-sequencing and somatic mutation data, a novel application of graphical models. Fusion of datasets offers substantial gains relative to inference of separate networks for each dataset. Our results demonstrate that network inference methods for non-Gaussian data can help in accurate modeling of the data generated by emergent high-throughput technologies. Availability and implementation: Source code is at https://github.com/</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Undirected graphical models or Markov networks are a popular class of statistical tools for probabilistic description of complex associations in high-dimensional data (cf.<ref type="bibr" target="#b29">Rue and Held, 2005</ref>). Biological processes in a cell involve complex interactions between genes and it is important to understand, which genes conditionally depend on each other. These dependencies can be inferred from the experimental data and represented in a gene network. As a popular approach to network modeling, Markov networks are particularly appealing because they focus on finding such conditional dependence relationships. Intuitively, the existence of a link between genes A and B in a Markov network indicates that the behavior of gene A is still predictive of gene B given all available measurements about gene A and its immediate neighbors in a network. Hence, Markov networks can help us to find a rich set of direct dependencies between genes that are stronger than gene correlations (<ref type="bibr" target="#b1">Allen and Liu, 2013</ref>).</p><p>Markov networks have been well studied in bioinformatics and numerous applications are concerned with inferring the network structure primarily from microarray and next generation sequencing gene expression data (<ref type="bibr" target="#b14">Kotera et al., 2012;</ref><ref type="bibr" target="#b10">Gallopin et al., 2013;</ref><ref type="bibr" target="#b31">Segal et al., 2003</ref>). They are complementary but not superior to other gene network inference approaches (<ref type="bibr" target="#b19">Marbach et al., 2012</ref>). However, the increasing variety of data generating technologies and heterogeneity of resulting data draw attention to two challenges in the context of Markov network inference: inference from nonGaussian distributed data, and simultaneous inference from many datasets. In bioinformatics, many datasets are high dimensional, contain a limited number of samples with a large number of zeros, and come from skewed distributions. Most existing methods assume that data follow a Gaussian distribution. While this assumption holds for typical log ratio expression values from microarray data, it is violated for measurements obtained from sequencing technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i230</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com<ref type="bibr">Bioinformatics, 31, 2015</ref>For example, gene expression levels from RNA-sequencing count how many times a transcript maps to a specific genomic location (<ref type="bibr" target="#b40">Wang et al., 2009</ref>) and as such these data are not Gaussian (<ref type="bibr" target="#b1">Allen and Liu, 2013</ref>). The Gaussian assumption is also violated for categorical datasets, such as data on mutation types and copy number variation data (<ref type="bibr" target="#b11">Hudson et al., 2010</ref>). While it would be possible to design a network inference for each specific data type, we could benefit from a procedure that can treat a wide class of distributions and can jointly consider all available data during network inference (<ref type="bibr" target="#b37">Zitnik and Zupan, 2015</ref>). We have developed a novel approach, called FUSENET, for inference of undirected networks from a number of high-dimensional datasets (<ref type="figure">Fig. 1</ref>). Our approach builds upon recent theoretical results about Markov networks (<ref type="bibr" target="#b43">Yang et al., 2012</ref><ref type="bibr" target="#b42">Yang et al., , 2013</ref>) and, unlike the previous works in Markov modeling, can be applied to settings where data arise from multiple related but otherwise nonidentical distributions. To achieve this level of modeling flexibility, we represent model parameters with latent factors. FUSENET implements data fusion through sharing of latent factors that are common to all datasets and distributions, and handles data diversity through inference of factors specific to a particular dataset. In simulation studies, FUSENET recovers the true networks underlying the observed data more accurately than several alternative approaches. The improved performance demonstrates that FUSENET can find conditional dependencies between genes that could not be reconstructed with Gaussian-based approaches. In a case study with breast cancer RNA-sequencing expression values and somatic mutation data, we demonstrate the benefits of joint network inference from multiple related datasets. The networks inferred collectively from both types of data show greater functional enrichment than networks learned from any data type alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The most straightforward approach to network inference is a similarity-based approach, which assumes that functionally related genes are likely to share high similarity with respect to a given dataset. A well-known network obtained with this approach is the S. cerevisiae genetic interaction network by<ref type="bibr" target="#b6">Costanzo et al. (2010)</ref>. Whenever the similarity value between two genes is above a threshold they are linked by an edge, which is referred to as a direct network inference approach (<ref type="bibr" target="#b14">Kotera et al., 2012</ref>). In contrast to direct network inference, model-based network inference via graphical models focuses on local dependencies between genes, where each gene is directly affected by a relatively small number of genes. Edges estimated by a graphical model can be related to causal inference (<ref type="bibr" target="#b26">Pearl and Verma, 1991</ref>). The problem of learning a network structure associated with an undirected graphical model has seen a wide range of applications ranging from social networks and image and speech processing (<ref type="bibr" target="#b22">Metzler and Croft, 2005;</ref><ref type="bibr" target="#b38">Wang et al., 2013</ref>) to genomics. Applications in bioinformatics include estimation of molecular pathways from protein interaction and gene expression data (<ref type="bibr" target="#b31">Segal et al., 2003;</ref><ref type="bibr" target="#b32">Stingo and Vannucci, 2011</ref>), reconstruction of gene regulatory networks from microarray data (<ref type="bibr" target="#b19">Marbach et al., 2012</ref>), inference of a cancer signaling network from proteomic data (<ref type="bibr" target="#b23">Mukherjee and Speed, 2008</ref>) and reconstruction of genetic interaction networks from integrated experimental data (<ref type="bibr" target="#b12">Isci et al., 2014</ref>). Methods applied to these problems and many other recent gene network inference algorithms (<ref type="bibr" target="#b2">Anjum et al., 2009;</ref><ref type="bibr" target="#b9">Friedman et al., 2008;</ref><ref type="bibr" target="#b21">Meinshausen and B√º hlmann, 2006;</ref><ref type="bibr" target="#b27">Ravikumar et al., 2010;</ref><ref type="bibr">Sch√§ fer and Strimmer, 2005</ref>) estimate Gaussian or binary Markov networks, i.e. they assume that data follow an approximately Gaussian distribution. Although non-Gaussian data are becoming increasingly common in biology, until now, very few network inference algorithms have been proposed for their treatment. When dealing with non-Gaussian data, some authors simply use methods that are based on a Gaussian assumption (<ref type="bibr" target="#b4">Cai et al., 2012</ref>). We show in experiments that this decision may result in poor predictive performance. Recently, various extensions of Gaussian Markov networks have been proposed that first Gaussianize the data, using for example a copula transform (<ref type="bibr" target="#b18">Liu et al., 2009</ref><ref type="bibr" target="#b17">Liu et al., , 2012</ref><ref type="bibr" target="#b25">Murray et al., 2013</ref>) or a log transform, and then apply algorithms that rely on an assumption of normality. While these approaches perform better than naƒ±¬®venaƒ±¬®ve application of Gaussian-based methods to untransformed data, they are ill-suited to data generated by next generation sequencing technologies (<ref type="bibr" target="#b1">Allen and Liu, 2013</ref>). A handful of recent algorithms (<ref type="bibr" target="#b1">Allen and Liu, 2013;</ref><ref type="bibr" target="#b10">Gallopin et al., 2013</ref>) have considered Markov networks for non-Gaussian data, using for example the Poisson distribution for RNA-sequencing read counts. In contrast to our FUSENET, these methods cannot integrate datasets across different data types, thereby limiting their ability to fuse information from many datasets. Our work presented here is similar in spirit to our recently developed methodology for data fusion via collective matrix factorization (<ref type="bibr" target="#b37">Zitnik and Zupan, 2015</ref>). The methodology therein can jointly model any number of datasets that can be represented with matrices. Unlike existing data integration approaches, it does not requireGene network inference by fusing data from diverse distributions i231 transforming data into a common data space (e.g. a gene space). We applied this methodology to mining disease-disease associations (<ref type="bibr" target="#b35">Zitnik et al., 2013</ref>), predicting drug toxicity (<ref type="bibr" target="#b36">Zitnik and Zupan, 2014</ref>) and gene functions (<ref type="bibr" target="#b37">Zitnik and Zupan, 2015</ref>) and observed substantial gains in predictive accuracy. While both our work here and in Zitnik and Zupan (2015) rely on latent factor models, they are substantially different from one another. First, FUSENET builds on the Markov network theory, whereas previously we considered matrix decomposition. Second, FUSENET is a probabilistic model that explicitly considers various data distributions, and third, FUSENET is a network inference approach, whereas our previous works focused on matrix completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>FUSENET takes as its input a collection of datasets where each dataset consists of a set of gene profiles (<ref type="figure">Fig. 1</ref>). Gene profiles can be heterogeneous and belong to different data types, e.g. data can be continuous, discrete or categorical. For example, measurements from RNA-sequencing represent the numbers of fragments that were mapped to a specific genomic location (<ref type="bibr" target="#b40">Wang et al., 2009</ref>). The RNA-sequencing expression values are then non-negative and integer valued and, hence, are not approximately Gaussian, but rather follow the Poisson or negative binomial distribution. This is in contrast to copy number variation data and mutation data, i.e. single-base substitutions, short indels, or multiple base substitutions, that might be modeled better with multinomial or categorical distributions. On the other end of spectrum are microarray gene expression data, which are approximately Gaussian distributed. The crucial feature of FUSENET is the representation of model parameters via latent factors. This feature, together with the sharing of latent factors between datasets, allows us to infer a network by simultaneously considering many datasets that each can arise from a different exponential family distribution (Section 3.7). We exemplify FUSENET by deriving Markov network models for two distributions from an exponential family, the Poisson distribution (Section 3.3) and the multinomial distribution (Section 3.5). Since the exponential family includes not only Gaussian but also binomial, multinomial, Poisson, gamma distributions and others, FUSENET can achieve great flexibility in estimating gene networks from diverse data (Section 3.6) and also comes with an efficient algorithm for network structure estimation (Section 3.8). Our work provides two novel contributions over current approaches to gene network inference discussed in Related work: @BULLET FUSENET simultaneously infers networks from datasets that may be generated by nonidentical distributions, and @BULLET FUSENET estimates large-scale genomic networks from increasingly common non-Gaussian distributed data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Markov networks</head><p>A Markov network specifies conditional dependence relationships between genes. In particular, if there is no edge between genes s and t then this implies that the behavior of s is independent of t given the set of immediate neighbors of s. From this local property (<ref type="bibr" target="#b24">Murphy, 2012</ref>), one can easily see that two genes (nodes) are conditionally independent given the rest of the genes iff there is no direct edge between them. The conditional independence (Markov) properties permit a rich set of dependencies among the nodes and hence, the connectivity of a Markov network can reveal complex relationships between its nodes (<ref type="bibr" target="#b1">Allen and Liu, 2013;</ref><ref type="bibr" target="#b13">Jalali et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Exponential family</head><p>The probability distributions that we study in this article are specific examples of a broad class of distributions called the exponential family (<ref type="bibr" target="#b7">Duda and Hart, 1973</ref>). Members of the exponential family have many important properties in common. Given parameters h, the exponential family of distributions over X is defined to be the set of distributions of the form:</p><p>P√∞X√û ¬º exp√∞hB√∞X√û √æ C√∞X√û √Ä D√∞h√û√û;</p><formula>(1)</formula><p>where B(X) are sufficient statistics, C(X) is a base measure and D√∞h√û is a log-normalization constant (<ref type="bibr" target="#b24">Murphy, 2012</ref>). The exponential family includes many widely used distributions, such as Bernoulli, binomial, Poisson, gamma, multinomial and Gaussian distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Parameterization of Markov networks</head><p>Let X ¬º √∞X 1 ; X 2 ;. .. ; X p √û be a random vector with X i being a random variable. Suppose G ¬º √∞V; E√û is an undirected graph with p nodes representing p variables in X, jVj ¬º p. Then the corresponding undirected graphical model is any distribution defined on X that satisfies Markov independence assumptions with respect to graph G (<ref type="bibr" target="#b24">Murphy, 2012</ref>). By the Hammersley-Clifford theorem (<ref type="bibr" target="#b24">Murphy, 2012</ref>), any such distribution of X decomposes according to graph G in the following way. Let C be a set of maximal cliques (fully connected subgraphs) in graph G and let f/ c √∞X c √û; c 2 Cg be " clique potential " functions. By the Hammersley-Clifford theorem, any distribution of X within the graphical model family defined by G can be represented as an exponential of a weighted sum of potential functions over the maximal cliques C:</p><formula>P√∞X√û / exp X c2C h c / c X c √∞ √û ! ; (2)</formula><p>where fh c ; c 2 Cg are the weights of potential functions. An important question is how one would select potential functions f/ c ; c 2 Cg to obtain various multivariate extensions of univariate distributions. Recently,<ref type="bibr" target="#b43">Yang et al. (2012)</ref>showed that if a node-conditional univariate distribution, i.e. distribution of a random variable conditioned on all other variables, belongs to an exponential family, it necessarily follows that the joint distribution of X has the form:</p><formula>P√∞X√û / exp√∞ X s2V h s B√∞X s √û √æ X s2V X t2N √∞s√û h st B√∞X s √ûB√∞X t √û √æ X s2V X t2; ... ;t k 2N √∞s√û h s;t2; ... ;t k B√∞X s √û Y k j¬º2 B√∞X tj √û √æ X s2V C√∞X s √û√û; (3)</formula><p>where the cliques are of size at most k, N s √∞ √û are neighbors of node s, B represent sufficient statistics and C is the base measure of the a given exponential family distribution (cf. Proposition 1 and Proposition 2 in<ref type="bibr" target="#b43">Yang et al. (2012)</ref>). These results tell us that the joint distribution specified in Eq. (3) has the most general form under the assumption of exponential family node-conditional distributions. Hence, learning a graphical model from the data can be reduced to learning weights fh s g [ fh st g [. .. [ fh s;t2; ... ;t k g of distribution-specific sufficient statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problem definition</head><p>Suppose we are given a collection D of n observations, D ¬º fx √∞1√û ; x √∞2√û ;. .. ; x √∞n√û g, where x √∞i√û is a p-dimensional vector drawn i.i.d. from a specific distribution of the form in Equation (3). This distribution has parameters fh √É c ; c 2 Cg and is associated with a graph G ¬º √∞V; E √É √û on p nodes. Graph G encodes Markov i232 M. Z itnik and B.Zupan independence properties between the respective variables. The goal of learning the structure of G is to infer an edge set E √É that corresponds to distribution, which generated observations in D.Hence, learning the network structure reduces to the problem of estimating weights f ^ h c ; c 2 Cg that should be as close as possible to the true but otherwise unknown parameters fh √É c ; c 2 Cg. In this article, we focus largely on a special case of pairwise Markov networks, where the joint distribution has cliques of size at most two:</p><formula>P X √∞ √û / exp √∞ X s2V h √É</formula><formula>(4)</formula><p>with entries h √É st 6 ¬º 0 if t 2 N √∞s√û and h √É st ¬º 0 if t 6 2 N √∞s√û.</p><formula>^ E ¬º [</formula><p>s2V;t2 ^ N √∞s√û f√∞s; t√ûg;</p><formula>(5)</formula><p>where (s, t) denotes an edge between s and t and ^ N √∞s√û ¬º ft 2 Vnfsg : ^ h st 6 ¬º 0g is the estimated neighborhood of node s. In the remainder of this section, we formulate two pairwise Markov networks, which assume either Poisson or multinomial data distribution. These two exponential family models are taken as an example through which we specify a general scheme for network inference from multiple potentially nonidentical data distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Poisson model specification</head><p>Following the work of<ref type="bibr" target="#b43">Yang et al. (2012)</ref>and Allen and Liu (2013), we define a Poisson Markov network model by specifying a distribution where all node-conditional distributions follow a univariate Poisson distribution. Our Poisson Markov network model is then a series of locally defined models, one for every variable (node). A local model for s is given by a distribution of X s conditioned on all other variables:</p><formula>P√∞X s jX Vns √û $ Poisson √∞exp fu s √æ X t2Vnfsg u T s W T Wu t X t g√û; (6)</formula><p>where X Vns ¬º fX t jt 2 Vnfsgg denotes the rest of the variables, and u s 2 R r and W 2 R r√Çr are model parameters. An r-dimensional vector u s is a latent factor for node s that consists of r latent components. For now, we assume that the number of latent components r is given; we will later discuss how to automatically determine r. Notice that the latent factor of node s, u s , represents the strength of membership of node s to r latent components and W models the interactions between all combinations of r latent components. The formulation of the Poisson conditional distribution in Equation (6) ensures that node pair-wise weights are symmetric, which is an appealing property when studying undirected graphical models. In particular, the contribution of X t towards P√∞X s jX Vns √û is the same as is the contribution of X s towards P√∞X t jX Vnt √û. We refer to our model as a model parameterized via latent factorization, since model parameters u s ; u t and W form a factorization of the edge weight h st , which is specified by a Markov network model in Equation (4). The importance of latent factor parameterization will be obvious later in Section 3.7 when we discuss collective network inference from many datasets. Recall the univariate Poisson distribution is given by the mass function P√∞X ¬º x√û ¬º k x exp √∞√Äk√û=x!, where k is the shape parameter. Our model extends the univariate Poisson in a natural and strict sense to the multivariate graphical model setting. The latter can be obtained from the univariate Poisson by setting the shape parameter to k ¬º exp √∞u s √æ P t2Vns u T s W T Wu t X t √û. We then write the expression in Equation (6) as:</p><formula>P√∞X s jX Vns √û ¬º expfu s X s √Ä log√∞X s !√û √æ X t2Vnfsg √∞u T s W T Wu t X s X t √Äexp√∞u s √æ u T s W T Wu t X t √û√ûg (7)</formula><p>Intuitively, variable X s in Equation (7) can be viewed as the response variable in a latent factor Poisson regression in which the other variables X Vns play the role of the predictors. Variables with strong relationships with gene s will have nonzero regression coefficients, and these will be connected to node s in the inferred graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Optimization of the Poisson model</head><p>The node-conditional distributions specified in Equation (7) define a global distribution that factors according to the cliques of the underlying graph G that we would like to estimate. We obtain edge set ^ E by stitching node neighborhoods as prescribed by</p><p>Equation (5), where we define the neighborhood of node s as ^ N √∞s√û ¬º ft 2 Vnfsg : u T s W T Wu t 6 ¬º 0g. This means that edge (s, t) is included in the network if the estimated product of respective latent factors of variables X s and X t is nonzero. To estimate edge set ^ E, we have to determine the node neighborhoods of all nodes in V. To achieve this goal, we solve a sparsity constrained conditional maximum likelihood estimation problem:</p><formula>min U;W X s2V ' s √∞U; W; D√û √æ a√∞Reg√∞U√û √æ Reg√∞W√û√û: (8)</formula><p>Here, U is a matrix with node latent factors placed in the columns, U ¬º ¬Ωu 1 ; u 2 ;. .. ; u n ¬ä. Equation (8) consists of two parts, which we discuss next. Terms involving Reg represent the elastic net penalties (<ref type="bibr" target="#b44">Zou and Hastie, 2005</ref>). The penalty is defined for U as Reg√∞U√û ¬º √∞1 √Ä k√û 1 2 jjUjj 2 2;1 √æ kjjUjj 1;1 , where k!0 is a regularization parameter controlling the amount of sparsity in the node neighborhood. The definition of the penalty term for W is analogous. Notice that the L 2;1 norm is the sum of 2-norms of the columns, jjUjj 2;1 ¬º P p s¬º1 jju s jj 2 2 , and the L 1;1 norm is the sum of 1-norms of the columns, jjUjj 1;1 ¬º P p s¬º1 jju s jj 1. Since latent factors are affected by the strength of regularization, the choice of parameter k is important. Procedure for selection of k is described in Supplementary Section 1. The crucial part of Equation (8) is, however, the sum of the node-wise Poisson likelihood functions. Given node s and n realizations of the associated random variable X s , the Poisson likelihood function ' s follows directly from Equation (7) and can be written as:</p><formula>' s √∞U; W; D√û ¬º √Ä 1 n log Y n i¬º1 P√∞X s ¬º x √∞i√û s jX Vns ¬º X √∞i√û ns √û ¬º √Ä 1 n X n i¬º1 √∞x √∞i√û s X √∞i√û ns U T ns W T Wu s √Äexp√∞X √∞i√û ns U T ns W T W√û√û;</formula><formula>(9)</formula><p>where x √∞i√û s is the i-th realization of X s in data D; X √∞i√û ns denotes the i-th realization of the rest of the variables X Vns , and U and W are matrix</p><p>Gene network inference by fusing data from diverse distributions i233 unknowns. Notice that node-wise terms are ignored here for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Multinomial model specification and optimization</head><p>We now develop a multinomial Markov network model that relies on latent factor parameterization of the model parameters and follows the same paradigm as our Poisson model described in the previous section. The multinomial model presented here is a natural extension of the multinomial graphical model described by<ref type="bibr" target="#b13">Jalali et al. (2011)</ref>. We start with the neighborhood recovery of one fixed node s and then combine the neighborhood sets across nodes to estimate the network. The multinomial model assumes that each variable X i from a random vector X follows a multinomial distribution with potentially different parameters. This means that X i can take any value from a small discrete set f1; 2;. .. ; mg of cardinality m. Probabilities of different values are not independent so that, given any m ‚Äì 1 of the probabilities, the probability of the remaining value is fixed. It is convenient to express the distribution in terms of only m ‚Äì 1 values, thereby leaving m ‚Äì 1 probability parameters that need to be estimated. The distribution of X s conditioned on other variables X Vns ¬º fX t : t 2 Vnfsgg is given by:</p><formula>P√∞X s ¬º jjX Vns √û ¬º exp√∞h sj √æ X t2Vnfsg X k h st;jk I k √∞X t √û√û 1 √æ X l exp √∞h sl √æ X t2Vnfsg X k h st;lk I k √∞X t √û√û (10)</formula><p>for all j 2 f1; 2;. .. m √Ä 1g. Here, h sj represents a node-wise term that models the probability of variable X s taking value j. The other model parameter is h st;jk , which models dependency between variable X s and variable X t when they take values j and k, respectively. We can view Equation (10) as a multiclass logistic (softmax) regression, where X s is the response variable and indicator functions associated with other variables:where I k √∞X t √û ¬º 1 if X t ¬º k else 0, are the predictors. We now proceed by writing model parameters h sj and h st;jk in the form of a product of latent factors. We gather node-wise terms h sj into a matrix Q 2 R p√Ç√∞m√Ä1√û. We factorize h st;jk as h st;jk ¬º u T s Q sj W T WQ tk u t. Here, u s and u t are r-dimensional latent factors and W 2 R r√Çr encodes interactions between latent components in the same way as is described inwhere definitions of U, W and Reg are the same is in the previous section. Here, the node-wise multinomial likelihood function ' s for node s follows from Equation (10) and can be written as:</p><formula>' s √∞U; Q; W; D√û ¬º √Ä 1 n log Y n i¬º1 P√∞X s ¬º x √∞i√û s jX Vns ¬º X √∞i√û ns √û ¬º √Ä 1 n X n i¬º1 √∞Q sx √∞i√û s √æ X t2Vnfsg X k u T s Q sx √∞i√û s W T WQ tk u t I k √∞x √∞i√û t √û√Ä log √∞1 √æ X l exp √∞Q sl √æ X t2Vnfsg X k u T s Q sl W T WQ tk u t I k √∞x √∞i√û t √û√û√û√û;</formula><formula>(12)</formula><p>where x √∞i√û s 2 f1; 2;. .. ; m √Ä 1g is the i-th realization of X s in data D; X √∞i√û ns denotes the i-th realization of the rest of the variables X Vns , and U, Q and W are matrix unknowns. Given latent factor estimates U and W, and the estimate of node-wise terms Q, we determine the neighborhood for node s as ^ N √∞s√û ¬º ft 2 Vnfsg : X j;k u T s Q sj W T WQ tk u t 6 ¬º 0g. This means that edge (s, t) is included in the network if product u T s Q sj W T WQ tk u t does not vanish over at least one choice of categories j and k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Other exponential family distributions</head><p>So far, we described in Section 3.3‚Äì3.5, the Poisson model and the multinomial model that are suitable for separately inferring the edge set of a Poisson or a multinomial Markov network. In this section, we would like to allude to the fact that a procedure with derivations very similar to those in the above sections can be applied to any exponential family distribution. From Equation (1), we see that the unnormalized probability of an exponential family distribution can be expressed as an exponential of a weighted linear combination of sufficient statistics. These sufficient statistics correspond to clique potential functions (see Sec. 3.1.3). Under the assumption of joint distribution having cliques of size at most two, node-conditional distributions take the form:where fh s ; s 2 Vg and fh st ; s; t 2 Vg are parameters that shall be estimated from the data. FUSENET yields a general framework for including data from any exponential family distribution, such as Gaussian, binomial, Poisson or multinomial distributions, in its predictive model by simply expressing weights fh s ; s 2 Vg and fh st ; s; t 2 Vg of a given distribution as products of appropriately selected latent factors. Here, factorization of the weights is appropriate if it allows fusion of data from diverse distributions, such that factorization consists of both latent factors that are shared between different distributions and factors that are specific to a particular distribution (<ref type="bibr" target="#b37">Zitnik and Zupan, 2015</ref>), a property that we describe in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Collective inference of a gene network</head><p>We proceed by formulating a collective network inference model, wherein a network is jointly estimated from multiple nonidentical data distributions. Let D x ¬º fx √∞1√û ; x √∞2√û ;. .. ; x √∞nx√û g be a set of n x observations of a random vector X, where each p-dimensional vector x √∞i√û is drawn from a distribution P x of the form of Equation (4) and let D y ¬º fy √∞1√û ; y √∞2√û ;. .. ; y √∞ny√û g be a set of n y observations where each p-dimensional vector y √∞i√û is drawn from distribution P y of the form of Equation (4). Importantly, distributions P x and P y are not necessarily identical in terms of their parameters or distribution type. For example, P x might denote the Poisson distribution and P y might be the multinomial distribution or they could both describe multinomial distributions that have different parameters. For simplicity of notation we provide here the formulation for the case with only two datasets, D x and D y , but notice that our analysis generalizes to any number of datasets. In collective network inference, we solve for:<ref type="bibr">2015</ref>). As is evident from Equation (13), the latent factor of node s, u s , participates both in terms associated with P x and terms related to P y. Hence, a good estimate of u s should simultaneously minimize both ' s;Px and ' s;Py , but should do so in a way that statistics internal to both data distributions are considered. To account for the fact that datasets may disagree and differ in how accurately they capture biological signals, FUSENET has parameters that are specific to every distribution. In particular, we allow that interactions between latent components in D x are different from those in D y and hence, the model has one latent matrix W for each distribution. An additional parameter Q captures the characteristics of a particular exponential family distribution, e.g., the bias associated with m categories in the multinomial distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Learning the models in practice</head><p>Now that we defined the FUSENET model, we explain how to solve related optimization problems. Notice that the exact optimization problem one needs to solve depends on a particular data setting, i.e. a particular combination of considered exponential family distributions. There has been a strong line of work on developing fast algorithms to solve sparse regression problems that are similar to Equations (8) and (11) including the work by<ref type="bibr" target="#b16">Krishnapuram et al. (2005</ref><ref type="bibr" target="#b20">), Meier et al. (2008</ref><ref type="bibr" target="#b13">), Jalali et al. (2011</ref>and Allen and Liu (2013). Existing algorithms for undirected graphical model selection assume that model parameters are independent of each other. This, however, is not true in FUSENET due to reasons discussed in Section 3.7 that are important to achieve data fusion. Consequently, this also means that we cannot use off-the-shelf optimization solvers. We propose to fit our FUSENET by computing cyclical coordinate descent along the path of regularization parameter k (see Supplementary Section 1). Parameters of FUSENET inference algorithm, i.e. regularization and latent dimensionality, are selected in data-dependent way via stability selection. Interested reader is referred to Supplementary Section 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental setup</head><p>We compare the performance of FUSENET to several state-of-the-art Markov network models in estimating the true underlying network structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance evaluation</head><p>The success of network recovery is evaluated by comparison to the gold standard networks, when they are available, and by functional enrichment of the inferred networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Assessing the accuracy of network recovery</head><p>Simulated data come with complete and unambiguous true underlying networks, hence we can assess the performance of the algorithms as follows. We report receiver operator curves (ROC) computed by varying the regularization parameter k, precision recall (PR) curves, and true and false positive rates for fixed k as estimated via stability selection. The true positive rate is estimated as proportion of the edges found by a network inference algorithm that are also in the true network. The false positive rate represents proportion of the edges in the inferred network that are not present in the true network. An algorithm with a perfect performance achieves an area under the ROC curve of 1, precision of 1 and recall of 1, a true positive rate of 1 and a false positive rate of 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Quantifying the functional content of inferred networks</head><p>We employ two approaches to evaluate the 'functional correctness' of the networks inferred from cancer data. First, we use SANTA (<ref type="bibr" target="#b5">Cornish and Markowetz, 2014</ref>) to quantify the strength of association between sets of functionally related genes from the Gene Ontology (GO) (<ref type="bibr" target="#b3">Ashburner et al., 2000</ref>) and the inferred network. Second, we overlay the inferred network with gene information from the GO and for every GO term assess how community-like a subnetwork of genes that belong to a particular GO term is. Communities are sets of genes with many connections between the members and few connections to the rest of the network. Four different structural notions of network communities exist in networks and we report the values of their representative scoring functions (<ref type="bibr" target="#b43">Yang and Leskovec, 2012</ref>). We refer the reader to Supplementary Section 4 for mathematical details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Considered gene network inference algorithms</head><p>In the experiments, we consider the Poisson FUSENET (Section 3.3), the multinomial FUSENET (Section 3.5) and FUSENET with fusion of Poisson and multinomial data distributions (Section 3.7). We compare our models to the Graphical Lasso (GLASSO) (<ref type="bibr" target="#b8">Friedman et al., 2007</ref>), which is a widely used Markov network model based on a Gaussian assumption. To see how FUSENET relates to techniques that perform data preprocessing, we consider the GLASSO after applying a log transform to the data plus one (e.g. cf.<ref type="bibr" target="#b10">Gallopin et al., 2013</ref>) and the GLASSO with the nonparanormal Gaussian copula transformation (NPN-Copula) (<ref type="bibr" target="#b18">Liu et al., 2009</ref>). We also compare FUSENET with two Markov network models that are designed for non-Gaussian distributed data: the Local Poisson Graphical Model (LPGM) (<ref type="bibr" target="#b1">Allen and Liu, 2013</ref>), and the Multinomial Markov Network Model (Mult-GM) (<ref type="bibr" target="#b13">Jalali et al., 2011</ref>). The crucial parameter of these methods is degree of regularization, which controls sparsity of the networks. We select the value for regularization via stability selection (see Supplementary Section 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Data</head><p>Network inference algorithms are evaluated based on simulated data and large-scale cancer genomic datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Multivariate data simulation</head><p>Four network structures are simulated: (i) the Erdo ‚Ä†s R√©nyi random network, where an edge between each pair of nodes is set with equal probability and independently of other edges; (ii) a hub network, where each node is connected to one of three hub nodes; (iii) a scalefree network, in which node degree distribution follows a powerlaw; and (iv) a small-world network, in which most nodes are not Gene network inference by fusing data from diverse distributions i235 neighbors of each other but most nodes can be reached from every other by a small number of hops. We refer the reader to Supplementary Section 2 for detailed description of the procedures used for data simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cancer genomic data</head><p>We apply network inference algorithms to two examples of nonGaussian high-throughput genomic data to learn (i) an mRNA expression network, (ii) a somatic mutation network and (iii) a collectively inferred gene network based on both data types. We download breast cancer (BRCA-US) gene expression data measured by next generation sequencing and breast cancer (BRCAUS) simple somatic mutation data from the International Cancer Genome Consortium (ICGC) (<ref type="bibr" target="#b11">Hudson et al., 2010</ref>) portal (release 17). We follow the steps in Allen and Liu (2013) and process RNAsequencing data to be approximately Poisson. Data preprocessing, whose detailed steps are described in Supplementary Section 3, results in a matrix with rows as the subjects (n exp ¬º 1; 012) and columns as genes (p exp ¬º 657). These genes form the nodes of our Poisson breast cancer mRNA network. Breast cancer simple somatic mutation data include single base substitutions, multiple base substitutions and short indels. Mutation data are converted into a matrix with rows as subjects (n mut ¬º 954) and columns as genes containing mutations or variations (500 genes). Each matrix entry is categorized into one of three groups based on the type of mutation: no mutation, single base substitution, insertion/deletion of &lt; 200 base pairs. For the collectively inferred network, we consider both gene expression profiles and somatic mutation data provided by the ICGC assuming the Poisson model for the RNA-seq data and the multinomial model for the mutation data. We refer the reader to Supplementary Section 3 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Network recovery with simulated data</head><p>In every simulation, we generated a dataset of observations based on a simulated network and then applied different network inference algorithms to determine whether the algorithms successfully recovered complex relationships between data variables. We simulated four network types, which are known to resemble the structure of real biological networks (<ref type="bibr" target="#b1">Allen and Liu, 2013;</ref><ref type="bibr" target="#b6">Costanzo et al., 2010</ref>). We report receiver operator curves computed by varying the regularization parameter k in<ref type="figure" target="#fig_3">Figure 3</ref>and Supplementary<ref type="figure">Figure S4</ref>, boxplots of true and false positive rates for fixed k as determined by stability selection in<ref type="figure" target="#fig_3">Figure 3</ref>, Supplementary Figures S2 and S4. Further, we evaluated precision and recall of the networks estimated from different data distributions in Supplementary Figures S2‚ÄìS5. Experimental evidence indicates that FUSENET outperforms Gaussian-based competitors (GLASSO, Log-GLASSO and NPNCopula) as well as existing methods that are designed specifically for the Poisson and the multinomial data (LPGM in<ref type="figure">Fig. 2</ref>and MultGM in<ref type="figure" target="#fig_3">Fig. 3</ref>). The overall good performance of FUSENET is consistent across the four types of network structure and the two data distributions that we considered in experiments. The improved statistical power of FUSENET and LPGM over methods that during network inference rely heavily on the assumption of normality is particularly impressive. Results in<ref type="figure" target="#fig_3">Figure 3</ref>suggest that in situations where this assumption is not satisfied, we can expect reduced prediction performance if we naively apply Gaussian-based methods, (GLASSO) or if we perform insufficient data preprocessing (Log-GLASSO). However, we note that sophisticated techniques that replace Gaussian distributed data by the transformed data obtained, e.g. through a semiparametric Gaussian copula (NPNCopula;<ref type="bibr" target="#b18">Liu et al. (2009)</ref>), can give substantial gains in accuracy over the naive analysis. These observations are not surprising as disregarding information about data distribution can adversely affect performance of prediction models. Our results demonstrate that employing the 'correct' statistical model, in this case FUSENET or LPGM, can lead to more accurate network inference. Next, we try to understand which algorithmic component of FUSENET contributes most to its good performance relative to existing algorithms for network structure learning. The primary difference between FUSENET and non-Gaussian-based methods considered here, LPGM and Mult-GM, is representation of model parameters with products of latent factors. In LPGM and similarly in Mult-GM, a prediction model is fitted locally by an algorithm, which performs a series of independent penalized regressions. This is in contrast with FUSENET, where different model parameters are not entirely independent of each other but rather rely on borrowing strength from each other via factorization. Our results on simulated data suggest that representation of model parameters through the use of latent factors is beneficial. Furthermore, latent parameterization can improve performance of network recovery beyond what is possible with models that do not use latent factors. On the downside, we note that due to coupling of model parameters, FUSENET is not trivially parallelizable, which is otherwise true for LPGM and Mult-GM. Results shown in Figures 2 and 3 are reported for datasets with a few hundred observations (n) and a few tens of variables (p; see figure captions). We note that reported results are consistent with experiments done in various high-dimensional scenarios even when the number of variables is greater than the number of observations (p &gt; n). Results therein reveal the same trend, namely, the overall strong performance of FUSENET in recovering true networks from non-Gaussian data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Functional content of genomic networks</head><p>An important challenge in cancer systems biology is to uncover complex dependencies between genes implicated in cancer. Since our knowledge about genome-scale gene networks is incomplete and only a few functional modules are known for higher organisms (<ref type="bibr" target="#b28">Rolland et al., 2014</ref>), our aim is to quantify associations between<ref type="figure">Fig. 2</ref>. Application of gene network inference algorithms to multinomialdistributed simulated data. Simulation studies on four network types were performed: random (see Supplementary<ref type="figure">Fig. S2</ref>), hub, scale-free and small world. For each graph type, we generated n ¬º 300 observations at a high signal-to-noise ratio (SNR) with P ¬º 50 variables (nodes) taking values from an alphabet of size m ¬º 3. Boxplots are shown for multinomial FUSENET (proposed here) and the multinomial graphical model (Mult-GM) (<ref type="bibr" target="#b13">Jalali et al., 2011)</ref>i236 M. Z itnik and B.Zupan the inferred gene networks and known cellular functions and phenotypes, and to assess the significance of these associations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Comparison of FUSENET variants with existing methods</head><p>To characterize how functionally informative the inferred networks are, we employ four structural definitions of network communities (<ref type="figure">Fig. 4</ref>and Supplementary Figs S6 and S7). These represent four possible notions of association between a given GO term and the inferred network (<ref type="bibr" target="#b43">Yang and Leskovec, 2012</ref>). The triangle participation ratio quantifies how well genes that are members of a given GO term are linked to each other in the inferred network. The cut ratio captures the abundance of external connectivity, i.e. edges between genes of a GO term and the rest of the network, whereas conductance and flake-ODF consider both internal and external network connectivity. Through these four measures we are able to estimate the overall concordance of inferred gene networks and known functional annotation of genes. For these reasons, networks that score higher on many measures should be considered more informative across a wider spectrum of cellular functions.<ref type="figure">Figure 4</ref>shows that gene network inferred by FUSENET through fusion of breast cancer RNA-sequencing data and somatic mutation data is more concordant with functional annotation data in the GO than are networks inferred by FUSENET from either RNA-sequencing or somatic mutation data alone. We note that we used Poisson FUSENET to infer network from RNA-sequencing data, multinomial FUSENET to infer network from somatic mutation data and collective FUSENET for joint network inference from RNA-sequencing and mutation data. These results demonstrate that combining data through the use of latent factors can perform better than independent modeling of each dataset alone. For each of the four community scoring measures in<ref type="figure">Figure 4</ref>, we compared score distributions of GO terms across three networks inferred by FUSENET using Kolmogorov-Smirnov tests. We concluded that the network inferred by FUSENET through fusion of RNAsequencing and mutation data associates with GO significantly more strongly than the other two networks (P value &lt; 1 √Ç 10 √Ä5 on all four measures from<ref type="figure">Fig. 4</ref>). This experiment shows how cancer genomic data provide different levels of information about cellular machinery, highlighting that it is possible to infer a network that better explains the mechanisms of cancer by combining multiple datasets in a principled statistical way. We further compared FUSENET to existing network inference methods on cancer data. The comparison was made only with LPGM, as this was the best performing method in our study on simulated data (Section 6.1) and in the cancer-data study of Allen and Liu (2013). Supplementary<ref type="figure">Figure S6</ref>shows the functional content of the networks inferred from RNA-sequencing data by either Poisson FUSENET or LPGM. On a related note, Supplementary<ref type="figure">Figure S7</ref><ref type="figure">Fig. S4</ref>), hub, scale-free and small world. These graph structures appear in many real biological networks. For each graph type, we generated data with n ¬º 200 observations with P ¬º 100 variables (nodes) at a low (first row) and high (second row) signal-to-noise ratio (SNR). Receiver operating curves and boxplots are shown for Poisson FUSENET (proposed here), the Local Poisson Graphical Model (LPGM) (<ref type="bibr" target="#b1">Allen and Liu, 2013</ref>), the Graphical Lasso (GLASSO) (<ref type="bibr" target="#b8">Friedman et al., 2007</ref>), the GLASSO on log-transformed data (<ref type="bibr">Log</ref><ref type="figure">Fig. 4</ref>. The strength of association between gene sets from the Gene Ontology (GO) and networks inferred with FUSENET. Inferred networks were overlaid with GO terms and subnetworks induced by each GO term were assessed for how well they corresponded to network communities. Four different scoring functions were used to quantify the presence of different structural notions of communities (Supplementary Section S4) that can appear in biological networks: flake-over-median-degree (flake-ODF), cut ratio, triangle participation ratio (TPR) and conductance. Considering breast cancer RNAsequencing (RNA-seq) and somatic mutation data (Mut), these boxplots show the gains that fusion of data from different distributions (Mut &amp; RNA-seq) can offer over network inference from any dataset alone, either RNA-seq or Mut. Poisson FUSENET was used with RNA-sequencing data, multinomial FUSENET with somatic mutation data and fully-specified FUSENET for joint consideration of RNA-sequencing and mutation data</p><p>Gene network inference by fusing data from diverse distributions i237</p><p>shows enrichment of the networks inferred from somatic mutation data by either multinomial FUSENET or Mult-GM. Notice that LPGM and Mult-GM were designed for data that are approximately Poisson distributed, such as measurements from RNA-sequencing, and multinomially distributed, such as various types of gene variations, respectively. These results demonstrate that networks inferred by FUSENET can better capture known GO annotations than networks obtained by methods such as LPGM and Mult-GM, whose prediction models do not have factorized representation. These observations are consistent across four complementary structural definitions of GO terms, where every GO term is viewed as a network community defined by its member genes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Networks via breast cancer data</head><p>We employ SANTA (<ref type="bibr" target="#b5">Cornish and Markowetz, 2014</ref>) to quantify the functional content of gene networks. SANTA extends the concept of gene set enrichment analysis to networks. We observed that GO terms indeed cluster more strongly on Poisson FUSENET's networks than on networks inferred by GLASSO and Log-GLASSO (P value &lt; 1 √Ç 10 √Ä6 , RNA-seq network), NPN-Copula (P value &lt; 1 √Ç 10 √Ä5 , RNA-seq network) and LPGM (P value &lt; 1 √Ç 10 √Ä4 , RNA-seq network). These results suggest that network edges inferred by FUSENET might represent more accurate indication of shared cellular functions than edges inferred by other considered methods. This effect was independent of the GO term size and was strongest for specific cellular functions such as 'centrosome cycle' (P value &lt; 1 √Ç 10 √Ä9 ), 'cellular response to DNA damage stimulus' (P value &lt; 1 √Ç 10 √Ä9 ), 'apoptotic process' (P value &lt; 1 √Ç 10 √Ä9 ) and 'regulation of cytokinesis' (P value &lt; 1 √Ç 10 √Ä8 ). We observed similar results when inferring networks from somatic mutation data. Gene network inferred by multinomial FUSENET was functionally richer than network inferred by Mult-GM. Here, the functional content of a network was quantified with SANTA as proportion of evaluated GO terms whose association strength with the network had P value &lt; 1 √Ç 10 √Ä5. Interactions that are captured by fusing both cancer related datasets recovered many gene‚Äìgene associations that have been previously linked to increased breast cancer predisposition and metastasis. For example, FUSENET revealed a hypothesized transcriptional regulatory GATA3 module (<ref type="bibr" target="#b39">Wang et al., 2014</ref>) consisting of fully connected GATA3, PTCH1, NFIB and PPARA. GATA3 is an important transcriptional regulator in breast cancer (<ref type="bibr" target="#b33">Theodorou et al., 2013</ref>), and low expression levels of GATA3 are associated with a poor prognosis (<ref type="bibr" target="#b0">Albergaria et al., 2009</ref>). It has been shown by<ref type="bibr" target="#b39">Wang et al. (2014)</ref>that PTCH1, PPARA and NFIB exhibit epistatic interactions with GATA3, have negatively correlated expression levels with GATA3 and that GATA3 binds to gene regions near NFIB, PTCH1 and PPARA in breast epithelial tumor cell line. Other interactions identified in our network include ATM and BRCA1, ATM and BRCA2, and CHEK2 and BRCA2, which are known gene-gene interactions whose mutations affect breast cancer susceptibility (<ref type="bibr" target="#b34">Turnbull et al., 2012</ref>). Another transcriptional module that was found by FUSENET consists of FLI1, JAK2 and CCND2. This module has been only recently associated with breast cancer patient outcome (<ref type="bibr" target="#b39">Wang et al., 2014</ref>). Interestingly, FLI1 module has been captured by FUSENET when fusing RNA-sequencing and mutation data but has been missed when using FUSENET with any of the two cancer datasets in isolation, as well as by any other inference algorithm considered in this study. One possible explanation for the latter result might be observations made by<ref type="bibr">Wang et al. (2014). Wang et al. examined</ref>The Cancer Genome Atlas breast cancer patient survival data and found that low expression or mutation in one or more members of the FLI1 module is associated with reduced overall survival time in all patients. The illustrative example of FLI1 module highlights an advantage of FUSENET over methods considering a single dataset during network inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>FUSENET is an approach for automatic inference of gene networks from data arising from potentially many nonidentical distributions. It is based on the theory of Markov networks, where the inferred network edges denote a type of direct dependence that is stronger than merely correlated measurements. An appealing property of FUSENET is its ability to estimate network edges by fusing potentially many datasets. In the case studies, FUSENET's models outperform several state-of-the-art undirected graphical models. We show that FUSENET's high performance is attributed to the ability to model nonGaussian distributions and fusion of data through sharing of latent representations. Our work here has broadened the class of off-theshelf network inference algorithms for simultaneously considering a wide range of parametric distributions and has combined Markov network inference with data fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was supported by ARRS (P2-0209, J2-5480), EU FP7 (Health-F52010-242038) and NIH (P01-HD39691).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Following the work of Ravikumar et al. (2010), Jalali et al. (2011) and Allen and Liu (2013), we approach the problem of Markov network structure learning via neighborhood estimation, where we obtain the global network estimate ^ E by stitching together the estimated neighborhoods of the nodes. The overall network structure is then:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>'</head><figDesc>Section 3.3. To estimate the latent factors and node-wise terms from the data we solve the following convex optimization program:s √∞U; Q; W; D√û √æ a√∞ Reg √∞U√û √æ Reg √∞Q√û √æ Reg √∞W√û√û; (11)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Application of gene network inference algorithms to Poisson-distributed simulated data. Simulation studies on four network types were performed: random (see Supplementary Fig. S4), hub, scale-free and small world. These graph structures appear in many real biological networks. For each graph type, we generated data with n ¬º 200 observations with P ¬º 100 variables (nodes) at a low (first row) and high (second row) signal-to-noise ratio (SNR). Receiver operating curves and boxplots are shown for Poisson FUSENET (proposed here), the Local Poisson Graphical Model (LPGM) (Allen and Liu, 2013), the Graphical Lasso (GLASSO) (Friedman et al., 2007), the GLASSO on log-transformed data (Log-GLASSO) (e.g. cf. Gallopin et al., 2013) and the GLASSO on data transformed through nonparanormal Gaussian copula (NPN-Copula) (Liu et al., 2009)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Fig. 3. Application of gene network inference algorithms to Poisson-distributed simulated data. Simulation studies on four network types were performed: random (see Supplementary Fig. S4), hub, scale-free and small world. These graph structures appear in many real biological networks. For each graph type, we generated data with n ¬º 200 observations with P ¬º 100 variables (nodes) at a low (first row) and high (second row) signal-to-noise ratio (SNR). Receiver operating curves and boxplots are shown for Poisson FUSENET (proposed here), the Local Poisson Graphical Model (LPGM) (Allen and Liu, 2013), the Graphical Lasso (GLASSO) (Friedman et al., 2007), the GLASSO on log-transformed data (Log-GLASSO) (e.g. cf. Gallopin et al., 2013) and the GLASSO on data transformed through nonparanormal Gaussian copula (NPN-Copula) (Liu et al., 2009)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2015. Published by Oxford University Press.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>P√∞X s jX Vns √û / exp√∞h s B√∞X s √û √æ X t2N √∞s√û h st B√∞X s √ûB√∞X t √û √æ C√∞X s √û√û</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>is important to notice the coupling of the parameters in FUSENET through which data fusion is achieved ( Zitnik and Zupan,</figDesc><table>min 

U;Q x ;Q y ; 
Wx ;Wy 

X 

s2V 

√∞' s;Px √∞U; Q x ; W x ; D x √û 

√æ' s;Py √∞U; Q y ; W y ; D y √û√û √æ reg: param:; 

(13) 

where regularization parameters depend on the form of data distri-
butions. In a specific scenario in which P x and P y are the Poisson 
and the multinomial distributions, respectively, we set Q x ¬º I. 

i234 
M. 
Z itnik and B.Zupan We specify the regularization according to the Poisson model in 
Equation (8) and the multinomial model in Equation (11) as: 

k√∞ Reg √∞U√û √æ Reg √∞W x √û √æ Reg √∞Q y √û √æ Reg √∞W y √û√û; 

where Reg is the elastic net penalty defined in Section 3.3. The esti-
mated neighborhood of node s, which corresponds to a random vari-
able X s 2 X, are then nodes whose behavior depends on behavior of 
s according to any of considered data distributions, 
^ 
N ¬º ft 2 Vnfsg : ^ h st;Px 6 ¬º 0 
W ^ h st;Py 6 ¬º 0g. In our specific scenario, 

parameters ^ h st;Px and ^ h st;Py would be given by ^ h st;Px ¬º u T 
s W T Wu t 
and ^ h st;Py ¬º 
P 
j;k u T 
s Q sj W T WQ tk u t . 
It </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Expression of FOXA1 and GATA3 in breast cancer: the prognostic significance in hormone receptor-negative tumours</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Albergaria</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Breast Cancer Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A local poisson graphical model for inferring networks from sequencing data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">I</forename>
				<surname>Allen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. NanoBiosci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="189" to="198" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A boosting approach to structure learning of graphs with and without prior knowledge</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Anjum</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2929" to="2936" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Gene Ontology: tool for the unification of biology</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ashburner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Utilizing RNA-seq data for cancer network inference</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Cai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE</title>
		<editor>Pal,R. and Ressom,H.</editor>
		<meeting><address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="46" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">SANTA: quantifying the functional content of molecular networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Cornish</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Markowetz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1003808</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">The genetic landscape of a cell</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Costanzo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">327</biblScope>
			<biblScope unit="page" from="425" to="431" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Pattern Classification and Scene Analysis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">O</forename>
				<surname>Duda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">E</forename>
				<surname>Hart</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<publisher>Wiley</publisher>
			<pubPlace>New Jersey, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Sparse inverse covariance estimation with the lasso</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="432" to="441" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse inverse covariance estimation with the graphical lasso</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="432" to="441" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A hierarchical Poisson log-normal model for network inference from RNA sequencing data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gallopin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">77503</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">International network of cancer genome projects</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">J</forename>
				<surname>Hudson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">464</biblScope>
			<biblScope unit="page" from="993" to="998" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayesian network prior: network analysis of biological data using external knowledge</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Isci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="860" to="867" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">On learning discrete graphical models using groupsparse regularization</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Jalali</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS. MLR</title>
		<editor>Dud√≠k,M.</editor>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="378" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">GENIES: gene network inference engine based on supervised analysis</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kotera</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="162" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">Z</forename>
				<surname>Itnik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zupan</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Sparse multinomial logistic regression: fast algorithms and generalization bounds</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Krishnapuram</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="957" to="968" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">High-dimensional semiparametric Gaussian copula graphical models</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2293" to="2326" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">The nonparanormal: Semiparametric estimation of high dimensional undirected graphs</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2295" to="2328" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Wisdom of crowds for robust gene network inference</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Marbach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="796" to="804" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">The group lasso for logistic regression</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Meier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="53" to="71" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">High-dimensional graphs and variable selection with the lasso</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Meinshausen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>B√º Hlmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1436" to="1462" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A Markov random field model for term dependencies</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Metzler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">B</forename>
				<surname>Croft</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
		<editor>Marchionini,G. et al.</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Network inference using informative priors</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mukherjee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">P</forename>
				<surname>Speed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>. Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="14313" to="14318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title level="m" type="main">Machine Learning: a Probabilistic Perspective</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">P</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>MIT Press</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Bayesian Gaussian copula factor models for mixed data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Murray</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="656" to="665" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Pearl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Verma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on the Principles of Knowledge Representation and Reasoning</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="441" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">High-dimensional ising model selection using &apos; 1regularized logistic regression</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ravikumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1287" to="1319" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A proteome-scale map of the human interactome network</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Rolland</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="1212" to="1226" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">Gaussian Markov Random Fields: Theory and Applications</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Rue</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Held</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>CRC Press</publisher>
			<pubPlace>Abingdon, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">An empirical Bayes approach to inferring large-scale gene association networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sch√§fer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="754" to="764" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Discovering molecular pathways from protein interaction and gene expression data</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Segal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="264" to="272" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Variable selection for discriminant analysis with Markov random field priors for the analysis of microarray data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">C</forename>
				<surname>Stingo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Vannucci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="495" to="501" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">GATA3 acts upstream of FOXA1 in mediating ESR1 binding by shaping enhancer accessibility</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Theodorou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="12" to="22" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Gene-gene interactions in breast cancer susceptibility</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Turnbull</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Mol. Genet</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="958" to="962" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Discovering disease-disease associations by fusing systems-level molecular data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zitnik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3202</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Matrix factorization-based data fusion for drug-induced liver injury prediction</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zitnik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zupan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Biomed</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">28527</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Data fusion by matrix factorization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zitnik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zupan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="41" to="53" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Markov random field modeling, inference &amp; learning in computer vision &amp; image understanding: a survey</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="1610" to="1627" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Widespread genetic epistasis among cancer genes</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">4828</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">RNA-Seq: a revolutionary tool for transcriptomics</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="57" to="63" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<monogr>
		<title level="m" type="main">Graphical models via generalized linear models</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1358" to="1366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">On Poisson graphical models</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<editor>Welling,M. and Ghahramani,Z.</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1718" to="1726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Defining and evaluating network communities based on ground-truth</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Leskovec</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MDS</title>
		<editor>Tang,J. et al.</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<monogr>
		<title level="m" type="main">Gene network inference by fusing data from diverse distributions i239</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>