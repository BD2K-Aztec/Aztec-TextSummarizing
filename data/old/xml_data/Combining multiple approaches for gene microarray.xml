
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Combining multiple approaches for gene microarray classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Loris</forename>
								<surname>Nanni</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<addrLine>Via Gradenigo</addrLine>
									<postCode>6 – 35131</postCode>
									<settlement>Padova, Italy</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Sheryl</forename>
								<surname>Brahnam</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Information Systems</orgName>
								<orgName type="institution">Missouri State University</orgName>
								<address>
									<addrLine>901 S. National</addrLine>
									<postCode>65804</postCode>
									<settlement>Springfield</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alessandra</forename>
								<surname>Lumini</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">DEIS</orgName>
								<orgName type="institution">Università di Bologna</orgName>
								<address>
									<addrLine>Via Venezia 52</addrLine>
									<postCode>47521</postCode>
									<settlement>Cesena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Combining multiple approaches for gene microarray classification</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="issue">8</biblScope>
							<biblScope unit="page" from="1151" to="1157"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts108</idno>
					<note type="submission">Advance Access publication March 5, 2012 Received on 22 November 2011; revised on 10 February 2012; accepted on 24 February 2012</note>
					<note>Copyedited by: SD MANUSCRIPT CATEGORY: ORIGINAL PAPER [17:10 25/3/2012 Bioinformatics-bts108.tex] Page: 1151 1151–1157 Associate Editor: Martin Bishop Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The microarray report measures the expressions of tens of thousands of genes, producing a feature vector that is high in dimensionality and that contains much irrelevant information. This dimensionality degrades classification performance. Moreover, datasets typically contain few samples for training, leading to the &apos;curse of dimensionality&apos; problem. It is essential, therefore, to find good methods for reducing the size of the feature set. Results: In this article, we propose a method for gene microarray classification that combines different feature reduction approaches for improving classification performance. Using a support vector machine (SVM) as our classifier, we examine an SVM trained using a set of selected genes; an SVM trained using the feature set obtained by Neighborhood Preserving Embedding feature transform; a set of SVMs trained using a set of orthogonal wavelet coefficients of different wavelet mothers; a set of SVMs trained using texture descriptors extracted from the microarray, considering it as an image; and an ensemble that combines the best feature extraction methods listed above. The positive results reported offer confirmation that combining different features extraction methods greatly enhances system performance. The experiments were performed using several different datasets, and our results [expressed as both accuracy and area under the receiver operating characteristic (ROC) curve] show the goodness of the proposed approach with respect to the state of the art. Availability: The MATHLAB code of the proposed approach is publicly available at bias.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>DNA microarray technology has proven to be an important breakthrough in molecular biology. This rapidly maturing technology is providing scientists with a means of monitoring the expression of genes on a genomic scale (<ref type="bibr" target="#b8">Chee et al., 1996</ref>). One important application area is disease prognostication (<ref type="bibr" target="#b21">Golub et al., 1999;</ref><ref type="bibr" target="#b48">Peng, 2006</ref>). Benefits include the potential for identifying individual genes responsible for disease (<ref type="bibr" target="#b12">Der et al., 1998;</ref><ref type="bibr" target="#b30">Huang and Keoman, 2005;</ref><ref type="bibr" target="#b40">Maglietta et al., 2007;</ref><ref type="bibr" target="#b66">Turashvilli et al., 2007</ref>) and for providing scientists with a more accurate means of diagnosis * To whom correspondence should be addressed. and prognosis (<ref type="bibr" target="#b0">Alon et al., 1999;</ref><ref type="bibr" target="#b1">Beer et al., 2002;</ref><ref type="bibr" target="#b2">Ben-Dor et al., 2003;</ref><ref type="bibr" target="#b7">Brown et al., 2000;</ref><ref type="bibr" target="#b16">Freije et al., 2004;</ref><ref type="bibr" target="#b49">Petricoin et al., 2002;</ref><ref type="bibr" target="#b50">Pomeroy et al., 2002;</ref><ref type="bibr" target="#b58">Singh et al., 2002;</ref><ref type="bibr" target="#b62">Tamayo et al., 1999</ref>). Largescale profiling of gene expression can reveal, for example, normal versus malignant cells and the genetic and cellular changes in the progression of tumor metastasis (<ref type="bibr" target="#b21">Golub et al., 1999</ref>). The benefits offered by simultaneously monitoring tens of thousands of genes, however, depend on developing tools capable of handling not only the sheer size of this data but also the small number of samples usually available for analysis. Machine learning systems are well suited for this problem, but they must be designed to handle high levels of noise, as only a small minority of genes is typically relevant for any given problem. The small sample size compared to the large number of features means that these systems must also contend with the dreaded 'curse of dimensionality' (<ref type="bibr" target="#b36">Lee et al., 2008</ref>). It would be very beneficial, therefore, if good methods for identifying these small sets of relevant genes could be developed. In the literature, gene selection methods have been organized into three categories: filter, wrapper and embedded methods (<ref type="bibr" target="#b5">Bontempi, 2007</ref>). Filter methods reveal dependencies without using classifiers and are based on statistical methods of ranking genes, e.g. t-statistics (<ref type="bibr" target="#b13">Devore and Peck, 1997;</ref><ref type="bibr" target="#b64">Tibshirani et al., 2002</ref>), class separability (<ref type="bibr" target="#b14">Dudoit et al., 2002</ref>) and Fisher's criterion (<ref type="bibr" target="#b6">Broet et al., 2004;</ref><ref type="bibr" target="#b35">Lai et al., 2004</ref>). Wrapper and embedded methods consider the mutual information among genes as well as its relevance (<ref type="bibr" target="#b47">Peng et al., 2005</ref>). Example classifiers used in wrapper methods include Bayesian classifier (<ref type="bibr" target="#b15">Figuiredo and Jain, 2001;</ref><ref type="bibr" target="#b24">Hastie et al., 2009</ref>), K-nearest neighbor (<ref type="bibr" target="#b24">Hastie et al., 2009;</ref><ref type="bibr" target="#b65">Tibshirani et al., 2003</ref>) and support vector machines (SVMs) (<ref type="bibr" target="#b18">Furey et al., 2000;</ref><ref type="bibr" target="#b23">Guyon et al., 2002</ref>). Wrapper methods are much slower than filter methods because they search for optimal combinations of features/genes, but filter methods may not select the most optimal set of features. Examples of embedded methods include one-norm SVM (<ref type="bibr" target="#b17">Fung and Mangasarian, 2000</ref>), logistic regression (<ref type="bibr" target="#b55">Shen and Tan, 2005</ref>), sparse logistic regression (<ref type="bibr" target="#b53">Roth, 2004</ref>) and methods based on regularization (<ref type="bibr" target="#b20">Ghosh and Chinnaiyan, 2005</ref>). An interesting embedded method is that developed by<ref type="bibr" target="#b31">Huerta et al. (2010)</ref>. They devised a Genetic Algorithm with Fisher's Linear Discriminant Analysis (LDA) as the fitness function that performed well across a number of databases using a small number of selected genes. Most of these filter, wrapper and embedded methods are comparable in accuracy (<ref type="bibr" target="#b19">Ghorai et al., 2011</ref>). Several recent advances include reducing the sample set (<ref type="bibr" target="#b9">Chen and Lin, 2011</ref>), using classifier ensembles (<ref type="bibr" target="#b19">Ghorai et al., 2011;</ref><ref type="bibr" target="#b29">Huang et al., 2010;</ref><ref type="bibr" target="#b63">Tan and Gilbert, 2003</ref>), rather than single classifiers and using hybrid or multiple sets of different type of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Nanni et al.</head><p>feature selection and transformation methods (<ref type="bibr" target="#b19">Ghorai et al., 2011</ref>). Chen and Lin (2011) have improved classifier performance by extracting significant samples that are located only on support vectors.<ref type="bibr" target="#b29">Huang et al. (2010)</ref>improve performance using decision forest for classification of gene expression data, and<ref type="bibr" target="#b60">Stiglic et al. (2010)</ref>use rotation forests for robust and improved classification accuracy.<ref type="bibr" target="#b19">Ghorai et al. (2011)</ref>have developed an ensemble that combines both filter and wrapper methods: a ranking method performs a fast reduction in dimensionality and a wrapper method refines the search. Their method has demonstrated comparable performance with wrapper methods while providing significant reduction in the computational burden. In this article, we propose to classify DNA microarray data using an ensemble of SVM classifiers, with each SVM trained on a different set of features. SVM is selected because it is considered to be one of the most powerful classifiers in microarray classification of cancers (<ref type="bibr" target="#b59">Statnikov et al., 2008</ref>) and in several other bioinformatic problems (<ref type="bibr" target="#b25">Hayat and Khan, 2011;</ref><ref type="bibr" target="#b61">Tahir et al., 2011</ref>). Even though SVM is a strong learner and thus not typically suitable for ensembles, it actually performs well in ensembles if coupled with the random subspace technique (<ref type="bibr" target="#b41">Nanni and Lumini, 2011</ref>). In our experiments, we specifically investigate approaches: (i) that compare standard feature selection methods, where only a subset of the whole gene set is retained and then used to train an SVM; (ii) that compare several feature transform methods, where the dimension of the feature vector is reduced and then used to train an SVM; (iii) that train a set of SVMs using a set of orthogonal wavelet coefficients of different wavelet mothers-these sets of coefficients are selected via Sequential Forward Floating Selection (SFFS) using the leaveone-dataset-out validation protocol, such that when a given dataset is classified, the sets of coefficients are selected by SFFS using the others datasets as validation set; and (iv) that consider the microarray as an image, where the texture descriptors are extracted from the image and used to train an SVM. Experiments are carried out on several datasets, and experimental results show that the proposed method performs well when considering both accuracy and the area under the ROC curve (AUC) as the performance indicators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>In this section, we briefly describe the feature selection, feature transform and classification and fusion methods, including the tree wavelet and texture descriptors used in our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature selection</head><p>The feature selection methods we explore are the following:In most cases, the code for the above methods was taken from the MATLAB Feature Selection Package available at http://featureselection.asu.edu/ In addition to the above listed feature selection methods, we also examine: @BULLET FFacsa2 1 (<ref type="bibr" target="#b39">Luo et al., 2011</ref>): a forward feature selection algorithm that is based on the aggregation of classifiers generated by a single attribute; @BULLET SVMrfe1 (<ref type="bibr" target="#b23">Guyon et al., 2002</ref>): the famous SVM-based recursive feature elimination method; @BULLET SFFS (<ref type="bibr" target="#b52">Pudil et al., 1994</ref>) 2 : an exhaustive search procedure that has been studied extensively and shown to perform well compared to competing methods (<ref type="bibr" target="#b33">Kudo and Sklansky, 2000</ref>). To reduce computation time, SFFS starts from the 500 genes selected by Fi; then the best set is extracted. SVM is used as the objective performance method.</p><p>See the Supplementary Material for a fuller discussion of Fisher score and SFFS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature transform</head><p>We explore the following feature transform techniques:</p><p>@BULLET Locally Linear Embedding (LLE), as proposed in@BULLET Neighborhood Preserving Embedding (NPE), as proposed in (<ref type="bibr" target="#b26">He et al., 2005</ref>). Unlike principal component analysis (PCA), which aims at preserving the global Euclidean structure of the data, NPE preserves the local neighborhood structure on the data manifold. As a result, NPE is less sensitive to outliers than is PCA. We used the MATLAB code freely available at http://www.zjucadcg.cn/dengcai/Data/data.html</p><p>See the Supplementary Material for a fuller discussion of NPE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Tree wavelet</head><p>In the case of one dimensional wavelet decomposition, the first step produces two sets of coefficients from the signal: (i) approximation coefficients, or scaling coefficients; and (ii) detail coefficients, or wavelet coefficients. The approximation coefficients are split into two parts repeating the same algorithm, being thereby replaced by approximation coefficients and detail coefficients. This decomposition process is repeated until a required level is reached (<ref type="bibr" target="#b38">Liu, 2009;</ref><ref type="bibr" target="#b41">Nanni and Lumini, 2011</ref>). In this article, we examine the following wavelets (until the sixth decomposition level): Haar, Daubechies order 7, Symmlet order 2, Coiflets order 2, Biorthogonal order for reconstruction 2 and for decomposition 2, Reverse Biorthogonal order for reconstruction 2 and for decomposition 2. For each set of coefficients (both approximation coefficients and detail coefficients) of a given decomposition level, a different classifier is trained. The decomposition is applied both on the original data and on the set of genes selected by Fisher score. SFFS is used to select a set of subbands. The testing protocol was the leave-one-dataset-out validation protocol. When a given dataset is classified, the sets of coefficients are selected using as the validation set the other datasets. A fuller discussion of wavelet decomposition and the set of subbands selected by SFFS considering all the datasets are reported in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gene microarray classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Texture descriptors</head><p>In this approach, we consider the microarray as an image from which a set of texture descriptors is extracted. First, we select a set of 900 genes using the Fisher criterion feature selection method. Then this 900-dimensional feature vector is reshaped as a matrix using random assignment. A total of 50 different random reshapings are performed. For each reshaping, a different SVM is trained, with results combined using a fusion rule. In this article, we examine the following image texture feature transforms: @BULLET Lu is a concatenation of the uniform bins extracted using local binary patterns (LBPs) (<ref type="bibr" target="#b43">Ojala et al., 2002</ref>) with P = 8 and P = 16. If x = 8 then R = 1, if x = 16 then R = 2. The length of the feature vector is 59 in the case x = 8 and 243 in the case x = 16; @BULLET Lr is rotation invariant uniform bins extracted using LBP with P = 8 and P = 16. If x = 8 then R = 1, if x = 16 then R = 2. The length of the feature vector is 10 in the case x = 8 and 18 in the case x = 16; @BULLET LP(x) is local phase quantization (<ref type="bibr" target="#b44">Ojansivu and Heikkila, 2008</ref>) with radius x = 3 or x = 5. The length of the feature vector is 256 in both cases;</p><p>@BULLET LQPu is different local quinary patterns (<ref type="bibr" target="#b42">Nanni et al., 2010</ref>) with uniform bins and with τ1 = {1,3,5,7,9} and τ2 = { τ1+2, τ1+4,…, τ1+11}. These are combined by a fusion rule (see the 'Results' section for details). See the Supplementary Material for a fuller discussion of local phase quantization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Classification and fusion</head><p>In this approach, we use SVM as the stand-alone classifier. SVM is a general purpose binary classifier based on statistical learning. It performs classification in two steps. In the first step, it maps the sample data vector into a higher dimensional data space by means of polynomial kernels or radial basis function kernels. In the second step, the algorithm finds a hyperplane in this space that has the largest margin separating the classes. The fusion step is performed by means of the sum rule or the majority voting (vote) rule. The first consists in summing the scores of all the classifiers of the ensemble and selecting the class with the highest score; the second simply selects the class with the higher number of votes (see the Supplementary Material for a fuller discussion of SVM and the sum and vote rules).@BULLET Medulloblastoma (M) (<ref type="bibr" target="#b50">Pomeroy et al., 2002</ref>): the researchers analyze 60 similarly treated patients from whom biopsies were obtained before receiving treatment. Using this dataset,<ref type="bibr">Pomeroyet et al.</ref>show that the clinical outcome of children with medulloblastomas is predictable on the basis of the gene expression profiles of their tumors at diagnosis; @BULLET Colon (C) (<ref type="bibr" target="#b0">Alon et al., 1999</ref>): the colon dataset contains 62 samples: 40 are tumor samples and 22 are normal controls. In this dataset, 2000 genes with highest intensity across the samples are considered; @BULLET Duke (D) (<ref type="bibr" target="#b39">Luo et al., 2011</ref>): this is a dataset that contains 44 patterns described by 7129 genes; @BULLET ALML (A) (<ref type="bibr" target="#b21">Golub et al., 1999</ref>): this leukemia dataset was derived from a study of gene expression in two types of acute leukemia: acute lymphoblastic leukemia (ALL) and acute myeloid-leukemia (AML). The dataset includes 47 cases of ALL and 25 cases of AML, together with 7129 genes; @BULLET DLBCL (DL) (<ref type="bibr" target="#b57">Shipp et al., 2002</ref>): the goal of this dataset is to distinguish diffuse large B-cell lymphoma (DLBCL) from follicular lymphoma (FL) morphology. This dataset contains 58 DLBCL samples and 19 FL samples.</p><p>In our first experiment, we compare several feature selection methods using a stand-alone SVM as the classifier for the function of the number of g genes retained: 150, 300 and 450, respectively. In<ref type="figure" target="#tab_2">Table 2</ref>, we report the average performance of the different approaches across all datasets (the performance for each dataset is reported in Supplementary Table S1 in the Supplementary Material).It is interesting to note that the best performance is obtained by the old Fisher criterion, which slightly outperforms the more recent FFacsa2, SVMrfe and the computationally heavy SFFS method. This advantage in performance is obtained using 450 genes. SVMrfe and SFFS performed best when fewer genes/features are retained. In our experiments, we choose the best kernel and the best parameters for each dataset using 10-fold cross validation on the training data. In the second experiment, we compare several feature transform methods using the stand-alone SVM as the classifier. To reduce the computation time, 1000 genes are first selected by Fisher and then PCA is used to decorrelate the data. In<ref type="figure" target="#tab_3">Table 3</ref>the average accuracy on all the datasets obtained using different feature transform methods is reported as a function of the dimension k of the projection space (k ∈{20,30,45}) (the accuracy obtained in each dataset is reported in Supplementary Table S2 in the Supplementary Material). The best performance is obtained by NPE that only slightly improves the performance obtained by Fi in the previous test reported in<ref type="figure" target="#tab_2">Table 2</ref>. In the third experiment, we evaluate the performance obtained by varying the image descriptors used to represent the microarray patterns (as described in Section 2.4). In<ref type="figure" target="#tab_4">Table 4</ref>we report the accuracy obtained: (i) by methods based on different descriptors; (ii) by the tree wavelet (TW ) approach (where the classifiers are combined by vote rule); (iii) by the ensemble FUS (which is the fusion by vote rule of TW, NPE and Fi) and, as a reference; (iv) by the best approaches previously tested (Fi and NPE). It is interesting to note in<ref type="figure" target="#tab_4">Table 4</ref>that not only does the fusion approach obtain the best average performance but also FUS closely matches the performance of the best approach for any given dataset: @BULLET In the prostate dataset (P), the best single approach is TW, which FUS matches; @BULLET In the breast dataset (B), NPE outperforms TW and F. FUS obtains a performance only slightly lower than NPE but higher than either Fi and TW ;We tried combining LQPr in FUS, but performance remained the same. The most advanced methods based on image descriptors (i.e. LQPr and LQPu) perform much better than do simple Lu, Lr and LP (we believe, however, that combinations of different texture descriptors with the simple methods would probably obtain performances closer to those obtained by standard approaches). In the fourth experiment, we compare the performance of FUS with several state-of-the art approaches: LI (<ref type="bibr" target="#b37">Liu et al., 2002</ref>), CN (<ref type="bibr" target="#b10">Cheng, 2010</ref>), GH (<ref type="bibr" target="#b19">Ghorai et al., 2011</ref>), LU (<ref type="bibr" target="#b39">Luo et al., 2011</ref>), PA (<ref type="bibr" target="#b46">Paliwal and Sharma, 2010</ref>), HU (<ref type="bibr" target="#b31">Huerta et al., 2010</ref>), BO (<ref type="bibr">BolónCanedo et al., 2012</ref>), CH (<ref type="bibr" target="#b9">Chen and Lin, 2011</ref>), OR (<ref type="bibr" target="#b45">Orsenigo and Vercellis, 2011</ref>) and PO (<ref type="bibr" target="#b51">Porto-Díaz et al., 2011</ref>). This comparison shows the goodness of the proposed approach with respect to the state of the art. The only dataset where our results are lower is with the Colon dataset (C). In several of the papers used in<ref type="figure" target="#tab_5">Table 5</ref>, the feature selection was performed using the training data, but system performance was measured with the testing set, where varying numbers of the features were retained (see<ref type="figure" target="#tab_9">Table 9</ref>for the performance of PO using the original code tested in our datasets). In<ref type="figure" target="#tab_5">Table 5</ref>, we give the best results reported for each method using the testing set. Our method, in contrast, used the same number offeatures both in training and testing as well as across all datasets. Our method is thus very suitable for general practitioners. In Tables 6–9, we report results obtained in the previous experiments using a more reliable performance indicator: the AUC. AUC can be interpreted as the probability that the classifier will assign a lower score to a randomly picked positive sample than to a randomly picked negative sample. In Table 6, we compare several feature selection methods using AUC (cf.<ref type="figure" target="#tab_2">Table 2</ref>where we used accuracy as the performance indicator). FFacsa2 provides the best performance. It should be noted that this difference is mainly due to the lower performance obtained by the other methods in the M dataset (see Supplementary<ref type="figure" target="#tab_3">Table S3</ref>in the Supplementary Material for results of each dataset). In<ref type="figure" target="#tab_7">Table 7</ref>, we compare the different feature transform techniques using AUC. The best performance, as in<ref type="figure" target="#tab_3">Table 3</ref>using accuracy, is obtained by NPE. In<ref type="figure" target="#tab_8">Table 8</ref>, we report the performance obtained in the third experiment. In this Table a new ensemble is evaluated, WF, which is the fusion by weighted sum rule of TW, NPE, Fi and LP(5).In the weighted sum rule, each classifier is weighted by a value between 0 and 1. The scores are then summed. Optimal weights are obtained using the leave-one-dataset-out validation protocol. In other words, when a given dataset is classified, the sets of weights are selected using as the validation set the others datasets. Our fusion approach WF obtains the best overall average performance using AUC. Moreover, fusion results for each dataset closely approximate the performance of the best methods reported for the individual datasets. In Table 9, we compare our best approach WF with the performance obtained by a random subspace of SVM trained using the original genes, LIU2 (<ref type="bibr" target="#b38">Liu, 2009</ref>), and OldTW (<ref type="bibr" target="#b41">Nanni and Lumini, 2011</ref>). Random subspace of SVM has been shown to be very effective (<ref type="bibr" target="#b3">Bertoni et al., 2009</ref>). The random subspace creates an ensemble such that each classifier is trained with a different subset of the original features. In our experiments, we combine results with sum rule using 50 classifiers, each trained with K features. In<ref type="figure" target="#tab_9">Table  9</ref>, K = 50% means that each classifier is trained with a subset that contains 50% of the original features, whereas K = x means that each classifiers is trained with x randomly selected genes. PO in<ref type="figure" target="#tab_9">Table 9</ref>refers to the results obtained using the original code shared by (<ref type="bibr" target="#b51">Porto-Díaz et al., 2011)</ref>with the following setting: we ran their approach starting from the 500 genes selected by Fi (in this way a more fair approach with our method is provided). It is interesting to note that now the performance on the Colon dataset (C) is lower than that obtained by our ensemble. WF outperforms the other methods. The advantage of using a combination of approaches is also demonstrated by the use of the Wilcoxon Signed-Rank test (<ref type="bibr" target="#b11">Demsar, 2006</ref>) developed for comparing the results of stand-alone methods with ensembles. The null hypothesis (that is there is no difference between the accuracies of the stand-alone methods and the ensemble) is rejected with a level of significance of 0.10. As an additional experiment, we investigated the relationship among the different approaches by evaluating the error independence between the classifiers trained using those features.<ref type="figure" target="#tab_0">Table 10</ref>reports the average Yule's Q-statistic (<ref type="bibr" target="#b34">Kuncheva and Whitaker, 2003</ref>) in the tested datasets. For two classifier G i and G j the Q-statistic, a posteriori measure, is defined as: where N ab is the number of instances in the test set, classified correctly (a = 1) or incorrectly (a = 0) by the classifier G i , and correctly (b = 1) or incorrectly (b = ) by the classifier G j. Q ∈<ref type="bibr">[ −1, 1]</ref>Copyedited by: SD MANUSCRIPT CATEGORY: ORIGINAL PAPER<ref type="bibr">[</ref>The bold values are the highest performance, the italic values are the values of parameters. and Q i,j = 0 for statistically independent classifiers. Classifiers that tend to recognize the same patterns correctly will have Q &gt; 0, and those that commit errors on different patterns will have Q &lt; 0. In this problem, the Q-statistic values are low enough to validate the idea of combining the different approaches. As a final experiment, in<ref type="figure" target="#tab_1">Table 11</ref>, we report the results of our ensemble on two other recent datasets from (<ref type="bibr" target="#b56">Shi et al., 2011</ref>). The first is a breast cancer dataset (WB) that contains a subset of ER-positive, lymphnode-negative patients who did not received adjuvant treatment. The raw intensity Affymetrix CEL files and normalized data by RMA procedures using Bioconductor packages are used for obtaining a final expression matrix comprising 22 283 features and 209 samples. The 71 patients who developed distant metastases or died within 5 years are classified as poor prognosis subjects, and the 139 patients who remained healthy for &gt;5 years are classified as good prognosis subjects. The second dataset (LA) contains gene expressions of 86 patients with primary lung ADCA; 62 patients were still alive, and 24 patients had died. Notice that all the parameters of WF are obtained using the nine datasets previously used throughout this article. In this test, we arrive at the same main conclusion of the previous test: the fusion, WF, obtains the best average performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gene microarray classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>The goal of this study was to develop a robust ensemble of SVM classifiers based on feature perturbation for microarray classification. The reported results of our experiments, expressed as both accuracy and AUC, show that our approach performs very well across several datasets. Our study examined an SVM trained using a set of selected genes by Fisher criterion, an SVM trained using the feature set obtained by NPE, a set of SVMs trained using a set of orthogonal wavelet coefficients of different wavelet mothers and a set of SVMs trained using texture descriptors extracted from the microarray, considering it as an image. The positive results we obtain compare well with those reported in the literature and provide further confirmation that ensembles of classifiers obtain more reliable results.</p><p>In future studies, we plan on testing our approach using more datasets. We will also study combining additional methods in ensemble construction (e.g. combining our feature perturbation approaches with a pattern perturbation approach).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest: none declared.</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Copyedited by: SD MANUSCRIPT CATEGORY: ORIGINAL PAPER [17:10 25/3/2012 Bioinformatics-bts108.tex] Page: 1153 1151–1157</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>O100.</head><figDesc>00 100.00 100.00 96.40 87.20 91.20 94.00 94.80 100.00 P 93.85 95.38 96.15 80.00 70.77 65.38 66.15 84.62 96.15 L 100.00 100.00 100.00 95.56 93.89 92.22 82.22 98.33 100.00 B 82.86 90.00 87.14 71.43 74.29 61.43 54.29 84.29 88.57 M 70.00 70.00 70.00 68.33 68.33 68.33 68.33 68.33 66.67 C 75.00 68.33 75.00 65.00 65.00 65.00 65.00 65.00 73.33 D 87.50 90.00 85.0 72.50 65.00 45.00 45.00 80.00 90.00 A 98.57 97.14 95.71 88.57 72.86 65.71 65.71 82.86 100.00 DL 98.57 98.57 98.57 75.71 75.71 68.57 68.57 77.14 98.57 avg 89.59 89.93 89.73 79.27 74.78 69.20 67.69 81.70 90.37 The bold values are the highest performance, the italic values are the values of parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Copyedited by: SD MANUSCRIPT CATEGORY: ORIGINAL PAPER [17:10 25/3/2012 Bioinformatics-bts108.tex] Page: 1155 1151–1157</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>.95 99.95 93.98 99.23 99.77 99.05 99.95 99.95 DL 99.95 99.76 99.95 94.89 94.08 95.98 98.82 94.70 99.95 99.95 avg 90.30 91.85 91.78 84.36 79.24 84.31 87.20 82.64 92.07 92.18 The bold values are the highest performance, the italic values are the values of parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FI</head><figDesc>versus NP 1.00 0.96 0.93 0.98 0.99 0.60 1.00 0.99 1.00 FI versus TW 1.00 0.99 0.93 0.94 0.93 0.63 0.98 1.00 1.00 NPE versus T 1.00 0.96 1.00 0.93 0.95 0.99 0.99 0.99 1.00</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 1. Characteristics of the datasets used in the experiments: the first column presents the number of attributes (#A), and the second column reports the number of examples (#E)</figDesc><table>Dataset 
#A 
#E 

Ovarian (O) 
15 154 
253 
Prostate (P) 
12 600 
102 
Lung (L) 
12 533 
181 
Breast (B) 
24 481 
78 
Medulloblastoma (M) 
7129 
60 
Colon (C) 
2000 
62 
Duke (D) 
7129 
44 
ALML (A) 
7129 
72 
DBCL (DL) 
7129 
77 

@BULLET Lung dataset (L) 3 (Gordon et al., 2002): the goal of 
this experiment is to classify between malignant pleural 
mesothelioma (MPM) and adenocarcinoma (ADCA) of the 
lung. Two classes are considered: 31 MPM tissue samples 
and 150 ADCA tissue samples; 

@BULLET Prostate tumors (P) (Singh et al., 2002): the goal of this 
experiment is to classify prostate tumor samples and normal 
non-tumor samples. Two classes are considered: 52 prostate 
tumor samples and 50 normal samples; 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 2. Average accuracy obtained using different feature selection methods as a function of the number g genes retained</figDesc><table>avg(ACC) Fi 
Gi 
Mr 
Sb 
Tt 
FFacsa SVMrfe SFFS 

g 150 87.50 78.47 84.44 80.61 84.39 87.26 
88.77 
88.85 
300 87.97 83.24 87.14 80.61 85.45 86.76 
88.95 
88.10 
450 89.59 85.53 87.25 80.61 86.24 87.67 
89.48 
88.48 

The bold values are the highest performance, the italic values are the values of 
parameters. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 3.</figDesc><table>Average accuracy obtained using different feature transform 
methods in reduced spaces of different dimensionality k 

avg(ACC) 
LLE 
OLDA 
ONPP 
NPE 

k 
20 
86.25 
89.06 
86.60 
89.93 
30 
86.42 
89.06 
87.40 
89.93 
45 
86.25 
89.06 
87.69 
89.93 

The bold values are the highest performance, the italic values are the values of 
parameters. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Table 4.</figDesc><table>Average accuracy obtained using different feature transform 
methods in reduced spaces of different dimensionality k 

ACC Fi 
NPE TW 
Lu 
Lr 
LP(3) LP(5) LQPu FUS 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>Table 5. Comparison among FUS and different state of the art methods ACC FUS LI CN GH LU PA HU BO CH OR PO outperforms TW and NPE. FUS, however, outperforms Fi.</figDesc><table>O 
100 
100 100 
P 
96.15 
90.16 
76.50 96.00 
95.09 
L 
100 
99.33 96.38 
97.30 99.30 98.89 
99.33 
B 
88.57 
73.70 
M 66.67 
C 
73.33 
82.77 80.72 
80.95 
85.60 90.00 
D 
90.00 
86.83 
A 
100 100 100 94.52 97.21 100 100 94.46 98.61 94.40 100 
DL 98.57 
95.56 
98.70 

The bold values are the highest performance, the italic values are the values of 
parameters. 

@BULLET In the ALML dataset (A), Fi </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><figDesc>Table 6. Average AUC obtained using different feature selection methods as a function of the number g genes retained</figDesc><table>avg(AUC) Fi 
Gi 
Mr 
Sb 
Tt 
FFacsa2 SVMrfe SFFS 

g 150 
89.70 79.17 86.62 85.22 84.01 89.51 
89.67 
89.70 
300 
89.62 86.56 89.21 85.22 85.58 90.63 
90.06 
89.62 
450 
90.30 87.20 88.63 85.22 86.34 90.40 
90.17 
90.30 

The bold values are the highest performance, the italic values are the values of 
parameters. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><figDesc>Table 7.</figDesc><table>Average AUC obtained using different feature transform methods 
in reduced spaces of different dimensionality k 

avg(AUC) 
LLE 
OLDA 
ONPP 
NPE 

k 
20 
89.49 
89.53 
90.06 
91.79 
30 
89.80 
89.53 
91.01 
91.83 
45 
90.33 
89.53 
91.69 
91.85 

The bold values are the highest performance, the italic values are the values of 
parameters. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="true"><figDesc>Table 8. AUC obtained by different texture descriptors, TW, Fi, NPE and the ensembles FUS and WF</figDesc><table>AUC Fi 
NPE TW Lu 
Lr 
LP(3) LP(5) LQPu FUS WF 

O 
99.97 99.97 99.97 99.72 97.89 99.89 99.89 99.55 99.97 99.97 
P 
95.44 96.50 98.24 87.28 85.31 89.47 90.45 86.52 97.50 97.71 
L 
99.97 99.97 99.97 99.46 99.46 99.63 99.97 98.55 99.97 99.97 
B 
94.53 97.99 91.08 89.93 80.22 88.45 90.58 91.74 97.11 97.33 
M 
61.17 69.13 66.62 49.04 43.00 46.73 49.55 45.44 66.55 66.82 
C 
68.19 65.51 72.10 57.69 54.52 59.89 66.00 45.42 69.02 69.17 
D 
93.61 97.95 98.21 81.33 64.71 79.54 89.77 82.86 98.66 98.72 
A 
99.95 99.95 99</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="true"><figDesc>Table 9. Comparison of WF with different state of the art methods using AUC as the performance indicator AUC LIU2 OldTW K = 64 K = 128 K = 512 K = 50% OC WF</figDesc><table>O 
99.97 99.97 
99.97 99.97 
99.97 
99.97 
99.30 99.97 
P 
97.00 96.70 
94.61 95.82 
95.14 
96.42 
93.47 97.71 
L 
99.90 99.97 
99.97 99.97 
99.97 
99.97 
99.97 99.97 
B 
86.50 91.10 
92.60 94.70 
95.52 
96.83 
93.38 97.33 
M 
– 
– 
58.60 54.81 
61.94 
52.95 
61.75 66.82 
C 
– 
– 
69.41 68.44 
68.44 
69.17 
63.37 69.17 
D 
– 
– 
97.70 98.21 
89.77 
89.77 
95.91 98.72 
A 
– 
– 
99.95 99.95 
99.95 
99.95 
99.95 99.95 
DL – 
– 
99.38 99.95 
99.76 
99.76 
98.25 99.95 
avg – 
– 
90.24 90.20 
90.05 
89.42 
89.48 92.18 

The bold values are the highest performance, the italic values are the values of 
parameters. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><figDesc>Table 10. Yule's Q-statistic between the stand-alone approaches</figDesc><table>compared 
O 
P 
L 
B 
M 
C 
D 
A 
DL 
descriptors 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" validated="false"><figDesc>Table 11. AUC obtained in the datasets used in (Shi et al., 2011) compared K= 64 K = 128 K = 512 FFacsa2 FV Fi NPE TW WF descriptors</figDesc><table>WB 
76.41 76.41 
75.72 
64.58 
69.56 73.50 67.93 72.97 74.19 
LA 
65.12 68.54 
69.03 
65.76 
66.27 71.53 73.02 67.04 71.31 
avg 
70.76 72.47 
72.37 
65.17 
67.91 72.51 70.48 70.00 72.75 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> The MATLAB code was shared by the original authors of FFacsa2, which also shared the code of SVMrfe. 2 Implemented as in PRTools (prtools.org/prtools.html).</note>

			<note place="foot" n="3"> RESULTS To assess the performance of our approach, we have conducted several experiments on a number of publicly available datasets. Below we provide a brief description of each dataset (the salient features of each dataset are summarized in Table 1): • Breast dataset (B) (van &apos;t Veer et al., 2002): the goal of this experiment is to identify patients who might benefit from adjuvant chemotherapy. Two classes are considered: patients who continued to be disease free after 5 years (44 samples) and patients who developed metastases within 5 years (34 samples); • Ovarian dataset (O) (Petricoin et al., 2002): the goal of this experiment is to identify proteomic patterns in serum that distinguish between ovarian cancer and normal non-cancer groups. Two classes are considered: 91 controls (Normal) and 162 ovarian cancers;</note>

			<note place="foot" n="3"> Publically available at http://www.chestsurg.org.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Alon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="6745" to="6750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Gene-expression profiles predict survival of patients with lung adenocarcinoma</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">G</forename>
				<surname>Beer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="816" to="823" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Tissue classification with gene expression profiles</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ben-Dor</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="559" to="583" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Classification of DNA microarray data with random projection ensembles of polynomial</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bertoni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th Italian Workshop on Neural Networks. IOS Press</title>
		<meeting><address><addrLine>Vietri sul Mare, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="60" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">An ensemble of filters and classifiers for microarray data classification</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bolón-Canedo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="531" to="539" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">A blocking strategy to improve gene selection for classification of gene expression data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Bontempi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Biofrom</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="293" to="300" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A mixture model-based strategy for selecting sets of genes in multiclass response microarray experiments</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Broet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2562" to="2571" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledge-based analysis of microarray gene expression data by using support vector machines</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">P</forename>
				<surname>Brown</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="262" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Assessing genetic information with high-density dna arrays</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="page" from="610" to="614" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A novel support vector sampling technique to improve classification accuracy and to identify key genes of leukaemia and prostrate cancer</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">H</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C.-H</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="3209" to="3219" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A sparse learning machine for high-dimensional data with application to microarray gene analysis</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Cheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Biofrom</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="636" to="646" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Demsar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Identification of genes differently regulated by interferon alpha, beta, or gamma using oligonucleotide arrays</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">D</forename>
				<surname>Der</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="15623" to="15628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">Statistics: the Exploration and Analysis of Data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Devore</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Peck</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Duxbury Press</publisher>
			<pubPlace>Florence, KY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparison of discrimination methods for the classification of tumors using gene expression data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dudoit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Baysean learning of sparse classifiers</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A T</forename>
				<surname>Figuiredo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">K</forename>
				<surname>Jain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR &apos;01</title>
		<meeting><address><addrLine>Miami, Florida</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Gene expression profiling of gliomas strongly predicts survival</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">A</forename>
				<surname>Freije</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="6503" to="6510" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Data selection for support vector machine classifiers</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Fung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">L</forename>
				<surname>Mangasarian</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computing Machinery Special Interest Group on Knowledge Discovery and Data Mining</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="64" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Support vector machine classification and validation of cancer tissue samples using microarray expression data</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">S</forename>
				<surname>Furey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="906" to="914" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Cancer classification from gene expression data by NPPC ensemble</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ghorai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Biofrom</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="659" to="671" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Classification and selection of biomarkers in genomic data using LASSO</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ghosh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Chinnaiyan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="147" to="154" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Molecular classification of cancer: class discovery and class predition by gene expression monitoring</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">R</forename>
				<surname>Golub</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="531" to="537" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Translation of microarray data into clinically relevant cancer diagnostic tests using gene expression ratios in lung cancer and mesothelioma</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Gordon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="4963" to="4967" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using support vector machines</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Guyon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="389" to="422" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Predicting membrane protein types by fusing composite protein sequence features into pseudo amino acid composition</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hayat</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Khan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="volume">271</biblScope>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Neighborhood preserving embedding</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth IEEE International Conference on Computer Vision (ICCV&apos;2005)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Bioinformatics-bts108.tex] Page</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="10" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Gene microarray classification</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Decision forest for clssification of gene expression data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="698" to="704" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Gene extraction for cancer diagnosis by support vector machines-an improvement</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">M</forename>
				<surname>Huang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Keoman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intel. Med</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="185" to="194" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">A hybrid LDA and genetic algorithm for gene selection and classification of microarray data</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B</forename>
				<surname>Huerta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="2375" to="2383" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Orthogonal Neighborhood Preserving Projections</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Kokiopoulou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Saad</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International conference on Data Mining</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Comparison of algorithms that select features for pattern classifiers</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kudo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sklansky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="25" to="41" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">I</forename>
				<surname>Kuncheva</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">J</forename>
				<surname>Whitaker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="181" to="207" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Statistical method for identifying diferential gene-gene coexpression patterns</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Lai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="3146" to="3155" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Investigating the efficiacy of nonlinear dimensionality reduction schemes in classifying gene-and protein-expression studies</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Biofrom</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="368" to="384" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">A comparative study on feature selection and classification methods using gene expression profiles and proteomic patterns</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Inform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="51" to="60" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Wavelet feature extraction for high dimensional microarray data</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="985" to="990" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Methods of forward feature selection based on the aggregation of classifiers generated by single attribute</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Luo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Med</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="435" to="441" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Selection of relevant genes in cancer diagnosis based on their prediction accuracy</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Maglietta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intel. Med</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="29" to="44" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">Wavelet selection for disease classification by DNA microarray data</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nanni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lumini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="990" to="995" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Local binary patterns variants as texture descriptors for medical image analysis</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nanni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intel. Med</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="117" to="125" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ojala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">Blur insensitive texture classification using local phase quantization</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Ojansivu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Heikkila</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image and Signal Processing</title>
		<meeting><address><addrLine>Cherbourg-Octeville, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">An effective double-bounded tree-connected isomap algorithm for microarray data classification</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Orsenigo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Vercellis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">Improved direct LDA and its application to DNA microarray gene expression data</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">K</forename>
				<surname>Paliwal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sharma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2489" to="2492" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b47">
	<analytic>
		<title level="a" type="main">Feature selection on mutual information: criteria of maxdependency, max-relevance, and min-redundancy</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intel</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1226" to="1238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b48">
	<analytic>
		<title level="a" type="main">A novel ensemble machine learning for robust microarray data classification</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="553" to="573" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b49">
	<analytic>
		<title level="a" type="main">Use of proteomic patterns in serum to identify ovarian cancer</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">F</forename>
				<surname>Petricoin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page" from="572" to="577" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b50">
	<analytic>
		<title level="a" type="main">Prediction of central nervous system embryonal tumour outcome based on gene expression</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Pomeroy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="page" from="436" to="442" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b51">
	<analytic>
		<title level="a" type="main">A study of performance on microarray data sets for a classifier based on information theoretic learning</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Porto-Díaz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="888" to="896" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b52">
	<analytic>
		<title level="a" type="main">Floating search methods in feature selection</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Pudil</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1119" to="1125" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b53">
	<analytic>
		<title level="a" type="main">The generalized LASSO</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Roth</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="16" to="18" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b54">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Roweis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Saul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b55">
	<analytic>
		<title level="a" type="main">Dimension reduction-based penalized logistic regression for cancer classification using microarray data</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">C</forename>
				<surname>Tan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Biofrom</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="166" to="175" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b56">
	<analytic>
		<title level="a" type="main">Top scoring pairs for feature selection in machine learning and applications to cancer outcome prediction</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">375</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b57">
	<analytic>
		<title level="a" type="main">Diffuse large B-cell lymphoma outcome prediction by geneexpression profiling and supervised machine learning</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Shipp</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b58">
	<analytic>
		<title level="a" type="main">Gene expression correlates of clinical prostate cancer behavior</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Singh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Cell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="203" to="209" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b59">
	<analytic>
		<title level="a" type="main">A comprehensive comparison of random forests and support vector machines for microarray-based cancer classification</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Statnikov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">319</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b60">
	<analytic>
		<title level="a" type="main">Finding optimal classifiers for small feature sets in genomics and protoemics</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Stiglic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="2346" to="2352" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b61">
	<analytic>
		<title level="a" type="main">Protein subcellular localization of fluorescence imagery using spatial and transform domain features</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tahir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b62">
	<analytic>
		<title level="a" type="main">Interpreting patterns of gene expression with self-organizing maps: methods and application to hematopoietic differentiation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tamayo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="2907" to="2912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b63">
	<analytic>
		<title level="a" type="main">Ensemble machine learning on gene expression data for cancer classification</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Tan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gilbert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="75" to="83" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b64">
	<analytic>
		<title level="a" type="main">Diagnosis of multiple cancer types by shrunken centroids of gene expression</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="6567" to="6572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b65">
	<analytic>
		<title level="a" type="main">Class predition by nearest shrunken centroids, with application to DNA microarrays</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="104" to="117" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b66">
	<analytic>
		<title level="a" type="main">Novel markers for differentiation of lobular and ductal invasive breast carcinomas by laser microdissection and microarry analysis Gene expression profiling predicts clinical outcome of breast cancer</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Turashvilli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cancer Nature</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">415</biblScope>
			<biblScope unit="page" from="530" to="536" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b67">
	<analytic>
		<title level="a" type="main">Characterization of a family of algorithms for generalized discriminant analysis on undersampled problems</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ye</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="483" to="502" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>