
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis PERMORY: an LD-exploiting permutation test algorithm for powerful genome-wide association testing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Roman</forename>
								<surname>Pahl</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Medizinische Biometrie und Epidemiologie</orgName>
								<orgName type="institution">Philipps-Universität Marburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Helmut</forename>
								<surname>Schäfer</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Medizinische Biometrie und Epidemiologie</orgName>
								<orgName type="institution">Philipps-Universität Marburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis PERMORY: an LD-exploiting permutation test algorithm for powerful genome-wide association testing</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="issue">17</biblScope>
							<biblScope unit="page" from="2093" to="2100"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq399</idno>
					<note type="submission">Received on May 13, 2010; revised on June 24, 2010; accepted on July 2, 2010</note>
					<note>[15:11 30/7/2010 Bioinformatics-btq399.tex] Page: 2093 2093–2100 Associate Editor: Martin Bishop</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: In genome-wide association studies (GWAS) examining hundreds of thousands of genetic markers, the potentially high number of false positive findings requires statistical correction for multiple testing. Permutation tests are considered the gold standard for multiple testing correction in GWAS, because they simultaneously provide unbiased type I error control and high power. At the same time, they demand heavy computational effort, especially with large-scale datasets of modern GWAS. In recent years, the computational problem has been circumvented by using approximations to permutation tests, which, however, may be biased. Results: We have tackled the original computational problem of permutation testing in GWAS and herein present a permutation test algorithm one or more orders of magnitude faster than existing implementations, which enables efficient permutation testing on a genome-wide scale. Our algorithm does not rely on any kind of approximation and hence produces unbiased results identical to a standard permutation test. A noteworthy feature of our algorithm is a particularly effective performance when analyzing high-density marker sets. Availability: Freely available on the web at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The analysis of genome-wide association studies (GWAS) using hundreds of thousands of single nucleotide polymorphism (SNP) markers requires strict control of the type I error (<ref type="bibr" target="#b5">Dudbridge and Gusnanto, 2008;</ref><ref type="bibr" target="#b15">Manly et al., 2004;</ref><ref type="bibr" target="#b18">Pe'er et al., 2008</ref>). Many simple approaches to multiple testing correction such as the Bonferroni method fail to account for linkage disequilibrium (LD) among SNPs, which leads to an overly conservative P-value correction. The resulting loss of power matters increasingly because the number of genetic markers and the marker density both grow constantly (<ref type="bibr" target="#b11">Howie et al., 2009</ref>). Permutation-based corrections fully account for the correlation among SNPs caused by LD and therefore are considered the gold standard of multiple testing correction in GWAS. They provide the highest statistical power among the procedures controlling * To whom correspondence should be addressed. family wise type I error risk. On the other hand, they require a lot more computational effort than the simple Bonferroni adjustment. For example, running a large number of permutations (~100K) for large-scale marker sets using standard software such as PLINK (<ref type="bibr" target="#b19">Purcell et al., 2007</ref>) can take up to several years of computing time (<ref type="bibr" target="#b6">Gao et al., 2008;</ref><ref type="bibr" target="#b9">Han et al., 2009</ref>). Progress has been made by the introduction of accelerated permutation procedures (<ref type="bibr" target="#b1">Browning, 2008;</ref><ref type="bibr" target="#b12">Kimmel and Shamir, 2006</ref>). The software PRESTO (<ref type="bibr" target="#b1">Browning, 2008</ref>) allows to perform moderate numbers of permutations (1000 to 10 000) for large datasets within a day or more and thus already the calculation of adjusted P-values in the region of 10 −3 to 10 −4. Nevertheless, there has been an ongoing demand for faster methods to compute genome-wide adjusted P-values, which has motivated the development of various approximation algorithms over the last years. A first alternative approach is based on the Bonferroni correction adjusting the testing threshold for M markers being tested to α = α/M.<ref type="bibr" target="#b2">Cheverud (2001)</ref>suggested to replace the 'Bonferroni M' by an effective number of independent tests (M eff ), which is derived from eigenvalues of the marker's correlation matrix. In this way, information about the correlation between SNPs is used and therefore results in a less conservative P-value adjustment than Bonferroni; that is, M eff &lt; M. Based on the initial idea, several authors proposed different ways of estimating M eff (<ref type="bibr" target="#b6">Gao et al., 2008;</ref><ref type="bibr" target="#b13">Li and Ji, 2005;</ref><ref type="bibr" target="#b16">Moskvina and Schmidt, 2008;</ref><ref type="bibr" target="#b17">Nyholt, 2004</ref>). However, in general it still yields conservative estimates in comparison with the permutation test (<ref type="bibr" target="#b9">Han et al., 2009</ref>). Another alternative framework is based on the multivariate normal distribution (MVN), which is used as an approximation of the unknown distribution of the marker set. Lin (2005) and Seaman and Müller<ref type="bibr" target="#b21">Myhsok (2005)</ref>were the first to propose MVN-based methods for multiple testing adjustment in association studies, followed by Conneely and Boehnke (2007) who increased its efficiency by numerically computing the asymptotic MVNs (<ref type="bibr" target="#b8">Genz, 1992</ref>), instead of deriving them by simulation. However, due to the numerical limitations of integrating high-dimensional MVNs, these approaches require a block-wise strategy in large marker sets, which does not consider correlations between disjoint marker blocks. To answer this problem,<ref type="bibr" target="#b9">Han et al. (2009)</ref>proposed a resamplingbased method called SLIDE, which uses a sliding window locally accounting for the inter-marker correlation. However, both accuracy and computational efficiency depend on the size of the window; that is, extending the window increases accuracy but at the same time results in a considerable loss of computational efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R.Pahl and H.Schäfer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Flow chart</head><p>presenting the basic algorithm structure. The key optimization modules are placed in the center lane (blue). For each marker, one of the three methods is chosen at runtime to be used for permutation. Altogether, numerous approximation methods have been proposed over the last few years steadily improving accuracy, but some concerns still remain. First of all, there is no agreement about a standard alternative method. Second, it is usually left to the user to set one or more method-specific parameters, such as setting the window size in SLIDE, which can complicate application for nonexpert users, especially since an optimal parameter choice frequently depends on the structure of the data at hand. Finally, alternative methods usually cannot cope with missing values and hence require additional imputation methods. In contrast permutation tests are not only the gold standard but also well known and easily applied independently from the underlying data. Thus, it is desirable to make permutation tests feasible for genome-wide application, which is done with the present article. We propose an optimized permutation test algorithm called PERMORY, which in terms of runtime performance is comparable to the fastest available approximation methods. Since our algorithm does not involve any kind of approximation, it provides exact results identical to those of a standard permutation test. Based on a standard permutation test, our algorithm includes several modules that exploit certain properties of genetic data such as high correlations between markers. The basic structure of our algorithm is depicted in<ref type="figure">Figure 1</ref>. In the following Section 2, we introduce some general notation followed by a description of the algorithms behind the most important modules (<ref type="figure">Fig. 1</ref>) and how they affect computational speed. In Section 3, we compare our method with existing permutation-based implementations as well as state-of-the-art alternative methods. We particularly consider different types of SNP chips and demonstrate that PERMORY performs especially well for high-density marker sets. We also provide examples of application to real data.</p><formula>Case r 0 r 1 r 2 R Control s 0 s 1 s 2 S Total n 0 n 1 n 2 N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">General notation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Familywise error rate</head><p>The approach to multiple testing correction used throughout this article relies on controlling the familywise error rate (FWER)—also known as the overall type I error rate—the probability of observing one or more false positives in a family of tests (<ref type="bibr" target="#b23">Westfall and Young, 1993</ref>). In particular, we consider the common frequentists approach of controlling the FWER in the strong sense such that FWER ≤ α for some significance level α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Statistical model</head><p>For a marker with two alleles, a genotype is defined as the number of minor alleles, yielding a set of three possible genotypes ={0,1,2}. Here, we do not treat missing genotype values for sake of simplicity, but the methods presented in this article can be readily extended to incorporate them as well. 1 In a standard case– control association study involving N individuals—at each marker—each individual is genotyped with one of the three genotypes. For each marker, we can construct a 2×3 contingency table (<ref type="figure" target="#tab_1">Table 1</ref>). To detect a disease marker, we compare genotype frequencies between affected (cases) and nonaffected (controls) individuals. A commonly applied test statistic is based on Armitage´s trend test (<ref type="bibr" target="#b0">Armitage, 1955</ref>), which can be written as (<ref type="bibr" target="#b20">Sasieni, 1997</ref>)</p><formula>T 2 (x) = N N r i x i −R n i x i 2 R N −R N n i x 2 i − n i x i 2 (1)</formula><p>where x i = i, i = 0,1,2, denote the scores of the three genotypes, and r i and n i denote the genotype counts in the cases and the pooled sample, respectively (<ref type="figure" target="#tab_1">Table 1</ref>). Basically any test statistic suitable for analyzing case–control SNP data can be calculated from these counts. Let g ∈ N , be a vector (or array) of length N that contains the genotype data of a marker for all individuals coded as 0,1,2 for the number of minor alleles. If g is stored in terms of an array g<ref type="bibr">[1:N]</ref>in the computer memory, the entire genotype information is extracted by accessing each of the N cells of g. Thus, calculating the test statistic for a marker basically consists of two steps:</p><p>(1) determine genotype frequencies by accessing all N cells of the corresponding array g<ref type="bibr">[1:N]</ref>; and</p><p>(2) conduct arithmetic operations to compute the test statistic<ref type="bibr">[</ref>When using a permutation test, each permutation of the case–control status modifies the genotype counts in the contingency table so that both steps have to be done over and over again. Due to the fact that GWAS involve large populations of up to several thousand individuals, Step 1 is much more time consuming than Step 2 so that accelerating the permutation test means to improve the way of determining the genotype frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 2095 2093–2100</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A fast LD-exploiting permutation test algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Permutation matrix</head><p>All algorithms in the present article require the permutations to be stored in advance. Formally, let P ∈ {0,1} K×N be the K ×N permutation matrix that encodes K permutations of the diseases status and i ∈ I = {1,2, ..., N} the index for an individual: P<ref type="bibr">[k,i]</ref>= 1, i-th individual of k-th permutation is affected 0, not affected</p><formula>(2)</formula><p>In our software implementation, large numbers of permutations are processed in blocks of 10K permutations, which costs a little extra time due to repeated file reading but has the added benefit that PERMORY usually does not need more than 1 GB of RAM (tested successfully for 10 9 permutations using 3K cases and 3K controls.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dummy code and bit arithmetic</head><p>Different software packages internally use different data formats for keeping the genotype data. Often the data are stored in integer or Boolean typed arrays, which is not ideal with respect to memory consumption. Here, we propose the usage of binary dummy codes, one for each genotype except the common genotype. Formally, for some genotype array g, let U g ∈ {0,1} (||−1)×N be the dummy coded genotype matrix:</p><formula>U g [γ,i] = 1, γ = g[i] 0, else (3)</formula><p>We omit the index for the common genotype because its frequency can be derived via the marginals of the contingency table (<ref type="figure" target="#tab_1">Table 1</ref>). Thus, the row index γ starts at 1. Since here ={0, 1, 2}, U consists of just two rows. Internally each row of U is stored as a bitset, reducing the required memory significantly as compared with integer arrays. While some other programs already use economic ways of storing the genotype data, for example, by 'packing' several genotypes into each internal word of data, our approach additionally enables efficient bit arithmetics on the bitsets. The pooled genotype frequencies n γ (<ref type="figure" target="#tab_1">Table 1</ref>) for some array g now can be derived as n γ = N i=0 U g<ref type="bibr">[γ,i]</ref>by simply counting bits, which is done a lot faster than summing up integer arrays. A little extra work is required, because we are not interested in the pooled frequencies n γ but rather in the case frequencies r γ ; that is, we must only count the 'case-bits' but not the 'control-bits'. An efficient approach is to set the 'control-bits' to '0' before the bit counting takes place. For this purpose each permutation array 2 P<ref type="bibr">[k, * ]</ref>[<ref type="bibr">Equation (2)</ref>] is applied as a bit mask using the logical AND conjunction, in this way blanking out the 'control bits' in the dummy bitset. The corresponding pseudo-code can be outlined as follows:</p><p>Listing 1 Permutation using bit arithmetics</p><formula>f o r ( k i n 1 :K) { / / f o r each p e r m u t a t i o n f o r ( γ i n 1 : 2 ) { / / f o r each g e n o t y p e r γ = BITCOUNT(U[ γ , * ] AND P[k , * ] ) ; } }</formula><p>An example of the basic bit arithmetic algorithm is presented in<ref type="figure" target="#fig_3">Figure 2A</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Genotype indexing</head><p>Let d ∈ {0,1} N be a vector encoding the disease status for R cases and S = N −R controls</p><formula>d [i] = 1</formula><p>, i-th individual is affected 0, else hence N i=1 d<ref type="bibr">[i]</ref>= R. As a matter of fact, any permutation d of d does not change the number of cases (i.e. N i=1 d<ref type="bibr">[i]</ref>= R) so that n 0 ,n 1 ,n 2 ,R,S and N (<ref type="figure" target="#tab_1">Table 1</ref>) are all invariant with respect to permutations of d. Furthermore, the s i for i = 0,1,2 can be derived as s i = n i −r i and r 0 as r 0 = R−r 1 −r 2 (<ref type="figure" target="#tab_1">Table 1</ref>). Thus, for any permutation of the genotype data, determining just the genotype counts r 1 and r 2 is entirely sufficient for the construction of the corresponding 2×3 contingency table. Browning (2008) was the first to use this property; instead of checking the disease status of every single individual, he basically considered only the heterozygous and least common homozygous genotypes and determined how many of them referred to affected individuals, thereby obtaining r 1 and r 2. Formally, he treated the index sets</p><formula>X g γ = i ∈ I : g[i] = γ and (4) D = i ∈ I : d [i] = 1 (5)</formula><p>That is, X g γ for γ = 1,2 contains all indices i of the data array g that belong to a specific genotype γ while D contains all i that are marked affected. The genotype frequencies in cases are then determined as cardinalities of the pairwise conjunctions of these sets:</p><formula>r 1 = X g 1 ∩D , r 2 = X g 2 ∩D . Listing 2</formula><p>presents both the standard and the corresponding genotype indexing approach for determining the genotype counts of a genotype array. Note that here as well as in the following listings we just consider a single genotype array to simplify matters.</p><formula>X γ ) { / / i i n 1 : l e n g t h ( X γ ) r γ += d [ X γ [ i ] ] ; } }</formula><p>A graphical example of the genotype indexing approach is given in<ref type="figure" target="#fig_3">Figure 2B</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Transposed permutation</head><p>In theory, the genotype indexing algorithm should compute in (|X 1 |+ |X 2 |)/N = (n 1 +n 2 )/N the time than the standard approach, but in practice this is not the case due to compiler and low-level optimization. The standard approach allows for a much better optimization in this regard because accessing all N cells in the genotype array g<ref type="bibr">[1:N]</ref>is implemented as a loop with a strictly monotonically increasing index. In contrast, the marker indices in the genotype indexing approach are not monotonic and only known at runtime. To answer this problem, we modify the inner permutation loop such that it no longer depends on the way the genotype frequencies are derived. First, consider the usual way of conducting all permutations in sequential order:</p><p>(1) Outer loop: consider permutation k (k = 1,...,K).</p><p>(2) Inner loop: derive the genotype frequencies for the permuted affection status.</p><p>(3) Next Permutation. Using our notation, the permutation matrix P is processed row by row. Second, consider processing P column-wise instead.</p><p>(1) Outer loop: consider individual i (i = 1,...,N).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R.Pahl and H.Schäfer</head><p>(2) Inner loop: count in how many of all permutations the individual is affected, that is, compute K k=1 P<ref type="bibr">[k,i]</ref>.</p><formula>(3) Next individual.</formula><p>Basically, the entire set of permutations now is processed individual by individual or, using our notation, P is transposed and then processed the usual way, which we therefore call 'transposed permutation'. As a result, the index of the sum in the inner loop has become monotonically increasing (i.e. k = 1,...,K) and genotype indexing in combination with transposed permutation (GIT) indeed requires just about (n 1 +n 2 )/N the time than the standard approach and therefore is very effective for permutation of markers with low minor allele frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 3 Transposed permutation and genotype indexing combined</head><formula>f o r ( γ i n 1 : 2 ) { f o r ( i i n X γ ) { / / o u t e r l o o p f o r ( k i n 1 :K) { / / p e r m u t a t i o n ( i n n e r l o o p ) R[ k , γ ] += P[k , i ] ; } } }</formula><p>Note that we need to keep track of the resulting genotype frequencies separately for each permutation. For this purpose, we define R ∈ N K×2 0 as the K ×2 matrix of genotype frequencies resulting from K permutations where R<ref type="bibr">[k,1]</ref>and R<ref type="bibr">[k,2]</ref>correspond to r 1 and r 2 of the k-th permutation, respectively. At the end of the procedure (Listing 3), row R<ref type="bibr">[k, * ]</ref>can be used to construct the 2×3 contingency table of the k-th permutation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Reconstruction memoization</head><p>In computing, memoization 3 is a (machine-independent) strategy to speed up computer programs by avoiding the repeated calculation of results for previously processed inputs. A memoized function remembers the results, and subsequent calls with remembered inputs return the remembered result rather than recalculating it. That is, memoization is a means of lowering a function's time cost in exchange for space cost. As a matter of principle, a function can only be memoized if calling the function has the exact same effect as replacing that function call with its return value. Let (g,f ) be the distance between two genotype arrays g and f defined as</p><formula>g,f := N i=1 0, g[i]=f [i] 1, g[i] = f [i]</formula><p>which is the total number of different positions between both arrays. First, consider two markers with identical genotype arrays g = f , or (g,f ) = 0. Since a permutation of the disease status does not modify the genotype data itself, the genotype frequencies r 1 and r 2 of both markers will be pairwise identical for any permutation. With all r 1 and r 2 resulting from K permutations of g being stored in R g<ref type="bibr">[ * , * ]</ref>, we can therefore omit all permutations for f and instead set R f<ref type="bibr">[ * , * ]</ref>= R g<ref type="bibr">[ * , * ]</ref>, thus memoizing the case frequencies under all permutations for f. Second, assume g is equal to f except for one single genotype in some individual x (i.e. g<ref type="bibr">[x]</ref>= f<ref type="bibr">[x]</ref>and (g,f ) = 1). For each permutation in which the x-th individual is affected, for some genotype γ ∈{0,1,2}, there are six possible distinct pairs of genotypes and for each pair R f<ref type="bibr">[ * ,γ]</ref>can be constructed from R g<ref type="bibr">[ * ,γ]</ref>as shown in<ref type="figure" target="#tab_2">Table 2</ref>. Thus, in the second scenario, the case frequencies r 1 and r 2 for f can be almost completely memoized, requiring only one or two additional operations (<ref type="figure" target="#tab_2">Table 2</ref>) per permutation. For each permutation in which the x-th individual is not affected, hence x / ∈ D [Equation (5)], the r 1 and r 2 do not change at all so that simply</p><formula>R f [ * , * ] = R g [ * , * ].</formula><formula>0 1 R g [ * ,1]+1 R g [ * ,2] 0 2 R g [ * ,1] R g [ * ,2]+1 1 0 R g [ * ,1]−1 R g [ * ,2] 1 2 R g [ * ,1]−1 R g [ * ,2]+1 2 0 R g [ * ,1] R g [ * ,2]−1 2 1 R g [ * ,1]+1 R g [ * ,2]−1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a Provided the x-th individual is affected</head><p>It follows by induction that for any f = g the corresponding R f<ref type="bibr">[ * , * ]</ref>can be constructed from R g<ref type="bibr">[ * , * ]</ref>by sequentially applying the scheme from<ref type="figure" target="#tab_2">Table 2</ref>for the set of diverse individuals that can be expressed in terms of the dummy codes [Equation</p><p>(3)] as follows:</p><formula>Y γ,g,f := i ∈ I : U g [γ,i] = U f [γ,i]</formula><p>For each permutation, the number of operations that are needed to construct R f<ref type="bibr">[ * , * ]</ref>from R g<ref type="bibr">[ * , * ]</ref>is equal to Y1,g,f + Y2,g,f . All these operations are entirely independent from the particular texture of each permutation so that once the required operations are determined for two pairs of genotype data arrays, they can be repeatedly applied for arbitrary permutations. Since the overall procedure is not only solely based on memoization but also requires reconstruction, we call it the reconstruction memoization (REM) method. In the implementation of the REM method, we again make use of transposed permutation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 4 Permutation using the REM approach</head><formula>n i f (U f [ γ , i ] == 1) R f [ k , γ ] += P[k , i ] e l s e R f [ k , γ ] −= P[k , i ] } } }</formula><p>Note that in order to keep the implementation simple and efficient, we do not distinguish between affected and non-affected individuals. Instead, we just add zeros in the latter case.<ref type="figure" target="#fig_3">Figure 2C</ref>provides a schematic representation with an example of a single permutation, for which the case frequency r 1 is derived. The two presented genotype arrays differ at three positions {2,4,8}; that is, (g,f ) = 3, which implies three add/subtract operations per permutation. Basically (g,f ) and 2·(g,f ) are the upper and lower bound, respectively, of the required number of operations per permutation. For a set of candidate genotype arrays {g 1 ,...,g m }, we achieve the maximal amount of memoization by using the genotype array that is most similar to f. That is, for γ = 1,2 we search for an index ˘ ı such that</p><formula>g ˘ ı ,f = min i=1,...,m g i ,f (6)</formula><p>The determination of ˘ ı provokes some additional computational effort, but is implemented efficiently using the dummy codes because this way computing (g,f ) is reduced to computing the Hamming distance Ham(U g<ref type="bibr">[γ, * ]</ref>,U f<ref type="bibr">[γ, * ]</ref>) between binaries, which can be done via the XORfunction. In the final permutation test algorithm, we process the genotype data marker by marker and store the permutation results for each processed marker, thereby building a set of candidate genotype arrays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A fast LD-exploiting permutation test algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.1">Sliding tail</head><p>One last problem remains to be solved in order to apply REM to large-scale datasets. The REM method exchanges time for space, which in this case means to keep the permutation results R g ∈ N K×2 0 of processed markers in the limited working memory of the computer. In addition, the determination of ˘ ı [Equation (6)] gets increasingly expensive with the growing set of candidate genotype arrays. However, considering the fact that genotype data of closely related markers is often highly correlated, it follows that the desired ˘ ı, or at least one that provides a close to minimal distance<ref type="bibr">[Equation (6)]</ref>, is presumably found in the neighborhood of the marker in question. It is therefore sufficient to only keep the permutation results for markers that are located within a limited range relative to the considered marker. Formally, given a fixed range size c and assuming the markers to be treated in sequential order, for some genotype array g i , we consider just the set {g i−c ,...,g i−2 ,g i−1 } as the candidate range of genotypes to be used with the REM algorithm. Once the first c markers in the set have been processed, the range can be thought of as a sliding tail, keeping the data information of the last c markers. It is important to note that in order to benefit from the REM method using the sliding tail, the markers must be sorted in accordance with their genomic locations. In reality, c is chosen to be small in comparison with the number of permutations K, which makes the determination of ˘ ı relatively cheap. In our algorithm we set the default value to c = 100, which is basically adequate for any data situation. A smaller value (e.g. c = 25) might improve the performance when using a small number of permutations (like 1000) or with marker sets that show low inter-marker correlation. Likewise, a higher value (e.g. c = 200) favors a lot of permutations (&gt;100 000) and a very high marker density. The amount of improvement in either direction, however, is marginal at best, mainly because the most correlated markers are expected to be located very close to each other. In other words, a tail of size c = 100 covers the most correlated markers most of the time so that in practice tuning this value is probably of no use. On the other hand, it might make sense to tune that option in huge simulation studies where the computation might take several weeks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.2">Method choice</head><p>Both GIT and REM are most applicable for specific kinds of marker data. While the GIT method performs well with low minor allele frequencies, the REM method benefits from highly correlated markers. The computational performance of both methods hence varies with the particular marker at hand. In contrast, the performance of the bit arithmetic method solely depends on the number of the individuals and hence is constant over all markers. During computation, for each marker, we estimate the performance of the methods based on the characteristics of the marker at hand (i.e. minor allele frequency, similarity to neighbored markers) and accordingly choose the fastest method to perform all permutations for that marker (<ref type="figure">Fig. 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We compare our method with existing permutation-based software, namely PRESTO 1.0.1 (<ref type="bibr" target="#b1">Browning, 2008</ref>) and PLINK 1.06 (<ref type="bibr" target="#b19">Purcell et al., 2007</ref>) as well as alternative approaches, for which we select simpleM (<ref type="bibr" target="#b6">Gao et al., 2008</ref>) representing the methods using M eff and SLIDE 1.0.4 (<ref type="bibr" target="#b9">Han et al., 2009</ref>) representing the MVN framework, respectively. To the best of our knowledge, these two algorithms both represent the fastest and most accurate methods of their class. We do not treat the RAT software by<ref type="bibr" target="#b12">Kimmel and Shamir (2006)</ref>, which is based on importance sampling, because it was designed as a special application to adjust a single, preferably highly significant P-value, whereas here we are interested in simultaneously adjusting a wide range of P-values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Accuracy</head><p>We initially present an accuracy evaluation, which serves both as a recap of accuracy results for the alternative methods and as a proof of concept for the permutation-based algorithms. We follow (<ref type="bibr" target="#b9">Han et al., 2009</ref>) using a similar type of presentation and the same basic dataset, which is the chromosome 22 data (5563 SNPs) of the Type 2 diabetes (T2D) study (1928 cases + 2934 controls) as part of the Welcome Trust Case Control Consortium Phase I study (WTCCC, 2007). 4 We randomly shuffle case–control status and compute P-values 5 until we obtain a dataset with uncorrected Pvalues in the range of 10 −7 to 10 −5 (x-axis in<ref type="figure" target="#fig_5">Fig. 3</ref>). This forms) after case–control status has been (re-)allocated randomly to the individuals. For each sampling-based method, we use 1 M permutations to derive corrected P-values. Each point constitutes the relative adjustment error as the ratio of the adjusted P-value and the corresponding reference P-value derived by a permutation test using 100 M permutations. The shaded area represents the 95% confidence region that covers the relative sampling error regarding 1 M permutations; that is, each point within that area is considered an accurate adjustment. All permutation-based methods are colored gray because they are expected to stay within the confidence region of the permutation reference P-values. (*For simpleM the default PCA cutoff of 0.995 is used.) our basic dataset. Next we calculate adjusted P-values for this dataset using a permutation test with 100 million permutations, which results in adjusted P-values ranging from 0.00057 to 0.066. These P-values constitute the reference adjusted P-values for this dataset, which are compared with the P-values produced by PERMORY, PRESTO and PLINK, each with 1 M permutations, SLIDE with a windows size of w = 100 and 1 M samplings, and simpleM using its default settings, respectively. We assume a method is accurate if its adjusted P-values are close to the reference P-values. In<ref type="figure" target="#fig_5">Figure 3</ref>, we depict the relative error of the methods as ratios between adjusted and reference P-values. We also construct a confidence region in order to cover the relative sampling error, caused by the Monte Carlo approach (in contrast to exhaustive enumeration of all possible permutations) of the presented methods. 6 As expected, all permutation-based methods stay within the confidence region of the reference. The SLIDE curve is consistent with the results presented in<ref type="bibr" target="#b9">Han et al. (2009)</ref>as (for this dataset) it is nearly as accurate as the permutation test. Instead of simpleM,<ref type="bibr" target="#b9">Han et al. (2009)</ref>in their work used a similar program called Keffective, for which simpleM might be considered an improved version (<ref type="bibr" target="#b7">Gao et al., 2010</ref>). In our simulation, simpleM performs slightly better than Keffective did in the work of<ref type="bibr" target="#b9">Han et al. (2009)</ref>. However, it still exhibits a trend of increasingly conservative adjustment for less significant P-values,The corresponding confidence intervals for 10 6 permutations as indicated in<ref type="figure" target="#fig_5">Figure 3</ref>are (0.92, 1.08) and (0.99, 1.01), respectively. which is a consequence of the plain Bonferroni-like correction using just a single threshold (M eff ) for all markers. With the exception of simpleM, which is not based on sampling, the precision of the other methods in<ref type="figure" target="#fig_5">Figure 3</ref>can be controlled by the number of the applied permutations.<ref type="figure" target="#tab_3">Table 3</ref>illustrates how the confidence region would change in<ref type="figure" target="#fig_5">Figure 3</ref>if we had applied a different number of permutations. Particularly, the curve of the simpleM method would be covered by the confidence region if the simulation was based on &lt;10K permutations, at least for the range of the depicted P-values. This also shows that for increasingly smaller adjusted (or true) P-values, a decent number of permutations is required in order to achieve a high precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R.Pahl and H.Schäfer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Runtime performance</head><p>All computations were done on a 64 bit AMD 2.4 GHz CPU running Debian GNU/Linux v5.0. First, the runtime performance is presented for real data from the Welcome Trust Case Control Consortium Phase II (WTCCC2) study. The data consists of 5667 individuals genotyped on the 1.2 M Illumina chip. Particularly, we use the data from all 1 115 428 SNPs of the 22 autosomal chromosomes. We create a case–control dataset by randomly dividing the 5667 individuals into 2833 cases and 2834 controls and then compute corrected P-values using 1K, 10K, 100K and 1M permutations, respectively (<ref type="figure" target="#tab_4">Table 4</ref>). Note that the actual P-values have no impact on the performance results and are thus omitted. Since simpleM is not permutation based, its result is placed in the footnote of the table. The PLINK 7 software was not primarily constructed for permutation testing and therefore yields an impractical runtime result for this data set. Using 10K permutations, PRESTO 8 still would take about 31 h to analyze all 1.1M SNPs, while PERMORY finishes in just 3 h, which is comparable to both approximative methods SLIDE and simpleM (<ref type="figure" target="#tab_4">Table 4</ref>). Overall the runtimes of the permutation-based methods increases linearly with the number of permutations, and so does the precision. Basically, a precision of requires ~1// permutations (<ref type="bibr" target="#b12">Kimmel and Shamir, 2006</ref>). To determine the effect of different marker densities on the relative performance of our algorithm, we secondly create simulated datasets for three standard SNP chip sizes: 500K, 1M and 2.4M, the latter mimicking marker sets today already being routinely used in genetic meta-analysis studies. The 500K marker set consists of SNPs from the Illumina Human660W-Quad, the 1M of SNPs from the Illumina Human1M-Duo and the 2.4M of SNPsThe runtime of simpleM using default principal component analysis (PCA) cutoff of 0.995 is 3 h.from HapMap phase 2 (<ref type="bibr">International HapMap Consortium, 2007</ref>). The data are simulated with the software HAPGEN proposed by<ref type="bibr" target="#b22">Spencer et al. (2009)</ref>, which mimics LD patterns in human populations based on existing phased haplotype data. As suggested on the HAPGEN web site, we use phased data releases of the CEU population from HapMap (http://hapmap.ncbi.nlm.nih .gov/downloads/phasing/2007-08_rel22/phased/), along with the recommended recombination rate files (http://mathgen.stats.ox.ac .uk/wtccc-software/recombination_rates/). We create case–control data comprising 3K cases and 3K controls for each chip size and measure the runtimes of computing adjusted P-values using the different algorithms (<ref type="figure">Fig. 4</ref>). Since the limited genetic diversity in the HapMap samples could have potentially lead to overestimating the efficiency of the proposed method, we have used the recombination option (-r) of the HapGen software. 9 This approach seems to be valid since the runtime results of PERMORY</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 2099 2093–2100</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A fast LD-exploiting permutation test algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Software implementation</head><p>PERMORY is written in the C++ language and makes extensive use of the Boost C++ Library (www.boost.org). For future releases, multithreading support is planned to increase the efficiency of the software on multi-core CPUs. The name PERMORY was coined by the words permutation and memory, emphasizing the use of memoization in the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>Multiple testing adjustment is important for genetic data analysis but it has been computationally challenging to use the gold standard method, permutation tests. One can think of two general approaches to this problem: either accelerate the permutation procedure or take an efficient approach to compute approximation and improve its accuracy. In recent years, research primarily has focused on the latter approach. We employed the former and have developed a permutation algorithm optimized for use with genetic data. Our algorithm not only presents a notable improvement over existing permutation test implementations but even can compete with the fastest alternative methods. We showed that our algorithm is also well equipped for the analysis of increasingly denser and larger marker sets including growing sample sizes. PERMORY hence relieves the computational burden of permutation testing on a Page: 2100 2093–2100</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R.Pahl and H.Schäfer</head><p>genome-wide scale, for faster or more accurate determination of genome-wide P-values, respectively. It also extends application in research, for example, enabling more extensive simulation studies using permutation. In the present article, we have covered genotypic trend tests for bi-allelic markers and binary traits. The PERMORY software at this point (version 0.4.0) also supports allelic tests and we plan to integrate support for multi-allelic markers in a future release. Extending the algorithm to the analysis of data with quantitative phenotypes and multiple measured phenotypes should be possible but adds a level of complexity to both the algorithm and the software implementation and therefore is subject of further research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Equation (1)].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>[15:</head><figDesc>11 30/7/2010 Bioinformatics-btq399.tex] Page: 2096 2093–2100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>[15:</head><figDesc>11 30/7/2010 Bioinformatics-btq399.tex] Page: 2097 2093–2100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Algorithm schemes of optimization modules. Genotype case frequencies r 1 and r 2 are computed for a data array containing eight genotype entries using (A) bit arithmetics and (B) genotype indexing. (C) The case frequency r 1 is derived for a second data array based on the result of the first array.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.3.</head><figDesc>Fig. 3. Accuracy evaluation of several P-value correction methods. We analyze the WTCCC1 T2D data (chromosome 22) after case–control status has been (re-)allocated randomly to the individuals. For each sampling-based method, we use 1 M permutations to derive corrected P-values. Each point constitutes the relative adjustment error as the ratio of the adjusted P-value and the corresponding reference P-value derived by a permutation test using 100 M permutations. The shaded area represents the 95% confidence region that covers the relative sampling error regarding 1 M permutations; that is, each point within that area is considered an accurate adjustment. All permutation-based methods are colored gray because they are expected to stay within the confidence region of the permutation reference P-values. (*For simpleM the default PCA cutoff of 0.995 is used.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig</head><figDesc>Fig. 4. Runtimes for differently sized marker sets. We consider three different marker sets consisting of 500K, 1M and 2.4M SNPs, respectively. For each marker set, we simulate a dataset of 3K cases + 3K controls and measure the runtimes required to compute adjusted P-values. In contrast to all other algorithms, the runtime of PERMORY does not increase in proportion to the number of SNPs, demonstrating the fact that the optimization techniques applied in PERMORY are particularly effective for high-density marker sets. Extrapolated runtimes of PLINK (omitted in the figure) are 43, 88 and 215 days, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1. Genotype distribution of a marker in a case–control study</figDesc><table>Genotype 

0 
1 
2 
Total 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2. Relation between case frequencies of two genotype data arrays that differ in exactly one (affected) individual x</figDesc><table>Genotype pair 
Genotype case frequency a 

g[x] 
f [x] 
R f [ * ,1] 
R f [ * ,2] 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>f o r ( γ i n 1 : 2 ) { R f [ * , γ ] = R g [ * , γ ]</figDesc><table>/ / s t a r t from R g 
f o r ( i i n Y γ,g,f ) { / / f o r each d i v e r s e i n d i v i d u a l 
f o r ( k i n 1 :K) { / / f o r each p e r m u t a t i o </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>Table 3. Confidence intervals of the relative sampling error for the most extreme P-values of Figure 3, depending on the number of permutations P-value Number of permutations</figDesc><table>Unadjusted 
Adjusted 
10 5 
10 4 
10 3 

1.63e-07 
0.00057 
(0.75, 1.29) 
(0.38, 2.28) 
(0.04, 9.69) 
2.03e-05 
0.06610 
(0.98, 1.02) 
(0.93, 1.08) 
(0.78, 1.26) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 4.</figDesc><table>Runtime of analyzing 1.1 million SNPs over 5667 individuals of 
WTCCC2 data 

#Permutations 
PERMORY 
SLIDE a 
PRESTO 
PLINK 

1K 
0.5 h 
2.9 h 
3.2 h 
7.7 day 
10K 
3 h 
5 h 
31 h 
77 day b 
100K 
1.2 day 
1.0 day 
12.8 day 
2.1 years b 
1M 
12 day 
8 day 
128 day b 
21 years b 

a Using window size of w = 100. 
b Extrapolated value. 

</table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2093 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [15:11 30/7/2010 Bioinformatics-btq399.tex]</note>

			<note place="foot" n="1"> We interpret missing values as kind of a special genotype leading to an additional column in the contingency table. The PERMORY software handles missing values.</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="2"> By using a &apos;*&apos; in the first (or second) position inside the brackets (i.e. [*, ] or [ ,*]) we refer to the entire column (or row) of that matrix.</note>

			<note place="foot" n="3"> While memoization might be confused with memorization (because of the shared cognate), memoization has a specialized meaning in computing.</note>

			<note place="foot" n="4"> We downloaded the corresponding dataset (example1.slide.gz) from their web site http://slide.cs.ucla.edu. 5 The analysis includes all non-polymorphic SNPs.</note>

			<note place="foot" n="6"> The sampling error of the reference permutation using 100 M permutations is negligibly small and therefore ignored.</note>

			<note place="foot" n="7"> Command line options: plink-noweb-model-trend-mperm ... 8 Command line options: java-Xmx2G-jar presto.jar missing = ? test = t ...</note>

			<note place="foot" n="9"> Command line: hapgen-h haplotype-data.haps-l legend-file.leg-r mapfile.map-Ne 11418-snptest-n 3000 3000. in Figure 4 (1M SNPs) are similar to the real data runtime results in Table 4 (10K permutations). While the simpleM algorithm displays the fastest performance for the smaller chips, PERMORY shows the best performance for the 2.4M SNP chip, which is mainly attributable to the REM module (Fig. 2C). Overall the 2.4M chip exhibits higher inter-marker correlation and lower allele frequencies due to an increased number of rare variants, both of which is explicitly exploited by the REM and the GIT algorithms, respectively. Note that for SLIDE we use a window size of w = 250 with the 2.4M chip, considering the fact that if the marker density increases, SLIDE must adjust its window size 10 in order to maintain a nearly full accuracy in the correction of the P-values. Apart from the number of genetic markers, the number of individuals that are included in todays meta-analysis or upcoming GWAS is likely to increase as well. Since a permutation test shuffles the phenotype status, an increasing number of individuals might adversely affect the performance of permutation test procedures. For this reason, we also perform runtime tests for a large sample comprising 10K cases + 10K controls but overall the relative performances between the methods is not much different as compared with Figure 4 (results not shown). It is worth noting in this context that the running time for permutation testing basically can be considered independent of sample size if the null distribution for large samples is estimated by only a subset of the samples as proposed by Dudbridge (2006). Another basic approach to enhancing permutation tests consists of parallelization using more than one CPU. If p permutations are desired and n CPUs are available, we only need to perform p/n permutations on each CPU and combine the resulting P-values. In this case the total runtime is cut down linearly in the number of CPUs.</note>

			<note place="foot" n="10"> This choice is in accordance with the authors of SLIDE who suggest a window size of w = 100 and w = 1000 in scenarios of collecting a set of 1 million and 10 million SNPs, respectively.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank Thomas Gebhardt for his support with the MaRC Linux Cluster. We further thank Daniel F. Schwarz, Brandon Greene and the anonymous reviewers for their valuable suggestions and comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Tests for linear trends in proportions and frequencies</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Armitage</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="375" to="386" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Presto: rapid calculation of order statistic distributions and multiple-testing adjusted p-values via permutation for one and two-stage genetic association studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Browning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">309</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A simple correction for multiple comparisons in interval mapping genome scans</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Cheverud</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Heredity</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="52" to="58" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">So many correlated tests, so little time! rapid adjustment of p values for multiple correlated tests</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">N</forename>
				<surname>Conneely</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Boehnke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">11581168</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A note on permutation tests in multistage association scans</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Dudbridge</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1094" to="1095" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Estimation of significance thresholds for genomewide association scans</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Dudbridge</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gusnanto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="227" to="234" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A multiple testing correction method for genetic association studies using correlated single nucleotide polymorphisms</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Gao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="361" to="369" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Avoiding the high bonferroni penalty in genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Gao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="100" to="105" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Numerical computation of multivariate normal probabilities</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Genz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="141" to="150" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Rapid and accurate multiple testing correction and power estimation for millions of correlated markers</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Han</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000456</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A second generation human haplotype map of over 3.1 million SNPs</title>
	</analytic>
	<monogr>
		<title level="j">International HapMap Consortium Nature</title>
		<imprint>
			<biblScope unit="volume">449</biblScope>
			<biblScope unit="page" from="851" to="861" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A flexible and accurate genotype imputation method for the next generation of genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">N</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000529</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A fast method for computing high-significance disease association in large population-based studies</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kimmel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Shamir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="481" to="492" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Adjusting multiple testing in multilocus analyses using the eigenvalues of a correlation matrix</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Heredity</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="221" to="227" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">An efficient monte carlo approach to assessing statistical significance in genomic studies</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">Y</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="781" to="787" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Genomics, prior probability, and statistical tests of multiple hypotheses</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">F</forename>
				<surname>Manly</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="997" to="1001" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">On multiple-testing correction in genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Moskvina</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">M</forename>
				<surname>Schmidt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="567" to="573" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">A simple correction for multiple testing for single-nucleotide polymorphisms in linkage disequilibrium with each other</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Nyholt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="765" to="769" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimation of the multiple testing burden for genomewide association studies of nearly all common variants</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Pe &apos;er</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="381" to="385" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Plink: a tool set for whole-genome association and populationbased linkage analyses</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Purcell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="559" to="575" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">From genotypes to genes: doubling the sample size</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Sasieni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1253" to="1261" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Rapid simulation of p values for product methods and multiple-testing adjustment in association studies</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Seaman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Müller-Myhsok</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="399" to="408" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Designing genome-wide association studies: sample size, power, imputation, and the choice of genotyping chip</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">C A</forename>
				<surname>Spencer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000477</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">Resampling-Based Multiple Testing</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Westfall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Young</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Genome-wide association study of 14,000 cases of seven common diseases and 3,000 shared controls</title>
	</analytic>
	<monogr>
		<title level="m">Welcome Trust Case Control Consortium</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="661" to="678" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>