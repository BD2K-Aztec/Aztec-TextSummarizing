
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics Parallel content-based sub-image retrieval using hierarchical searching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">7 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Lin</forename>
								<surname>Yang</surname>
							</persName>
							<email>lin.yang@uky.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">Department of Biostatistics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Kentucky</orgName>
								<address>
									<settlement>Lexington</settlement>
									<region>KY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Xin</forename>
								<surname>Qi</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Biomedical Imaging and Informatics</orgName>
								<orgName type="institution" key="instit1">The Cancer Institute of New Jersey</orgName>
								<orgName type="institution" key="instit2">Rutgers University</orgName>
								<address>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Fuyong</forename>
								<surname>Xing</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">Department of Biostatistics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Kentucky</orgName>
								<address>
									<settlement>Lexington</settlement>
									<region>KY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tahsin</forename>
								<surname>Kurc</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Center for Comprehensive Informatics</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Joel</forename>
								<surname>Saltz</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Center for Comprehensive Informatics</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<forename type="middle">J</forename>
								<surname>Foran</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Biomedical Imaging and Informatics</orgName>
								<orgName type="institution" key="instit1">The Cancer Institute of New Jersey</orgName>
								<orgName type="institution" key="instit2">Rutgers University</orgName>
								<address>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimage informatics Parallel content-based sub-image retrieval using hierarchical searching</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="996" to="1002"/>
							<date type="published" when="2014">7 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt623</idno>
					<note type="submission">Received on June 8, 2013; revised on October 5, 2013; accepted on October 21, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The capacity to systematically search through large image collections and ensembles and detect regions exhibiting similar morphological characteristics is central to pathology diagnosis. Unfortunately, the primary methods used to search digitized, whole-slide histopathology specimens are slow and prone to inter-and intra-observer variability. The central objective of this research was to design, develop, and evaluate a content-based image retrieval system to assist doctors for quick and reliable content-based comparative search of similar prostate image patches. Method: Given a representative image patch (sub-image), the algorithm will return a ranked ensemble of image patches throughout the entire whole-slide histology section which exhibits the most similar mor-phologic characteristics. This is accomplished by first performing hierarchical searching based on a newly developed hierarchical annular histogram (HAH). The set of candidates is then further refined in the second stage of processing by computing a color histogram from eight equally divided segments within each square annular bin defined in the original HAH. A demand-driven master-worker parallelization approach is employed to speed up the searching procedure. Using this strategy, the query patch is broadcasted to all worker processes. Each worker process is dynamically assigned an image by the master process to search for and return a ranked list of similar patches in the image. Results: The algorithm was tested using digitized hematoxylin and eosin (H&amp;E) stained prostate cancer specimens. We have achieved an excellent image retrieval performance. The recall rate within the first 40 rank retrieved image patches is $90%. Availability and implementation: Both the testing data and source code can be downloaded from http://pleiad.umdnj.edu/CBII/ Bioinformatics/.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The exponential growth of imaging in biomedical research in the past decade has resulted in an increasing demand for efficient content-based image retrieval (CBIR) systems, which can detect and locate similar images in large-scale collections given a representative input query. Several state-of-the-art CBIR systems (<ref type="bibr" target="#b10">Lam et al., 2007;</ref><ref type="bibr">Rahman et al., 2011a, b;</ref><ref type="bibr" target="#b25">Zheng et al., 2003</ref>) have been designed to facilitate the execution of queries across separate images in support of diagnostic decisions. However, with the advent of whole-slide digital microscopy, which can generate high-resolution images rapidly, users of CBIR systems are often more interested in performing subregion searching and navigation (usually searching for an image patch exhibiting specific patterns or structures, containing an object). When provided with a region of interest (i.e. a query patch), a CBIR system should be able to return patches in a set of images that contain localized subregions exhibiting features similar to the query patch. This process is called content-based sub-image retrieval (CBSIR). An advantage of CBSIR is that the relevance of images is not limited by changes in specific viewpoint of the image or any background clutter that might be present (<ref type="bibr" target="#b11">Lampert, 2009</ref>). In practice, this approach makes it possible for pathologists and other investigators to select an area or object of interest within a digitized specimen. Recently, researchers have proposed methods for performing CBSIR on both natural and medical images. Luo and<ref type="bibr" target="#b13">Nascimento (2004)</ref>have introduced relevance feedback by applying a tile reweighting approach to assign penalties to tiles that compose database images and update the penalties for all retrieved images within each iteration. To perform region-of-interest (ROI) queries,<ref type="bibr" target="#b23">Vu et al. (2003)</ref>have presented a SamMatch framework-based similarity model. A hash table-based method for image object retrieval is presented in<ref type="bibr" target="#b9">Kuo et al. (2009</ref><ref type="bibr">). A partbased approach reported in Ke et al. (2004</ref>is used to address the sub-image retrieval problem using a local sensitive hashing searching algorithm. However, this strategy is time-consuming because of the large amount of features that need to be computed. To perform large-scale subregion retrieval, the method reported in<ref type="bibr" target="#b16">Philbin et al. (2007)</ref>uses approximate K-means and hierarchical K-means to build large vocabularies followed by a randomized tree-based quantization algorithm.<ref type="bibr" target="#b22">Tang et al. (2011)</ref>have incorporated a contextual synonym dictionary to the bag of visual words framework for large-scale visual object searches, where synonym words are used to describe visual objects with the same semantic meaning. A fast and efficient subwindow search (ESS) algorithm is presented in<ref type="bibr" target="#b12">Lampert et al. (2008)</ref>to localize regions of interest using a branch-and-bound scheme, which enables efficient maximization of a large class of classification functions over all possible sub-images. Building on the ESS algorithm, Lampert (2009) has introduced a new box set parameterization that is suitable for subregion retrieval and a two layer branch-and-bound scheme to localize objects in large image collections. Another subregion-driven image retrieval method can be found in Sivic and Zisserman (2009), which represents objects with a set of viewpoint invariant region descriptors and uses a spatial layout to rank the retrieved regions. In an attempt to address the challenges of subregion retrieval in medical image datasets, Simonyan et al. (2011) have developed a structured visual search method.<ref type="bibr" target="#b1">Cavallaro et al. (2011)</ref>have proposed a method for executing ROI queries in CT scans. This method first executes instance-based regression in combination with interpolation techniques to map scanned slides to the height of a human body model. Next, it finds a stable mapping while deriving a minimal amount of matching points. In this article, we have proposed a three-stage CBSIR system that is different from the previous efforts. We have designed a novel feature called a hierarchical annular histogram (HAH), which is proven to be not only accurate but also computationally efficient. The algorithm flowchart is shown in<ref type="figure" target="#fig_0">Figure 1</ref>. The workflow first performs hierarchical searching using HAH. It subsequently refines the search by computing a color histogram from eight equally divided segments of each square annular bin, which we refer to as the refined HAH. Finally, mean-shift clustering is executed to delineate densely overlapping candidates to generate the final content-based rank retrieval results. We also implemented a parallelization strategy for the CBSIR system based on the well-known master–worker style execution to scale CBSIR to large numbers of images. The master–worker strategy uses a demand-driven assignment scheme in which images are assigned by a master process to worker processes dynamically whenever workers become idle. This strategy is suitable for CBSIR, as search for images patches similar to the query patch can be performed independently. We have developed a unique extension to this basic strategy to take advantage of hierarchical searching to reduce the list of images to be processed when resources are limited and shared by other clients and applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SUB-IMAGE RETRIEVAL</head><p>CBSIR systems typically require users to select a representative image patch, an object or a pattern of interest within an image (<ref type="figure" target="#fig_1">Fig. 2a</ref>), and this selection is used as a query to retrieve images containing similar signatures from the database. The core of this process is the ability to compute features that accurately and objectively describe the characteristics of the images patches. For this purpose, we have developed a novel feature called HAH, which is described in detail in Section 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hierarchical annular histogram</head><p>Given a query image patch (<ref type="figure" target="#fig_1">Fig. 2a</ref>), the algorithm first segments it into several closed bins with equal intervals as shown in<ref type="figure" target="#fig_1">Figure 2b</ref>. Next, a color histogram for each bin is computed, and all the histograms are concatenated to form a single histogram, HAH. The HAH has several nice properties: (i) the metric is scale and rotation invariant; (ii) it captures spatial configuration of image local features; and (iii) it is suitable for hierarchical searching for sub-image retrieval. Using the HAH, the discriminative power of each image patch descriptor is significantly improved as compared with traditional color histograms, which does not consider the spatial configuration of image patches. Our experiments have shown that for medical images, image patches containing a range of different structures may show similar traditional color histogram distribution, but exhibit different HAH profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Three stage CBSIR system</head><p>The CBSIR system consists of three stages: hierarchical searching, refined searching and mean-shift clustering. The hierarchical searching stage implements an iterative process that discards the least similar candidates within each iteration. The process begins by calculating the color histograms of the inner central bins for candidate patches and compares them with those of the query patch. Based on the calculated dissimilarity, it removes a certain percentage of candidates after the first iteration. In the second iteration, it only calculates the color histograms from the second central bin and deletes another set of candidates by computing the level of dissimilarity with the query patches histograms from the two inner bins. This process is conducted iteratively, and the final candidates that pass all the iterations are the image patches that are most similar to the query patch. To rank the candidates in each step, we define the similarity SðHðX q Þ, HðX r ÞÞ between query X q and candidate X r patches as follows:</p><formula>SðHðX q ðiÞ, Þ, HðX r ðiÞÞÞ ¼ 1 2 X i jHðX q ðiÞÞ À HðX r ðiÞÞj 2 HðX q ðiÞÞ þ HðX r ðiÞÞ ð1Þ</formula><p>where HðX q=r ðiÞÞ is the i-th bin of the HAH of the patch X q=r. A smaller 2 distance indicates strong similarity between the candidate and the query patch. The hierarchical searching procedure can greatly reduce the time complexity because it only computes one bin of HAH and potentially rejects a large portion of candidates at each iteration. As a result, the number of candidates passed onto the next step is reduced significantly.<ref type="figure" target="#fig_2">Figure 3</ref>illustrates the entire hierarchical searching procedure. In the refined searching stage, each annular bin is equally divided into eight segments (<ref type="figure" target="#fig_1">Fig. 2c</ref>), and a color histogram iscomputed in each segment and concatenated to generate a single histogram. The final candidates are chosen based on the similarity measure S defined in Equation (1). In the third stage, meanshift clustering, based on the algorithm by Comaniciu and Meer (2002), is applied to provide the final refinement of the search results. Because only a relatively small number of candidates are kept after the hierarchical searching stage, the refined searching process is not particularly time consuming. the image) to the master processor or, if preferred by the user, writes them to disk, when it completes processing the image. This demand-driven assignment of images to workers achieves better computational load balance across the worker processors. Because hierarchical searching may eliminate some image patches from further consideration, the cost of processing each image will vary, accordingly. If a static assignment of images to processors were used instead, it could result in significant load imbalance across the worker processors. On a parallel computation system, backend computation resources are typically accessed by multiple applications. If the hierarchical CBSIR were to be deployed as a service that could be accessed remotely, there could be requests from multiple clients concurrently. This would require that the backend resources be shared among those requests. It would be important to look for mechanisms to reduce resource usage, if possible, to be able to scale the service to larger number of clients and reduce long execution times for large image datasets. We have introduced a novel extension to the basic parallelization approach to leverage the hierarchical search stage in our CBSIR method to accomplish this goal as summarized later in the text. Instead of processing an image through all of the stages in the CBSIR workflow shown in<ref type="figure" target="#fig_0">Figure 1</ref>, a predetermined number of iterations of the hierarchical searching step are applied to the target image. The number of iterations could be provided by the client submitting the request or could be set as a system parameter in the service. After the predetermined number iterations have been executed, a similarity metric is computed and assigned to the image. At each iteration of the hierarchical searching step, each image patch, which is deemed sufficiently similar to the query patch by the algorithm, is assigned a similarity value. Depending on the specific application, the image similarity measure could be as follows:</p><p>(i) the number of image patches whose similarity values exceed a user-defined or systemdefined threshold or (ii) the average of similarity values of the image patches in the image. After similarity measures have been computed, the images are sorted based on the prescribed similarity values. The client could then choose a subset of the images for further processing through the full CBSIR workflow. We have prototyped this approach in a parallel implementation to evaluate its impact on execution times of a client request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation of sub-image retrieval functionality</head><p>The sub-image rank retrieval results were systematically evaluated using a prostate cancer dataset containing 96 whole-slide scanned prostate specimens. Each whole-slide scanned image contains 10 000 Â 10 000 pixels. All specimens had been prepared at the Department of Pathology and Laboratory Medicine and University of Pittsburgh Medical Center using standard hematoxlyin and eosin staining techniques for a set of cases representing the range of Gleason scores. Each specimen was digitized using a 40Â volume scan setting on a high-resolution Trestle/Zeiss MedMicro whole-slide imaging device (virtual microscope). The resulting images were stored in multitiled tagged image file format (TIFF) format on a redundant array of independent disks (RAID) storage system. All specimens used in these studies were de-identified using institutional review board (IRB)-approved protocols to make certain that they could not be traced back to patients. The data are mirrored at three different sites, two within Rutgers Cancer Institute of New Jersey and one that is housed within the Rutgers Robert Wood Johnson Medical School. To compare the performance of the proposed HAH and the three-stage CBIR system performance, we have compared our results with four widely used features for content-based image retrieval: laws moments, co-occurrence matrix (COOC), texture feature coding method (TFCM) and local binary patterns (LBP). Previous studies (<ref type="bibr" target="#b5">Foran et al., 2011</ref>) had shown that texture features can capture the underlying variations that exist in normal and cancer tissues. We chose to implement and compare these four features for this study because (i) they capture rotationand intensity-invariant features and are not sensitive to region of interest (window) size. (ii) All of these features that we compared are widely used in CBIR in recent literatures (<ref type="bibr" target="#b0">Akakin and Gurcan, 2012;</ref><ref type="bibr" target="#b2">Chen and Chua, 2001;</ref><ref type="bibr" target="#b4">Doyle et al., 2006;</ref><ref type="bibr" target="#b14">Naik et al., 2009;</ref><ref type="bibr" target="#b21">Takala et al., 2005;</ref><ref type="bibr" target="#b24">Zhao et al., 2012</ref>). Laws moments are simple texture measurements that are used to describe different textures. Local masks are generated to detect various types of image intensity distribution. The one dimensional image filtering masks are created to computer the energy of the texture and represented with a vector. The filters are designed to capture level, edge, spot, wave and ripple. Laws moments are used in<ref type="bibr" target="#b14">Naik et al. (2009)</ref>for image retrieval and classification. COOC (also called spatial gray-level dependence matrices) were first proposed by Haralick and Shanmugam (1973) and were based on the estimation of the intensity second-order joint conditional probability density functions for various distances and for four specified directions (0, 45, 90 and 135 ) between two pixels. Texture features calculated using the COOC quantify the distribution of gray-level values within an image. For this study, four texture features including contrast, correlation, energy and homogeneity were calculated from the COOC within the segmented ROIs from four specified directions within a 3 Â 3 local window. Contrast is a measure of the gray-level variation between pairs of image elements. Correlation is a measure of uniform and repeated structures. Energy is sensitive to image regions that have only a small number of intensity distribution patterns, and therefore it is an indicator of uniformity or smoothness. COOC is widely used in recent literatures for content-based image retrieval (<ref type="bibr" target="#b0">Akakin and Gurcan, 2012;</ref><ref type="bibr" target="#b4">Doyle et al., 2006</ref>). TFCM<ref type="bibr" target="#b7">Horng et al. (2002)</ref>is a coding scheme in which each pixel is represented by a texture feature number (TFN). The TFN of each pixel is generated based on a 3 Â 3 texture unit as well as the gray-level variations of its eight surrounding neighbor pixels. The TFNs are used to generate a TFN histogram from which texture feature descriptors are quantified. In this work, we calculated coarseness, homogeneity, mean convergence and variance. Coarseness measures drastic intensity change in the eight connective neighborhoods. Homogeneity measures the total number of pixels whose intensity has no significant change in the eight connective neighborhoods. Mean convergence indicates how closely the texture approximates the mean intensity within a texture unit. Variance measures deviation of TFNs from the mean. Code entropy, which measures the information content of coded TFNs, was also calculated, in four orientations 0, 45, 90 and 135. TFCM is used in Chen and Chua (2001) for image/video retrieval. The LBP method is a multiresolution approach for gray-scale and rotation-invariant texture extraction (<ref type="bibr" target="#b15">Ojala et al., 2002</ref>). The region of interest is separated into multiple windows and each pixel in the window is compared with its neighbors. If the center pixel value is bigger than its neighbor, it will be marked as '1' and otherwise it will be marked as '0'. The LBP histogram is computed within the window to describe the patterns. LBP was applied to extract rotation-invariant uniform patterns for each image. Within the segmented ROI, three different radii (R) of a circle with corresponding numbers (N) of local neighbors of center pixel for the circle were calculated using a multiresolution approach to gray-scale and rotation-invariant texture extraction based LBP. The radii (R) of circles used in the experiments and corresponding numbers (N) of local neighbors were R ¼ 1 and N ¼ 8; R ¼ 2 and N ¼ 12 and R ¼ 4 and N ¼ 16, respectively. LBP is widely used in recent literatures (<ref type="bibr" target="#b21">Takala et al., 2005;</ref><ref type="bibr" target="#b24">Zhao et al., 2012</ref>) for image retrieval. An example of sub-image ranked retrieval results using the proposed method is shown in<ref type="figure" target="#fig_5">Figure 4</ref>. In this experiment, one random image patch provided by a pathologist is fed into the algorithm. This patch represents a region of interest in digitized prostate cancer specimens and, the purpose is to locate similar image patches in the database. The right panel represents the ranked CBIR results. The top four image patches represent the most similar cases, whereas the bottom four image patches denote the most dissimilar cases. As one can tell, the top rank retrieval results are visually similar to the query patch. The accuracy of the ranked retrieval results was verified by a boardcertified surgical pathologist. To quantitatively compare the image content-based rank retrieval performance, we have conducted 100 queries and asked three pathologists to rank the top 200 image patches retrieved from the prostate cancer dataset that contains 96 whole-slide scanned images using different algorithms. The final groundtruth results, including the Gleason scores, were generated based on a majority voting from the three pathologists. The recall curve is used to evaluate the image content-based rank retrieval results. The recall rate R is defined as follows:</p><formula>R ¼ jsr À gtj jgtj ð2Þ</formula><p>where sr represents the retrieval results and gt represents the ground truth sub-image patches. The recall curves are calculated as a function of the number of retrieved image patches. If the computer-generated ranking of a retrieved image patch agrees with the human expert ranking, this image patch is counted as a correct result. Please note that as the number of retrieved image patches increases, R will increase to approach 100%. For a better retrieval algorithm, the value of R will rapidly approach to 100% with a relatively larger area under curve, which represents that the algorithm is able to identify similar cases in the first several retrieval results. The comparative recall curves using 10 randomly selected queries of a total 100 queries are shown in<ref type="figure" target="#fig_4">Figure 5</ref>. The comparative average recall curves over all 100 queries using five different algorithms (Laws, COOC, TFCM, LBP and the proposed HAH) are presented in<ref type="figure" target="#fig_7">Figure 6</ref>. It is obvious that the proposed method provides the most accurate recall curves that can correctly identify 90% of the content-related patches within the first 40 rank retrieval results compared with the human experts ground-truth rankings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation of parallel implementation</head><p>The performance of the parallel implementation is evaluated using the distributed memory computation clusters. This first set of experiments was carried out on a small cluster system,where each computation node has four 6-core CPUs. A dataset with 96 whole-slide scanned images and a single query patch was used in the experiments.<ref type="figure" target="#fig_8">Figure 7</ref>shows the execution time of hierarchical and nonhierarchical CBSIR for processing 96 whole-slide scanned images using different numbers of CPU cores. In this experiment, each image is a unit of task, and the number of CPU cores varies from 8 to 64 on eight computation nodes. The non-hierarchical CBSIR processes each image by scanning all image patches and computing similarity values for each patch, unlike the hierarchical CBSIR, which eliminates some of the image patches from further processing. As illustrated in<ref type="figure" target="#fig_8">Figure 7</ref>, the hierarchical searching algorithm takes much less time than the non-hierarchical version. These results show that one can achieve substantial computational benefits using the hierarchical searching approach in the proposed framework. The execution time decreases for both algorithms as more cores are used, as expected. Our results indicate that parallel processing can be efficiently used to dramatically decrease processing times and make the process of large-scale datasets feasible. The first set of experiments also shows that even when hierarchical CBSIR is executed on a parallel machine, the execution time for processing a large whole-slide scanned image dataset may be high—it took $2.3 h to process all 96 whole-slide scanned images on 64 CPU cores because we need to search all the potential image patches. As one can imagine, the number of candidates is huge due to the size of the whole-slide scanned digital slide. Even for a query image patch 100 Â 100, one whole-slide scanned image (10 000 Â 10 000) can generate one million candidates with only 10% overlap among candidates. In the next set of experiments, we investigate the use of the hierarchical searching step to reduce the number of images to be processed, as is described in Section 2. In these experiments we randomly selected 48 wholeslide scanned images and conduct the experiments using 8 computation nodes with 16 cores. We first executed the hierarchical searching step on all the images and then selected 16 images based on the similarity measures. The selected images are then processed using the full hierarchical CBSIR algorithm.<ref type="figure" target="#fig_6">Figure 8</ref>shows the execution time of the hierarchical searching step with different number of iterations (the first three columns one iteration, two iterations, three iterations in the figure) as well as processing 16 and 48 images on 16 cores. As is seen from the figure, the cost of the hierarchical searching steps increases as the number of iterations executed in that step increases, as expected. However, the cost of this step is still considerably small compared with processing all the images. The column (3 þ 16) shows the execution time of processing 16 images plus the cost of the hierarchical searching step with three iterations. When the hierarchical searching step is used to select a smaller subset of images for processing, the execution time can be reduced considerably. It took $5200 seconds for processing 16 images including the hierarchical searching step with three iterations compared with 11 800 s for processing all 48 images. The first set of experiments was performed using the MATLAB implementation of the CBSIR algorithm. MATLAB provides efficient functions and toolboxes that make easier to develop algorithms quickly and efficiently. However, MATLAB is not installed on many cluster systems. Hence, we developed a Java version of the hierarchical CBSIR algorithm and ported the parallel code to support the Java implementation. Like the MATLAB implementation, the parallel code calls the Java executable to execute the CBSIR workflow. The parallel code handles copying</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this article, we have presented the design and implementation of a content-based sub-image retrieval (CBSIR) and navigation framework and its parallel implementation. This framework uses a simple yet powerful hierarchical searching based on a novel feature call HAH to reduce the cost of extracting image patches from a large-scale, whole-slide scanned, high-resolution microscopy datasets with the purpose of seeking the most similar cases as the given query patch. We also presented its parallel implementation in details. Our results show that performance savings can be significant with the hierarchical CBSIR compared with non-hierarchical CBSIR because the hierarchical searching step can be leveraged to reduce the number of images to be analyzed using a user-defined similarity measure. The cost of the hierarchical searching step is small enough that substantial reduction in resource usage can be achieved when a subset of images are selected and processed, even when the cost of the hierarchical searching step is added to the overall execution time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. The algorithm flow chart of the proposed CBSIR system framework. The three stages include hierarchical searching, refined searching and final mean-shift clustering</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. The illustration of hierarchical annular histogram (HAH) and refined HAH. The red rectangles represent the hierarchical searching procedure. The black lines separate the image patch into eight segments for the refined searching step</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. The illustration of the proposed hierarchical searching using HAH. Within each step, a certain percentage of candidates will be discarded, and the final candidates that pass all the stages will be kept and refined in the final mean-shift clustering stage</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.5.</head><figDesc>Fig. 5. The precision-recall curves for 10 testing image patches</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. The sub-image content-based rank retrieval results. The left panel is the query image; the middle panel is the retrieval results representing the most similar cases. The right panel is the retrieval results representing the most dissimilar cases. The number 3, 4 and 5 correspond to different Gleason scores</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.8.HAH</head><figDesc>Fig. 8. Performance impact of using the hierarchical searching step to select a subset of images for analysis. The first three columns show the execution time of the hierarchical searching step with different number of iterations. The columns (processsing 16 images and processing 48 images) show the execution time of analyzing 16 and 48 images, respectively, using the hierarchical CBSIR. The column (3 þ 16) shows the execution time of analyzing 16 images plus the cost of the hierarchical searching step with three iterations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.6.</head><figDesc>Fig. 6. The average recall curve (the recall percentage over the number of retrieved image patches). The areas under the curve (AUCs) are also listed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.7.</head><figDesc>Fig. 7. Execution times in seconds of the hierarchical and non-hierarchical CBSIR algorithms for processing 96 images on a distributed memory cluster system. The number of CPU cores is varied from 8 to 64</figDesc></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Parallel content-based sub-image retrieval at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3"> PARALLEL EXECUTION The hierarchical CBSIR reduces the execution time required to conduct query searches significantly; however, processing large ensembles of images may still take a long time even when carried out on a high-end workstation. To address this computational challenge, we have engineered a solution based on a master– worker parallelization strategy for high-throughput processing of a set of images. We have chosen master–worker parallelization because similarity computations on image tiles or whole image can be carried out independently. This allows for multiple images or image tiles to be processed concurrently for any given query. Our implementation treats each image (or individual image tile, if the image has been partitioned) as the basic unit of processing. If an image is partitioned into multiple disjointed tiles, each tile needs to be padded in x-and y-dimensions by an amount equal to the x-resolution and y-resolution of the maximum query patch, respectively. This step is necessary to ensure that no patches matching the query patch are divided across tile boundaries. Using this strategy, one processor on the parallel machine is designated as the master processor, whereas the remaining processors constitute the worker processors. Each query patch is broadcast to all worker processors, whereas images are assigned to the worker processors dynamically using a demand-driven strategy. The master processor is responsible for receiving requests from the worker processors, selecting the next image in the image set and assigning it to one of the workers. When a worker becomes idle, it requests an image from the master. On receiving an image, the worker searches for patches in the image that either match or are similar to the query patch. The worker returns the list of matching/similar patches (i.e. their locations in</note>

			<note place="foot">L.Yang et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Content-based microscopic image retrieval system for multi-image queries</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">C</forename>
				<surname>Akakin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">N</forename>
				<surname>Gurcan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="758" to="769" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Region of interest quesries in CT scans</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cavallaro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international Conference on Advances in Spatial and Temporal Databases</title>
		<meeting>the 12th international Conference on Advances in Spatial and Temporal Databases</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="65" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A match and tiling approach to content-based video retrieval</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Chua</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Conference on Multimedia and Expo</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Mean shift: a robust approach toward feature space analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Comaniciu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Meer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A boosting cascade for automated detection of prostate cancer from digitized histology</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Doyle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Aided Intervention</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="504" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Image miner: a software system for comparative analysis of tissue microarrays using content-based image retrieval, high-performance computing, and grid technology</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Foran</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inf. Assoc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="403" to="415" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Textural features for image classification</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Haralick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">D</forename>
				<surname>Shanmugam</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Texture feature coding method for classification of liver sonography</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H</forename>
				<surname>Horng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="33" to="42" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient near-duplicate detection and sub-image retrieval</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Ke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="869" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Query expansion for hash-based image object retrieval</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kuo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Content-Based Image Retrieval for Pulmonary Computed Tomography Nodule Images</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lam</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SPIE Medical Imaging</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">Detecting objects in large image colletions and vedios by efficient subimage retrieval</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lampert</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="987" to="994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Beyond sliding windows: object localization by efficient subwindow search</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lampert</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Content-based sub-image retrieval using relevance feedback</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Luo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Nascimento</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia Databases</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="2" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">A boosted distance metric: application to content based image retrieval and classification of digitized histopathology</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Naik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proccedings of</title>
		<meeting>cedings of</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ojala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">Object retrieval with large vocabularies and fast spatial mathching</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Philbin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Bag-of-features basd medical image retrieval via multiple assignemnt and visual words weighting</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Rahman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A learning-based similarity fusion anf filtering approach for biomedical image retrieval using SVM classification and relevance feedback</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Rahman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="640" to="646" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Immediate structured visual search for medical images</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Simonyan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: MICCAI. pp</title>
		<imprint>
			<biblScope unit="page" from="288" to="296" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient visual search of vedios cast as text retrieval</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sivic</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Zisserman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Patten Ana. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="591" to="606" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Block-Based Methods for Image Retrieval Using Local Binary Patterns</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Takala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Scandinavian Conference on Image Analysis</title>
		<meeting>. 14th Scandinavian Conference on Image Analysis</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="882" to="891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Contextual synonym dictionary for visual object retrieval</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Tang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="503" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Image retrieval based on regions of interest</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Vu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1045" to="1049" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Rotation-invariant image and video description with local binary pattern features</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tran. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1465" to="1477" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Design and analysis of a content-based pathology image retrieval system</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Zheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="245" to="255" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Execuuon Time (seconds) Number of CPU Cores Fig. 9. Scalability of the hierarchical CBSIR when the number of query images is increased from 64 to 372 as the number of processing cores is increased from 32 to 186</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>