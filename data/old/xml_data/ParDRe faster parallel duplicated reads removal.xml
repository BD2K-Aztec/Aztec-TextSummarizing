
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ParDRe: faster parallel duplicated reads removal tool for sequencing studies</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Jorge</forename>
								<surname>Gonz Alez-Domínguez</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Grupo de Arquitectura de Computadores</orgName>
								<orgName type="institution">Universidade da Coruñ a</orgName>
								<address>
									<addrLine>Campus De Elviñ a</addrLine>
									<postCode>15071</postCode>
									<region>A Coruñ</region>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Bertil</forename>
								<surname>Schmidt</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Parallel and Distributed Architectures Group</orgName>
								<orgName type="institution">Johannes Gutenberg University Mainz</orgName>
								<address>
									<postCode>55128</postCode>
									<settlement>Mainz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ParDRe: faster parallel duplicated reads removal tool for sequencing studies</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw038</idno>
					<note type="submission">Received on 25 November 2015; revised on 5 January 2016; accepted on 17 January 2016</note>
					<note>Sequence analysis Associate Editor: John Hancock *To whom correspondence should be addressed.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>Contact: jgonzalezd@udces</keywords>
			</textClass>
			<abstract>
				<p>Current next generation sequencing technologies often generate duplicated or near-duplicated reads that (depending on the application scenario) do not provide any interesting biological information but can increase memory requirements and computational time of downstream analysis. In this work we present ParDRe, a de novo parallel tool to remove duplicated and near-duplicated reads through the clustering of Single-End or Paired-End sequences from fasta or fastq files. It uses a novel bitwise approach to compare the suffixes of DNA strings and employs hybrid MPI/multithreading to reduce runtime on multicore systems. We show that ParDRe is up to 27.29 times faster than Fulcrum (a representative state-of-the-art tool) on a platform with two 8-core Sandy-Bridge processors. Availability and implementation: Source code in C þþ and MPI running on Linux systems as well as a reference manual are available at https://sourceforge.net/projects/pardre/</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The progress of Next Generation Sequencing (NGS) technologies has led to large datasets that are used in a wide range of bioinformatics applications. Preprocessing of NGS datasets is often required to either reduce their sizes or improve data quality. One such preprocessing step is the removal of duplicated and near-duplicated reads (<ref type="bibr" target="#b4">Zhou and Rokas, 2014</ref>). There are two approaches to remove these type of reads: mapping-based and de novo strategies. The first approach initially maps the reads to a reference genome and discards those reads that are aligned to the same position (<ref type="bibr" target="#b2">Pireddu et al., 2011</ref>). Unfortunately, it requires a complete genome as reference, which is not always available. The de novo approach only needs the NGS input data and has gained attention in recent years. Examples of de novo tools include FastUniq (<ref type="bibr" target="#b3">Xu et al., 2012</ref>) (not able to remove near-duplicated reads), Fulcrum (<ref type="bibr" target="#b0">Burriesci et al., 2012</ref>) (parallelized for multicore and distributed systems with MapReduce) and G-CNV (<ref type="bibr" target="#b1">Manconi et al., 2015</ref>) (parallelized for CUDA-enabled GPUs). In this paper we describe ParDRe a fast de novo tool to remove duplicated and near-duplicated reads with support for both SingleEnd and Paired-End datasets. ParDRe uses a novel bitwise approach to compare DNA strings and exploits the computational power of current multicore CPUs by employing both multithreading and Message Passing Interface (MPI). Mutithreading support is part of all compilers that follow the C þþ11 standard while there exist many MPI open public compilers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Implementation</head><p>ParDRe is based on the prefix-clustering approach (<ref type="bibr" target="#b0">Burriesci et al., 2012;</ref><ref type="bibr" target="#b1">Manconi et al., 2015</ref>), where the first l bases of a read are considered the prefix. The procedure starts by clustering all reads according to their prefix. Reads with the same prefix are stored in the same cluster and each MPI process is in charge of different clusters. All processes read the input file in parallel with efficient MPI I/O routines. For each read the processes apply a hash function to theprefix that returns a value h. If h mod P (P denotes the number of processes) is equal to the process ID, it stores the read in the corresponding cluster. Otherwise, it discards the read and continues with the next one. Once a process has finished the clustering, it compares the suffixes of the reads that belong to the same cluster. Three optimization techniques have been applied to this step. First, instead of comparing all possible pairs of reads within the cluster, we compare the first read to all other reads. We save the calculated number of mismatches for each read in an array dist. Subsequently, we only compare the suffixes of those reads i, j for which jdist<ref type="bibr">[i]</ref>À dist<ref type="bibr">[j]</ref>j is less equal than the number of allowed mismatches, as otherwise we can directly conclude that reads i and j are not similar. The second optimization stores each base of the suffixes with a 4-bit encoding in an array of 64-bit integers (16 bases per array entry). Instead of comparing the suffix bases one by one, we use a novel approach that applies a bitwise XOR operation. This operation returns a 64-bit mask with exactly two bits equal to one for each mismatch. Then, we apply the popcount routine to count the number of bits equal to one. If the result divided by two is lower or equal than the number of allowed mismatches, one of the reads is removed. We keep the read with the highest average quality score among the mismatches. Finally, ParDRe allows to generate a second level of parallelization by creating several threads per MPI process, which analyze different clusters in parallel. The assignment of clusters to threads is performed through a dynamic distribution; i.e. once a thread finishes all the comparisons within one cluster, it looks for the next cluster of the process that has not been computed yet. The main advantage of the dynamic distribution is that the workload can adapt to the size of the clusters; i.e. threads analyze more clusters if they are smaller. However, this distribution requires thread synchronization to a list in shared memory that saves which clusters have already been analyzed. After all the clusters have been analyzed, each process writes the remaining reads into an intermediate output file (one intermediate file per process). Therefore, this read printing is performed in parallel. Once all processes have finished, ParDRe gathers the information of all the intermediate files into the final output (with OS routines to concatenate files) and deletes the intermediate files. It means that the output provided to the user is written into a unique file. All the configuration parameters (input and output files, prefix length l, number of allowed mismatches, number of threads per process, etc) are specified in the command line. An explanation of all the arguments, as well as installation and execution instructions, are included in the reference manual available with ParDRe.<ref type="figure" target="#tab_1">Table 1</ref>summarizes the runtime to remove near-duplicated reads of the dataset SRR921889 (named after its accession number in the NCBI sequence read archive) with 50 million reads of 100 bases each. We have used four different configurations. The accuracy of the prefix-clustering approach for near-duplicate removal has been analyzed in (<ref type="bibr" target="#b0">Burriesci et al., 2012;</ref><ref type="bibr" target="#b1">Manconi et al., 2015</ref>). We have also verified that ParDRe returns similar results to Fulcrum for those reads that do not contain N bases. Concretely, they detect the same pairs of duplicated reads but, among them, they might select a different one to discard. Therefore, our experimental evaluation focuses on the speed of the tools. Fulcrum is executed using one thread per core (16 threads on the Intel system and 64 threads on the AMD platform). Furthermore, two runtime values are measured for our tool in order to assess the performance improvement obtained by the use of MPI:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>(i) using only threads (one MPI process); and (ii) using the hybrid approach with the best combination of processes and threads. We also include in our table the runtime for G-CNV on an NVIDIA K20 GPU, obtained from (<ref type="bibr" target="#b1">Manconi et al., 2015</ref>). The selected configurations are the same as in the G-CNV reference in order to provide a fair comparison. The results show that ParDRe consistently outperforms Fulcrum. Firstly, our C þþ suffix comparison based on bitwise operations is faster than the Python implementation included in Fulcrum. Additionally, Fulcrum uses MapReduce for parallelization. Thus, it needs intermediate files to distribute the clusters among threads. ParDRe uses an efficient on-demand multithreaded implementation that only requires main memory and avoids the overhead of I/O operations. Moreover, the experimental results also show that launching MPI processes instead of only threads further improves performance. This is due to two reasons. On the one hand, as explained in Section 2, the efficient parallel MPI I/O routines allow us to parallelize the reading and clustering of the input dataset, as well as the writing of the results. On the other hand, the hybrid approach reduces the thread synchronization overhead to know which clusters have not been analyzed yet, but it still exploits all the available cores in the machine thanks to the MPI parallelization.. Furthermore, we can assert that ParDRe executed on both systems is also faster than G-CNV running on specialized hardware (an NVIDIA K20 GPU). Regarding the memory consumption, ParDRe requires less than 7GB in the worst case (for all tests in<ref type="figure" target="#tab_1">Table 1</ref>), while Fulcrum and G-CNV require 1.6 and 17.3 GB, respectively. Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Two multicore platforms, with two 8-core Intel Xeon E5-2660 Sandy-Bridge and four 16-core AMD Opteron 6272 processors, are used to compare the runtime of ParDRe and Fulcrum. Up to our knowledge, Fulcrum was the fastest available tool to remove duplicate reads that allows mismatches and exploits the computational power of CPU multicore systems. ParDRe is compiled with GCC v4.9.2 and OpenMPI v1.8.8 on the Intel machine, whereas GCC v4.8.1 and OpenMPI v1.6.5 are used on the AMD system. Fulcrum runs with Python v2.6.6 on both platforms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 1562 Bioinformatics, 32(10), 2016, 1562–1564 doi: 10.1093/bioinformatics/btw038 Advance Access Publication Date: 22 January 2016 Applications Note</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Experimental results for ParDRe and Fulcrum (v 0.43) removing near-duplicated reads of SRR921889 on two multicore platforms</figDesc><table>Two 8-core Intel Xeon E5-2660 Sandy-Bridge 
Four 16-core AMD Opteron 6272 
K20 GPU* 

Prefix 
length 

Num. 
Mis. 

Fulcrum 
runtime 

ParDRe 
threads 
runtime 

ParDre 
hybrid 
runtime 

Speedup 
Fulcrum 
runtime 

ParDRe 
threads 
runtime 

ParDre 
hybrid 
runtime 

Speedup 
G-CNV* 
runtime 

10</table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">J.Gonz alez-Domínguez and B.Schmidt at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Fulcrum: condensing redundant reads from highthroughput sequencing studies</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Burriesci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1324" to="1327" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">G-CNV: a GPU-based tool for preparing data to detect CNVs with read-depth methods</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Manconi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Bioeng. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">SEAL: a distributed short read mapping and duplicate removal tool</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Pireddu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2159" to="2160" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">FastUniq: a fast de novo duplicates removal tool for paired short reads</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Xu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Prevention, diagnosis and treatment of highthroughput sequencing data pathologies</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rokas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Ecol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1679" to="1700" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>