
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-scale automated identification of mouse brain cells in confocal light sheet microscopy images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Paolo</forename>
								<surname>Frasconi</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DINFO)</orgName>
								<orgName type="institution">Universit a di Firenze</orgName>
								<address>
									<postCode>50139</postCode>
									<settlement>Firenze, Italy</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ludovico</forename>
								<surname>Silvestri</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory">European Laboratory for Nonlinear Spectroscopy (LENS)</orgName>
								<orgName type="institution">Universit a di Firenze</orgName>
								<address>
									<postCode>50019</postCode>
									<settlement>Sesto Fiorentino</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Paolo</forename>
								<surname>Soda</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Integrated Research Centre</orgName>
								<orgName type="institution">Universit a Campus Bio-Medico di Roma</orgName>
								<address>
									<postCode>00128</postCode>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Roberto</forename>
								<surname>Cortini</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering (DINFO)</orgName>
								<orgName type="institution">Universit a di Firenze</orgName>
								<address>
									<postCode>50139</postCode>
									<settlement>Firenze, Italy</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Francesco</forename>
								<forename type="middle">S</forename>
								<surname>Pavone</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory">European Laboratory for Nonlinear Spectroscopy (LENS)</orgName>
								<orgName type="institution">Universit a di Firenze</orgName>
								<address>
									<postCode>50019</postCode>
									<settlement>Sesto Fiorentino</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Giulio</forename>
								<surname>Iannello</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Integrated Research Centre</orgName>
								<orgName type="institution">Universit a Campus Bio-Medico di Roma</orgName>
								<address>
									<postCode>00128</postCode>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large-scale automated identification of mouse brain cells in confocal light sheet microscopy images</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="587" to="593"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu469</idno>
					<note>BIOINFORMATICS Contact: paolo.frasconi@unifi.it Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Recently, confocal light sheet microscopy has enabled high-throughput acquisition of whole mouse brain 3D images at the micron scale resolution. This poses the unprecedented challenge of creating accurate digital maps of the whole set of cells in a brain. Results: We introduce a fast and scalable algorithm for fully automated cell identification. We obtained the whole digital map of Purkinje cells in mouse cerebellum consisting of a set of 3D cell center coordinates. The method is accurate and we estimated an F 1 measure of 0.96 using 56 representative volumes, totaling 1.09 GVoxel and containing 4138 manually annotated soma centers. Availability and implementation: Source code and its documentation are available at http://bcfind.dinfo.unifi.it/. The whole pipeline of methods is implemented in Python and makes use of Pylearn2 and modified parts of Scikit-learn. Brain images are available on request.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Understanding the cytoarchitecture of the mammalian central nervous system on a brain-wide scale is becoming a compelling need in neuroscience (<ref type="bibr" target="#b19">Kasthuri and Lichtman, 2007;</ref><ref type="bibr" target="#b38">Sporns et al., 2005</ref>). In fact, single-neuron projections often span through the whole encephalon (<ref type="bibr" target="#b25">Lichtman and Denk, 2011</ref>), supporting functional connection between anatomically distant regions. Therefore, charting cellular localizations and projections throughout the whole brain is a mandatory step to afford a comprehensive view of brain function. Many efforts are thus devoted to build cellular-resolution, brain-wide neuroanatomical atlases of the mouse brain (<ref type="bibr" target="#b3">Bohland et al., 2009;</ref><ref type="bibr" target="#b21">Kleinfeld et al., 2011;</ref><ref type="bibr" target="#b28">Oh et al., 2014</ref>). Such maps would eventually allow characterizing on a structural basis the physiology and pathology of the central nervous system at various stages, ranging from development to neurodegeneration. To map the structure of the mouse brain, in the past years several high-throughput imaging techniques have been developed. Electron microscopy coupled with automatic tissue sectioning has been exploited to reconstruct neuronal wiring with nanometric resolution (<ref type="bibr" target="#b5">Briggman et al., 2011;</ref><ref type="bibr" target="#b22">Knott et al., 2008</ref>); however, its use is still limited to small brain regions because the slow imaging rates makes whole-brain measurements impossible at the moment (<ref type="bibr" target="#b5">Briggman and Bock, 2011</ref>). On the other hand, optical methods have coarser resolution, but can be used to image the entirety of mouse brain (<ref type="bibr" target="#b29">Osten and Margrie, 2013</ref>). The three main optical approaches used to map mouse brain anatomy are micro-optical sectioning tomography (MOST) (<ref type="bibr" target="#b24">Li et al., 2010;</ref><ref type="bibr" target="#b26">Mayerich et al., 2008</ref>), serial two-photon tomography (STP) (<ref type="bibr" target="#b34">Ragan et al., 2012</ref>) and light sheet microscopy (LSM) (<ref type="bibr" target="#b20">Keller and Dodt, 2012</ref>). The former technique allows mouse brain reconstruction with high contrast and resolution in 3D, but imaging time can reach even 1 month for a single brain (<ref type="bibr" target="#b13">Gong et al., 2013</ref>). STP shows the excellent contrast and resolution characteristic of multiphoton microscopy, but it operates with rough axial sampling [1 m section every 50 m (<ref type="bibr" target="#b34">Ragan et al., 2012)</ref>] and to our knowledge no full sampling reconstruction of a whole mouse brain has been demonstrated with this technique. LSM, coupled with chemical clearing procedures to render the brain transparent (<ref type="bibr" target="#b0">Becker et al., 2012;</ref><ref type="bibr" target="#b8">Chung et al., 2013</ref>), permits reconstruction of the whole mouse brain with micron-scale resolution in a timescale ranging from hours to a few days (<ref type="bibr" target="#b11">Dodt et al., 2007</ref>). The contrast affordable with this latter method is usually lower than the one of MOST and STP, because of residual light scattering inside the cleared tissue. However, LSM currently is the only method allowing acquiring a significant number of samples with full 3D resolution. Furthermore, an implementation called confocal light sheet microscopy (CLSM) shows 100% contrast increase with respect to conventional LSM, allowing to distinguish neuronal somata in whole-brain tomographies (<ref type="bibr" target="#b37">Silvestri et al., 2012</ref>). In this technique, however, different fixation efficiencies within the whole organ and inhomogeneous optical clearing give rise to a large variability in contrast throughout the entire volume (as an example, three regions are shown at the top of<ref type="figure" target="#fig_3">Fig. 3</ref>). Because of this heterogeneity, na€ ıve segmentation or localization methods (e.g. thresholding) cannot be applied to analyze whole-brain datasets obtained with CLSM. The availability of advanced imaging techniques for whole brain mapping introduces the new challenge of extracting quantitative human-readable information from the data (<ref type="bibr" target="#b15">Helmstaedter et al., 2011</ref>). There exist several proposals for automatic localization or segmentation of cell bodies in 2D (<ref type="bibr" target="#b7">Buggenthin et al., 2013;</ref><ref type="bibr" target="#b27">Navlakha et al., 2013</ref>) and 3D microscopy (<ref type="bibr" target="#b12">Forero et al., 2010;</ref><ref type="bibr" target="#b23">LaTorre et al., 2013;</ref><ref type="bibr" target="#b33">Quan et al., 2013</ref>).<ref type="bibr" target="#b12">Forero et al. (2010)</ref>presented a method based on image filtering and object morphology analysis that automatically counts the number of dying cells in images of Drosophila embryos collected at the confocal microscope. The method was tested on small stacks of 130MVoxels and it attained a recall, precision and F 1 *To whom correspondence should be addressed. ß The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com of 0.98, 0.97 and 0.97, respectively (see Section 3.1.2 for definitions).<ref type="bibr" target="#b23">LaTorre et al. (2013)</ref>propose an algorithm for segmenting neuronal mouse cells in 3D images of somatosensory cortex of 14 day old rats collected using a confocal laser scanner. The method, which needs information obtained in a 2D segmentation stage, was tested on a volume containing, in total, 600–700 neurons belonging to three different cortical layers (15.4 MVoxels). This method achieved a recall, precision and F 1 ranging in (0.95, 0.99), (0.94, 0.95) and (0.95, 0.97), respectively.<ref type="bibr" target="#b33">Quan et al. (2013)</ref>presented a neuron soma localization method, based on a minimization problem, which was tested on an image dataset of brain coronal profile of transgenic fluorescence mice (2–10 weeks old) collected using a fluorescence MOST system. The size of tested stack was 1300 Â 1850 voxels (361 MVoxels) and the algorithm localized $2500 neurons with a recall of 0.88. In this article, we address the two major challenges that arise when attempting to perform information extraction from CLSM images: large datasets, and significant contrast heterogeneity. A mouse brain has a volume of the order of 1 cm 3 , yielding image sizes in the TeraByte scale at the micron-resolution. In these cases, the only alternative to the massive use of manwork [as in (<ref type="bibr" target="#b5">Briggman et al., 2011</ref>)] is the development of fully automatic tools. To achieve this goal, the inherent contrast variability in CLSM requires sufficient robustness with respect to the parameters of the extraction algorithms: fine-tuning of parameters on different regions [as suggested e.g. by<ref type="bibr" target="#b33">Quan et al. (2013)</ref>] may be practically unfeasible with images containing hundreds of thousands of neurons. The method presented in this article is based on three core algorithmic ideas: mean shift clustering to detect soma centers (Section 2.2), supervised semantic deconvolution by means of neural networks for image enhancement (Section 2.3) and manifold learning for filtering false positives (FPs) (Section 2.4). The implementation makes use of Pylearn2 (<ref type="bibr" target="#b14">Goodfellow et al., 2013</ref>) and modified parts of Scikit-learn (<ref type="bibr" target="#b30">Pedregosa et al., 2011</ref>). To demonstrate its capabilities, we applied the algorithm to localize and count the Purkinje cells in the cerebellum of an L7-GFP mouse (<ref type="bibr" target="#b40">Tomomura et al., 2001</ref>), a transgenic animal in which this neuronal population is labeled with enhanced green fluorescent protein (EGFP). We obtained an F 1-measure of 0.96 and an area under the recall–precision curve of 0.97. To our knowledge, this is the first complete map of a selected neuronal population in a large area of the mouse brain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MATERIALS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Materials</head><p>The images used for this study were obtained with CLSM, a method that combines the advantages of light sheet illumination with a confocal detection scheme. The protocol to obtain the images is described in detail in (<ref type="bibr" target="#b37">Silvestri et al., 2012</ref>). Briefly, brain tissue is fixed with paraformaldehyde and subsequently cleared by substitution of water with a refractive-indexmatching liquid (<ref type="bibr" target="#b0">Becker et al., 2012;</ref><ref type="bibr" target="#b11">Dodt et al., 2007</ref>). The clearing procedure leads to isotropic tissue shrinkage of $20% in each direction, corresponding to a reduction of $50% in volume. Transparent brains are then imaged with the CLSM apparatus, which produces single-channel 8bit TIFF files. The voxel size of the dataset presented here is 0.8 Â 0.8 Â 1 m 3. To collect the whole volume, many parallel adjacent image stacks are acquired by the apparatus. The stacks partially overlap with the neighbors, allowing subsequent alignment and fusion via a software tool designed to work with large dataset (TeraStitcher) (<ref type="bibr" target="#b4">Bria and Iannello, 2012</ref>). Final data are saved as a non-redundant collection of non-overlapping stacks; copies of the dataset at lower resolutions are also saved, facilitating the visualization and 3D navigation of the whole image (<ref type="bibr" target="#b32">Peng et al., 2014</ref>). The main dataset analyzed is the whole cerebellum of a 10 day old L7GFP mouse (<ref type="bibr" target="#b40">Tomomura et al., 2001</ref>). In this transgenic animal, all Purkinje cells express EGFP, allowing visualization and mapping of this neuronal population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mean shift clustering</head><p>2.2.1 Substacking. We begin by splitting the whole 3D image into a set of relatively small substacks of size W Â H Â D. Partitioning the image has a number of advantages. First, it allows us to approximate a local-thresholding procedure (see Section 2.2.3) without incurring in the computational cost of fully fledged local thresholding algorithms (<ref type="bibr" target="#b35">Sahoo et al., 1988</ref>). Second, dividing a large image in several substacks enables an immediate multi-core parallel implementation where each substack is processed separately in a different thread. Third, it is convenient to work on substacks during the manual annotation process (see Section 3.1.1), which is necessary to create the ground truth data used to estimate the quality of the predictions. Substacks need to overlap to avoid border effects in the subsequent clustering procedure (see Section 2.2.2). The overlap length M was designed to ensure that every cell with a center detected inside the substack of size ðW À MÞ Â ðH À MÞ Â ðD À MÞ falls entirely within the substack of size W Â H Â D (<ref type="figure">Fig. 1</ref>). In our images, the visible region of a Purkinje soma ranges between 11 and 18 voxels in diameter, corresponding to 13 Ä 22 m in the tissue (taking into account the shrinkage introduced by the clearing procedure). We therefore used M = 20 in our experiments. Also, when W, H, D range in 100–150, substacks are small enough to obtain an approximately local binarization threshold and, at the same time, large enough to keep the overhead due to the processing of overlapping regions within acceptable limits. All the algorithms described below operate independently on single substacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Cell identification</head><p>Clustering is an extremely common segmentation approach in low-level computer vision and image processing. Typically in these applications the goal is to group together pixels sharing similar features or colors. Here we propose a different strategy aiming at grouping together voxels belonging to the same soma. Our algorithm outputs cluster centroids that (ideally) correspond to soma centers. M H W<ref type="figure">Fig. 1</ref>. Overlapping of substacks (depicted in 2D for simplicity). Processing is carried out in the region of size W Â H but detected cells are only accepted if their centers fall within the region of size ðW À MÞ Â ðH À MÞ (delimited by dashed lines). Sample accepted and rejected cells after processing the central substack are shown as light and dark circles, respectively i588</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.Frasconi et al.</head><p>Because the number of clusters is clearly unknown in our case (because it corresponds to the number of cells), we take a non-parametric approach with a variant of mean shift (<ref type="bibr" target="#b10">Comaniciu and Meer, 2002</ref>). The algorithm takes as input two sets of points, L and S, where each point is represented by a triplet p ! =ðx; y; zÞ of 3D coordinates. L is the set of voxels whose intensity exceeds the background threshold as explained in Section 2.2.3. The classic mean shift algorithm would start from all available data points, place a kernel on each of them and shift each point toward the mean value computed as the kernel-weighted average of the data. In our variant, we improve both its running time and its statistical precision by starting from a carefully chosen set of seeds S (see Section 2.2.4). Pseudocode of our variant is listed below.</p><p>ClusterðS; L; m; KÞ</p><formula>1 C=; 2 for each p ! 2 S 3 c ! = p ! 4 repeat 5 c ! = 1 Z X q ! 2L mð q ! Þ q ! Kð c ! À q ! Þ 6 until converged 7 C=C [ f c ! g 8 return UniqðCÞ</formula><p>In the above code, m is a function returning the intensity of a voxel and K the kernel function. In practice we use a spherical kernel:</p><formula>Kð a ! Þ= 1 ifk a ! k5R 0 otherwise (</formula><p>where R is a parameter that should be smaller than the expected radius of a cell. The normalization factor Z in line 5 is defined as</p><formula>Z= X p ! 2L mð p ! Þ Kð c ! À p ! Þ</formula><p>so that c ! gets assigned to the 'center of mass' of points falling within the sphere defined by the kernel function. We use KD-trees (<ref type="bibr" target="#b1">Bentley, 1975</ref>) to retrieve this set of points. The function Uniq in line 8 removes near-duplicates from C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Thresholding</head><p>The overall running time of the clustering algorithm presented in Section 2.2.2 is dominated by time required to answer ball queries to the KD-tree, which grows at least as OðjSjlog jLjÞ. For this reason, the image is thresholded to get rid of dark voxels, which are unlikely to be part of a soma. Thresholding also helps to limit the number of false-positive detections. We used a multi-threshold version of the maximum entropy approach of (<ref type="bibr" target="#b18">Kapur et al., 1985</ref>). We set three ranges of voxel intensities and computed by maximum entropy the two delimiting thresholds 1 and 2. The first range ½0; 1  was regarded as background, i.e. dark areas, which we assumed to contain no detectable soma. The two other ranges were retained as foreground.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Seeding</head><p>The set of seeds S is determined as follows. First, we extract all local maxima of the image using a 3D max-filter. Second, we perform a 3D convolution of the image with a normalized spherical filter of size r. Seeds are then all local maxima such that the corresponding value in the convolved image is above the binarization threshold 1 determined in Section 2.2.3. In other words, we require that the average voxel intensity in the ball or radius r centered on a local maximum be above 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Supervised semantic deconvolution</head><p>The clustering procedure described above yields good results (details in Section 3.2) on image regions where cell somata have high and uniform intensity and the contrast on dendritic trunks is modest. Other regions are more problematic: if the thresholding and seed selection is too strict, faintly visible somata disappear during the preparation of sets S and L, leading to false-negative detections; if too loose, then many non-soma regions (such as dendritic arbors or axonal bundles) are retained and FPs arise. To improve over this intrinsic difficulty, we carried out a preprocessing stage by applying a non-linear filter trained to boost weak somata and decrease the voxel intensities in non-soma regions. This step was carried out in a supervised fashion because we believe that the FPs versus false negatives (FNs) trade-off can only be properly addressed by introducing human knowledge. The goal of semantic deconvolution is not to undo the blurring or degradation effects associated with the image acquisition process (as in classic deconvolution) but rather to enhance and standardize the visibility of specific entities of interest in the image (somata in our case). We trained a neural network to map the original image into an 'ideal' image, which is entirely black except for small white spheres positioned at the locations of the true cell somata. In<ref type="figure" target="#fig_0">Figure 2</ref>we illustrate the concept on a small image portion. In order to smooth the neural network targets far away from the somata centers, we actually generated the ideal image by first setting the intensity of the central voxel to the maximum value and then applying a (non-normalized) 3D Gaussian filter with =3:5, truncated at 1:5. We reserved 10 labeled substacks to build a training set. Note that our approach does not require us to perform a precise segmentation of cell somata: markers at the locations of the true centers (see Section 3.1.1 for details of the ground-truth preparation procedure) are sufficient. As a consequence, the human effort required to carefully annotate in this way the 10 training substacks (0.11% of a whole cerebellum image, 1770 cells in total) was modest ($3 h of work). The use of neural networks as non-linear convolutional filters for 3D images has been proposed before in (<ref type="bibr" target="#b17">Jain et al., 2007</ref>) where the goal was to recover human drawn cell boundaries in electron microscopy images at much higher (20 nm) resolution. In our case, the 10 training substacks would total 194 MVoxel, $400 times the training set used in (<ref type="bibr" target="#b17">Jain et al., 2007</ref>). Additionally, the resulting training set would be highly unbalanced because, in our images, the vast majority of voxels fall in dark regions. Therefore, rather than performing a full convolution, we sampled $2 million training patches ensuring that half of them ('positive' patches) overlapped with locations of cell centers and the remaining half ('negative' patches) were at least 30 voxels away from the centers and had an average gray level above 10. The neural network was trained on small cubic patches of size ð2s+1Þ Â ð2s+1Þ Â ð2s+1Þ. In our experiments we used s = 6, yielding patches of 2197 voxels. The goal is to predict, for each voxel, the conditional probability that it falls in a white area of the original image. A naive approach would be to use a neural network with ð2s+1Þ 3 inputs and one single output (corresponding to the central voxel). However, this approach would have at least two disadvantages. First, nearby output voxels are correlated, and predicting them independently is not the best choice from a statistical point of view. Second, filtering a whole volume of size n (assumed to be cubic for simplicity) would require time Oðn 3 s 3 Þ. Instead, we used a neural network with ð2s+1Þ 3 outputs. In this way, several adjacent voxels are predicted simultaneously, sharing the same feature maps as in a multi-task learning problem<ref type="bibr" target="#b7">Caruana, 1997</ref>). The semantically deconvolved image R is then obtained aswhere (x, y, z) is the generic output voxel, Z is a normalization factor and Fða; b; cÞ denotes the 3D patch produced in output by the neural network when the input is the 3D patch of the original image centered at coordinates (a, b, c). In this formulation, each output voxel is actually obtained by averaging several predictions, which helps to reduce the variance component of the generalization error. Using 3D output patches is also advantageous from a computational point of view. First, note that the running time of a network with ð2s+1Þ 3 output is still Oðs 3 Þ (in facts it just takes twice the time of a network with a single output). Second, rather than moving the patch by one voxel, we may move the patch by skipping d voxels along each dimension. In this way, the overall running time is reduced to Oðn 3 s 3 =d 3 Þ. In our experiments, we used d =4 with a speedup of $32 with respect to the naive approach. This is significant because filtering 120GVoxels takes over a day on a Xeon E5-2665 computer with 16 physical cores, and using the naive approach would require more than a month. Note that when using a stride of length d, the normalization factor Z in Equation 1 actually depends on the test point (x, y, z) because not all output voxels are obtained by averaging the same number of predictions. We used a network with two fully connected hidden layers: 2197 inputs, 500 and 200, units in the hidden layers, and 2197 outputs ($1.6 million parameters in total). Preliminary experiments with a third layer did not yield appreciable improvements. We used sigmoidal output units, which allow us to interpret each output as the conditional probability that a certain voxel belongs to a cell soma given the original image patch as input. Similarly to (<ref type="bibr" target="#b16">Hinton et al., 2006</ref>), we pretrained the first two layers in an unsupervised fashion (as Gaussian–binary and binary–binary restricted Boltzmann machines, respectively). Some of the filters learned by the first layer of the network are shown in Supplementary<ref type="figure">Figure S4</ref>. Fine-tuning of the overall network was finally performed by backpropagation, training for $100 epochs of stochastic gradient descent with momentum and with a minibatch size of 10. Altogether, training took slightly 52 days on 16 cores. Semantic deconvolution was performed on substacks of size ðW+2sÞ Â ðH+2sÞ Â ðD+2sÞ to ensure that the cell identification subroutines (see Section 2.2) receive data with no border effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Manifold modeling</head><p>The procedure described in this section takes advantage of specific anatomical background knowledge. In several brain regions, such as in the cerebellum, cells are not scattered randomly in the 3D space but are laid out in manifolds. For example, the cerebellum cortex folds into folia or leaves that can be naturally modeled as manifolds. As it turns out, isolated or off-manifold centers predicted by the algorithms described above are almost invariably false-positive detections. Hence, an effective falsepositive filter may be designed by estimating the distance of each predicted center from the manifold formed by other predicted centers. Our approach exploits manifold learning [specifically, the Isomap algorithm (<ref type="bibr" target="#b39">Tenenbaum et al., 2000)]</ref>and locally weighted regression (<ref type="bibr" target="#b9">Cleveland, 1979</ref>) to obtain such an estimate. Because Isomap needs to compute the eigendecomposition of the estimated geodesic distance matrix from the nearest-neighbors graph, it cannot be applied to large set of points. Thus, we begin by partitioning predicted centers into smaller subsets. The approach is inspired by a computer graphics technique known as chartification (<ref type="bibr" target="#b42">Zhou et al., 2004</ref>). Chartification algorithms, however, are typically designed to work on meshes rather than point clouds and they are not robust enough to handle the noisy detections that occur in our application. We used instead the following procedure. First, we obtained a set of seeds by computing the centroid of detections within each substack in which the overall image was divided (see Section 2.2.1). Second, starting from each seed, we formed a chart by running a uniform cost search on the nearest neighbors graph with edges weighted by Euclidean distances, proceeding until a predefined geodesic distance from the seed was reached. Charts obtained in this way may overlap but this is fine because our goal is ultimately to detect FPs. Manifold distances on each chart are estimated using the following algorithm:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.. ; d ðnÞ g</head><p>In the above code, the procedure Isomap takes as input the predicted centers and returns their 2D embeddings H=fðu ðiÞ ; v ðiÞ Þ; i=1;. .. ; ng obtained by first computing the nearest neighbors graph to obtain estimated geodesic distances and then performing multidimensional scaling [see (<ref type="bibr" target="#b39">Tenenbaum et al., 2000</ref>) for details]. The procedure Lowess learns a locally weighted regression model from the 2D coordinates (u, v) back to the 3D coordinates (x, y, z). Lowess is a lazy learner, which simply stores the training data and at prediction time performs weighted linear regression. For the sake of completeness we briefly summarize the method here. Given the left-out test point ðu ðiÞ ; v ðiÞ Þ, we first form the matrix V 2 R nÀ1Â2 , whose j-th row is w ðjÞ ðu ðjÞ ; v ðjÞ Þ and where the real-valued weights w ðjÞ are given by the Gaussian kernel</p><formula>w ðjÞ =exp À kðu ðiÞ ; v ðiÞ Þ À ðu ðjÞ ; v ðjÞ Þk 2 2 : ð2Þ</formula><p>We then form the matrix X 2 R nÀ1Â3 whose j-th row is w ðjÞ ðx ðjÞ ; y ðjÞ ; z ðjÞ Þ. Lowess computes its prediction as</p><formula>f ni ðu ðiÞ ; v ðiÞ Þ=ðu ðiÞ ; v ðiÞ Þ &gt; V &gt; V À Á À1 V &gt; X: ð3Þ</formula><p>To reduce the influence of outliers, we finally used the iterative reweighting approach described in (<ref type="bibr" target="#b9">Cleveland, 1979</ref>). Intuitively, f ni ðu ðiÞ ; v ðiÞ Þ reconstructs the 3D coordinates of the i-th center given the other centers in the chart. If the i-th center is far from the manifold, then we expect the Euclidean distance d ðiÞ (see Line 4 in the above algorithm) between the true and reconstructed coordinates to be high, yielding a sensible criterion for filtering out false-positive detections. As noted above, our charts may overlap, meaning that multiple distance values d ðiÞ are estimated whenever a center appears in multiple charts. In these cases, we eventually retained the minimum estimated manifold distance. The quality of Isomap embeddings is sensitive to outliers; we thus found it beneficial to run the manifold filter iteratively, first with a high distance threshold of 40 voxels, to get rid of gross false-positive detections, and a second time with a smaller threshold to perform a finer grained filtering.that the contrast variability in the whole image was well represented. Some nearly empty regions were also included to better estimate the false-positive rate. Cell centers were located with the help of a modified version of the Vaa3D software package (<ref type="bibr" target="#b31">Peng et al., 2010</ref>). In our version, the one-right-click pinpointing procedure takes advantage of the 3D mean shift algorithm described in Section 2.2 but applies it to a cylinder whose main axis is defined by the line connecting the observer point and the clicked point. Using a fairly small cylinder radius ($6–8 voxels) and rotating the 3D view of the image to avoid overlaps, the cylinder will almost always contain just one soma and a reliable marker can be assigned in just a few seconds. The 3D mean shift algorithm also ensures that the marker identifies the soma center with good accuracy. Still, the high variability in image quality makes hand labeling non-trivial. We found that two independent human labelings on nine substacks disagree on 40 markers of 957.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Measuring performance</head><p>For each substack, we compare the set of cluster centers C returned by the clustering procedure, and the set of ground truth centers G. To properly compare predictions against the ground truth we need to ensure that each predicted soma center is uniquely associated with at most one ground truth center. For this purpose, we first construct an undirected bipartite graph with vertex set C [ G. For each pair c ! 2 C and g ! 2 G we add an edge with weight</p><formula>w cg = 1 +k c ! À g ! k if k c ! À g ! k5D</formula><p>, being D the expected diameter of a Purkinje soma (we set D = 16 in our experiments) and ¾ a small constant preventing numerical overflows. We then compute the maximum weight bipartite matching. A predicted center c ! is considered to be a true positive (TP) if it is matched to a ground truth center g ! such that k c ! À g ! k5D=2. Unmatched predictions are counted as FPs and unmatched ground truth centers are counted as FNs. We finally compute precision, recall and F 1 measure as P=TP=ðTP+FPÞ; R=TP=ðTP+FNÞ and F 1 = 2PR P+R. To avoid the bias due to border effects, we take advantage of the overlapping between substacks (<ref type="figure">Fig. 1</ref>) and exclude from the TP, FP or FN counts all points (either predictions or ground truth) falling in the outer region of thickness M=2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mean shift clustering on the raw image</head><p>We ran the algorithm of Section 2.2 on the raw image, with different values of the parameters r (radius of the seed ball) and R (radius of the kernel). As expected, the algorithm achieves its best performance when both parameters are set to a value that roughly corresponds to the radius of the smallest somata in the image (<ref type="figure">Fig. 4</ref>). Too low values for r generate too many seeds, increasing the chances of false-positive detections. Precision is also sensitive to the kernel radius because small values of R tend to generate multiple detections within the same true soma. The slight increase of FNs when increasing R can be explained as follows: when two somata are close to each other and almost touch, a large kernel drives the algorithm to converge near the border between the two somas. When setting r = 6 and R = 5.5, the cell detector on raw images attains a precision of 0.76 and a recall of 0.71, corresponding to 920 FPs and 1213 FNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Using semantic deconvolution</head><p>The performance of the mean shift algorithm increases dramatically when applied to the image cleaned by the semantic deconvolution technique described in Section 2.3. Setting r = 6 and R = 5.5 yields 493 FPs and just 120 FNs, corresponding to a precision of 0.89, a recall of 0.97 and an<ref type="figure">Fig. 4</ref>. Comparing performance of the mean shift algorithm before and after semantic deconvolution and varying the parameters r (seed radius ball) and R (kernel size). Left: performance when varying r and fixing R = 6. Right: performance when varying R and fixing r = 6shown in<ref type="figure">Figure 4</ref>, the algorithm is also much less sensitive to the choice of R. If r is too small with respect to the expected soma radius, many FPs arise. This is because the neural network may hallucinate small non-soma light regions as soma (one example occurs in the leftmost region of the central substack shown in<ref type="figure" target="#fig_3">Fig. 3</ref>). Increasing r beyond six continues to improve precision at the expense of recall, but keeping the F 1-measure almost constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Using the manifold filter</head><p>We finally evaluated the effect of the manifold modeling technique described in Section 2.4. We first computed the estimated manifold distances and filtered all predictions with d ðiÞ 440. This step removed some FPs without losing any significant recall. We then applied reestimated manifold distances on the remaining predictions and computed a recall–precision curve when varying the manifold distance threshold. Starting from the set of cells detected with r = 6 and R = 5.5, we obtained the curve shown in<ref type="figure" target="#fig_4">Figure 5</ref>. The area under this curve is 0.97. As expected, precision decreases with the distance threshold, while recall increases. Still, it is possible to reduce significantly the number of FPs without sacrificing recall. Any threshold between 11 and 27 voxels keeps the F 1-measure 40.96. The sensitivity of the overall method with respect to r and R is further reduced after the manifold filter: any value of r and R between 5 and 7 yields an F 1-measure 40.95 if using a distance threshold of 20. With the application of the manifold filter (with threshold 20), the algorithm detected 224 222 Purkinje cells in the whole cerebellum image (<ref type="figure" target="#fig_5">Fig. 6</ref>). This number is consistent with previous estimates based on stereology (<ref type="bibr" target="#b2">Biamonte et al., 2009;</ref><ref type="bibr" target="#b41">Woodruff-Pak, 2006</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Discussion</head><p>Quantitative histological measurements are typically restricted to small portions of tissue. In fact, on the one hand, conventional microscopy techniques are unable to generate large-scale volumetric datasets (<ref type="bibr" target="#b29">Osten and Margrie, 2013</ref>). On the other hand, currently available algorithms for cell segmentation or localization usually require carefully tuned parameters and therefore cannot cope with the image variability that may be present in large-scale datasets. The only well-established quantitative method to investigate cytoarchitecture on a brain-wide scale is stereology (<ref type="bibr" target="#b36">Schmitz and Hof, 2005</ref>), which, however, provides only estimates of the number of cells, without a precise map of their spatial distribution. Furthermore, stereological estimates rely on a priori assumptions about the imaged tissue, which make the final result dependent on the starting hypothesis (<ref type="bibr" target="#b36">Schmitz and Hof, 2005</ref>). Here, we presented an algorithm for fully automatic detection of neuronal soma in CLSM fluorescence images, in which human supervision is needed only for the initial training of a neural network. After training on a small sample of substacks, the neural network is able to generalize well on different brain regions. This suggests that the network trained on one cell type and one brain will be able to perform semantic deconvolution equally well for the same cell type of other brains within a uniform population of animals. The robustness of the method when applied to heterogeneous samples should be further investigated. In particular, it might be necessary to collect larger and more representative datasets if one wants to detect cells with different sizes/shapes or in comparative studies involving animals with anatomical variations or disease models. In our experience, the overall work devoted to labeling was modest compared with the work devoted to sample preparation and image acquisition. The capabilities of this algorithm have been demonstrated by localizing all the Purkinje neurons in a whole mouse cerebellum. The algorithm is robust against the contrast variability in different image regions. The sensitivity of performance with respect to the mean shift kernel radius and the manifold filter distance is modest (<ref type="figure" target="#fig_4">Figs 4 and 5</ref>) and the seed selection parameter r can be chosen according to the expected size of visible soma. One possible future extension to improve our quantitative results is to associate a confidence score or a probability to each detection. Our method obtains the best results when the manifold filter is used. This can be a limitation, as the cellular subset under investigation might be scattered in all the three dimensions, without any apparent uniformity in the spatial distribution. Further, even if neurons lie on a manifold in physiological conditions, this regularity might disappear (at least partly) in presence of a pathology. Thus, if one wants to compare healthy and unhealthy subjects, a manifold-independent localization pipeline could provide more reliable results. Anyhow, the modeling of the manifold can be useful also in this case, allowing a quantitative description of the spatial scattering of neurons. The combination of the method presented here with genetically targeted expression of fluorescent proteins, or with whole-brain immunohistochemistry (<ref type="bibr" target="#b8">Chung et al., 2013</ref>), will allow precisely localizing and counting selected neuronal populations throughoutthe entire encephalon, eventually leading to a set of brain-wide cytoarchitectonic maps of the various cell types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>We presented an automated pipeline for the localization of neuronal soma in large-scale images obtained with CLSM. The method has been validated on images of the cerebellum of an L7-GFP mouse. We found that semantic deconvolution significantly boosted performance at a modest cost in terms of hand labeling. We obtained an F 1 value of 0.96. While some margin for improvement may remain, human labeling disagreement suggests that F 1 values 40.98 are unlikely to be attainable. We further demonstrate the algorithm by producing the full map of Purkinje cells in the whole mouse cerebellum.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.2.</head><figDesc>Fig. 2. Illustration of semantic deconvolution: a portion of the original image (left), the associated ideal image (middle), image filtered by the trained neural network (right). Best viewed by zooming in a computer screen</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>=Lowess ðHnfðu ðiÞ ; v ðiÞ Þg; Cnfðx ðiÞ ; y ðiÞ ; z ðiÞ ÞgÞ 4 d ðiÞ =kf ni ðu ðiÞ ; v ðiÞ Þ À ðx ðiÞ ; y ðiÞ ; z ðiÞ Þk 5 return fd ð1Þ ; .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. More examples of semantic deconvolution (substacks not included in the training set). Top: original images. Bottom: results of semantic deconvolution. Best viewed by zooming in a computer screen</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.5.</head><figDesc>Fig. 5. Effects of the manifold distance filter. Left: recall–precision curve. Right: performance measures as a function of the distance threshold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.6.</head><figDesc>Fig. 6. The final set of predicted Purkinje cell centers as a point cloud</figDesc></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">P.Frasconi et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Chemical clearing and dehydration of GFP expressing mouse brains</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Becker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">33916</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Multidimensional binary search trees used for associative searching</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Bentley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="509" to="517" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Interactions between neuroactive steroids and reelin haploinsufficiency in Purkinje cell survival</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Biamonte</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiol. Dis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="103" to="115" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A proposal for a coordinated effort for the determination of brainwide neuroanatomical connectivity in model organisms at a mesoscopic scale</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Bohland</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000334</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Terastitcher-a tool for fast automatic 3d-stitching of teravoxel-sized microscopy images</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bria</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Iannello</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">316</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Volume electron microscopy for neuronal circuit reconstruction</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">L</forename>
				<surname>Briggman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">D</forename>
				<surname>Bock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="154" to="161" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Wiring specificity in the direction-selectivity circuit of the retina</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">L</forename>
				<surname>Briggman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">471</biblScope>
			<biblScope unit="page" from="183" to="188" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">An automatic method for robust and fast cell detection in bright field images from high-throughput microscopy Multitask learning</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Buggenthin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Structural and molecular interrogation of intact biological systems</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Chung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<biblScope unit="page" from="332" to="337" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust locally weighted regression and smoothing scatterplots</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Cleveland</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="829" to="836" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Mean shift: a robust approach toward feature space analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Comaniciu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Meer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEET Pattern Anal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Ultramicroscopy: three-dimensional visualization of neuronal networks in the whole mouse brain</title>
		<author>
			<persName>
				<forename type="first">H.-U</forename>
				<surname>Dodt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="331" to="336" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Deadeasy Mito-Glia: Automatic counting of mitotic cells and glial cells in Drosophila</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">G</forename>
				<surname>Forero</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">10557</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Continuously tracing brain-wide long-distance axonal projections in mice at a one-micron voxel resolution</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Gong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="87" to="98" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">Pylearn2: a machine learning research library arXiv preprint arXiv</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">J</forename>
				<surname>Goodfellow</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1308" to="4214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">High-accuracy neurite reconstruction for highthroughput neuroanatomy</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Helmstaedter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1081" to="1088" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Supervised learning of image restoration with convolutional networks</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Jain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Computer Vision (ICCV). IEEE Piscataway</title>
		<meeting>the 11th International Conference on Computer Vision (ICCV). IEEE Piscataway</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A new method for gray-level picture thresholding using the entropy of the histogram</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kapur</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis., Graph. Image Process</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="273" to="285" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">The rise of the &apos;projectome&apos;</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Kasthuri</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Lichtman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="307" to="308" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Light sheet microscopy of living or cleared specimens</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Keller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-U</forename>
				<surname>Dodt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="138" to="143" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Large-scale automated histology in the pursuit of connectomes</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kleinfeld</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="16125" to="16138" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Serial section scanning electron microscopy of adult brain tissue using focused ion beam milling</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Knott</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2959" to="2964" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">3D segmentations of neuronal nuclei from confocal microscope image stacks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Latorre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neuroanat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Micro-optical sectioning tomography to obtain a high-resolution atlas of the mouse brain</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="1404" to="1408" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">The big and the small: challenges of imaging the brain&apos;s circuits</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Lichtman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Denk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="page" from="618" to="623" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Knife-edge scanning microscopy for imaging and reconstruction of three-dimensional anatomical structures of the mouse brain</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Mayerich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Microsc</title>
		<imprint>
			<biblScope unit="volume">231</biblScope>
			<biblScope unit="page" from="134" to="143" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised segmentation of noisy electron microscopy images using salient watersheds and region merging</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Navlakha</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">294</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A mesoscale connectome of the mouse brain</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">W</forename>
				<surname>Oh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">508</biblScope>
			<biblScope unit="page" from="207" to="214" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Mapping brain circuitry with a light microscope</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Osten</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">W</forename>
				<surname>Margrie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="515" to="523" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Scikit-learn: machine learning in python</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Pedregosa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">V3D enables real-time 3D visualization and quantitative analysis of large-scale biological image data sets</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="348" to="353" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Extensible visualization and analysis for multidimensional images using Vaa3D</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="193" to="208" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">NeuroGPS: automated localization of neurons for brain circuits using L1 minimization model</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Quan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1414</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Serial two-photon tomography for automated ex vivo mouse brain imaging</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ragan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="255" to="258" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey of thresholding techniques</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">K</forename>
				<surname>Sahoo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis., Graph Image Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="233" to="260" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Design-based stereology in neuroscience</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Schmitz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hof</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="813" to="831" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Confocal light sheet microscopy: micron-scale neuroanatomy of the entire mouse brain</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Silvestri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Express</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="20582" to="20598" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">The human connectome: a structural description of the human brain</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Sporns</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">B</forename>
				<surname>Tenenbaum</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Purification of Purkinje cells by fluorescence-activated cell sorting from transgenic mice that express green fluorescent protein</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tomomura</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="57" to="63" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">Stereological estimation of Purkinje neuron number in C57BL/6 mice and its relation to associative learning</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Woodruff-Pak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="233" to="243" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Iso-charts: stretch-driven mesh parameterization using spectral analysis</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics</title>
		<meeting>the Eurographics<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>