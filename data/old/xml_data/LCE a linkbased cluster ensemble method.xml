
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gene expression LCE: a link-based cluster ensemble method for improved gene expression data analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Natthakan</forename>
								<surname>Iam-On</surname>
							</persName>
							<email>natthakan@mfu.ac.th</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aberystwyth University</orgName>
								<address>
									<settlement>Aberystwyth</settlement>
									<region>Ceredigion</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tossapon</forename>
								<surname>Boongoen</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aberystwyth University</orgName>
								<address>
									<settlement>Aberystwyth</settlement>
									<region>Ceredigion</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Simon</forename>
								<surname>Garrett</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aberystwyth University</orgName>
								<address>
									<settlement>Aberystwyth</settlement>
									<region>Ceredigion</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Olga</forename>
								<surname>Troyanskaya</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Gene expression LCE: a link-based cluster ensemble method for improved gene expression data analysis</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="issue">12</biblScope>
							<biblScope unit="page" from="1513" to="1519"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq226</idno>
					<note type="submission">Received on December 14, 2009; revised on March 18, 2010; accepted on April 20, 2010</note>
					<note>[15:46 21/5/2010 Bioinformatics-btq226.tex] Page: 1513 1513–1519 Associate Editor: Availability: Online supplementary and implementation are available at: http://users.aber.ac.uk/nii07/bioinformatics2010 Contact: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: It is far from trivial to select the most effective clustering method and its parameterization, for a particular set of gene expression data, because there are a very large number of possibilities. Although many researchers still prefer to use hierarchical clustering in one form or another, this is often sub-optimal. Cluster ensemble research solves this problem by automatically combining multiple data partitions from different clusterings to improve both the robustness and quality of the clustering result. However, many existing ensemble techniques use an association matrix to summarize sample-cluster co-occurrence statistics, and relations within an ensemble are encapsulated only at coarse level, while those existing among clusters are completely neglected. Discovering these missing associations may greatly extend the capability of the ensemble methodology for microarray data clustering. Results: The link-based cluster ensemble (LCE) method, presented here, implements these ideas and demonstrates outstanding performance. Experiment results on real gene expression and synthetic datasets indicate that LCE: (i) usually outperforms the existing cluster ensemble algorithms in individual tests and, overall, is clearly class-leading; (ii) generates excellent, robust performance across different types of data, especially with the presence of noise and imbalanced data clusters; (iii) provides a high-level data matrix that is applicable to many numerical clustering techniques; and (iv) is computationally efficient for large datasets and gene clustering.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The use of clustering is vital both for visualizing and extracting useful information from microarray data. However, different algorithms (or even the same algorithm with different parameters) often provide distinct clusterings. As a result, it is extremely difficult for users to decide which algorithm and parameters will be optimal for a given set of data—this is because no single-pass/simple * To whom correspondence should be addressed. clustering algorithm can perform the best for all datasets (<ref type="bibr" target="#b19">Kuncheva and Hadjitodorov, 2004</ref>), and discovering all types of cluster shapes and structures presented in data is impossible for any known clustering algorithm (<ref type="bibr" target="#b7">Duda et al., 2000;</ref><ref type="bibr" target="#b13">Handl et al., 2005</ref>). Clinical researchers commonly use simple clustering methods, such as agglomerative hierarchical and k-means (<ref type="bibr" target="#b2">Bredel et al., 2005;</ref><ref type="bibr" target="#b32">Sorlie et al., 2003</ref>) to cluster cancer microarray samples, despite the advent of several new techniques that capitalize on the inherent characteristics of gene expression data (noise and high dimensionality) to improve clustering quality (e.g.<ref type="bibr" target="#b3">Brunet et al., 2004;</ref><ref type="bibr" target="#b22">Liu et al., 2003;</ref><ref type="bibr" target="#b24">McLachlan et al., 2002</ref>). de<ref type="bibr" target="#b6">Souto et al. (2008)</ref>says, this is because the use of such methods is difficult for non-expert users. Recently, cluster ensembles or consensus clusterings have emerged as simple, effective, one-stop methods for improving the robustness and quality of clustering results. Cluster ensembles combine multiple clustering decisions (referred to as 'base clusterings' or 'ensemble members') where the base clusterings contain diversity in their choice of clusters by:</p><p>(i) using a single clustering algorithm with random parameter initializations (<ref type="bibr" target="#b18">Kim et al., 2009;</ref><ref type="bibr" target="#b25">Monti et al., 2003;</ref><ref type="bibr" target="#b36">Yu et al., 2007</ref>); (ii) employing multiple clustering algorithms (<ref type="bibr" target="#b35">Swift et al., 2004</ref>); (iii) selecting a random number of clusters (<ref type="bibr" target="#b10">Fred and Jain, 2005;</ref><ref type="bibr" target="#b20">Kuncheva and Vetrov, 2006</ref>); (iv) using different subsets of gene (<ref type="bibr" target="#b1">Avogadri and Valentini, 2009;</ref><ref type="bibr" target="#b36">Yu et al., 2007</ref>); or (v) using data sampling techniques (<ref type="bibr" target="#b8">Dudoit and Fridyand, 2003;</ref><ref type="bibr" target="#b25">Monti et al., 2003</ref>). Most existing methods compare cluster associations between each of the N samples in the dataset to produce an N ×N pairwise similarity matrix [i.e. consensus (<ref type="bibr" target="#b25">Monti et al., 2003</ref>), agreement (<ref type="bibr" target="#b35">Swift et al., 2004</ref>) and co-association (<ref type="bibr" target="#b10">Fred and Jain, 2005</ref>) matrices], to which a consensus function (e.g. agglomerative hierarchical clustering) is applied to acquire the final data partition. With the ensemble of two base clusterings ={π 1 ,π 2 } and five samples (x 1 ,...x 5 ) that is given in<ref type="figure" target="#fig_0">Figure 1a</ref>, the corresponding similarity matrix is shown in<ref type="figure" target="#fig_0">Figure 1b</ref>. An alternative approach (<ref type="bibr" target="#b9">Fern and Brodley, 2004</ref>; Strehl and<ref type="bibr" target="#b33">Ghosh, 2002</ref>) to pairwise similarity methods makes use of an N ×P binary cluster-association matrix (BM) (where P denotes the number of clusters in an ensemble).<ref type="figure" target="#fig_0">Figure 1c</ref>shows the example of such matrix that is generated from the ensemble of<ref type="figure" target="#fig_0">Figure 1a</ref>. Despite reported success and efficiency, these methods generate the ultimate clustering result based on incomplete information of a cluster ensemble. The underlying association matrix presents sample–cluster relations at a coarse level and completely ignores the relations among clusters (<ref type="bibr" target="#b14">Iam-on et al., 2008</ref>). As a result, the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N.Iam-on et al.</head><formula>(π 1 ={C 1 1 ,C 1 2 ,C 1 3 } and π 2 ={C 2 1 ,C 2 2 }), (b)</formula><p>the corresponding pairwise similarity matrix and (c) BM, respectively. performance of such techniques may consequently be degraded as many matrix entries are left unknown, each presented with zero. In response, we present a new method—the LCE—for clustering data. It significantly extends the hybrid bipartite graph formulation (HBGF) technique (<ref type="bibr" target="#b9">Fern and Brodley, 2004</ref>), by applying a graphbased consensus function to an improved cluster association matrix, instead of the conventional BM. This article explores its application to the problem of clustering cancer microarray samples, and is shown to refine the cluster-association matrix, as well as reducing the number of unknown entries and, therefore, increasing accuracy; moreover, it can easily replace or augment a researcher's existing clustering tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>The proposed LCE methodology is illustrated in<ref type="figure">Figure 2</ref>. It includes three major steps: (i) creating M base clusterings to form a cluster ensemble; (ii) creating a refined cluster-association matrix (RM) using a link-based similarity algorithm (Weighted Connected-Triples, WCT); and (iii) generating the final data partition by exploiting the spectral graph partitioning (SPEC) technique as a consensus function. This framework is similar to that of HBGF (<ref type="bibr" target="#b9">Fern and Brodley, 2004</ref>), except the second step that is introduced for constructing a refined information matrix. As compared to HBGF that is based on the BM, LCE may enhance effectiveness of the former using a more informative RM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Creating a cluster ensemble</head><p>Let X ={x 1 ,...,x N } be a set of N samples and let ={π 1 ,...,π M } be a cluster ensemble with M base clustering results. Each base clustering returns a set of</p><formula>clusters π i ={C i 1 ,C i 2 ,...,C i k i }, such that k i j=1 C i j = X,</formula><p>where k i is the number of clusters in the i-th clustering. As in many previous studies (<ref type="bibr" target="#b10">Fred and Jain, 2005;</ref><ref type="bibr" target="#b18">Kim et al., 2009</ref>), the k-means clustering algorithm is used to generate base clusterings, each with random initialization of cluster centers. Euclidean distance is used to measure the dissimilarity between two samples unless stated otherwise. For each base clustering, there are two schemes of selecting the number of clusters: Fixed-k (k = √ N, where N is the number of samples) and Random-k (k ∈ {2,..., √ N}). To create diversity in an ensemble, k should be greater than the expected number of clusters and the common rule-of-thumb is k = √ N (<ref type="bibr" target="#b10">Fred and Jain, 2005;</ref><ref type="bibr" target="#b12">Hadjitodorov et al., 2006</ref>). Note that the quality of the<ref type="figure">Fig. 2</ref>. The LCE framework: (i) a cluster ensemble ={π 1 ,...,π M } is created from M base clusterings; (ii) a refined cluster-association matrix (RM) is then generated from the ensemble using the WCT algorithm; and (iii) a final clustering result (π * ) is produced by a consensus function of the spectral graph partitioning (SPEC). final clustering is directly subjected to the diversity among base clusterings (<ref type="bibr" target="#b20">Kuncheva and Vetrov, 2006</ref>). Another alternative to generate diversity within an ensemble is to exploit a number of different data partitions. To this extent, the cluster ensemble is also established on various data subspaces. Similar to the study of<ref type="bibr" target="#b36">Yu et al. (2007)</ref>, for a given N ×d dataset of N samples and d genes, an N ×q data subspace (where q &lt; d) is generated by q = q min ++α(q max −q min )</p><formula>(1)</formula><p>here α ∈<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>is a uniform random variable, q min and q max are the lower and upper bounds of the generated subspace, respectively. In particular, q min and q max are set to 0.75d and 0.85d. A gene is selected one by one from the pool of d genes, until the collection of q is obtained. The index of each selected gene is determined as follows, where h denotes the h-th gene in the pool of d genes and β ∈[0,1) is a uniform random variable.</p><formula>h ==1+βd (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generating a refined cluster-association matrix (RM)</head><p>In particular to HBGF, BM has been used to summarized information presented in an ensemble. Each entry in this matrix BM(x i ,C j ) ∈{0,1} represents a crisp association degree between sample x i ∈ X and cluster C j ∈. According to<ref type="figure" target="#fig_0">Figure 1</ref>, which shows an example of cluster ensemble and the corresponding BM, a large number of entries in the BM are unknown, each presented with 0. Intuitively, this may limit the quality of a data partition generated by any consensus function. These conditions occur when relations between different clusters of a base clustering are originally assumed to be nil. It is important to note that each sample can associate (to a certain degree within<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>) to several clusters of any particular clustering, at the same time. These hidden or unknown associations can be estimated upon the similarity among clusters, discovered from a link network of clusters. Based on this insight, the refined cluster-association matrix (RM) is put forward as the enhanced variation of the original BM. Its aim is to approximate value of unknown associations ('0') from known ones ('1'), whose association degrees are preserved within the RM (i.e. BM(x i ,cl) = 1 → RM(x i ,cl) = 1). For each clustering π t ,t = 1...M and their corresponding clusters C t 1 ,...,C t kt (where k t is the number of clusters in the clustering π t ), the association degree RM(x i ,cl) ∈<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>that sample x i ∈ X has with each cluster cl ∈{C t 1 ,...,C t kt } is estimated as follows:</p><formula>RM(x i ,cl) = 1 i f cl = C t * (x i ) sim(cl,C t * (x i )) otherwise (3)</formula><p>where C t * (x i</p><p>) is a cluster label (corresponding to a particular cluster of the clustering π t ) to which the sample x i belongs. In addition, sim(C x ,C y ) ∈<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>not appropriate for re-scaling associations within the RM. In fact, such local normalization will significantly distort the true semantics of known associations ('1'), such that their magnitudes become dissimilar, different from one clustering to another. According to our empirical investigation, the quality of RM is usually higher than other soft, fuzzy-like variations of the BM, which can be obtained from sample-to-cluster distances or a fuzzy cluster ensemble. See Supplementary Section 8.1 for details of such methods and associated experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">WCT: a link-based similarity algorithm</head><p>Given a cluster ensemble of data samples X, a weighted graph G = (V ,W ) can be constructed, where V is the set of vertices each representing a cluster and W is a set of weighted edges between clusters. Formally, the weight assigned to the edge w xy ∈ W , that connects clusters C x ,C y ∈ V , is estimated by</p><formula>w xy = |L x ∩L y | |L x ∪L y | (4)</formula><p>where L z ⊂ X denotes the set of samples belonging to cluster C z ∈ V .<ref type="figure">Figure 3a</ref>shows the network of clusters that is generated from the example given in<ref type="figure" target="#fig_0">Figure 1</ref>. Note that circle nodes represent clusters and edges exist only when the corresponding weights are non-zero. Given this network formalism, the new WCT algorithm is introduced to disclose the similarity between any pair of clusters. It extends the Connected-Triple method (<ref type="bibr" target="#b30">Reuther and Walter, 2006</ref>) that has been originally developed to identify ambiguous author names within publication databases. In particular, the similarity of any C x ,C y ∈ V can be estimated by counting the number of Connected-Triples (i.e. triples) they are part of. Formally, a triple, Triple = (V Triple ,W Triple ), is a subgraph of G containing three vertices</p><formula>V Triple ={C x ,C y ,C k }</formula><p>⊂V and two non-zero edges W Triple ={w xk ,w yk }⊂W , with w xy = 0. An example of triple within the network of<ref type="figure">Figure 3a</ref>is shown in<ref type="figure">Figure 3b</ref>. This simple counting might be sufficient for any indivisible object, e.g. name or sample. However, to evaluate the similarity between clusters, it is important to realize and take into account the composite characteristic of a cluster (i.e. shared members). Inspired by this idea, the WCT measure of clusters C x ,C y ∈ V with respect to each triple C k ∈ V , is estimated as</p><formula>WCT k xy = min(w xk ,w yk ) (5)</formula><p>where w xk ,w yk ∈ W are weights of the edges connecting clusters C x and C k , and clusters C y and C k , respectively. The count of all triples (1...q) between clusters C x and C y can be calculated as follows:</p><formula>WCT xy = q k=1 WCT k xy (6)</formula><p>Then, the similarity between clusters C x and C y can be estimated by</p><formula>sim(C x ,C y ) = WCT xy WCT max × DC (7)</formula><p>where WCT max is the maximum WCT pq value of any two clusters C p ,C q ∈ V and DC ∈ (0,1) is a constant decay factor (i.e. confidence level of accepting two non-identical clusters as being similar). Following the example shown in<ref type="figure" target="#fig_0">Figs 1</ref>and 3, the discovered link-based similarities/relations and the resulting RM are presented in<ref type="figure" target="#fig_1">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Applying a consensus function to RM</head><p>Having obtained a refined cluster-association matrix (RM) with the aforementioned link-based similarity algorithm, a graph-based partitioning method is exploited to obtain the final clustering. This consensus function requires the underlying matrix to be initially transformed into a weighted bipartite graph. Formally, given an RM representing associations between N samples and P clusters in an ensemble , a weighted bipartite graphGiven such graph, the spectral graph partitioning (SPEC) method similar to that of<ref type="bibr" target="#b26">Ng et al. (2002)</ref>is applied to generate a final data partition. This is a powerful method for decomposing an undirected graph, with good performance being exhibited in many application areas, including protein modelling, information retrieval and identification of densely connected on-line hypertextual regions (<ref type="bibr" target="#b23">Luxburg, 2007</ref>). Principally, given a graph G = (V ,W ), SPEC first finds the K largest eigenvectors u 1 ,...,u K of W , which are used to formed another matrix U (i.e. U =[u 1 ,<ref type="bibr">...,u K ]</ref>), whose rows are then normalized to have unit length. By considering the row of U as K-dimensional embedding of the graph vertices, SPEC applies k-means to these embedded points in order to acquire the final clustering result. Further details of SPEC can be found in Supplementary Section 1.</p><formula>G = (V ,W</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Experiment design</head><p>The experiments set out to investigate the performance of LCE compared to a number of different simple/standard clustering algorithms and state-ofthe-art cluster ensemble methods, over real gene expression and synthetic datasets. The compared techniques include: (i) HBGF that is the baseline model of LCE; (ii) four simple clustering techniques that are usually used by clinical researchers to analyse microarray data<ref type="bibr">[</ref></p><formula>1 ,...,π M } of a dataset X ={x 1 ,...,x N }, an N ×N</formula><p>Page: 1516 1513–1519</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N.Iam-on et al.</head><formula>) = 1 M M m=1 S m (x i ,x j ),</formula><p>where CO(x i ,x j ) ∈<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>represents the similarity measure between samples x i ,x j ∈ X. In addition, S m (x i ,x j ) = 1 if C m (x i ) = C m (x j ), and S m (x i ,x j ) = 0 otherwise. Note that C m (x i ) denotes the cluster label of the m-th clustering to which a sample x i ∈ X belongs. Since co-association matrix (CO) is a similarity matrix, any similaritybased clustering algorithm (referred to as 'consensus function') can be applied to this matrix to yield the final partition π * (<ref type="bibr" target="#b10">Fred and Jain, 2005</ref>). Among several existing similarity-based techniques, the most well-known is agglomerative hierarchical clustering algorithm. Specifically to the problem of clustering cancer samples, MULTI-K (<ref type="bibr" target="#b18">Kim et al., 2009</ref>) and CC HC (<ref type="bibr" target="#b25">Monti et al., 2003</ref>) methods make use the SL and AL agglomerative hierarchical clusterings as consensus functions, respectively. In addition, to obtain π * , the GCC approach (<ref type="bibr" target="#b36">Yu et al., 2007</ref>) transforms the CO matrix into a graph of samples to which the normalized cut algorithm (<ref type="bibr" target="#b31">Shi and Malik, 2000</ref>of the bipartite graph that is generated from the BM. There is no edge connecting vertices of the same object type, and the weight of an edge between any data point and cluster is either 1 (when the sample belongs to the cluster) or 0 (otherwise). SPEC (<ref type="bibr" target="#b26">Ng et al., 2002</ref>) is exploited to obtain the final clustering result from this graph. This effectively allows the quality of the two cluster-association matrices (i.e. BM and RM) to be compared. CSPA creates a similarity graph, where vertices represent samples and edges' weight represent similarity scores obtained from the CO matrix. Afterwards, a graph partitioning algorithm called METIS (<ref type="bibr" target="#b15">Karypis and Kumar, 1998</ref>) is used to partition the similarity graph into K clusters. HGPA constructs a hyper-graph, where vertices represent samples and the same-weighted hyper-edges represent clusters in the ensemble. Then, HMETIS (<ref type="bibr" target="#b16">Karypis et al., 1999</ref>) is applied to partition the underlying hyper-graph into K parts. MCLA creates a graph where each vertex corresponds to each cluster in the ensemble and each edge's weight between any two cluster vertices is computed using the binary Jaccard measure. METIS is also employed to partition the meta-level graph into K meta-clusters. The final clustering is produced by assigning each sample to the meta-cluster with which it is most frequently associated. Note that the performance of SL, CL, AL and KM are always assessed over the original data, without using any information of cluster ensemble.</p><p>The effectiveness of LCE and other cluster ensemble methods with different ensemble sizes and types are also empirically examined. Details of gene expression datasets and experiment setting are presented below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Real gene expression datasets</head><p>This evaluation is based on real gene expression data, obtained from nine published microarray studies, and summarized in<ref type="figure" target="#tab_1">Table 1</ref>. The experiments were conducted over filtered datasets as given in the empirical study of de<ref type="bibr" target="#b6">Souto et al. (2008)</ref>, where uninformative genes are removed for a better quality of clustering result. Details of the types of datasets, data preprocessing and the gene selection method are given in Supplementary Sections 2.1–2.2. To rigourously evaluate the robustness of LCE and its compared techniques, they are also assessed on both simulated gene expression data (with noise and imbalanced clusters) and geometrically complicated datasets (see Supplementary Sections 3–4 for data descriptions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Experiment setting</head><p>The proposed LCE method and its competitors are evaluated, using the experiment setting illustrated below. @BULLET Each cluster ensemble method is evaluated over four different types of ensemble: (i) Fixed-k with full-space data (with d genes), (ii) Fixed-k with subspace data (with q genes), (iii) Random-k with full-space data and (iv) Random-k with subspace data, respectively.</p><p>@BULLET An ensemble size (M) of only 10 base clusterings was used. @BULLET To generate a refined cluster-association matrix (RM), the constant decay factor (DC) of 0.9 is exploited with the underlying link-based similarity algorithm (i.e. WCT). @BULLET For a comparison purpose, as in Fern and Brodley (2004) and<ref type="bibr" target="#b18">Kim et al. (2009)</ref>, each clustering method divides data points into a partition of K (the number of true classes for each dataset, known as 'gold standard') clusters, which is then evaluated against the corresponding true partition using a set of well-known evaluation indices. Note that, true classes are known for all datasets but are absolutely not used in any way by the cluster ensemble process; they are only used to evaluate the quality of the clustering results after clustering is complete. This assessment framework has been successfully adopted in de<ref type="bibr" target="#b6">Souto et al. (2008)</ref>@BULLET The current research follows several previous studies (<ref type="bibr" target="#b18">Kim et al., 2009;</ref><ref type="bibr" target="#b25">Monti et al., 2003;</ref><ref type="bibr" target="#b36">Yu et al., 2007</ref>) that focus on clustering samples of a given microarray data into known groups, i.e. class prediction. In particular to these methods, the quality of data partition π * generated by a clustering technique is directly compared against the Page: 1517 1513–1519known partition (i.e. class labels), using external validity indices such as Adjusted Rand (AR;<ref type="bibr">Hubert and Arabie, 1985</ref>), Normalized Mutual Information (NMI;<ref type="bibr" target="#b33">Strehl and Ghosh, 2002</ref>) and Classification Accuracy (CA;<ref type="bibr">Nguyen and Caruana, 2007</ref>). These specific indices are exploited for evaluating the performance of the proposed LCE method, against several other clustering techniques. The limitation of this evaluation is that the capability of examined methods for 'class discovery' has not been reviewed. Unlike the task of class prediction, the quality of data partition is determined by a structural properties of clusters, e.g. a compactness of samples in a cluster and a distance between clusters. To this extent, an initial study regarding of LCE for the task of class discovery is provided in Supplementary Section 8.2. In addition, the analysis of gene domain is another prominent research, in which LCE may prove to be useful. In particular, a better quality assessment should make use of a validity index that takes into account known gene functions, instead of simple external or internal indices mentioned earlier. Here, the performance of a given clustering algorithm is justified in terms of its ability to produce biologically meaningful clusters using a reference set of functional classes, which can be obtained from prior biological knowledge specific to a microarray study or may be formed using the growing databases of Gene Ontologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LCE method for improved gene expression data analysis</head><p>@BULLET The quality of each cluster ensemble method with respect to a specific ensemble setting is generalized as the average of 50 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>The results 1 with real gene expression data are summarized in<ref type="figure" target="#fig_4">Figure 5</ref>, where each investigated clustering method is represented with its average validity measure across all validity indices, datasets and ensemble types. It is clear that LCE regularly performs better than any of these clustering methods. It also enhances the performance of KM, which is used as base clusterings. In particular, HBGF is apparently less effective than LCE. This information suggests that the quality of the refined cluster-association matrix (RM) is superior than the original BM counterpart. See the full results with real gene expression datasets in Supplementary Section 2.3. Following the study of<ref type="bibr" target="#b20">Kuncheva et al. (2006)</ref>, to rigourously evaluate the quality of investigated clustering techniques, the number of times that one method is significantly better and worse (to 95% confidence level) than the others are assessed across all experiment settings. Let X C (i,β) be the average value of validity index C ∈ {CA, NMI, AR} across n runs (n = 50 in this evaluation) for a cluster ensemble method i ∈ CM (CM is a set of 12 experimented clustering methods), on a specific experimentsetting β ∈ ST (ST is a set of 40 unique combination of four ensemble types and ten real gene expression datasets). The 95% CI,</p><formula>[L X C (i,β) ,U X C (i,β) ], for the mean X C (i,β) of each validity criterion C is calculated by L X C (i,β) = X C (i,β) − 1.96 S C (i,β) √ n and U X C (i,β) = X C (i,β) + 1.96 S C (i,β) √ n</formula><p>. Note that S C (i,β) denotes the SD of the validity index C across n runs for a clustering method i and an experiment setting β. In addition, multiple runs of any setting β ∈ ST are different and independent—each with a unique ensemble that is generated by randomly selected parameters, and possibly dissimilar gene subsets. The number of times that one method i ∈ CM is significantly better than its competitors, B C (i) (in accordance with the validity criterion C, across all experiment settings), can be defined as</p><formula>B C (i) = ∀β∈ST ∀i * ∈CM,i * =i better β C (i,i * ) (8) better β C (i,i * ) = 1 if L X C (i,β) &gt; U X C (i * ,β) 0 otherwise (9)</formula><p>Similarly, the number of times that one method i ∈ CM is significantly worse than its competitors, W C (i), in accordance with the validity criterion C, can be computed as</p><formula>W C (i) = ∀β∈ST ∀i * ∈CM,i * =i worse β C (i,i * ) (10) worse β C (i,i * ) = 1 ifU X C (i,β) &lt; L X C (i * ,β) 0 otherwise (11)</formula><p>Using the aforementioned assessment formalism,<ref type="figure" target="#fig_5">Figure 6</ref>illustrates for each method i ∈ CM the statistics of total performance</p><formula>(B−W ) i = ∀C∈{CA,NMI,AR} B C (i)−W C (i)</formula><p>. The results shown in this figure indicate that LCE is more effective than other clustering techniques included in this experiment. Since SL and AL do not perform well over the examined datasets, MULTI-K and CC HC that use the former and latter as a consensus function, respectively, are less accurate than other cluster ensemble methods and KM. However, their performance may improve with an ensemble that is much larger than the one investigated herein (i.e. M &gt;&gt; 10). In addition to this evaluation scheme, a further performance analysis with a paired t-test is discussed in Supplementary Section 2.4. Another important investigation is on the subject of relations between performance of experimented cluster ensemble methods and different types of ensemble being explored in the present evaluation.<ref type="figure" target="#fig_6">Figure 7</ref>shows the average validity measures of different cluster ensemble methods across all validity indices and real gene expression datasets. For each method, its performance with Page: 1518 1513–1519,0.2,...,0.9} and the performance of the LCE method (the averages of CA, NMI and AR over 10 real gene expression datasets and 4 ensemble types), whose values are presented in X-axis and Y-axis, respectively. Note that the averaged performance of other cluster ensemble methods are also included for a comparison purpose. four ensemble types (Full-space + Fixed-k, Full-space + Random-k, Subspace + Fixed-k, and Subspace + Random-k) are compared. It is clear that LCE is more effective than other cluster ensemble techniques over all ensemble types, with its best performance being generated from a 'Full-space + Fixed-k' ensemble. Most methods work better with Full-space ensembles, as compared to Subspace alternatives. Unlike LCE, GCC and other graph-based techniques that usually produce a superior performance with a Fixed-k ensemble type, MULTI-K and CC HC are best when coupled with Random-k ensembles. Although the results are impressive, on several datasets, it is important to ensure they are obtainable in a wide range of conditions. To this end the LCE algorithm's response was examined to perturbations in its parameters, and by investigating its time and space complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N.Iam-on et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parameter analysis</head><p>The parameter that has any effect on the results of LCE is DC [see<ref type="bibr">Equation (7)]</ref>. With the ensemble size of 10, we varied this value from 0.1 through 0.9, in steps of 0.1, for three validity measures, and obtained the results in<ref type="figure" target="#fig_7">Figure 8</ref>. This<ref type="figure">figure clearly</ref>shows that the results are robust, and do not depend strongly on any particulary value of DC. This makes it easy for users to obtain high-quality, reliable results when using LCE, particularly since values of DC near 0.7 generally produce the best results. Although there is variation in response across the DC values, the performance of LCE is always better than any of the other cluster ensemble methods included in this assessment. Another important parameter that may determine the quality of a cluster ensemble technique, is the ensemble size (M). Intuitively, the larger an ensemble is, the better the performance becomes.According to<ref type="figure" target="#fig_8">Figure 9</ref>in which DC = 0.9, this heuristic is applicable to LCE, where its validity measures (averages of CA, NMI and AR across all experimental settings) gradually incline to the increasing value of M ∈{10,20,...,100}. Furthermore, LCE performs better than its competitors with all different ensemble sizes. Note that a bigger ensemble leads to an improved accuracy, but with the tradeoff of run time—but, again, even the worst results for LCE are better than the best results of the other methods. These findings regarding the relation between LCE and its parameters have also been observed when both DC and M are simultaneously analysed (see details in Supplementary Section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Complexity analysis</head><p>The space and time complexity of creating a refined clusterassociation matrix (RM) are O(P 2 +NP) and O(P 2 l +NP), where N is the number of samples, P denotes the number of all clusters in an ensemble and l represents the average number of neighbours connecting to one cluster in a link network of clusters. For each entry (corresponding to clusters C x ,C y ∈ ) in the P ×P matrix of cluster similarity, WCT searches through l neighbors of C x (or C y ) to identify connected triples. Following this, the RM of size N ×P is created using the aforementioned similarity matrix. As a result, LCE is computationally efficient with the time complexity generally converging to O(N). Please consult Supplementary Section 6 for details of the scalability test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Additional utilization of RM with simple clusterings</head><p>Besides its current utilization through the formation of a weighted bipartite graph, the RM can also be regarded as a 'high-level' data matrix to which any simple clustering algorithm can be directly applied. Promising results have been obtained from the exploitation of six simple clustering techniques with RM: RM + SL, RM + CL, RM + AL, RM + KM, RM + Partitioning Around Medoids and RM + spectral clustering, respectively (see detailed results in Supplementary Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>A new LCE method has been introduced for clustering gene expression data samples that has greatly improved accuracy and efficiency. The performance of LCE is usually superior than existing graph-based ensemble techniques, and those that are particularly developed for gene data analysis. LCE is highly effective over real gene expression datasets and synthetic data collections (with Page: 1519 1513–1519</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LCE method for improved gene expression data analysis</head><p>the presence of noise and non-equal-size clusters). Unlike existing pairwise similarity based counterparts, LCE is efficient for clustering large-size datasets, including the clustering of genes. Specifically, the refined cluster-association matrix (RM) used by LCE is able to recover and account for unknown entries in the original BM counterpart, and hence, delivers a superior clustering performance. With its consistent performance over settings of parameter, ensemble type and size, LCE also proves to be a user-friendly data analysis tool, especially for non-expert users.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. An example of (a) cluster ensemble of samples {x 1 ...x 5 } that consists of two base clusterings (π 1 ={C 1 1 ,C 1 2 ,C 1 3 } and π 2 ={C 2 1 ,C 2 2 }), (b) the corresponding pairwise similarity matrix and (c) BM, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.4.</head><figDesc>Fig. 4. Details of disclosed WCT similarities/relations with DC being 0.9, and the resulting RM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>k-means (KM), single-linkage (SL), complete-linkage (CL) and average-linkage (AL)]; (iii) three pairwise similarity-based cluster ensemble algorithms that have been developed so far for gene expression data analysis [MULTI-K, consensus clustering with hierarchical clustering (CC HC ) and graph-based consensus clustering (GCC)], and three graph-based cluster ensemble techniques that have been considered as benchmarks in the literature [Clusterbased Similarity Partitioning Algorithm (CSPA), Hyper-Graph Partitioning Algorithm (HGPA) and Meta-Clustering Algorithm (MCLA)]. Details of examined cluster ensemble techniques are given below. @BULLET Pairwise similarity-based cluster ensemble methods are based principally on the pairwise similarity among samples. Given a cluster ensemble ={π</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>to compare the performance of different simple clustering algorithms over a large number of gene expression datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.5.</head><figDesc>Fig. 5. Average validity measures of different clustering methods, across all validity indices (CA, NMI, AR) and experimental settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.6.</head><figDesc>Fig. 6. The statistics of total performance, summarized across all evaluation indices, i.e. (B−W ) i ,∀i ∈ CM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.7.</head><figDesc>Fig. 7. Average validity measures of different cluster ensemble methods across all validity indices and real gene expression datasets, categorized in accordance with four types of ensemble.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.8.</head><figDesc>Fig. 8. The relations between DC ∈{0.1,0.2,...,0.9} and the performance of the LCE method (the averages of CA, NMI and AR over 10 real gene expression datasets and 4 ensemble types), whose values are presented in X-axis and Y-axis, respectively. Note that the averaged performance of other cluster ensemble methods are also included for a comparison purpose.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.9.</head><figDesc>Fig. 9. Performance of different cluster ensemble methods in accordance with ensemble size (M ∈{10,20,...,100}), as the averages of validity measures (CA, NMI and AR) across all real gene expression datasets and ensemble types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><figDesc>Funding: Scholarship of the Ministry of Science and Technology, Royal Thai Government (to N.I.-O.). Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>denotes the similarity between any two clusters C x ,C y , which can be discovered using the following link-based algorithm. Note that, for any clustering π t ∈ , 1≤ ∀C∈πt RM(x i ,C) ≤ k t. Unlike the measure of fuzzy membership, the typical constraint of ∀C∈πt RM(x i ,C) = 1 is</figDesc><table>Page: 1515 1513–1519 

LCE method for improved gene expression data analysis 

Fig. 3. Examples of (a) cluster network and (b) connected-triple between 
vertices C 1 
1 and C 1 
3 , where w C 1 

1 C 1 

3 

= 0. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>) can be constructed, where V = V X ∪V C is a set of vertices representing both samples V X and clusters V C , and W denotes a set of weighted edges that can be defined as follows: @BULLET w ij = 0 when vertices v i ,v j ∈ V X , i.e. correspond to samples. @BULLET w ij = 0 when vertices v i ,v j ∈ V C , i.e. correspond to clusters. @BULLET w ij = RM(v i ,v j ) when vertices v i ∈ V X and v j ∈ V C. The bipartite graph G is bi-directional such that w ij is equivalent to w ji .</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 1.</figDesc><table>Description of real gene expression datasets: tissue type, microarray chip type, number of samples (N), number of original genes (d  *  ), number of 
selected genes (d), number of classes (K) and class distribution 

Dataset 
Tissue 
Chip Samples Original 
Selected Classes Class 
(N) 
genes (d  *  ) genes (d) (K) 
distribution 

Leukemia1 (Golub et al., 1999) 
Bone marrow 
Affy 
72 
7129 
1877 
2 
47, 25 
Leukemia2 (Golub et al., 1999) 
Bone marrow 
Affy 
72 
7129 
1877 
3 
38, 9, 25 
Leukemia3 (Armstrong et al., 2002) 
Blood 
Affy 
72 
12 582 
2194 
3 
20, 24, 28 
Breast-Colon tumors (Chowdary et al., 2006) 
Breast and colon Affy 
104 
22 283 
182 
2 
62, 42 
Brain Tumor (Nutt et al., 2003) 
Brain 
Affy 
50 
12 625 
1377 
4 
14, 14, 7, 15 
Central nervous system (Pomeroy et al., 2002) 
Brain 
Affy 
42 
7129 
1379 
5 
10, 8, 10, 10, 4 
Multi-tissue1 (Ramaswamy et al., 2001) 
Multi-tissue 
Affy 
190 
16 063 
1363 
14 
11, 10, 11, 11, 22, 11, 10, 10, 
30, 11, 11, 11, 11, 20 
Multi-tissue2 (Su et al., 2001) 
Multi-tissue 
Affy 
174 
12 533 
1571 
10 
26, 8, 26, 23, 12, 11, 7, 27, 6, 28 
Hepatocellular carcinoma (Chen et al., 2002) 
Liver 
cDNA 180 
22 699 
85 
2 
104, 76 
Small, round blue-cell tumors (Khan et al., 2001) Multi-tissue 
cDNA 83 
6567 
1069 
4 
29, 11, 18, 25 

See Supplementary Material for further details. 

similarity matrix (CO) is constructed as CO(x i ,x j </table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 1513 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [15:46 21/5/2010 Bioinformatics-btq226.tex]</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> This section only contains a summary of our empirical evaluation over real gene expression data. For more detailed results and experiments with other data collections, please see Supplementary Sections 2-4.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">MLL translocations specify a distinct gene expression profile that distinguishes a unique leukemia</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Armstrong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="41" to="47" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Fuzzy ensemble clustering based on random projections for DNA microarray data analysis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Avogadri</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Valentini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="173" to="183" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Functional network analysis reveals extended gliomagenesis pathway maps and three novel MYC-interacting genes in human gliomas</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bredel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="8679" to="8689" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Metagenes and molecular pattern discovery using matrix factorization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Brunet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="4164" to="4169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Gene expression patterns in human liver cancers</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Cell</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1929" to="1939" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Prognostic gene expression signatures can be measured in tissues collected in RNAlater preservative</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Chowdary</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Diagn</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="31" to="39" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Clustering cancer gene expression data: a comparative study</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>De Souto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">497</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Pattern Classification</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">O</forename>
				<surname>Duda</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn. Wiley-Interscience</note>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Bagging to improve the accuracy of a clustering procedure</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dudoit</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fridyand</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1090" to="1099" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Solving cluster ensemble problems by bipartite graph partitioning</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<forename type="middle">Z</forename>
				<surname>Fern</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">E</forename>
				<surname>Brodley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning<address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Combining multiple clusterings using evidence accumulation</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L N</forename>
				<surname>Fred</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">K</forename>
				<surname>Jain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="835" to="850" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Golub</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="531" to="537" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Moderate diversity for better cluster ensembles</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">T</forename>
				<surname>Hadjitodorov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Fusion</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="264" to="275" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Computational cluster validation in post-genomic data analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Handl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3201" to="3212" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Refining pairwise similarity matrix for cluster ensemble problem with cluster relations</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Iam-On</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eleventh International Conference on Discovery Science</title>
		<meeting>Eleventh International Conference on Discovery Science<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Multilevel k-way partitioning scheme for irregular graphs</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Karypis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="96" to="129" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Multilevel hypergraph partitioning: applications in VLSI domain</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Karypis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. VLSI Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Khan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="673" to="679" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">MULTI-K: accurate classification of microarray subtypes using ensemble k-means clustering</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">260</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Using diversity in cluster ensembles The Hague, The Netherlands</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">I</forename>
				<surname>Kuncheva</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">T</forename>
				<surname>Hadjitodorov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Systems</title>
		<meeting>the IEEE International Conference on Systems<address><addrLine>Man &amp; Cybernetics, IEEE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1214" to="1219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of stability of k-means cluster ensembles with respect to random initialization</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">I</forename>
				<surname>Kuncheva</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Vetrov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1798" to="1808" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Experimental comparison of cluster ensemble methods</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">I</forename>
				<surname>Kuncheva</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Fusion, International Society of Information Fusion</title>
		<meeting>International Conference on Fusion, International Society of Information Fusion<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust singular value decomposition analysis of microarray data</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="13167" to="13172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Luxburg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">A mixture model-based approach to the clustering of microarray expression data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="413" to="422" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Consensus clustering: a resampling-based method for class discovery and visualization of gene expression microarray data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Monti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="91" to="118" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">On spectral clustering: analysis and an algorithm</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="849" to="856" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Gene expressionbased classification of malignant gliomas correlates better with survival than histological classification</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Nutt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1602" to="1607" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Prediction of central nervous system embryonal tumour outcome based on gene expression</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pomeroy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="page" from="436" to="442" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiclass cancer diagnosis using tumor gene expression signatures</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ramaswamy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 98</title>
		<meeting>. Natl Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="15149" to="15154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Survey on test collections and techniques for personal name matching</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Reuther</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Walter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Metadata Semantics Ontologies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="89" to="99" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Malik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Repeated observation of breast tumor subtypes in independent gene expression data sets</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Sorlie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="8418" to="8423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Cluster ensembles: a knowledge reuse framework for combining multiple partitions</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Strehl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ghosh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="583" to="617" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Molecular classification of human carcinomas by use of gene expression signatures</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Su</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="7388" to="7393" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Consensus clustering and functional interpretation of geneexpression data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Swift</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph-based consensus clustering for class discovery from gene expression data</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2888" to="2896" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>