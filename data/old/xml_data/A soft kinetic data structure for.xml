
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A soft kinetic data structure for lesion border detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Sinan</forename>
								<surname>Kockara</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Central Arkansas</orgName>
								<address>
									<postCode>72035</postCode>
									<settlement>Conway</settlement>
									<region>AR</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Mutlu</forename>
								<surname>Mete</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Texas A&amp;M University Commerce</orgName>
								<address>
									<postCode>75429</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Vincent</forename>
								<surname>Yip</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Central Arkansas</orgName>
								<address>
									<postCode>72035</postCode>
									<settlement>Conway</settlement>
									<region>AR</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Brendan</forename>
								<surname>Lee</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Central Arkansas</orgName>
								<address>
									<postCode>72035</postCode>
									<settlement>Conway</settlement>
									<region>AR</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Kemal</forename>
								<surname>Aydin</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Arkansas</orgName>
								<address>
									<addrLine>Pine Bluff</addrLine>
									<postCode>71601</postCode>
									<region>AR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A soft kinetic data structure for lesion border detection</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="21" to="28"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq178</idno>
					<note>[10:48 12/5/2010 Bioinformatics-btq178.tex] Page: i21 i21–i28 BIOINFORMATICS Contact: skockara@uca.edu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The medical imaging and image processing techniques, ranging from microscopic to macroscopic, has become one of the main components of diagnostic procedures to assist dermatologists in their medical decision-making processes. Computer-aided segmentation and border detection on dermoscopic images is one of the core components of diagnostic procedures and therapeutic interventions for skin cancer. Automated assessment tools for dermoscopic images have become an important research field mainly because of inter-and intra-observer variations in human interpretations. In this study, a novel approach—graph spanner— for automatic border detection in dermoscopic images is proposed. In this approach, a proximity graph representation of dermoscopic images in order to detect regions and borders in skin lesion is presented. Results: Graph spanner approach is examined on a set of 100 dermoscopic images whose manually drawn borders by a dermatologist are used as the ground truth. Error rates, false positives and false negatives along with true positives and true negatives are quantified by digitally comparing results with manually determined borders from a dermatologist. The results show that the highest precision and recall rates obtained to determine lesion boundaries are 100%. However, accuracy of assessment averages out at 97.72% and borders errors&apos; mean is 2.28% for whole dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Melanoma is the fifth most common malignancy in the US. Invasive and in-situ melanoma has rapidly become one of the leading cancers in the world. Malignant melanoma, the most deadly form of skin cancer, is one of the most rapidly increasing cancers. 62 480 incidences and 8420 deaths are the estimated numbers in the USA in 2008 (<ref type="bibr" target="#b14">Jemal et al., 2008</ref>). In malignant melanoma, early diagnosis is particularly important since melanoma can be cured with a simple excision operation. Dermoscopy, also known as dermatoscopy, is one of the major non-invasive skin imaging techniques that is extensively used in the diagnosis of melanoma and other skin lesions. This imaging technique offers more visible image subsurface structures when compared to conventional clinical images (<ref type="bibr" target="#b1">Argenziano et al., 2002;</ref><ref type="bibr" target="#b8">Fleming et al., 1998</ref>). Dermoscopy also helps identifying various morphological features; for instance, blotches, streaks, blue-white areas, dots/ globules and pigment networks (<ref type="bibr" target="#b17">Menzies et al., 2003</ref>). Because of these unique features, screening errors can be reduced at the inspection. In addition, greater differentiation between difficult lesions, such as pigmented Spitz * To whom correspondence should be addressed. nevi, clinically equivocal lesions can be provided (<ref type="bibr" target="#b27">Steiner et al., 1993</ref>). Dermoscopic assessment remains one of the most critical steps in the diagnosis and subsequent treatment of malignant melanoma. Recent improvements in imaging techniques have led to the automated discovery of lesions. Traditionally, assessment of tumor margins is done manually by a dermatologist. The recognition of cancerous regions is a time consuming and error prone process, and it is innate in the nature of the human inspection. Unfortunately, for inexperienced dermatologists, dermoscopy may actually lower the diagnostic accuracy (<ref type="bibr">Binder et al., 1995</ref>). The use of a fast and reliable computerized system could markedly increase the number of examined images for the existence of cancer regions. Moreover, the computerized image analysis is able to minimize the effect of interand intra-observer variability. Inter-observer variability is defined in terms of the decisions assigned between different observers on the same subject. However, intra-observer variability is defined in terms of the decisions assigned within the observer; for instance, the same dermatologist judges differently on the same image at different times. Therefore, unlike inexperienced dermatologists, when it comes to trying to minimize the chance of diagnostic errors, it is important to develop computerized image analysis techniques. These techniques alleviate the difficulty and subjectivity of visual interpretations which are the major contributors to the diagnostic errors (<ref type="bibr" target="#b4">Celebi et al., 2009</ref>). In the investigation of melanoma, delineation of region-of-interest is the first and key step in the automated analysis of skin lesion images for many reasons. First and foremost, the border structure provides important information for accurate diagnosis. Asymmetry, border irregularity and abrupt border cutoff are of many clinical features calculated based on the border lesion. Furthermore, the extraction of other important clinical indicators such as atypical pigment networks, globules and blue–white areas critically depends on the border detection (<ref type="bibr">Schaefer et al., 2009a, b</ref>). At the first stage for analysis of dermoscopy images, automated border detection is usually being applied (<ref type="bibr">Celebi et al., 2007a, b</ref>). There are many factors that make automated border detection complex, e.g. low contrast between the surrounding skin and the lesion, fuzzy and irregular lesion border, intrinsic artifacts such as cutaneous features (air bubbles, blood vessels, hairs and black frames) to name a few (<ref type="bibr" target="#b4">Celebi et al., 2009</ref>). According to<ref type="bibr" target="#b4">Celebi et al. (2009)</ref>automated border detection can be divided into four sections: pre-processing, segmentation, post-processing and evaluation. Preprocessing step involves color space transformation (<ref type="bibr" target="#b19">Pratt, 2007</ref>), contrast enhancement (<ref type="bibr" target="#b6">Delgado et al., 2008</ref>) and artifacts removal (<ref type="bibr" target="#b3">Celebi, 2008;</ref><ref type="bibr" target="#b11">Geusebroek, 2003;</ref><ref type="bibr" target="#b15">Lee 1997;</ref><ref type="bibr" target="#b18">Perreault and Hébert, 2007;</ref><ref type="bibr" target="#b25">Schmid, 1999;</ref><ref type="bibr" target="#b28">Wighton 2008;</ref><ref type="bibr" target="#b29">Zhou 2008</ref>). Segmentation step involves partitioning of an image into disjoint regions (<ref type="bibr" target="#b26">Sonka et al., 2007</ref>). Post-processing step is used to obtain the lesion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Kockara et al.</head><p>border (<ref type="bibr">Celebi, 2007a, b;</ref><ref type="bibr" target="#b16">Melli, 2006;</ref><ref type="bibr" target="#b13">Iyatomi, 2006</ref>). Evaluation step involves dermatologists' evaluations on the border detection results. In this study, a proximity graph representation approach to detect regions and borders in skin lesions for dermoscopic images is introduced. This approach is based on a soft kinetic data structure (SKDS): graph spanners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A SKDS</head><p>Today the need for processing continuously moving points in a wide range of application areas such as geographic information systems, networking, traffic control, weather forecasting and nearest neighbor search is more pervasive than ever. The ideal solution for maintaining and processing continuously moving points has not been thoroughly presented yet. However, there are two recent approaches for processing moving points; they are dynamic data structures (DDS) and kinetic data structures (KDS). DDS assume that the data points change their positions only at explicitly known time steps; thus, they are not adequate solution for maintaining and processing continuously moving points. The alternative approach to DDS is given in the context of computational geometry with KDS which are recently introduced by<ref type="bibr">Basch et al. (1999)</ref>. In KDS, it is assumed that points' motions are unknown but not arbitrary since equations of motions are assumed to be algebraic functions of time (typically linear or polynomially bounded) (<ref type="bibr" target="#b12">Guibas et al., 1998</ref>). In other words, it is assumed that there are no sudden position leaps that cannot be defined by an algebraic function of time. KDSs consist of hierarchies of points that keep hierarchy updated for moving points. Superior form of KDS for dynamic points under unpredictable motions is called SKDS (<ref type="bibr" target="#b5">Czumaj and Sohler, 2001</ref>). SKDSs are approximate data structures that are used to answer proximity queries. In the light of abovementioned definition of SKDS, to our knowledge, deformable spanner (DS) (<ref type="bibr" target="#b10">Gao et al., 2006</ref>) is the first SKDS that maintains its structure under formerly unknown motion models in 3D. DS supports all the criteria of uniformity, controllability, locality, being discrete and proximity based that a good KDS would provide (<ref type="bibr" target="#b0">Alexandron et al., 2007;</ref><ref type="bibr" target="#b20">Russel and Guibas, 2005</ref>). These criteria facilitate spanner's usage in different application areas. Locality of edges is affected by a small subset of the total point set. This means that changes in one part of the graph do not generally affect the spanner edges in the other parts. There is only one uniform combinatorial element in the spanner that is called edge. Spanner is controllable to allow us to produce controllers (e.g. expansion ratio) capable of capturing the shape of the object with various degrees of tightness or looseness. Spanners are discrete; thus, their description does not include any geometric coordinates. Proximities in the spanner determine the local interactions and in turn local interactions determine the behavior of the moving points. We consider the dermoscopy image's pixel colors in the context of computational geometry with SKDS. Our hypothesis is that: important characteristics (e.g. color combinations) of a skin lesion image can be obtained in a proximity graph representation by examining colors and their color-space (e.g. RGB) closeness relationships. Thus, we represent images as graphs to obtain color patterns. In order to represent an image as a graph, we take a cue from<ref type="bibr" target="#b10">Gao et al. (2006)</ref>and produce graph spanner approach for image segmentation. High-level patterns from properties of unique colors represented in an image are exposed by a hierarchical graph</p><p>spanner. SKDS approach we use—hierarchical graph spanner— representation (in short: balls hierarchy, BH) is explained in Section 2.2. Even though BH is capable of handling dynamic changes in images (e.g. video stream) in our case of detecting lesion borders in dermoscopy images; image pixels are static data points in 2D. There exists numerous innovative graph-based image segmentation approaches in the literature.<ref type="bibr" target="#b22">Shi et al. (1998)</ref>treated segmentation as a graph partitioning problem, and proposed a novel unbiased measure for segregating subgroups of a graph, known as the normalized cut (NC) criterion. More recently, Felzenszwalb and Huttenlocher (2004) developed a segmentation technique by defining a predicate for the existence of boundaries between regions, utilizing graph-based representations of images. However, our graph spanner method approaches image segmentation problem as an approximate shortest path finding problem with a given expansion ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notations and preliminaries</head><p>A B i-level hierarchical representation is called clusters of balls (B) or BH. A pair (χ,d) is called metric space where χ is a point set and d is a distance function. d : χ × χ → [0,∞) satisfying the d(u,v) = 0 if and only if points u and v are equal, and symmetry and triangle inequality hold for distance function d(u,</p><formula>v) = d(v,u), d(u,v) + d(v,z) ≥ d(u,z),</formula><p>respectively, where u, v and z are nodes in the hierarchy. B is in the metric (χ, d) and is a sequence of levels B 0 , B 1 , ..., B h where h = log ξ R . indicates upper bound, h represents number of hierarchical levels, R represents radius at the highest level and ξ is a constant and called expansion ratio. This value determines how much a cluster ball will expand from one level to the upper level. For instance, v at level i+1 is a parent of u at level i is represented as P i+1 (u i ) = v or P(u i ) = v i+1 , where u ∈ B i , v ∈ B i+1. P j (u i ) = v, j&gt;i indicates that u at level i has v as a parent at level j where j ≥ i+1. C i (v i+1 ) = u or C(v i+1 ) = u i indicates that u at level i is a child of v at level i+1 or C i (v j ) = u, j &gt; i, v's i-th level child is u. One node may have multiple children at the same level and has single parent. However, one node can be covered by multiple cluster balls from the upper levels. Neighbors of v where v ∈ B i is represented as N(</p><formula>v i ), N(v i ) = {u i ∈ B i , |u i v i | ≤ ηrξ i−1 }</formula><p>where η is neighbor coefficient, r is minimum radius, and rξ i is a radius at the level i. Ball v's neighbor at level i is represented as N(v i ) = u i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">BH</head><p>Hierarchical representation of graph spanners is approximating the metric space with a hierarchy of nodes based upon a sampling of the data subsets. The construction of these sets should be guaranteed with the following properties (<ref type="bibr" target="#b10">Gao et al., 2006</ref>):</p><p>(1) B h —the highest level cluster ball—covers entire set of points (χ) in the graph G.</p><p>(2) Vertex set V initially exists from points where each point is a center of a cluster ball. V i represents vertices at level i where these vertices are cluster balls' centers at level i.</p><formula>V = 0≤i≤h V i and V i ⊆V i−1 .</formula><p>(3) No cluster ball at the same level covers other ball's center. Therefore, d|c(B k i )c(B m i )| &gt; rξ i , where i is level, c(B k i ) ∈ V represents center of a ball k at level i. B k i ∈ B i , rξ i or r i is radius at the level, and k = m.Page: i23 i21–i28</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A soft kinetic data structure for lesion border detection</head><p>(4) There is a geometrically decreasing order among the clusters; B h , B h−1 , ... ,B 0 , where B 0 is the original point set itself and only contains a single vertex cluster. The cluster B i-where I = 0,1,2,…,h-is a ball with radius r i at level i.</p><p>(5) Ball clusters are hierarchical. B i is refined representation of one lower level cluster B i−1. There is no lower level cluster which is not contained or covered by an upper level cluster. That means hierarchical representation of clusters is laminar family of sets.</p><p>(6) Each edge in hierarchy connects some neighbor clusters at the same level in B i (neighbor edge).</p><p>(7) Some children clusters of B i in B i−1 are connected by edges (child edge).</p><p>(8) Each B i−1 cluster is covered by cluster in B i (B i−1 ⊆ B i ). Therefore, |B i−1 | ≥ |B i | where |B i−1 | represents number of clusters at level i−1. Equality holds only in the situation that each and every cluster becomes parent cluster of itself.</p><p>(9) Maximum number of distance scales (number of levels) is h = log ξ t where t is maximum distance between any two nodes.</p><p>(10) According to coverage property ∀u ∈ B i−1 with i ≤ h, ∃v ∈ B i. Every cluster ball's center is covered by one upper level's cluster ball's center. A cluster ball can be covered by another concentric ball (u = v) at one upper level.</p><p>(11) According to the separation property, u, v ∈ B i+1 where u = v, d G (u,v) ≥ rξ i , and r is minimum radius (radius at the first level where i = 0).</p><p>(12) Cousin property implies that two close points that belong to different balls at B i are children of the same ball at B k where i &lt; k ≤ h (h, number of levels in the hierarchy). This implies that cousins will have common ancestor.</p><p>(13) There exists a parent chain from a point u at level i to its parent at j, where j &gt; i. This chain can be followed by:</p><formula>P j (…(P i+3 (P i+2 (P i+1 (u i ))))…) = v, u =</formula><p>v when u expands up to the level j (parent of itself).</p><formula>(14)</formula><p>There is no unique hierarchy even for the same point set. Different insertion order of points would result in different but equally good hierarchy construction.</p><formula>(15) If C i (v i+1 ) = u or C(v i+1 ) = u i and u = v, then N(v i ) = u i. If a ball u i</formula><p>is a child of another ball v i+1 at upper level, then u i must be neighbor of v i. This implies that a ball cannot become a child before becoming a neighbor. This is because no position leap is assumed.</p><p>Next section clarifies how these properties are satisfied and applied to construct BH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Hierarchy construction</head><p>In this section, survivors, non-survivors and balls represent points. Ball is used in order to represent point with its radius-covering.<ref type="figure" target="#fig_1">Figure 1</ref>illustrates BH construction steps for 10 points by using properties given in Section 2.2. In this illustration, hierarchy is consisting of four levels (property 9). Each level of the hierarchy is represented in different colors; black, red, blue and green colors, respectively. Dashed circles represent radius-covering at the level.In the first level original data points exist with minimum radius r. Since minimum distance between closest color pairs (assuming in 3D RGB color space) in an image is 1, r is assigned as 1. As seen from the first level, since no other ball center is covered by any other ball, all survive (exist in the level). In the second level, only five points survive, since other points are covered by survivors with radius in the second level, R2. Non-survivor points become children of survivors. This relation is represented by child edges (see property 7 above) which are illustrated as steady black lines. R2 is expanded from minimum radius by expansion ratio (ξ); thus, R2 = r ξ 1. Superscript 1 represents level difference between level 2 and 1. Steady red lines in the second level represent neighbor edges (see property 6 above) which represent neighbor relations between any two survivor points (N(v i ) = {u i ∈ B i , |u i v i | ≤ ηrξ i−1 }). Two survivors are neighbors if and only if distance between them is smaller than or equal to the neighbor coefficient (η) times radius at the level (R2). In the third level, there exist only three balls (blue) with radius R3 = ξ 2 r, and a single non-survivor which becomes a child. Now, there are three neighbors (blue lines) in the third level. In level 4, there is only a single survivor (green) with two children. This survivor is called root and covers all existing points. Notice that in order a non-survivor point to become a child of a survivor point, it needs to be a neighbor of the survivor point in the previous level. Once hierarchy is constructed, BH keeps hierarchical representation of approximate shortest paths among all the existing points. Hierarchy construction time is O(n log n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE HIERARCHY REPRESENTATION FOR DERMOSCOPY IMAGES</head><p>Data points for an image are pixel's RGB colors. Once all pixels are inserted into the BH, color pixels are segmented as illustrated in<ref type="figure" target="#fig_2">Figure 2</ref>. Note that, due to the nature of RGB space similar colors are close to each other. After the construction, hierarchy is ready for a proximity query e.g. nearest neighbors. A proximity query will return any pixel with the specified color and its geometric i23neighbors in color space (RGB or any color space). Firing a query is corresponding to tree traversal. As seen from<ref type="figure" target="#fig_2">Figure 2</ref>, the suspected cancer regions, borders and the background are available right after the indexing process. In<ref type="figure" target="#fig_2">Figure 2</ref>each branch of the tree is corresponding to one of the segments; the background (branch 1), right outside the border (branch 2), right inside the border including border (branch 3) and the lesion (inside the border, branch 4), respectively. Once hierarchy is constructed, the segments can be easily extracted by a simple hierarchy traversal. Depending on applications, segmentation also contributes to image regions or border identification. In dermoscopy images, some edges of the lesions are clearly defined while some have poorly defined edges such as the basal cell carcioma. Different significant parts of these images are successfully identified by performing three unique queries to recognize: (i) cancer region, (ii) cancer region border and (iii) the entire background. It is observed after the experiments that smallest number of children branch under the root node always indicates border. Since dermatologists focus on borders for diagnosis, we also return borders (branch 3 in<ref type="figure" target="#fig_2">Fig. 2</ref>) as a result of border query. Note that this hierarchy indexing method does not require any initial seed point which means that BH is a global approach. Most often networks and points in nature are dynamic. Points are moving towards or against applied stimuli. Therefore, dynamic update operations such as insert and expand in the BH have profound impact on adapting hierarchy for motions. The following section will introduce insert and expand operations in the pseudo codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Kockara et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION</head><p>The most important operation in hierarchy construction is insert operation. To do that, first, expand operation is given as below. A range of precision and computation time trade-offs have been implicated for using two different insertion schemes; optimum insertion and best optimum insertion respectively. Since precision is more important for us, we implemented best optimum insertion scheme as seen in Algorithm 2 below. This insertion scheme inserts new point into the best optimum place instead of the first optimum place found. In the best optimum insertion, the closest point among all other points is found by simply traversing the tree. To do that, in Algorithm 2 node Q's all children must be traversed. When the closest node is found among all the children, this closest node must be traversed recursively until no covering node (see property 3 in Section 2.2) is found. The last found node is called the best optimum place for insertion. Best optimum insertion scheme as a result succinctly provides higher precision and in turn leads to a better range query e.g. nearest neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>BH method is tested on a set of 100 dermoscopy images obtained from the EDRA Interactive Atlas of Dermoscopy (<ref type="bibr" target="#b1">Argenziano et al., 2002</ref>). These are 24-bit RGB color images with dimensions ranging from 577 × 397 to 1921 × 1285 pixels. The benign lesions include nevocellular nevi and dysplastic nevi. Two unique queries are used to extract the desired region of the images. The first query is performed by looking for an entire branch of a directly related child node (DRCN) of the root node (RN). According to<ref type="figure" target="#fig_2">Figure 2</ref>, node 1, 33, 572 and 916 are DRCNs. Node zero is the RN. Each DRCN along with all their children nodes form one branch of the hierarchy. The hierarchy segments an image based on distance between colors and stores the pixel values in separated branches. Therefore, by querying each branch of the hierarchy, different color segment of an image can be obtained separately. For instance, the border of an indexed image can be archived by querying the entire branch of 33 in<ref type="figure" target="#fig_2">Figure 2</ref>. The second query is very similar to the first query except that the neighbors of children of all DRCN are included. This query yields an additional region of the image: the background. According to<ref type="figure" target="#fig_2">Figure 2</ref>, children of one are neighbors of 916's children. The BH based border detection errors are objectively quantified using dermatologist-determined borders as the ground truth. The BH detected border images overlaid on top of the dermatologistdetermined border images. Quantative error metrics such as true/false positive/negative ratios found according to the overlay images.<ref type="figure" target="#fig_5">Figure 4</ref>shows sample original images<ref type="bibr">[</ref>Page: i25 i21–i28</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A soft kinetic data structure for lesion border detection</head><p>among 100 images with the highest, lowest, and on average border error (BE) ratios<ref type="bibr">]</ref>. The BH detected borders and interiors (e.g. combination of branches 3 and 4 of<ref type="figure" target="#fig_2">Fig. 2</ref>), overlaid images, and dermatologist-determined region are all illustrated, respectively, in<ref type="figure" target="#fig_5">Figure 4</ref>. Second, accuracy of our method is quantified by digitally comparing results with manually determined borders from a dermatologist. We evaluated border detection error of BH. Manual borders were obtained by selecting a number of points on the lesion border, connecting these points by a second-order B-spline and finally filling the resulting closed curve (<ref type="bibr" target="#b3">Celebi, 2008</ref>). Using the dermatologist-determined borders, the automatic borders obtained from the BH are compared using three quantitative error metrics: BE, precision and recall. BE is developed by<ref type="bibr" target="#b9">Gao et al. (1998) and</ref><ref type="bibr">Schaefer et al. (2009a, b</ref>), and given by</p><formula>BE = [(AB⊕MB)/MB]× 100,</formula><p>where ⊕ is exclusive OR operator, essentially underlines disagreement between target (ManualBorder, MB) and predicted (AutomaticBorder, AB) regions. Referring to information retrieval terminology, nominator of the BE means summation of false positive (FP) and false negative (FN). Denominator is obtained by adding true positive (TP) to false negatives (FN). An illustrative example is given in<ref type="figure" target="#fig_4">Figure 3</ref>. In the figure, assume that red and blue borders are drawn by a dermatologist and a non-expert, respectively. TP indicates correct lesion region found automatically. Similarly, TN shows healthy region (background) for both manual and computerassessment agreed on. FN and FP are labels for missed lesion and erroneous positive regions, respectively. Addition to BE, we also reported precision (positive predictive value) and recall (sensitivity) for each experimental image in<ref type="figure">Table 2</ref>. Note that all definitions run over number of pixels in the particular region. Precision = TP/TP + FP,Recall = TP/TP + FN.<ref type="figure" target="#fig_5">Figure 4</ref>demonstrates how our method is compared quantitatively against dermatologist drawn image. In the figure left is original image, middle is dermatologist drawn image, and right (red area) is automatically found border image which is overlaid on top of the manually drawn image. In the experiments for 100 dermoscopy images dataset, the expansion ratio constant is determined by randomly chosen three sample images as shown in<ref type="figure">Table 1</ref>. As a result, the expansion ratio is chosen as 1.5 since this value was maximizing both precisions and recalls for three sample images as seen in<ref type="figure">Table 1</ref>. In<ref type="figure">Table 2</ref>mean is ∼1.0 (and σ = 0.001) and recall's mean is 0.97 (σ = 0.003). The results show that accuracy of assessment averages out at 97.72%. A rough comparison of our findings with<ref type="bibr">Schaefer et al. (2009a, b</ref>) and<ref type="bibr" target="#b3">Celebi et al. (2008)</ref>showed that the mean errors of our method are obviously less than their results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">COMPARISON AND DISCUSSION</head><p>In this section, existing graph based image segmentation methods NCs method (<ref type="bibr" target="#b21">Shi and Malik, 1997</ref>), the efficient graph based segmentation method (EGS) (<ref type="bibr" target="#b7">Felzenszwalb and Huttenlocher, 2004</ref>), and the BH are compared with respect to efficiency on lesion border detection and computation complexities on dermoscopy images. C++ source codes for NC and EGS obtained from authors' websites. In<ref type="figure" target="#fig_7">Figure 5</ref>, results for a single lesion image generated from NC, EGS and BH overlaid, respectively, on the physician drawn ground truth image. As shown in<ref type="figure" target="#fig_7">Figure 5</ref>, much better results are obtained from BH. In NC, minimization of the normalized cost function is NP hard. This method down-samples the original image then conducts initial segmentation in down-sampled image and finally initial segmentation is expanded to the original image. Its computation complexity is O(n 3 ). Therefore, it only works on small sized images (e.g. 100 × 90). NC is a supervised method which requires expected number of clusters as a parameter. It is efficient on finding global segments; however, its efficiency reduces greatly if there are noises or tiny blemishes in the image. As seen in<ref type="figure" target="#fig_7">Figure 5</ref>, that degrades efficiency of the method for border detection in lesions since border regions have similar features with noise. Overall average precision of NC for 100 dermoscopy image dataset is 100%; however, average recall is 67% which makes NC inefficient for border detection in dermoscopy images. However, EGS is able to preserve details in low-variability image regions (e.g. shadow regions) while ignoring details in high variability regions. Therefore, as seen from illustration in<ref type="figure" target="#fig_7">Figure 5</ref>, high variability regions in the interior of border (holes) are segmented as different regions. In this approach, results will be considerably affected by outliers since even two segments with low weight edge between them are combined as a single segment. Even though the computational complexity is O(n log n), in order to make the method more robust to outliers; definition of the difference between two regions needs to be changed. However, finding correct definition of difference is NP hard. The threshold function is the key element to determine the size of the segments. Variability on threshold changes results drastically. In this approach, when threshold is low, accuracy becomes high and computation speed Original Image NC Overlay Image EGS Overlay Image BH Overlay Imagereduces significantly. Overall average precision of EGS for 100 dermoscopy images is 100%; however, average recall is 55% which makes EGS also inefficient for border detection in dermoscopy images. The BH is capable of accurately locating segments and has following features. First, it locates all local, non-local and global segments in a single hierarchical structure. Global segments are represented at higher levels in the hierarchy, non-local segments are represented in middle levels of the hierarchy, and local segments are represented in lower levels of the hierarchy. Second, it is a seedless and non-supervised method which does not require prior knowledge about expected number of clusters. Third, it is dynamic. Since it is a SKDS, it is capable of updating hierarchy according to dynamic changes. This dynamic nature may lead to analyzing dynamic behavior of changes in segments by time. Fourth, inherently hierarchical classes of special structures are hold in the hierarchy. There is inherent hierarchical structuring in nature. For instance, in a scene object parts exist in objects and lower-level features exist in object-parts in a hierarchical fashion. Although these spatial patterns (objects, object-parts, etc.) are quite different, they are manifested in different levels of the BH. Finally, unlike EGS and NC, BH has single parameter which is called expansion ratio. As seen from<ref type="figure">Table 1</ref>, change in expansion ratio does not affect results significantly unlike in EGS. The complexity of the BH is O(n log n); however, it runs in near linear time with respect to number of graph edges. In addition, the complexity of dynamic update operation is O(log n). Detail precision, recall, BE rates are listed for BH in<ref type="figure">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this study, a novel approach for automatic detection of skin lesions: BH is presented. The BH is a SKDS that keeps proximity graph representation in hierarchical form. It maintains geometric closeness relations among the point sets (colors). This data structure builds a hierarchical decomposition of a connected graph with certain properties (see Section 2.2 for properties). Our approach is examined on a set of 100 dermoscopy images. Error rates: false positives and false negatives along with true positives and true negatives are quantified by digitally comparing results with manually determined borders from a dermatologist as the ground truth. The assessments obtained from our method are quantitatively analyzed with respect to BEs, precisions and recalls. Moreover, visual outcome showed that our method effectively delineated targeted lesions. Results proved that accuracy of automated assessments with the BH averages 97.72% which is higher than previously proposed methods. Also, BH is compared against well-known graph based segmentation methods on dermoscopy images and BH outperformed these methods. As a result, our approach finds both the lesions and the lesion borders with high precision rates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>i22 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:48 12/5/2010 Bioinformatics-btq178.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Hierarchy construction steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. A sample hierarchy representation of a dermoscopy image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>which are selected i24 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:48 12/5/2010 Bioinformatics-btq178.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Accuracy and error quantification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. Overlay images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>Figure 4 demonstrates how our method is compared quantitatively against dermatologist drawn image. In the figure left is original image, middle is dermatologist drawn image, and right (red area) is automatically found border image which is overlaid on top of the manually drawn image. In the experiments for 100 dermoscopy images dataset, the expansion ratio constant is determined by randomly chosen three sample images as shown in Table 1. As a result, the expansion ratio is chosen as 1.5 since this value was maximizing both precisions and recalls for three sample images as seen in Table 1. In Table 2 results for 100 images are displayed. For 100 images, BH's BE's mean is 2.28% (and σ = 3.01), precision's</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.5.</head><figDesc>Fig. 5. Segmentation results from NC, EGS and BH from left to right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Benchmark results for different expansion ratios for three sample images</figDesc><table>Expansion ratio 
1.2 
1.5 
2.0 

Precision 
Image 1 
0.927 
0.975 
0.976 
Image 2 
0.881 
0.882 
0.878 
Image 3 
0.977 
0.939 
0.930 

Recall 
Image 1 
1 
0.995 
0.995 
Image 2 
0.999 
1 
0.999 
Image 3 
1 
1 
0.999 

</table></figure>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:48 12/5/2010 Bioinformatics-btq178.tex] Page: i24 i21–i28</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:48 12/5/2010 Bioinformatics-btq178.tex] Page: i26 i21–i28</note>

			<note place="foot">Basch,J. et al. (1999) Data structures for mobile data. J. Algorithms, 31, 1–28. Binder,M. et al. (1995) Epiluminescence microscopy. A useful tool for the diagnosis of pigmented skin lesions for formally trained dermatologists. Arch. Dermatol., 31, 286–291. Celebi,M.E. et al. (2007a) Unsupervised border detection in dermoscopy images. Skin Res. Technol., 13, 454–462. Celebi,M.E. et al. (2007b) A methodological approach to the classification of dermoscopy images. Comput. Med. Imag. Graphics, 31, 362–373. i27 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">i28 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A soft kinetic data structure for lesion border detection</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Kinetic and dynamic data structures for convex hulls and upper envelopes</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Alexandron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Geometr. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="144" to="158" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title level="m" type="main">Dermoscopy: a Tutorial</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Argenziano</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>EDRA Medical Publishing and New Media</publisher>
			<pubPlace>Milan, Italy</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="48" to="60" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq178. .tex] Page: i28 i21–i28 S.Kockara et al</note>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Border detection in dermoscopy images using statistical region merging</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Celebi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Skin Res. Technol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="347" to="353" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Lesion border detection in dermoscopy images</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Celebi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imag. Graphics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="148" to="153" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Soft kinetic data structures</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Czumaj</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sohler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the 12th Annual ACM-SIAM Symposium on Discrete Algorithms<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Independent histogram pursuit for segmentation of skin lesions</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Delgado</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="157" to="161" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient graph-based image segmentation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">F</forename>
				<surname>Felzenszwalb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">P</forename>
				<surname>Huttenlocher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="167" to="181" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Techniques for a structural analysis of dermatoscopic imagery</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">G</forename>
				<surname>Fleming</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput, Med. Imag. Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="375" to="389" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Segmentation of dermatoscopic images by stabilized inverse diffusion equations</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>. IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="823" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Deformable spanners and applications</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Geometry: Theory Appl</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2" to="19" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast anisotropic gauss filtering</title>
		<author>
			<persName>
				<forename type="first">J.-M</forename>
				<surname>Geusebroek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Image Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="938" to="981" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Kinetic data structures—a state of the art report</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">J</forename>
				<surname>Guibas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop Algorithmic Foundation Robot. A.K. Peters</title>
		<editor>Agarwal,P.K. et al.</editor>
		<meeting>Workshop Algorithmic Foundation Robot. A.K. Peters<address><addrLine>Wellesley, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="191" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Quantitative assessment of tumor extraction from dermoscopy images and evaluation of computer-based extraction methods for automatic melanoma diagnostic system</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Iyatomi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Melanoma Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Jemal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer J. Clinicians</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="71" to="96" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A software approach to hair removal from images</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">K</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="533" to="576" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparison of color clustering algorithms for segmentation of dermatological images</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Melli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Progress in Biomedical Optics and Imaging</title>
		<meeting><address><addrLine>San Diego, CA, USA, SPIE, Bellingham, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="3" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<monogr>
		<title level="m" type="main">An Atlas of Surface Microscopy of Pigmented Skin Lesions: Dermoscopy</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">W</forename>
				<surname>Menzies</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>Sydney, Australia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Median filtering in constant time</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Perreault</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hébert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="2389" to="94" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Digital Image Processing: PIKS Inside</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">K</forename>
				<surname>Pratt</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring protein folding trajectories using geometric spanners</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Russel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">J</forename>
				<surname>Guibas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Symp. Biocomp</title>
		<imprint>
			<biblScope unit="page" from="42" to="53" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Malik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition<address><addrLine>San Juan ; Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="731" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Image and video segmentation: the normalized cut framework</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1998 International Conference on Image Processing (ICIP&apos;98)</title>
		<meeting>1998 International Conference on Image Processing (ICIP&apos;98)</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Skin lesion extraction in dermoscopic images based on colour enhancement and iterative segmentation</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Schaefer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Image Processing</title>
		<meeting>IEEE International Conference on Image Processing<address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3361" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Skin lesion segmentation using cooperative neural network edge detection and colour normalisation</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Schaefer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Information Technology and Applications in Biomedicine</title>
		<meeting>the Ninth International Conference on Information Technology and Applications in Biomedicine<address><addrLine>Larnaca, Cyprus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Segmentation of digitized dermatoscopic images bytwo-dimensional color clustering</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Schmid</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="164" to="171" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Image processing, analysis, and machine vision. CengageEngineering</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sonka</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistical evaluation of epiluminescence dermoscopy criteria for melanocytic pigmented lesions</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Steiner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Acad. Dermatol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="581" to="588" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Dermoscopic hair disocclusion using inpainting</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Wighton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE Medical Imaging</title>
		<editor>Reinhardt,J.M. and Pluim,J.P.W.</editor>
		<meeting>the SPIE Medical Imaging<address><addrLine>San Deigo, CA, USA, SPIE, Bellingham, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="691427" to="691427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Feature-preserving artifact removal from dermoscopy images</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE Medical Imaging</title>
		<editor>Reinhardt,J.M. and Pluim,J.P.W.</editor>
		<meeting>the SPIE Medical Imaging<address><addrLine>San Deigo, CA, USA, SPIE, Bellingham, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="69141" to="69142" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>