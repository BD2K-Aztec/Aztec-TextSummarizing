
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Journaled string tree—a scalable data structure for analyzing thousands of similar genomes on your laptop</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">. 24 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Ren</forename>
								<forename type="middle">E</forename>
								<surname>Rahn</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Freie Universit € at Berlin</orgName>
								<address>
									<addrLine>Takustr. 9</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<surname>Weese</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Freie Universit € at Berlin</orgName>
								<address>
									<addrLine>Takustr. 9</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Knut</forename>
								<surname>Reinert</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Freie Universit € at Berlin</orgName>
								<address>
									<addrLine>Takustr. 9</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Journaled string tree—a scalable data structure for analyzing thousands of similar genomes on your laptop</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="3499" to="3505"/>
							<date type="published" when="2014">. 24 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu438</idno>
					<note type="submission">Sequence analysis Advance Access publication July 15, 2014 Received on April 11, 2014; revised on June 30, 2014; accepted on July 2, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Michael Brudno Contact: rene.rahn@fu-berlin.de</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Next-generation sequencing (NGS) has revolutionized biomedical research in the past decade and led to a continuous stream of developments in bioinformatics, addressing the need for fast and space-efficient solutions for analyzing NGS data. Often researchers need to analyze a set of genomic sequences that stem from closely related species or are indeed individuals of the same species. Hence, the analyzed sequences are similar. For analyses where local changes in the examined sequence induce only local changes in the results, it is obviously desirable to examine identical or similar regions not repeatedly. Results: In this work, we provide a datatype that exploits data paral-lelism inherent in a set of similar sequences by analyzing shared regions only once. In real-world experiments, we show that algorithms that otherwise would scan each reference sequentially can be speeded up by a factor of 115. Availability: The data structure and associated tools are publicly available at http://www.seqan.de/projects/jst and are part of SeqAn, the C++ template library for sequence analysis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Next-generation sequencing (NGS) has revolutionized biomedical research in the past decade and led to a continuous stream of developments in bioinformatics, addressing the need for fast and space-efficient solutions for analyzing NGS data. Especially since the sequencing efficiency of modern NGS technologies outpaced the improvement of storage capacities, which directly leads to a growing economical issue, as storing and sharing the generated information is now bounded by the available storage and network resources (<ref type="bibr" target="#b15">Kahn, 2011</ref>). The same technology led to the generation of comprehensive catalogs for genetic variations of the human (<ref type="bibr" target="#b9">Durbin et al., 2010;</ref><ref type="bibr" target="#b11">Frazer et al., 2007</ref>) and other organisms as well (e.g.<ref type="bibr" target="#b1">Auton et al., 2012;</ref><ref type="bibr" target="#b16">Keane et al., 2011</ref>). Moreover, the rapid advances in NGS made ambitious sequencing endeavors like the 1000 Genomes Project (<ref type="bibr">The 1000</ref><ref type="bibr">Genomes Project Consortium, 2012</ref>), systematic studies of 425 000 cancerous genomes (The International Cancer Genome<ref type="bibr">Consortium, 2010</ref>) or most eagerly the announced goal of the Personal Genome Project to sequence 100 000 human genomes (<ref type="bibr" target="#b3">Ball et al., 2012</ref>) possible. Those resources then provide detailed information about the genetic diversity of entire populations, which will be important to the societal health sector to acquire better understandings of the correlation between clinical conditions and phenotypes and their corresponding genotypes. As a result, two major challenges need to be tackled. The first challenge clearly is to compress the available sequence data to relieve disk and network resources. Owing to the high redundancy of sequences originating from the same or related organism, referential sequence compression has been proven to be especially efficient for these kinds of data (e.g.<ref type="bibr" target="#b7">Deorowicz and Grabowski, 2011;</ref><ref type="bibr" target="#b17">Kuruppu et al., 2011;</ref><ref type="bibr" target="#b24">Pinho et al., 2012;</ref><ref type="bibr" target="#b30">Wandelt and Leser, 2012</ref>). More recently<ref type="bibr" target="#b6">Deorowicz et al. (2013)</ref>exploited cross-sequence correlations to achieve profitable compression ratios for the data of the 1000 Genomes Project. The second challenge, however, is to devise algorithms and data structures that can handle the massive amounts of available data to incorporate those information in existing analyzing pipelines. Clearly, one solution would be to apply the algorithms sequentially to each sequence contained in the database, but the runtimes scale linearly to the number of sequences included. Thus, it is desirable to analyze the data in succinct form to archive runtimes proportional to the compressed size. This paradigm is also known as compressive genomics (<ref type="bibr" target="#b21">Loh et al., 2012</ref>). The FM-index (<ref type="bibr" target="#b10">Ferragina and Manzini, 2000</ref>) and the compressed suffix array (<ref type="bibr" target="#b20">Lippert, 2005</ref>), for example, are succinct representations of indices that can be searched efficiently. Yet, indexing thousands of genomes with these data structures would still exceed currently available memory capacities by far. In the past 5 years, this problem was subject in several publications (<ref type="bibr" target="#b14">Huang et al., 2013;</ref><ref type="bibr" target="#b18">Lam et al., 2010;</ref><ref type="bibr" target="#b21">Loh et al., 2012;</ref><ref type="bibr" target="#b22">M€ akinen et al., 2009;</ref><ref type="bibr" target="#b25">Schneeberger et al., 2009;</ref><ref type="bibr" target="#b27">Sir en et al., 2011</ref>). Here, the focus was moved from considering each sequence individually to exploiting similarities among the sequences to reduce the overall memory footprint, and to gain substantial speedups opposed to the sequential case.<ref type="bibr" target="#b21">Loh et al. (2012)</ref>presented compression-accelerated BLAST and BLAT, both tools to search patterns in a non-redundant sequence library approximatively. These methods, however, require the compressed sequence library to be generated in a computationally intensive preprocessing phase.<ref type="bibr" target="#b14">Huang et al. (2013</ref><ref type="bibr" target="#b25">), Schneeberger et al. (2009</ref><ref type="bibr" target="#b27">) and Sir en et al. (2011</ref>used as input a more general format consisting of a reference sequence and a set of variants for a collection of sequences, which is a common representation of the data produced by large sequencing endeavors such as the 1000 Genomes Project. Subsequently they built an index over the reference set exploiting the high *To whom correspondence should be addressed. ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com similarities. Yet, the read-mapper BWBBLE (<ref type="bibr" target="#b14">Huang et al., 2013</ref>) was the first practical tool capable of mapping reads against thousand genomes simultaneously. In their approach, they indexed a multi-genome reference sequence with the FM-index and adapted the Burrows-Wheeler Aligner (BWA) (<ref type="bibr" target="#b19">Li and Durbin, 2009</ref>) to work on the indexed multi-genome. To construct the multi-genome, they needed a context size to determine the sequence context left and right of genomic regions harboring insertions or deletions; thus, the entire multi-genome and the accompanied index must be reconstructed on changes of the context size. However, there exists a plethora of algorithms for sequence analysis that are sequential in nature. That means they scan the sequences to be analyzed from left to right and perform some computation, e.g. compute an approximate matching or alignment of a query sequence to a reference sequence, or scan sequences in the context of a hidden Markov model (HMM) (e.g. De<ref type="bibr" target="#b5">Bona et al., 2008</ref>). There are many more applications such as filtering and verification algorithms in read mappers (<ref type="bibr" target="#b31">Weese et al., 2012</ref>) or searching with position-specific scoring matrices (<ref type="bibr" target="#b12">Henikoff et al., 2000;</ref><ref type="bibr" target="#b26">Scordis et al., 1999</ref>). After reading a character of the string, the algorithm will change its internal state and possibly report some results.<ref type="bibr" target="#b4">Barton et al. (2013)</ref>gave an algorithm to solve the pattern matching problem with Hamming distance for a set of extremely similar sequences. In their model, they assumed that each sequence differs in around 10 positions to every other sequence within the set. To find all occurrences of a pattern within all sequences they searched first the reference sequence and used then some auxiliary tables to check if at the reported positions the pattern can be found for the other sequences too. Besides the impractical error model for real biological data, they did not provide any experiments to evaluate their method. Thus, to the best of our knowledge, we provide for the first time a general solution to generically speed up a large class of algorithms when working on sets of similar strings. We will mostly address the reduction of execution time and space of such algorithms by providing a data type, called journaled string tree (JST) that can be traversed similarly to a simple for-loop over all sequences while exploiting the high similarity. The algorithm must simply be able to store its state when asked, continue its computation from a stored state when presented with a new character and work locally, i.e. when scanning a sequence its current state solely depends on a fixed-size window of last seen characters, also called context. Our approach is based on a reference-based compression of shared sequence parts with some additional bookkeeping. For example, if lets say 1 Mb of a set of 100 genomes is shared and we want to compute a semiglobal alignment on all sequences, we will execute the alignment only once on this stretch of 1 Mb. For regions that exhibit differences, a corresponding sequence context is constructed on-thefly and then examined. We can show that our approach exhibits speedups of 4100 times when analyzing a set of 2185 sequences of chromosome 1 [two haplotypes of 1092 sequences from the 1000 genomes project (<ref type="bibr" target="#b0">Altshuler et al., 2010</ref>) and a reference sequence] compared with running the algorithms sequentially while using only $3.8 GB of space. This speedup includes all overheads. The speedup in searching alone is up to a factor of 570.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>We</head><p>will first give an informal description of the JST data structure and our traversal method using the example in<ref type="figure" target="#fig_2">Figure 3</ref>depicting (a) three similar sequences and (b) the corresponding JST. In the example, we search for a string of length 4 using an exact string matching algorithm. In general, instead of iterating over all strings in the set sequentially, our method simultaneously traverses a set of strings from left to right. With this strategy, algorithms based on sequentially scanning a sequence can be easily extended to a large set of similar sequences, while only modest memory requirements are needed. The only additional and algorithm dependent information required is the length of the so-called sequence context, i.e. the window of last-seen characters that solely determine the internal state of the algorithm. For example, an online algorithm that searches a query of length n with up to k errors depends on a sequence context of length n + k, whereas in<ref type="figure" target="#fig_2">Figure 3</ref>the context length for exact pattern matching is the length of the query, which is 4 in this example. In our approach, we use the reference sequence r as the anchor coordinate system and store positions, so called branch-nodes, at which at least one other sequence has a "-event, i.e. a deletion of a substring of the reference sequence, an insertion of a string relative to the reference sequence or a replacement of a substring of the same length between a sequence in the set and the reference sequence. For example, in<ref type="figure" target="#fig_2">Figure 3</ref>, the gray points labeled L, M, N, O are branch-nodes. The respective positions in the other sequences will be determined ondemand while scanning from left to right using a reference-based compressed representation of the sequences called journaled strings. We use a bitvector to denote which sequences have a "-event for a given reference position. During the traversal the method constructs the required sequence contexts on-the-fly using the bitvectors and respective journaled strings and presents them to the algorithm. Whenever a branch-node is encountered we store the state of the algorithm to continue computations later from that position. Once the deviating sequence part has been processed, the algorithm will be asked to restore its last state and continue with a new character. The algorithm can in addition signal after processing a character, whether it needs the information for which sequences the presented sequence context is valid, e.g. when a string matching algorithm found a match.<ref type="figure" target="#fig_0">Figure 1</ref>depicts the general communication processes between the Journaled String Tree traversal and a sequential algorithm. The article is organized as follows. In Section 2.2, we describe our simple, yet fast, reference-based compression scheme; in Section 2.3, we describe how to traverse the set of strings simultaneously and apply any algorithm that sequentially streams over sequences with a limited sequence context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definitions</head><p>A string s=s 0. .. s nÀ1 is sequence of characters of an alphabet S. The length of a string is denoted as jsj=n. A substring of s is denoted as s½i : j=s i. .. s jÀ1 , with 0 i5j n. The special case s½i : i+1 will be shortened to s<ref type="bibr">[i]</ref>. A "-event is a tuple ðs; i; r; j; x; "Þ with " 2 fR; I; Dg describing the event that occurred in s at position i relative to position j in sequence r. x denotes the string associated with this event, i.e. if "=R, then x=s½i : i+jxj is the string replacing r½j : j+jxj and if "=I, then x=s½i : i+jxj is the inserted string in s, otherwise if "=D, then x=r½j : j+jxj represents the deleted string in r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Journaled strings–compressed searchable strings</head><p>A journaled string is a referentially compressed version of a string s, which stores a pointer to a reference sequence r, an additional string ib, called insertion buffer, and a binary search tree JðÞ, called journal tree, over segments representing substrings of r or ib. We refer to such segments as journal entries. A journal entry is a tuple e=ðvp; pp; l; Þ 2 N 3 Â f0; 1g, where indicates the source of the corresponding segment (0 ! r; 1 ! ib). We call an entry with = 0 an original entry and an entry with = 1 an insertion entry. vp denotes the virtual position, i.e. the begin position of this segment within the target sequence s. Accordingly, pp denotes the physical position referring to the begin position within r, if = 0, and ib otherwise. The length of e is denoted by the parameter l, and for any two journal entries e and e 0 we define e5e 0 , vp5vp 0. Generating journaled strings. Given a reference sequence r, a sequence s and n corresponding "-events sorted in ascending order, we can construct a journaled string in OðnÞ time as follows. We create an original entry for each substring of r bounded by the end and begin coordinate of two adjacent "-events and cover each insertion by an insertion entry, while the inserted string is appended to the insertion buffer. Deletion events do not trigger the creation of a new entry but are covered by gaps between the physical end and begin position of two neighboring original entries, which can also be interleaved with insertion entries. Replacements are simply handled as an insertion followed by a deletion of the same size. Accessing journaled strings. To randomly access the journaled string at a position i, we first search the journal tree JðÞ for an entry ðvp; pp; l ; Þ with vp i5vp+l. The actual character can then be accessed at position pp+ði À vpÞ in the corresponding substring of this entry. Hence, the random access time is Oðlog jJðÞjÞ. Scanning the whole journaled string from left to right can be realized via an in-order traversal of the journal tree (<ref type="figure" target="#fig_1">Fig. 2</ref>) in Oðjj+jJðÞjÞ= OðjjÞ time, i.e. a single sequential access requires amortized Oð1Þ time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Traversing thousands of genomes</head><p>In the following section, we will give a formal description of the JST and describe the algorithm to traverse this data structure with any contextbased algorithm. Given a set of strings s 1 ;. .. ; s t and their sets of "-events D 1 ;. .. ; D t according to a common reference sequence r. To reduce the space required to store the "-events, we collapse all events shared by a set of strings into a single structure, called the branch-node. Formally, we say u=ðj; x; C; "Þ is a branch-node of type " that occurs at branch-position j in the reference sequence r, with x being the corresponding string associated with the respective "-event and C f1;. .. ; tg being the set of the strings harboring this event. In the following, we will refer to C as the coverage. It holds that k 2 C , 9 i2N ðs k ; i; r; j; x; "Þ 2 D k. W.l.o.g. we assume that none of the sequences has two different "-events at the same position j, and thus, the coverages of all branchnodes at the same branch-position j are disjoint. Let label(u), pos(u) and cov(u) be the values x, j and C, respectively, for any branch-node u. A JST T is a data structure consisting of an array of branch-nodes u 2 VðTÞ sorted in ascending order according to their branch-position pos(u), a pointer to the common reference sequence r and a set of journal strings 1 ;. .. ; t. The journaled strings are generated from the given set of all "-events, and the corresponding sequences in S as outlined in the Section 2.2. Basic traversal. For a sequential algorithm A with a context length w, the traversal over a JST T simply shifts a window over the reference sequence r. After every shift the current context is evaluated by an external algorithm A, which returns a shift length to move the window to the next required context. In addition, A can interact with the current state of the traversal, e.g. to request the positions of all strings that are valid for the current context. Whenever the window reaches into a branch-node u 2 VðTÞ, a new subtree, whose depth depends on the context length, is branched off. We iteratively traverse this subtree and use a stack S, which stores the current state of the traversal and A, for backtracking. In the following, we will describe how to generate all necessary subtree information on-thefly. First, we explain the branching strategy when the current window intersects with a branch-node and subsequently discuss step by step how to refine the subtree traversal, while maintaining the invariant that for each context explored by the traversal always a valid coverage is sustained. Branching. To proceed the traversal in the subtree starting at the branch-node u, it is obvious that the left and right sequence context flanking the respective "-event is needed to provide A with all necessary information. This can be achieved by transferring the current window to any journaled string harboring this event. A representative k can be simply selected from the coverage k 2 covðuÞ. To determine in Oðlog jJð k ÞjÞ time where the respective "-event occurs in k , we augment each journal entry e 2 Jð r Þ by the rank of the associated branch-node in a preprocessing step. Once the entry has been found, the begin and end position of the window in k can be computed from the respective begin position of the window within the reference and the branch-position pos(u). Moreover, the traversal over the current branch is stopped whenever the window exceeds the current "-event represented by u.<ref type="figure" target="#fig_2">Figure 3</ref>depicts this pruning of the branches depending on the window length, which is 4 in the given example. Context-based subtree construction. So far we have only considered the simple case where the current branch is solely dependent on the branchnode it originates from. However, depending on the context length and the distribution of the branch-nodes, it might happen that multiple branch-nodes affect the current branch, resulting in an expanding subtree. For example, the branch-node O in<ref type="figure" target="#fig_2">Figure 3</ref>induces a split of the branch coming from N. We will refer to such branch-nodes inducing a split in the current branch as split-nodes to distinguish them from their original meaning. Accordingly, the node O 0 in<ref type="figure" target="#fig_2">Figure 3</ref>represents the split-node induced by O. Let u be the branch-node of the current branch and v its successor. Then v induces a split in the branch coming from u if the following conditions are satisfied:</p><p>(1) covðuÞ \ covðvÞ 6 ¼ 1.The first and the second conditions ensure that there exists a subset of strings covering v that also covers u. Otherwise, the contexts for all strings covering u are either aware of the "-event represented by v or none of the strings harbor the respective "-event. The third condition checks that the current context is affected by the split-node. The current branch is split if all conditions are fulfilled, and hence, the coverage of the active branch is partitioned into the sets covðuÞ \ covðvÞ and covðuÞncovðvÞ. Now the traversal is continued with the coverage set containing k, whereas the remaining set is stored on the stack S together with the current states of the traversal and A. Suppressing invalid sequences. In addition, we keep track of the coverages of all branch-nodes that currently fall into the window over the reference sequence, as well as the coverages of replacements and deletions that were encountered previously and still affect the current window. For example, the deletion represented by branch-node M in<ref type="figure" target="#fig_2">Figure 3</ref>also affects all windows starting at position 13 and 14 in r (denoted by the dashed lines below the tree). Whenever A requests for it, we on-demand compute the sequences the context is valid for using the auxiliary information. We also use this information to skip windows that have been examined already. In<ref type="figure" target="#fig_2">Figure 3</ref>, for example, if the algorithm finished the branch at branch-node N and passes to the next branch-node O, it is clear that all windows beginning before the insertion in O have been searched already when processing N, as all sequences covering O also cover N. Hence, it is sufficient to move the context directly to the beginning of the insertion. Processing blocks. The traversal over the JST can be conducted blockwise. To do so, we partition the set of branch-nodes into blocks of size B4w, according to their positions within the reference sequence. Whenever we enter a new block, we load it into memory and discard it after processing all contained branch-nodes. In general, no more than two blocks are kept in memory at the same time. Dynamic updates. It is possible to add k sequences to the JST dynamically. To do so, the k sequences are represented as k single-sequence JSTs, i.e. each hosts one sequence only, referring to the common reference sequence. Then, the JSTs can be merged into the existing JST in Oðnklog kÞ time, where n is the size of the largest branch-node array using a ðk+1Þ-way merge step. During the merge, we either add the index of the currently processed sequence to the coverage set if the branch-node already exists or insert a new branch-node at the corresponding position. In a new traversal, the journaled strings for the recently added sequences are then constructed on-demand as described in the previous sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Implementation</head><p>We implemented all data structures, programs and functions in SeqAn, the C++ software library for sequence analysis (D € oring et al., 2008). To memory efficiently represent the coverage information, each branch-node stores a packed bitvector. The binary search tree of the journaled string is realized as a sorted array, as the variants are incorporated in left-to-right scan manner. We used binary search to look up a given entry within the array. To make our JST data structure applicable to a wide range of algorithms, we implemented a templatized Finder object, which hides the traversal and the state management from the outer interfaces. The user can simply plug-in its own functor to this object and implement the functions getState() and setState() if necessary. As an example, we provide functors for the naive,<ref type="bibr" target="#b13">Horspool (1980)</ref>, Shift-And and Shift-Or (Baeza<ref type="bibr" target="#b2">Yates and Gonnet, 1992</ref>) exact pattern search algorithms, as well as Myers' bitvector algorithm for approximate search (<ref type="bibr" target="#b23">Myers, 1999</ref>). To evaluate running times and memory consumptions, we implemented a benchmark application, which is available on request to the authors. Furthermore, we have implemented a tool to transform a vcf file into our own genome delta format called gdf. This format simply stores the variants in a compact form and the respective bit vectors for each variant (<ref type="bibr" target="#b6">Deorowicz et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>We used data from the 1000 Genomes Project (<ref type="bibr">The 1000</ref><ref type="bibr">Genomes Project Consortium, 2012</ref>) to evaluate our traversal over the JST. We took the vcf file for chromosome 1 and transformed it into a gdf file for different sets of sequences. The gdf file storing 1092 genotypes without the reference sequence used only 446 MB instead of 87 GB needed for the vcf file. Note that the original size of chromosome 1 in fasta format is nearly 250 MB. In fact, we could compress the gdf file with gzip to 58 MB in only 14 s, suggesting that further studies of the compressibility of this format would yield good compression ratios.Although we made all analyses based on the gdf format, we could also process vcf files directly at the expense of longer I/O times. Reading the complete gdf file of chromosome 1 containing 2 993 910 variants for 1092 individuals took merely 4.2 s. For the runtime and memory evaluation, we generated different datasets from the vcf file representing the genotypes of 1, 32, 64, 128, 256, 512 and 1092 sequences and one set with 2184 sequences generated from both haplotypes of the 1092 sequences and additionally included the reference sequence itself. We performed the traversal on each set with the exact online-search algorithm Horspool and with Myers' bitvector algorithm for approximate pattern search. The experiments were conducted on a Debian GNU/Linux machine with 72 GB of RAM and a 2.67 GHz Intel(R) Xeon(R) CPU X5650 processor. The presented results for the JST are obtained with a block size of 100 000. Running time. The total running times are depicted in the columns under the respective heading in<ref type="figure" target="#tab_1">Table 1</ref>for Myers' algorithm and in<ref type="figure">Table 2</ref>for the Horspool algorithm. The total running time for the JST search includes loading the reference sequence and the gdf file as well as the generation of the journaled strings and the search itself. We compared the total running time with the sequential case, where we load at most 100 fasta sequences at a time into memory and then sequentially searched over the sequences. Except for the single reference search (the JST is empty) in row 1, the JST traversal is faster than the sequential processing for the same number of sequences for both algorithms. The factor column represents the speedup of the JST over the sequential search. The figures clearly reveal, that the more sequences are added the more the speedup grows, albeit there is a little decrease for 1093 sequences compared with 513 sequences. In addition, it can be seen that the running times for the Horspool algorithm are in general faster than for Myers' bitvector algorithm, while the speedup over the sequential case is smaller. Additionally, we measured the search time without any generation or loading times and compared again the running times of the JST traversal with the sequential search. All figures for the search time are presented in Tables 1 and 2 too. For two sequences, our approach is already faster than the sequential case. Moreover, the speedup for Myers' bitvector algorithm increases almost continuously up to a factor of 577 for 2185 sequences. Again, the running times for the Horspool algorithm are less than for Myers' bitvector algorithm, but the speedup is higher for the latter one.Note. Naive refers to the sequential processing of fasta sequences. a</p><p>At most 100 fasta sequences were loaded into memory at a time.</p><p>Memory consumption. The last two columns of Tables 1 and 2 present the memory usage of both strategies. The measured memory consumptions are identical for both algorithms. Again we can see the same behavior as for the running times. In the sequential case, the memory consumption for searching solely the reference is slightly less than for the JST. However, with two sequences both methods use roughly the same amount of memory. For more sequences, the JST memory consumption increases only sublinear in the size of the contained sequences. The analysis of 2185 sequences requires 3.72 GB of RAM. Different block sizes. In addition to the block size of 100 k, we tested our approach with blocks of length 500 k and compared the performance with a version that loads all variants at once in memory. Clearly, the memory consumption increases with higher block sizes. One thousand ninety-three sequences require 4.73 GB of RAM with a block size of 500 k, and 17.06 GB if all variants are stored in memory. Thus, even for the setting with the largest memory consumptions, our approach stores 1093 sequences within 6% of the space the naive variant would require to store all sequences simultaneously. In addition, the measured running times for the 100 k blocks are slightly lower than using larger blocks. Different pattern sizes. The JST traversal strongly depends on the number of variants contained in the set because the more branch-points are available the more often the algorithm needs to split branches and update coverages. We simulated this behavior by increasing the size of the pattern and searching with each pattern the set of 1093 sequences. We measured only the search times because the generation times are not affected by the pattern size.<ref type="figure">Figure 4</ref>depicts the behavior of the search time for different pattern sizes. The blue line represents the search with the Horspool algorithm. The search time increases slowly to 13.78 s for a pattern of size 256. The red line represents Myers' bitvector search. Here we can see a major increase when increasing the pattern size from 64 to 128. For patterns larger than the word size, which is 64 bits in our case, the algorithm has a more complex procedure, which results in longer running times. Yet, the search time of 55.21 s for a pattern of size 256 is still 55 times faster than searching the sequences sequentially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION AND CONCLUSION</head><p>In this article, we presented a data structure called the JST, to represent a set of sequences as a set of variants based to a common coordinate system given by a common reference sequence and a set of accompanied bitvectors. We used searchable referentially compressed strings, called journaled strings, to generate a succinct representation for any sequence from this set. Furthermore, we implemented a traversal over the JST, while searching regions shared by a subset of the sequences simultaneously. Moreover, we loaded parts of the journaled strings dynamically on-demand to decrease the memory consumptions tremendously, while the running time remained unchanged. During the traversal, we built only those parts of the JST that were necessary to evaluate the current context. These methods work dynamically for any window length and do not need any preprocessing phase. The results show that any algorithm that processes an input sequence with a given window length can greatly benefit from our approach. We tested our approach on different-sized sets of chromosome 1 sequences generated from the vcf file of the 1000 Genomes Project. All our experiments showed a better performance and memory consumptions compared with the sequential processing of the same number of sequences in fasta format. The only case our approach was slower and used slightly more memory was when we analyzed the reference sequence only. For two sequences we already measured a gain over the sequential case. We analyzed the search and the total times for an exact pattern search with the Horspool algorithm and an approximate pattern search with Myers' bitvector algorithm. Comparing the total times for different number of genomes revealed a growing speedup factor opposed to the sequential running time, except when performing the search on 1093 sequences. Here the speedup factor dropped a little bit compared with its previous trend. The same drop cannot be seen when comparing the respective search times for both algorithms, and hence, it must be a result of longer generation times for the journaled strings. This seems to be plausible, as when increasing the number of the sequences the number of variants contained in the set also increased. The figures in the second column of<ref type="figure" target="#tab_1">Table  1 and 2</ref>show the number of all variants contained in this set. For 1093 sequences, there were almost 1 million more variants contained in the set than for 513 sequences. This fact is supported by adding the running times for 2185 sequences to the comparison. We used both haplotypes of the 1092 sequences contained in the vcf file to generate the 2184 sequences plus the reference sequence. Hence, the number variants remains the same, while the number of sequences is again doubled. Here the speedup factor starts to grow again, with almost the same factor as it did before. We observed that loading variations block-wise with a block size of 100 k not only lowers the expected memory consumption but also shows slightly better running time results. This behavior can be explained by considering the binary lookup necessary to find the journal entry representing a branch-node. If the set to be searched is smaller, then the lookup will be faster. Additionally, generating journaled strings for larger block sizes results in higher memory consumptions, and hence, caching effects can slow down the overall generation time. We showed that our method scales in time as well as memory usage well with the number of sequences and the number of variants contained in the set. We gained speedups for 2184JST-Myers JST-Horspool<ref type="figure">Fig. 4</ref>. JST search time depending on the pattern size over 1093 genotypes of chromosome 1 sequences up to a factor of $577 for the search time and $115 for the total running time compared with the sequential case, while we used only 3.72 GB of RAM. Motivated by the low memory consumptions, we used an Apple MacBook Pro with 8 GB main memory to search the set of 1093 sequences with Myers' bitvector algorithm and a pattern of size 64. This took only 78.51 (9.4) s in total (search only) while using $2.2 GB of RAM. Currently, we are extending the traversal to support multi-core parallelism. We will implement and test two different coreparallel approaches: parallelizing the traversal over the branchnodes and splitting the search space over the reference into multiple chunks. In the first version, we implement a singleproducer-multiple-consumer strategy, where one producer thread iterates over the branch-nodes and adds the states necessary to conduct a valid traversal over the branches to a threadsafe queue. A team of consumer threads can then dequeue the states independently from the queue and traverse the preceding reference segment starting from the predecessor node to the current branch-node and the branch itself. In the second strategy, we divide the reference sequence into multiple chunks and let a team of threads process untouched chunks concurrently. To do so, we need a preprocessing step over the set of branch-nodes, which resolves possible conflicts between the coverage sets of two neighboring chunks. Imagine a deletion at the end of a chunk that also affects the first positions of the adjacent chunk right of it. If two threads process these two chunks in parallel, then the thread working on the affected chunk might report wrong results because its active coverage set does not reflect the deletion beginning in the previous chunk. Furthermore, we will modify the journaled strings to represent single-nucleotide polymorphisms more efficiently, as they account for the largest number of variants available in public databases. This will further lower the memory consumption. Given the promising results of our approach, we will extend the set of functors to allow more complex algorithms, e.g. filter and verification algorithms, and integrate them into existing tools such as read mappers and variant caller to make them applicable to large collections of sequences. Moreover, our approach would allow to immediately incorporate new reference sequences into the existing set or to assemble domain-specific reference sets dynamically from an external pool, opening the door to tailored medical applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Interaction between the JST and a sequential algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Journaled string of s 1 referentially compressed against r from Figure 3. Original entries are drawn with black lines and insertion entries with green lines (node 2 and 3). The insertion buffer ib contains CG. The gray strings in each entry represent the corresponding substrings, which are not stored but depicted for clarification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Online search of the pattern p = AGCG over a JST depicted in (b) representing the four aligned sequences in (a), where r is chosen as the reference. The window length is 4. The bullets on the black line represent the branch-nodes: L=ð6; G; f2; 3g; RÞ; M=ð12; TAT; f1; 2g; DÞ; N=ð21; C; f1; 2; 3g; RÞ; O=ð22; G; f1g; IÞ. Below is plotted the reference with the reference coordinates. Branches are indicated by gray lines labeled with the respective sequence context depending on the window length and with the virtual positions of the chosen proxy (marked sequence number). The sets at the end denote the coverage. O 0 is a split-node induced by O in the branch of N. The dotted lines capped with diamonds below the reference positions represent the ranges in which invalid paths are suppressed. The orange (dashed) lines represent matches of the pattern p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Funding: This work was supported by the Deutsche Forschungsgemeinschaft [1712/4-1, Algorithmic engineering for high throughput sequencing to R.R.] and by the Federal Ministry of Education and Research [16V0080 to D.W.]. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Timings and memory consumption for approximate string matching with Myers' bitvecor algorithm and a pattern of size 64</figDesc><table>Number of sequences 
Number of variants 
Total time 
Search time 
Memory consumption 

JST (s) 
Naive (s) 
Factor 
JST (s) 
Naive (s) 
Factor 
JST (GB) 
Naive (GB) a 

1 
0 
6.56 
5.58 
0.85 
3.38 
2.88 
0.85 
0.63 
0.42 
2 
291 435 
6.50 
11.17 
1.72 
3.43 
5.46 
1.59 
0.68 
0.68 
33 
777 948 
9.10 
184.15 
20.24 
4.46 
90.21 
20.23 
0.80 
8.66 
65 
894 324 
10.30 
362.80 
35.22 
4.74 
177.63 
37.47 
0.86 
17.12 
129 
1 023 137 
13.36 
719.50 
53.85 
5.07 
352.46 
69.52 
0.99 
26.34 
257 
1 316 377 
18.66 
1434.70 
76.89 
5.83 
702.12 
120.43 
1.15 
26.34 
513 
2 106 043 
33.04 
2863.90 
86.67 
7.74 
1401.44 
181.06 
1.54 
26.34 
1093 
2 993 910 
76.61 
6101.94 
79.65 
10.58 
2985.83 
282.21 
2.58 
26.34 
2185 
2 993 758 
106.46 
12 198.38 
114.59 
10.34 
5968.85 
577.25 
3.72 
26.34 

Note. Naive refers to the sequential processing of fasta sequences. 

a 

At most 100 fasta sequences were loaded into memory at a time. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2.</figDesc><table>Timings and memory consumption for exact string matching with the Horspool algorithm and a pattern of size 64 

Number of sequences 
Number of variants 
Total time 
Search time 
Memory consumption 

JST () 
Naive (s) 
Factor 
JST (s) 
Naive (s) 
Factor 
JST (GB) 
Naive (GB) a 

1 
0 
3.74 
3.48 
0.93 
0.51 
0.45 
0.88 
0.63 
0.42 
2 
291 435 
4.28 
6.68 
1.56 
0.72 
0.90 
1.25 
0.68 
0.68 
33 
777 948 
6.38 
111.64 
17.50 
1.24 
16.52 
13.32 
0.80 
8.66 
65 
894 324 
7.04 
219.95 
31.24 
1.41 
32.17 
22.82 
0.86 
17.12 
129 
1 023 137 
9.91 
436.42 
44.04 
1.61 
63.46 
39.42 
0.99 
26.34 
257 
1 316 377 
15.44 
869.29 
56.30 
2.07 
126.03 
60.88 
1.15 
26.34 
513 
2 106 043 
27.95 
1735.18 
62.08 
3.19 
251.18 
78.74 
1.54 
26.34 
1093 
2 993 910 
63.30 
3696.95 
58.40 
5.49 
534.73 
97.40 
2.58 
26.34 
2185 
2 993 758 
93.55 
7390.51 
79.00 
5.15 
1068.78 
207.49 
3.72 
26.34 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">R.Rahn et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Journaled string tree at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">A map of human genome variation from population-scale sequencing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Altshuler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A fine-scale chimpanzee genetic map from population sequencing</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Auton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="page" from="193" to="198" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A new approach to text searching</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Baeza-Yates</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">H</forename>
				<surname>Gonnet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A public resource facilitating clinical use of genomes</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">P</forename>
				<surname>Ball</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="11920" to="11927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Querying highly similar sequences</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Barton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Biol. Drug Des</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="119" to="130" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Optimal spliced alignments of short sequence reads</title>
		<author>
			<persName>
				<forename type="first">De</forename>
				<surname>Bona</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="174" to="180" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Genome compression: a novel approach for large collections</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Deorowicz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2572" to="2578" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust relative compression of genomes with random access</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Deorowicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Grabowski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2979" to="2986" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">SeqAn an efficient, generic C++ library for sequence analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>€ Oring</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A map of human genome variation from population-scale sequencing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Opportunistic data structures with applications</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ferragina</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Manzini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Symposium on Foundations of Computer Science. FOCS&apos;00</title>
		<meeting>the 41st Annual Symposium on Foundations of Computer Science. FOCS&apos;00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="390" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A second generation human haplotype map of over 3.1 million SNPs</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Frazer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">449</biblScope>
			<biblScope unit="page" from="851" to="861" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Increased coverage of protein families with the blocks database servers</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">G</forename>
				<surname>Henikoff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="228" to="230" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Practical fast searching in strings</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">N</forename>
				<surname>Horspool</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Pract. Exper</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="501" to="506" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Short read alignment with populations of genomes</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="361" to="370" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">On the future of genomic data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">D</forename>
				<surname>Kahn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="728" to="729" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Mouse genomic variation and its effect on phenotypes and gene regulation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">M</forename>
				<surname>Keane</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">477</biblScope>
			<biblScope unit="page" from="289" to="294" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimized relative lempel-ziv compression of genomes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kuruppu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fourth Australasian Computer Science Conference</title>
		<meeting>the Thirty-Fourth Australasian Computer Science Conference</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Indexing similar dna sequences</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Lam</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Aspects in Information and Management</title>
		<editor>Chen,B.</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="180" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast and accurate short read alignment with burrows– wheeler transform</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1754" to="1760" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Space-efficient whole genome comparisons with burrows-wheeler</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lippert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="407" to="415" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Compressive genomics</title>
		<author>
			<persName>
				<forename type="first">P.-R</forename>
				<surname>Loh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="627" to="630" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Storage and retrieval of individual genomes</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>M€ Akinen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Molecular Biology. LNCS</title>
		<editor>Batzoglou,S.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">5541</biblScope>
			<biblScope unit="page" from="121" to="137" />
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A fast bit-vector algorithm for approximate string matching based on dynamic programming</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="395" to="415" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">GReEn: a tool for efficient compression of genome resequencing data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Pinho</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Simultaneous alignment of short reads against multiple genomes</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Schneeberger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">98</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Fingerprintscan: intelligent searching of the prints motif database</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Scordis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="799" to="806" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Indexing finite language representation of population genotypes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sir En</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6833</biblScope>
			<biblScope unit="page" from="270" to="281" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">An integrated map of genetic variation from 1,092 human genomes</title>
	</analytic>
	<monogr>
		<title level="m">The 1000 Genomes Project Consortium</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">The International Cancer Genome Consortium. (2010) International network of cancer genome projects</title>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">464</biblScope>
			<biblScope unit="page" from="993" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive efficient compression of genomes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wandelt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Leser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Razers 3: faster, fully sensitive read mapping</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weese</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2592" to="2599" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>