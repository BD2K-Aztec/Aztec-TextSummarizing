
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Bayesian network prior: network analysis of biological data using external knowledge</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Senol</forename>
								<surname>Isci</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit1">Bogazici University</orgName>
								<orgName type="institution" key="instit2">Kandilli Campus</orgName>
								<address>
									<postCode>34684</postCode>
									<region>Cengelkoy -Istanbul</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">TUBITAK-BILGEM, Informatics and Information Security Research Center</orgName>
								<orgName type="department" key="dep2">Gebze-Kocaeli</orgName>
								<address>
									<postCode>41470</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Haluk</forename>
								<surname>Dogan</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Genetics and Bioengineering</orgName>
								<orgName type="institution">Istanbul Bilgi University</orgName>
								<address>
									<postCode>34060</postCode>
									<settlement>Eyup -Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Cengizhan</forename>
								<surname>Ozturk</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit1">Bogazici University</orgName>
								<orgName type="institution" key="instit2">Kandilli Campus</orgName>
								<address>
									<postCode>34684</postCode>
									<region>Cengelkoy -Istanbul</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Hasan</forename>
								<forename type="middle">H</forename>
								<surname>Otu</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Genetics and Bioengineering</orgName>
								<orgName type="institution">Istanbul Bilgi University</orgName>
								<address>
									<postCode>34060</postCode>
									<settlement>Eyup -Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="middle">Alfonso</forename>
								<surname>Valencia</surname>
								<roleName>Prof</roleName>
							</persName>
						</author>
						<title level="a" type="main">Systems biology Bayesian network prior: network analysis of biological data using external knowledge</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">6</biblScope>
							<biblScope unit="page" from="860" to="867"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt643</idno>
					<note type="submission">Received on July 19, 2013; revised on October 2, 2013; accepted on November 2, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Supplementary Information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Reverse engineering GI networks from experimental data is a challenging task due to the complex nature of the networks and the noise inherent in the data. One way to overcome these hurdles would be incorporating the vast amounts of external biological knowledge when building interaction networks. We propose a framework where GI networks are learned from experimental data using Bayesian networks (BNs) and the incorporation of external knowledge is also done via a BN that we call Bayesian Network Prior (BNP). BNP depicts the relation between various evidence types that contribute to the event &apos;gene interaction&apos; and is used to calculate the probability of a candidate graph (G) in the structure learning process. Results: Our simulation results on synthetic, simulated and real biological data show that the proposed approach can identify the underlying interaction network with high accuracy even when the prior information is distorted and outperforms existing methods. Availability: Accompanying BNP software package is freely available for academic use at http://bioe.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Gene interaction (GI) networks provide insight for understanding the biological mechanisms that explain various phenotypes in health and disease. The inference of GI networks from highthroughput biological data is an important and challenging task in systems biology. Throughout the literature, the term GI has been used in a broad sense implying direct and indirect interactions between genes and/or gene products. Several machine learning and statistical methods have been proposed for the problem (<ref type="bibr" target="#b0">Akutsu et al., 2000;</ref><ref type="bibr" target="#b1">D'Haeseleer et al., 2000;</ref><ref type="bibr" target="#b9">Hecker et al., 2009;</ref><ref type="bibr" target="#b18">Lezon et al., 2006;</ref><ref type="bibr" target="#b20">Liang et al., 1998;</ref><ref type="bibr" target="#b36">Yeung et al., 2002</ref>) and Bayesian network (BN) models have gained popularity for the task of inferring gene networks (<ref type="bibr" target="#b4">Friedman and Koller, 2003;</ref><ref type="bibr" target="#b6">Friedman et al., 2000;</ref><ref type="bibr" target="#b7">Hartemink, 2005;</ref><ref type="bibr" target="#b15">Kim et al., 2003</ref>). Because of the complexity of GI networks and the sparse, noisy nature of experimental data, machine learning and statistical methods may lead to poor reconstruction accuracy for the underlying network. One way to overcome this problem would be to incorporate prior biological knowledge when making network inferences using experimental data. Due to technological advances in sequencing, microarray, proteomics and related fields, biological and clinical data are being produced at an ever increasing rate. The 2013 database issue of the Nucleic Acids Research journal lists 1512 molecular biology databases, which provide a vast amount of annotated data and meta data that could be used in a systematic way (Fernandez-Suarez and<ref type="bibr" target="#b3">Galperin, 2013</ref>). BNs have a number of features that make them viable candidates for combining prior knowledge and data as BNs can deal with uncertainty, avoid over fitting a model to training data, and learn from incomplete datasets. BNs handle stochastic events in a probabilistic framework accounting for noise, which results in emphasizing only strong relations in the observed data. Furthermore, BNs are able to focus on local interactions where each node is directly affected by a relatively small number of nodes (<ref type="bibr" target="#b6">Friedman et al., 2000</ref>) and interactions defined by a BN can be related to causal inference (<ref type="bibr" target="#b34">Verma and Pearl, 1991</ref>). These properties are similarly observed in biological networks justifying the use of BNs in exploring pathways in the setting of identifying GI networks using experimental data. Learning algorithms for both the structure and parameters of BNs have been developed (<ref type="bibr" target="#b25">Neapolitan, 2004</ref>). Most of the research on BNs has focused on directed acyclic graphs (DAGs) and static systems with discrete variables and/or linear Gaussian models.<ref type="bibr" target="#b6">Friedman et al. (2000)</ref>used BNs to generate a causal model of the yeast cell-cycle data using either a model with discretized expression levels (e.g. Boolean, or underexpressed/normal/overexpressed), or a linear Gaussian model. The latter treats the expression level of a gene as being normally distributed around a mean which is a linear sum of inputs. Therefore, rather than true causal relationships, the results may represent co-regulation of genes. Accordingly, a method to sample network structures from the posterior distribution with Markov Chain Monte Carlo (MCMC) has been introduced (<ref type="bibr" target="#b4">Friedman and Koller, 2003</ref>). Many BN structure learning algorithms are based on heuristic search techniques with the likelihood approximation because of the infeasible computational complexity. These approaches may lead to a false model, as neither the search technique nor the objective functions guarantee the optimal solution. Informative priors generated from existing biological information can improve structure learning to get better models to describe the *To whom correspondence should be addressed. ß The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. underlying GIs. In several studies the use of prior biological knowledge in conjunction with gene-expression data has been shown to improve the fidelity of network reconstruction.<ref type="bibr" target="#b8">Hartemink et al. (2002)</ref>incorporated genomic location data to guide the BN model inference.<ref type="bibr" target="#b29">Tamada et al. (2003)</ref>proposed a method, which iteratively detects consensus motifs based on the structure of the estimated network model, then evaluates the network using the result of the motif detection, until the inferred network becomes stable.<ref type="bibr" target="#b12">Imoto et al. (2003)</ref>proposed a framework utilizing Gibbs distribution where an energy function was used to evaluate the probability of an edge in the inferred networks.<ref type="bibr" target="#b35">Werhli and Husmeier (2007</ref>) extended this approach to integrate multiple sources of prior knowledge into dynamic Bayesian network (DBN) learning via MCMC sampling. Mukherjee and Speed (2008) proposed a scheme to incorporate known network features including edges, classes of edges, degree distributions, and sparsity into gene network reconstruction within a Bayesian learning framework utilizing MCMC sampling. These studies were limited in the use of external biological knowledge by incorporating only certain features, such as network topology or binding sites in promoter regions. Furthermore, in the aforementioned approaches manual curation and/or incorporation of the external knowledge are employed. In this article, we present a framework to incorporate multiple sources of prior knowledge, regardless of its type, into BN learning. The meaning of prior knowledge in our context is the enumeration of pair-wise interactions of genes from biological information sources and the use of this information in BN modeling. The proposed method is fully automatic and does not use likelihood approximations to find the optimal network that explains observed experimental data. We propose a novel framework that uses BN infrastructure itself to incorporate external biological knowledge when learning networks. This infrastructure yields GI information for pairs of genes, which can be used as informative priors to calculate the probability of a candidate graph, G. This information is then incorporated in the networklearning process that tries to identify the most probable graph given data. We provide an open-access web-based implementation of the proposed method at http://bioe.bilgi.edu.tr/BNP. Our results indicate that we can successfully reconstruct networks using synthetic data in addition to simulated and real geneexpression data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>The schematic depiction of the overall proposed method is presented in<ref type="figure">Figure 1</ref>. Pair-wise interaction information is gathered from biological databases and a BN model for prior knowledge, Bayesian Network Prior (BNP) is developed. In BNP, one node is depicted as GI and the topology represents the dependence structure for different evidence types within each other and with the GI node. For a set of genes, the model is instantiated with the given evidence and/or experimental data for each pair of genes. The GI node is used to infer whether the gene pair is related or not, represented by a prediction value between 0 and 1. A prior knowledge matrix, B, is populated with these prediction values for all gene pairs. Using a proposed novel energy formula and informative prior formula, this prior knowledge is utilized to calculate the probability of a candidate DAG, G, in the structure learning process. This parameter is used to optimize P(GjD) instead of the likelihood, P(DjG), used by existing structure learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Informative structure priors</head><p>A BN is a compact graphical representation of the joint probability distribution over a set of random variables and consists of a DAG ¼ (V, E), with a node set V corresponding to the random variables X 1 ,. .. , X n and an edge set E on these nodes and a set of conditional probability distributions Â for each node in the DAG. The DAG encodes the assertions of conditional independence. If the random variables are discrete, conditional probability distributions Â can be represented as a set of conditional probability tables (CPT). CPTs list the probabilities for each value that a child node can assume given a combination of values of its parents. In GI network-modeling studies using BNs, X i represents a gene and edges represent relationship between genes. The task of network inference (i.e. structure learning) is to make inferences regarding the graph G that best explains the data. This can be achieved by finding the DAG G that maximizes PðGjDÞ ¼ PðDjGÞPðGÞ PðDÞ where P(DjG) is the likelihood, P(D) is the probability of the data, P(G) is the structure prior (or network prior) probability of the graph G andwe employ a greedy search algorithm that aims to maximize P(GjD). For a given candidate DAG, G, we calculate P(G) by first obtaining the prior information matrix, B. Unlike existing methods, the proposed approach does not use categorized prior knowledge but assigns probabilities to each candidate edge. The matrix B is obtained by instantiating BNP with the evidence vector for each pair of genes in the input gene set. These evidence vectors can originate from any performed experimental data at hand, or external knowledge, or both. Let B be the prior information matrix, where B(i, j) ¼ P(X ij ), the degree of prior belief that gene i and j interact based on external knowledge. Let A G denotes the adjacency matrix of the candidate graph G. We define the matrix U such that U(i, j) ¼ 1 – [B(i, j)A G (i, j)], the element by element multiplication of B and A G. Note that if there exists no edge from i to j in G, U(i, j) ¼ 1; and if there is an edge from i to j in G, U(i, j) is inversely proportional to our prior belief on the existence of the edge. The total energy of G is defined as:</p><formula>EðGÞ ¼ X i, j</formula><p>Uði, jÞ N 2 where N is the number of nodes in G. This way, we do not assign categorical values for U(i, j) and exploit fully the information about prior existence of an edge. Informative structure prior is formulated as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PðGjÞ ¼ Ce ÀEðGÞ</head><p>where C is a scaling constant. The choice of C does not affect the relative comparison during scoring of graphs in structure learning. The hyperparameter can be marginalized using PðGÞ ¼ c:</p><formula>1 H À L Z H L e ÀEðGÞ d:</formula><p>For ease of simulation, the integral is calculated for a range of E(G) and stored in a lookup table. In the numerical calculation of this integral, Á ¼ H – L is the parameter of interest, which is optimized as explained in subsection 3.2. The integration approach automatically incorporates the uncertainty on the parameter by averaging the likelihood values of the parameter. Point estimates acquired by maximizing the parameters may change arbitrarily with arbitrary re-parameterizations. Point estimates maximize the probability density without taking into account the complementary volume information, which may yield in suboptimal results. When one has a choice of which variables to integrate over and which to maximize over, it is suggested that one would integrate over as many variables as possible in order to capture the relevant volume information of high-dimensional probability distributions (<ref type="bibr" target="#b21">MacKay, 1996</ref><ref type="bibr" target="#b22">MacKay, , 1999</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Bayesian network prior</head><p>The goal in building BNP is to construct a framework such that the distilled external biological knowledge is used in an intelligent way to make an assessment about the interaction of a pair of genes. Previously,<ref type="bibr" target="#b30">Troyanskaya et al. (2003)</ref>proposed a Bayesian Framework for combining various data sources for gene function prediction. In this method a Naive Bayesian model was constructed. The parameters (CPTs) of the model were determined by experts. Then, a separate network was instantiated for each gene pair by initializing the bottom-level nodes with evidence and the probability of the functional relationship between the two genes was updated. The model was designed for functional prediction, not for GI network learning. Here, we describe a novel-prior knowledge inference model that automatically learns parameters of the nodes used in BNP that predicts if two genes interact using external biological knowledge. The model organism chosen for BNP was human and the external data came from pathway, microarray, gene and protein interaction databases. The assembled information source is made up of 'evidence types', each making a 'Yes' or 'No' call about the interaction of two genes and BNP is the BN that represents the relation between these evidence types and GI. In what follows, we explain the data sources in detail. Microarray co-expression was calculated using two datasets. The first dataset aims to provide a gene atlas for the human genes and examines 79 normal human tissues with 158 samples (<ref type="bibr" target="#b28">Su et al., 2004</ref>). The second database came from the 'Reference Database for Gene Expression Analysis' (RefExA) that represents 70 normal human tissue samples (http://www.lsbm.org). Affymetrix Expression Console v1.1 was used to normalize the samples using the MAS 5.0 method. Probe sets with absence calls in all of the samples were omitted from further analysis. Centered Pearson correlations were calculated and 71 617 pairs of probe sets with a correlation value greater than 0.98 were passed on to be used to construct BNP. KEGG (<ref type="bibr" target="#b14">Kanehisa et al., 2012</ref>), NCI/ NATURE (<ref type="bibr" target="#b26">Schaefer et al., 2009</ref>) and Reactome (<ref type="bibr" target="#b33">Vastrik et al., 2007</ref>) databases were utilized to gather pathway based evidence data. 3258 pair-wise gene relations that existed in at least two of the three pathway databases were used for further analysis. A dataset was obtained from BioGrid (<ref type="bibr" target="#b27">Stark et al., 2011</ref>) with evidence of interactions that are observed in experiments with 17 different assay types such as affinity capture and two-hybrid. BioGrid analysis revealed a total of 35 600 non-redundant pair-wise interactions. After the microarray probe set level data was regressed to the gene level and all three sources were merged, 60 950 pair-wise GIs based on 19 evidence types were obtained (see Supplementary<ref type="figure">Table S1</ref>). A GI node is appended to this evidence matrix (where rows represent gene pairs and columns represent evidence types) with a 'true' value if there were at least two evidence types implying interaction. BNP was built by learning both structure and parameters using Greedy Hill Climbing (<ref type="bibr" target="#b25">Neapolitan, 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constructing the BNP</head><p>BNP was built using the GI evidence matrix that contained 460 000 pairs of genes. The model was trained and tested using a 5-fold cross validation approach, where the dataset was randomized and 80% of the data was used to train the model and 20% of the data was used to test the model. Success rate of the model with respect to the GI data label is calculated as the classification error. This procedure was repeated five times and average error values were calculated. At each time, after BNP was built with 80% of the evidence matrix using the Greedy Hill Climbing (GHC) method, the remaining 20% of the data matrix was tested by inferring the value of the GI node. This test was done through instantiation of BNP using the evidence vector of a given pair of genes. Loopy Belief Propagation inference algorithm was used for inference. If the inference value was 40.5, the GI node was taken to be 'true'. The classification error rate for the 5-fold cross validation was 0.105 AE 0.003 implying an accuracy of $90% when estimating if two genes interact given external biological knowledge. Final BNP was constructed with the entire evidence matrix using the GHC method. The strength of the probabilistic relationships expressed by the edges of BNP was measured using Friedman's bootstrap method with 1000 repeats (<ref type="bibr" target="#b5">Friedman et al., 1999</ref>). Model averaging was used to build a consensus DAG of BNP, containing only the significant edges with a significance threshold of 0.413 determined by using the method of<ref type="bibr" target="#b24">Nagarajan et al. (2010)</ref>. The consensus DAG of BNP is shown in<ref type="figure" target="#fig_1">Figure 2</ref>. BNP consists of 20 nodes and 98 edges. The density of the network is 0.52 with an average degree of 9.8, showing high connectivity. The most connected nodes are 'Microarray' (denoting an interaction based on gene expression) and 'Reconstituted Complex' (implying an interaction is detected between purified proteins in vitro) with 19 edges, i.e. full connectivity. These are followed by '<ref type="bibr">Two-Hybrid' (18 edges</ref>), Affinity Capture MS (17 edges) and Affinity Capture Western (16 edges) assays. BNP provides a unique depiction about how different experimental assays are related to each other and to the event of GI, which opens ways to new hypotheses about assay type interrelation. The evidence matrix and the source code used to build BNP as well as the parameters of the final BNP model are available on the web portal hosting BNP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sensitivity analysis of prior parameters</head><p>We used the ubiquitous Sprinkler BN shown in Supplementary<ref type="figure">Figure S1</ref>to test the sensitivity of the proposed method to the prior formula hyperparameter. Sprinkler BN is a binary network that shows the conditional probability distributions for the events of the weather being cloudy, raining, grass being wet and the sprinkler being on. We generated simulated discrete datasets that follow the model shown in Supplementary<ref type="figure">Figure S1</ref>and marginal likelihood P(DjG) scores with uniform flat priors. In this and all subsequent AUC calculations, the edges are considered to be undirected. For each Á value, the scoring was repeated 50 times by generating new data sizes of 10, 20, 50 and 100. In Supplementary<ref type="figure" target="#fig_1">Figure S2</ref>, we plot the mean AUC values obtained versus the parameter interval values. Our results suggest that the proposed method always outperforms the likelihood based approaches and the performance reaches a plateau for Á values of 1 and higher. Based on these observations, for the remaining experiments, we used a Á value of 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Incorporation of P(G)</head><p>Following optimization of the prior parameters, we tested the incorporation of P(G) on the Sprinkler BN as well as randomly generated 5-node BNs. In the Sprinkler BN tests, we generated data that follows the model shown in Supplementary<ref type="figure">Figure S1</ref>for a dataset size 1000. We scored each of the 543 possible 4-node DAGs in a brute force approach without using a heuristic search algorithm. We calculated P(DjG) using BDe and P(GjD) using the proposed approach. In Supplementary Table S2, we show the top 10 scoring DAGs with the highest P(GjD) scores using nine different distorted prior matrix cases. Our results suggest that the proposed approach outperforms conventional structure learning methods even when the prior structure matrix B is vastly distorted. The true DAG comes uniquely out at the top when P(GjD) is considered. It is possible to differentiate between DAGs in the same Markov Equivalence Class by incorporatingP(G), however, this does not hold true for the P(DjG) scores, which do not use P(G). We then generated 100 random 5-node BNs along with their CPTs. Datasets of size 100 were generated with BNT and both likelihood and proposed scores were calculated for the DAGs. In applying the proposed approach, we distorted the prior matrix so that it did not always represent the true adjacency matrix. For a given DAG, we changed the real edge probabilities in the prior matrix with a fixed value between 0.7 and 1.0. This value was randomly chosen for each DAG. If no edge was present in the true DAG, this was reflected with a probability value of 0 in the prior knowledge matrix. Again a brute force method was used in that all 29 281 possible 5-node DAGs were created and scored using both methods. In Supplementary<ref type="figure" target="#fig_3">Figure S3</ref>, we show the percent rank of the true DAG for both methods with changing distortion levels. Percent rank is calculated as<ref type="bibr">[</ref>. In all the simulations, the proposed method ranked the true DAG higher than it was ranked using marginal likelihood scoring. The average percent rank of the true DAG using the proposed method was 0.09%. In other words, the true DAG was ranked as approximately the 27th best scoring DAG, on average, using the proposed method. On the other hand, the average percent rank of the true DAG using the likelihood scoring approach was 2.28%, implying that the true DAG was ranked as approximately the 670th best scoring DAG on average. We further analyzed the performance of the posterior probability scoring with informative priors against likelihood scoring with flat priors on the 4-node Sprinkler network and a randomly selected 5-node network in detail (see Supplementary<ref type="figure" target="#fig_4">Fig. S4</ref>). In the application of the proposed method, we distorted the prior knowledge matrix by assigning the same probability values, 'a', to the edges and the same probability values, 'b', to the entries with no edges using all combinations for 'a' and 'b' in the range<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>with 0.1 increments. The generated dataset size was 100 and the process was repeated 10 times for each pair of (a, b). In<ref type="figure" target="#fig_3">Figure 3</ref>, we show the AUC values using a heatmap. The x-axis represents probability values assigned to non-existing edges and the y-axis represents probability values assigned to the true edges in the graph. Each pixel encodes the average AUC value for the 10 simulations for a given (a, b) and the lower left quadrant represents prior knowledge that the true edge probability is in the range of<ref type="bibr">[0.6–1.0]</ref>and the false edge probability is in the range of [0.0–0.4]. In the lower left quadrant, the overall mean AUC of the posterior probability scoring was 480% for the Sprinkler BN and close to 70% for the 5-node BN. If the true edges are indicated in the prior matrix with high accuracy, then the proposed method performs quite well in finding the DAG under investigation. For example, in the Sprinkler BN, when the true edges are correctly represented with a 1 in the prior matrix, AUC remains at 100% even the false edge probabilities are as high as 0.9. For a fixed true edge probability of 0.9, the average AUC is $92% when the false edge probability ranges from 0 to 0.9. A similar trend is observed for the 5-node BN. The heat maps shown in<ref type="figure" target="#fig_3">Figure 3</ref>also indicate that incorrect prior knowledge is punished by our informative prior model severely and the proposed system is more robust to false positives than it is to false negatives in the prior matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Synthetic pathway data</head><p>We picked 23 human KEGG pathways and modeled them as BNs as previously described (<ref type="bibr" target="#b13">Isci et al., 2011</ref>). The pathway names and their graph properties can be found in Supplementary Table S3. For each BN, a dataset of size 50 was generated using BNT with CPTs fitting to the DAGs. The original DAGs were used to obtain distorted prior matrices. In this case, distortion was introduced by adding Gaussian noise to the true DAG's adjacency matrix A T to obtain the prior matrix B. The distortion rate was calculated using d ¼ Fro (A T – B)/ Fro(A T ), where Fro(A) represents the Frobenius norm of the matrix A (da<ref type="bibr" target="#b2">Piedade et al., 2009</ref>). The distortion rate was set to be in the<ref type="bibr">[0.0–0.3]</ref>range and this range was covered in 0.05 increments rendering seven discrete rates. For each pathway and distortion rate, the synthetic data generation, distortion and structure-learning steps were repeated five times both using the proposed method based on information priors and the likelihood based standard methods. In<ref type="figure" target="#fig_4">Figure 4</ref>, we represent the average AUC values as a function of the introduced distortion rates. For all iterations, learnt DAGs with informative priors had higher AUCs (between 0.9 and 1) compared to the AUCs (between 0.5 and 0.6) for DAGs learnt with flat priors. The proposed method showed less variation in its performance measure compared to the standard methods. As the distortion level was increased, the difference between the mean AUC values of DAGs learnt with informative prior and flat prior had a tendency to decrease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Simulated pathway data</head><p>We used the same 23 KEGG pathways used in the previous step to generate simulated gene expression data. SynTReN v1.12 was used to generate the signal levels for the genes in each of the 23 pathways with 10 control and 10 test samples and $10% background noise (Van den<ref type="bibr" target="#b32">Bulcke et al., 2006</ref>). The input data for structure learning was obtained as previously described (<ref type="bibr" target="#b13">Isci et al., 2011</ref>). Briefly, columns represent genes in the pathway and rows represent observations. Each row (observation) is obtained by the fold change values of the genes between one pair of control and test samples. The input matrix consisted of 100 observations (10 control Â 10 test) and reflected the distribution of fold change values between the two classes of samples. This matrix was discretized into three levels using k-means clustering (<ref type="bibr" target="#b19">Li et al., 2010</ref>). The inferred DAGs using prior knowledge (proposed method) and unifrom prior knowledge (flat prior, standard methods) were compared to the original pathway structures using AUC values. This process was repeated five times for each pathway. When the proposed method was employed, the BNP was instantiated for each gene pair in the given pathway to obtain the GI probability for the pair omitting the evidence from the KEGG information priors. These values made up the prior information matrix, B. During the instantiation, the evidence vector used composed of existing evidence information for the gene pair in the databases and the microarray correlation value calculated by the input GI data. This exemplifies the utility of the proposed method in which one can build interaction networks based on different evidence types originating from the performed experimental data. The BNP workflow then collates this observed information with the distilled structure obtained from external knowledge bases to infer the GI probability for a pair of genes. The results for the AUC values between predicted and true DAGs for the 23 KEGG pathways using simulated GI data are shown in<ref type="figure" target="#fig_5">Figure 5</ref>. The proposed method dramatically surpassed classical structure learning methods where the AUC values for the DAGs found using the proposed method, on average, were 30% higher. The average AUC value for the proposed method was 86%. The improvement introduced by BNP shows the value of incorporating existing external knowledge when reverse engineering GI networks from noisy GI data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Real microarray data</head><p>We tested the proposed method using real GI data obtained from Renal Cell Cancer (RCC) and Normal samples as deposited in NCBI's GEO database with accession numbers GSE 11024 (<ref type="bibr" target="#b17">Kort et al., 2008</ref>) and GSE 8271 (<ref type="bibr" target="#b16">Koeman et al., 2008</ref>). Input data was obtained as previously described (<ref type="bibr" target="#b13">Isci et al., 2011</ref>). Briefly, MAS 5.0 normalized data was used and IDs in the array platform that correspond to a given node in a given pathway were pooled and summarized as one representative signal value using one-step Tukey's bi-weight algorithm (<ref type="bibr" target="#b11">Hoaglin et al., 2000</ref>). Generation of the observation matrix to be used in the structure learning process for a given pathway and incorporation of BNP were carried out as explained in the previous subsection. We attempted at finding seven KEGG pathways shown to be important in RCC (<ref type="bibr" target="#b13">Isci et al., 2011</ref>) using the expression values of the genes in these pathways from the two real RCC microarray datasets. The AUC values for the predicted and true pathways using the proposed method and likelihood scoring based methods are shown in<ref type="figure" target="#fig_6">Figure 6</ref>. In all seven cases, the proposed method found the underlying KEGG pathway with greater accuracy. The average AUC values for the proposed and existing methods were 89% and 57%, respectively. In Supplementary<ref type="figure" target="#fig_5">Figure S5</ref>, we show the GI network found using the proposed method for the genes in the 'glycosaminoglycan degradation' pathway. The comparison of this network with the true KEGG pathway (hsa00531) shows that 495% of the edges that exist in the true pathway are correctly found in the reconstructed network. The proposed method inserted six edges that did not exist in the true pathway. However, as biological pathways may be incomplete, these inserted edges have the potential to suggest interactions that are yet to be discovered and should not be regarded as real false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>In this article, we describe a framework to incorporate multiple sources of prior knowledge, regardless of its type, into Bayesian network learning. In several studies, the use of prior biological knowledge of the GI network in conjunction with GI data has been suggested to improve the fidelity of network reconstruction. However, existing methods fail to rigorously harness and use the existing wide range of biological information. The proposed BNP model makes inferences about interactions between gene pairs. The model is instantiated each time with the given experimental data to infer whether the gene pair is related or not, represented by a prediction value between 0 and 1. A prior knowledge matrix is populated with prediction values for all combinations of gene pairs. Using a proposed energy and informative prior function, the prior knowledge is utilized in learning network structure with the Greedy Search algorithm in the BN framework. The goal on these applications is to construct gene networks from GI data and a list of genes of interest. We tested</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>865</head><p>Network analysis of biological data the sensitivity our prior model to its parameters and analyzed the performance of the posterior probability scoring with informative priors against scoring with flat priors. Our BNP model incorporating selective evidence types rendered an accuracy of 490% when estimating if two genes interact given external biological knowledge. This informative prior formula is integrated into the greedy search algorithm to learn Bayesian networks. It was shown that the proposed method was able to infer real pathways with high AUC values, using both synthetic and real GI data.</p><p>The proposed framework can be extended to analyze time series gene expression data using Dynamic BNs. This can be achieved through a straightforward application where the calculated P(G) using BNP is incorporated in dynamic network-learning methods. Bayesian structure learning algorithms and the improved algorithms described in this article have certain limitations in terms of the size of the network to apply to. Any biological pathway may not work alone but function as part of a large atlas. Therefore, inferring large GI networks (atlas) from data. For each of the seven pathways real microarray data was used to obtain the observation matrices used in the structure learning process. Proposed method using informative priors (AUCp) and likelihood based methods using flat priors (AUCf) were used to compare the learned networks with the original KEGG pathways is an important but challenging task. The proposed method is applicable to this problem when the network to be learned can be decomposed into a modular structure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>using the Bayes Net Toolbox (BNT) for Matlab (http://cs.ubc.ca/ $murphyk). We used a range of Á values of [ L , H ] from 0.1 to 20 and performed receiver operating characteristic (ROC) curve analysis. The area under the curve (AUC) values for the best performing DAGs were calculated using posterior probability P(GjD) with informative priors (proposed method)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Topology of the BNP. BNP depicts the conditional dependence structure between various evidence types and the GI node based on external biological knowledge. BNP is used to predict the interaction probability for two genes using provided experimental data combined with external information. Links of the GI node are shown in solid lines for visual purposes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>(rank of the true DAG's score/number of all DAGs) Â 100%]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Heat map for the AUC values for the Sprinkler and a 5-node BN. The color-scale used for the heat maps are shown at the bottom. Each pixel denotes a fixed true-edge, no-edge probability pair and summarizes the mean AUC of 10 simulations. The AUC values were calculated using the proposed method based on dataset sizes of 100, each following the joint probability distribution implied by the networks. Lower left corner implies a well composed prior matrix, B, as true edge probabilities are close to 1 and no-edge probabilities are close to 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Average AUC values for the proposed (prior) and standard likelihood based (flat) methods. The x-axis represents the distortion rate used in the prior matrix, B. Twenty-three KEGG pathways were modeled as BNs and five fitting datasets of size 50 for each pathway was generated. Learned networks using the two methods were compared to the KEGG pathways for AUC calculation. In application of the proposed method the adjacency matrix of the original pathway was distorted by adding Gaussian noise to the matrix entries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Average AUC values for 23 KEGG pathways based on simulated gene expression data. Proposed method using informative priors (AUCp) and standard methods using flat priors (AUCf) were compared. For each pathway, simulated gene-expression values were used after some data preprocessing to reverse engineer the original DAG. In the simulations, 10 test and 10 control samples, yielding a dataset size of 100, were used. Five simulated datasets per pathway were produced</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.6.</head><figDesc>Fig. 6. AUC values for the seven KEGG pathways known to be active in Renal Cell Cancer (RCC). For each of the seven pathways real microarray data was used to obtain the observation matrices used in the structure learning process. Proposed method using informative priors (AUCp) and likelihood based methods using flat priors (AUCf) were used to compare the learned networks with the original KEGG pathways</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><figDesc>Conflict of Interest: None declared.</figDesc></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">P(GjD) is the posterior probability of G. In commonly used heuristic structure learning algorithms, P(DjG) is optimized instead of the true model P(GjD). The likelihood criterion does not guarantee to find the optimum solution even if a heuristic approach is not employed. Nevertheless, optimizing the likelihood can be justified by assuming P(D) and P(G) to be equal for all G. The former assumption can be regarded as reasonable as D is observed. However, the latter assumption is generally not correct and is made mainly due to difficulties in calculating P(G) and/or lack of prior knowledge on G. Use of uniform (flat) priors for Gs ignores the contribution of P(G) and this may cause failure in differentiating between DAGs that are in the same Markov equivalence set. Therefore, the true DAG among the ones that support the same conditional probability distribution cannot be identified. The proposed approach aims to calculate P(G) using external knowledge and provide improvements in the structure-learning phase for GI networks. For discrete BNs, most of the learning tasks are performed by calculating P(DjG) with the Bayesian Dirichlet equivalent (BDe) scoring function and by assuming uniform (flat) prior structure for all possible candidate DAGs (Heckerman et al., 1995). In the proposed approach, Fig. 1. Overall workflow of the proposed method. BNP is constructed using GI information from external biological databases and when instantiated with an evidence vector for a pair of genes, the GI probability is inferred. For a list of genes, the pair-wise interaction information is stored in the prior matrix B, which is used to calculate the probability of a candidate graph G in the structure learning process 861 Network analysis of biological data at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">S.Isci et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="863"> Network analysis of biological data at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithms for identifying Boolean networks and related biological networks based on matrix multiplication and fingerprint function</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Akutsu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="331" to="343" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Genetic network inference: from co-expression clustering to reverse engineering</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>&apos;haeseleer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="707" to="726" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">DISPARE: DIScriminative pattern refinement for position weight matrices</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Da Piedade</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">388</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">The 2013 Nucleic acids research database issue and the online molecular biology database collection</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<forename type="middle">M</forename>
				<surname>Fernandez-Suarez</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">Y</forename>
				<surname>Galperin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Koller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="95" to="125" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Data analysis with Bayesian networks: a bootstrap approach</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI)<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Using Bayesian networks to analyze expression data</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="601" to="620" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Reverse engineering gene regulatory networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Hartemink</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="554" to="555" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining location and expression data for principled discovery of genetic regulatory networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hartemink</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing 2002 (PSB02). World Scientific</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="437" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Gene regulatory network inference: data integration in dynamic models-a review</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hecker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biosystems</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="86" to="103" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks: the combination of knowledge and statistical data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Heckerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="197" to="243" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">Understanding Robust and Exploratory Data Analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">C</forename>
				<surname>Hoaglin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayesian network and nonparametric heteroscedastic regression for nonlinear modeling of genetic network</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Imoto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bioinform. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="231" to="252" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Pathway analysis of high-throughput biological data within a Bayesian network framework</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Isci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1667" to="1674" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">KEGG for integration and interpretation of large-scale molecular data sets</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kanehisa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="109" to="114" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Inferring gene networks from time series microarray data using dynamic Bayesian networks</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">Y</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="228" to="235" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Somatic pairing of chromosome 19 in renal oncocytoma is associated with deregulated EGLN2-mediated [corrected] oxygen-sensing response</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Koeman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">The E2F3-Oncomir-1 axis is activated in Wilms&apos; tumor</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">J</forename>
				<surname>Kort</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="4034" to="4038" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Using the principle of entropy maximization to infer genetic interaction networks from gene expression patterns</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">R</forename>
				<surname>Lezon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="19033" to="19038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Comparative study of discretization methods of microarray data for inferring transcriptional regulatory networks</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">520</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">REVEAL, a general reverse engineering algorithm for inference of genetic network architectures</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Liang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing. World Scientific</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="18" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Hyperparameters: Optimize, or Integrate Out?</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J C</forename>
				<surname>Mackay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics</title>
		<editor>Heidbreder,G.R.</editor>
		<imprint>
			<publisher>Maximum Entropy and Bayesian Methods Springer</publisher>
			<biblScope unit="issue">62</biblScope>
			<biblScope unit="page" from="43" to="59" />
			<date type="published" when="1996" />
			<publisher>Maximum Entropy and Bayesian Methods Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Comparison of approximate methods for handling hyperparameters</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J C</forename>
				<surname>Mackay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1035" to="1068" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Network inference using informative priors</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mukherjee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">P</forename>
				<surname>Speed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="14313" to="14318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Functional relationships between genes associated with differentiation potential of aged myogenic progenitors</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Nagarajan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Physiol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning Bayesian Networks</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">E</forename>
				<surname>Neapolitan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">PID: the pathway interaction database</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">F</forename>
				<surname>Schaefer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="674" to="679" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">The BioGRID Interaction Database: 2011 update</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Stark</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="698" to="704" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A gene atlas of the mouse and human protein-encoding transcriptomes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">I</forename>
				<surname>Su</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="6062" to="6067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Estimating gene networks from gene expression data by combining Bayesian network model with promoter element detection</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Tamada</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="227" to="236" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b30">
	<monogr>
		<title level="m" type="main">A Bayesian framework for combining heterogeneous data sources for gene function prediction</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">G</forename>
				<surname>Troyanskaya</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>in. Saccharomyces cerevisiae</note>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<biblScope unit="page" from="8348" to="8353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">SynTReN: a generator of synthetic gene expression data for design and analysis of structure learning algorithms</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Van Den Bulcke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Reactome: a knowledge base of biologic pathways and processes</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Vastrik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Verma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Pearl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Conference on the Principles of Knowledge Representation and Reasoning</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="441" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Reconstructing gene regulatory networks with bayesian networks by combining expression data with multiple sources of prior knowledge</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">V</forename>
				<surname>Werhli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Husmeier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Reverse engineering gene networks using singular value decomposition and robust regression</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">K</forename>
				<surname>Yeung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="6163" to="6168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<monogr>
		<title level="m" type="main">Network analysis of biological data</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>