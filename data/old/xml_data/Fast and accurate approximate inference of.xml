
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and accurate approximate inference of transcript expression from RNA-seq data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">James</forename>
								<surname>Hensman</surname>
							</persName>
							<email>Contact: james.hensman@sheffield.ac.uk or panagiotis.papastamoulis@manchester.ac.uk or Magnus.Rattray@manchester.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Sheffield Institute for Translational Neuroscience (SITraN)</orgName>
								<address>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Panagiotis</forename>
								<surname>Papastamoulis</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Life Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Peter</forename>
								<surname>Glaus</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">The University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Antti</forename>
								<surname>Honkela</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Helsinki Institute for Information Technology (HIIT)</orgName>
								<orgName type="institution" key="instit2">University of Helsinki</orgName>
								<address>
									<settlement>Helsinki</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Magnus</forename>
								<surname>Rattray</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Life Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast and accurate approximate inference of transcript expression from RNA-seq data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv483</idno>
					<note type="submission">Received on January 23, 2015; revised on August 3, 2015; accepted on August 7, 2015</note>
					<note>Genome analysis *To whom correspondence should be addressed. † The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors. Associate Editor: Ivo Hofacker Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Assigning RNA-seq reads to their transcript of origin is a fundamental task in transcript expression estimation. Where ambiguities in assignments exist due to transcripts sharing sequence , e.g. alternative isoforms or alleles, the problem can be solved through probabilistic inference. Bayesian methods have been shown to provide accurate transcript abundance estimates compared with competing methods. However, exact Bayesian inference is intractable and approximate methods such as Markov chain Monte Carlo and Variational Bayes (VB) are typically used. While providing a high degree of accuracy and modelling flexibility, standard implementations can be prohibitively slow for large datasets and complex transcriptome annotations. Results: We propose a novel approximate inference scheme based on VB and apply it to an existing model of transcript expression inference from RNA-seq data. Recent advances in VB algorith-mics are used to improve the convergence of the algorithm beyond the standard Variational Bayes Expectation Maximization algorithm. We apply our algorithm to simulated and biological datasets, demonstrating a significant increase in speed with only very small loss in accuracy of expression level estimation. We carry out a comparative study against seven popular alternative methods and demonstrate that our new algorithm provides excellent accuracy and inter-replicate consistency while remaining competitive in computation time. Availability and implementation: The methods were implemented in R and Cþþ, and are available as part of the BitSeq project at github.com/BitSeq. The method is also available through the BitSeq Bioconductor package. The source code to reproduce all simulation results can be accessed via github.com/BitSeq/BitSeqVB_benchmarking.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>RNA-seq is a technology with the potential to identify and quantify all mRNA transcripts in a biological sample (<ref type="bibr" target="#b15">Mortazavi et al., 2008</ref>). Some of these transcripts come from different isoforms or alleles of the same genes or from closely related homologous genes, and consequently they may share much of their primary sequence. Currently, popular RNA-seq technologies generate short reads that must be aligned to the genome or transcriptome to quantify V C The Author 2015. Published by Oxford University Press.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3881</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. expression levels. In some cases the observed reads could originate from several different transcripts and there may be few reads that are useful to distinguish these transcripts. It is therefore a challenging statistical problem to uncover the expression levels of closely related transcripts. A recent assessment confirms this by showing significant variability between results obtained using different computational pipelines (SEQC/MAQC-III<ref type="bibr" target="#b23">Consortium, 2014</ref>). Probabilistic latent variable models, in particular mixture models (<ref type="bibr" target="#b9">Jiang and Wong, 2009;</ref><ref type="bibr" target="#b5">Glaus et al., 2012;</ref><ref type="bibr" target="#b10">Katz et al., 2010;</ref><ref type="bibr" target="#b13">Li and Dewey, 2011;</ref><ref type="bibr" target="#b14">Li et al., 2010;</ref><ref type="bibr" target="#b16">Nariai et al., 2013;</ref><ref type="bibr" target="#b27">Trapnell et al., 2013;</ref><ref type="bibr" target="#b28">Turro et al., 2011</ref>) provide a popular and effective approach for inferring transcript expression levels from RNA-seq data. Such models can be used to deconvolve the signal in the read data, assigning reads to alternative, pre-defined transcripts according to their probability of originating from each. The term mixture model derives from the interpretation of the data as being derived from a mixture of different transcripts, the mixture components, with each read originating from one component. Although reads originate from only one component they may map to multiple related components, resulting in some ambiguity in their assignment. Transcript expression levels are model parameters (mixture component proportions) that have to be inferred from the mapped read data. Due to their probabilistic nature these models can fully account for multiple mapping reads, complex biases in the sequence data, sequencing errors, alignment quality scores and prior information on the insert length in pairedend reads. Mixture models have been successfully applied to infer the proportion of different gene isoforms or allelic variants in a particular sample (<ref type="bibr" target="#b9">Jiang and Wong, 2009;</ref><ref type="bibr" target="#b10">Katz et al., 2010;</ref><ref type="bibr" target="#b28">Turro et al., 2011</ref>), for inferring gene and isoform expression levels (<ref type="bibr" target="#b14">Li et al., 2010;</ref><ref type="bibr" target="#b13">Li and Dewey, 2011;</ref><ref type="bibr" target="#b15">Mortazavi et al., 2008;</ref><ref type="bibr" target="#b21">Roberts and Pachter, 2013;</ref><ref type="bibr" target="#b27">Trapnell et al., 2013</ref>) and for transcript-level differential expression calling (<ref type="bibr" target="#b5">Glaus et al., 2012;</ref><ref type="bibr" target="#b27">Trapnell et al., 2013</ref>). Inference in latent variable models such as these can be carried out by maximum likelihood (ML) or Bayesian parameter estimation. In ML the choice of parameters that maximizes the data likelihood is obtained through a numerical optimization procedure. In the case of mixture models a popular choice of algorithm is the Expectation Maximization (EM) algorithm, as first applied to this model and expressed sequence tag data by<ref type="bibr" target="#b29">Xing et al. (2006)</ref>and later to RNA-seq data by<ref type="bibr" target="#b14">Li et al. (2010)</ref>. For Bayesian inference the most popular approach is Markov chain Monte Carlo (MCMC) and for the case of mixture models a Gibbs sampler is most often used (<ref type="bibr" target="#b5">Glaus et al., 2012;</ref><ref type="bibr" target="#b10">Katz et al., 2010;</ref><ref type="bibr" target="#b13">Li and Dewey, 2011</ref>). An advantage of Bayesian inference is that one obtains a posterior probability over the model parameters rather than just a point estimate. This provides a level of uncertainty in the inferred transcript expression levels as well as information about the covariation between estimates for closely related transcripts. The uncertainty information can be usefully propagated into downstream analysis of the data, e.g. calling differentially expressed transcripts from replicated experiments (<ref type="bibr" target="#b5">Glaus et al., 2012</ref>). A Bayesian method, BitSeq, was proposed in which inference was carried out using a collapsed Gibbs sampler (<ref type="bibr" target="#b5">Glaus et al., 2012</ref>). The method was shown to perform well, especially for the task of inferring the relative expression of different gene isoforms and for ranking transcripts according to their probability of being differentially expressed between conditions. However, for typical modern RNA-seq datasets with hundreds of millions of read-pairs the Gibbs sampler can be inconveniently slow, creating a computational bottleneck in applying a Bayesian approach. As the volume of data continues to grow and gene models are becoming more complex as more alternative transcripts are discovered, more efficient inference algorithms are required so that Bayesian methods can be used to provide practical computational tools. An alternative approach to Bayesian inference is to use deterministic approximate inference algorithms such as Variational Bayes (VB) (reviewed in<ref type="bibr" target="#b1">Bishop, 2006</ref>). While MCMC algorithms are attractive due to their asymptotic approximation guarantees, VB often provides a much faster method to obtain a good approximation to the posterior distribution. For models where Gibbs sampling can be applied there is typically a closely related VB Expectation Maximization (VBEM) algorithm. In this contribution, we show how VB can be used to massively speed up inference in the BitSeq model for transcript expression-level inference. We show that the mean transcript expression level estimates are very close to those obtained with MCMC. We use a recent formulation of VB (<ref type="bibr" target="#b6">Hensman et al., 2012</ref>) which is shown to provide a greater speed up when compared with a more standard VBEM algorithm. Our new algorithm is implemented in the most recent version of the BitSeq, allowing the method to be applied to much larger RNA-seq datasets in equal computing time. An alternative VB method, TIGAR, was recently proposed for the same problem using a standard VBEM algorithm (<ref type="bibr" target="#b16">Nariai et al., 2013</ref>). The assumptions made in our approximation are similar to those used in TIGAR, but the empirical comparisons herein show that our proposed method performs better in terms of computation time and required memory, while also providing improved accuracy on real and simulated data. The improvement in terms of reduced computational cost is due to our adoption of a novel VB method. Furthermore, we investigate the effects of the variational assumption in this problem, and compare empirically to results using the gold standard, MCMC. The article is organized as follows. In Section 2, we review the original BitSeq probabilistic model and describe our new inference algorithm, BitSeqVB, explaining the principles underlying our improved optimization scheme. In Section 3, we benchmark our new method against the original BitSeq algorithm and six popular alternative methods using realistic simulated data and real human RNA-Seq data. We consider accuracy in terms of expression estimation, relative with-gene transcript proportions and between-replicate consistency. We also compare the computation time required for all methods and compare the new VB algorithm to more standard MCMC and VBEM inference algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Our probabilistic model of RNA-seq follows Stage 1 of<ref type="bibr" target="#b5">Glaus et al. (2012)</ref>, and is similar to that used by RSEM. We summarize our notation in<ref type="figure" target="#tab_1">Table 1</ref>. The probabilistic model is shown using standard directed graphical notation in<ref type="figure" target="#fig_1">Figure 1</ref>. Here we have focused on themixture part of the analysis, assuming that the model which associates reads to transcripts [i.e. pðr n j T m Þ] is known. Following BitSeq (<ref type="bibr" target="#b5">Glaus et al., 2012</ref>), we compute this part of the model a priori, with parameters estimated from uniquely aligned reads. We consider RNA-seq assays independently, computing an approximate posterior for the transcript proportions h in each assay. Subsequent analysis such as differential expression can be done using the estimated distributions of each assay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The generative model</head><p>Transcript fragment proportions The generative model for an RNA-seq assay is as follows. We assume that the experiment produces of collection of RNA fragments, where the abundance of fragments derived from transcript T m in the assay is h m. Fragments are then sequenced in these proportions, so that the prior probability of any fragment corresponding to transcript T m is h m. Introducing a convenient allocation vector z n for each read, we can write</p><formula>pðZjhÞ ¼ Y N n¼1 Y M m¼1 h znm m ; (1)</formula><p>where z nm 2 f0; 1g is a binary variable which indicates whether the nth fragment came from the mth transcript (z nm ¼ 1) and is subject to P M m¼0 z nm ¼ 1. We use Z to represent the collection of all allocation vectors. We note that both h and Z are variables to be inferred, with h the main object of interest. h can be transformed later into some more convenient measure, for instance reads per kilobase of length per million sequenced reads (RPKM) (<ref type="bibr" target="#b15">Mortazavi et al., 2008</ref>), though it is more convenient from a probabilistic point of view to work with h directly. The variables Z are sometimes known in the machine learning literature as latent variables. Although not of interest directly, inference of these variables is essential to infer h.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read model</head><p>An important part of the model is the likelihood term pðr n jT m Þ which is the probability of generating the nth read from the mth transcript. Writing the collection of all reads as R ¼ fr n g N n¼1 , the likelihood given a set of alignments Z is</p><formula>pðRjT; ZÞ ¼ Y N n¼1 Y M m¼1 pðr n jT m Þ znm ; (2)</formula><p>where T m represents the mth transcript and T represents the transcriptome. The values of pðr n jT m Þ for all alignments can be computed before performing inference in h since we are assuming a known transcriptome. For paired-end reads, the mates originate from a single fragment and their likelihood is inferred jointly.where l is the length of a fragment, p is its position and seq mlp denotes the underlying reference sequence. The fragment length distribution can be pre-defined or inferred empirically. The position likelihood, Pðpjl; T m Þ, can be either uniform or account for different biases using an empirical model as in<ref type="bibr" target="#b5">Glaus et al. (2012)</ref>. The last term, Q i¼1;2 Pðr ðiÞ n jseq mlp Þ describes the probability of observed read sequences based on quality scores and base discrepancy between read and reference. For detailed description of the alignment likelihood estimation please refer to Glaus et al.</p><formula>(2012).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identifying noisy reads</head><p>Our model is similar to previous work (<ref type="bibr" target="#b5">Glaus et al., 2012</ref>), but does not contain a variable identifying reads as belonging to a 'noise' class. To circumvent the explicit formulation of a model with this variable, we introduce a 'noise transcript' which we append to the list of known transcripts. The generative probability of any read from this transcript, pðr n jT 0 Þ, is again calculated according to the model described in<ref type="bibr" target="#b5">Glaus et al. (2012)</ref>. Due to the conjugate relationships between the variables in our model and those of<ref type="bibr" target="#b5">Glaus et al. (2012)</ref>, the models are the same, subject to a slight reformulation of the prior parameters.</p><p>Prior over h The final part of our model is to specify some prior belief in the vector h. To make our approximations tractable, it is necessary to use a conjugate prior, which in this case is a Dirichlet distribution</p><formula>pðhÞ ¼ Cð^ a o Þ Y M m¼1 Cða o m Þ Y M m¼1 h a o m À1 m (4)</formula><p>where a o m represents our prior belief in the values of h m and ^ a o ¼ P M m¼1 a o m. We use a weak but proper prior a o m ¼ 1; m ¼ 0. .. M which corresponds to a single 'pseudo-count' read (or read-pair) for each transcript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Approximate inference</head><p>We are interested in computing the posterior distribution for the mixing proportions, pðh j R; TÞ / P Z pðR j T; ZÞpðZ j hÞpðhÞ. For very small datasets, it is possible to perform exact Bayesian inference in this model, however for any realistically sized problem, exact inference is impossible due to the combinatorial explosion of the number of possible solutions. Our proposed solution is to use a collapsed version of Variational Bayes (VB). VB involves approximating the posterior probability density of all the model parameters with another distribution q, qðh; ZÞ % pðh; ZjR; TÞ:</p><formula>(5)</formula><p>The approximation is optimized by minimising the Kullback-Leibler (KL) divergence between qðh; ZÞ and pðh; ZjR; TÞ (<ref type="bibr" target="#b1">Bishop, 2006</ref>). To make the VB approach tractable, some factorizations need to be assumed in the approximate posterior. In the case of the current<ref type="figure" target="#fig_1">1</ref>. Graphical model of the RNA-seq mixture problem. Given a known Transcriptome T and some observed reads R, the inference problem is for h through the latent variables Z</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast and accurate approximate inference of transcript expression</head><p>model, we assume that the posterior probability of the transcript proportions factorizes from the alignments: qðh; ZÞ ¼ qðhÞqðZÞ:</p><formula>(6)</formula><p>Further factorizations in qðZÞ occur due to the simplicity of the model, revealing qðZÞ ¼ Q N n¼1 qðz n Þ. We write the approximate distribution for qðZÞ using the parameters / nm :</p><formula>qðZÞ ¼ Y N n¼1 Y M m¼1 / znm nm : (7)</formula><p>We need not introduce parameters for qðhÞ since it will arise implicitly in our derivation in terms of /.</p><p>The objective function Approximate inference is performed by optimization: the parameters of the approximating distribution are changed so as to minimize the KL divergence. Whilst the KL divergence is not computable, it is possible to derive a lower bound on the marginal likelihood, maximization of which minimizes the KL divergence (see e.g.<ref type="bibr" target="#b1">Bishop, 2006</ref>). Here we derive a lower bound which is dependent only on the parameters of qðZÞ, with the optimal distribution for qðhÞ arising implicitly for any given qðZÞ. First we construct a lower bound on the conditional log probability of the reads R given the transcript proportions h and the known transcriptome T: ln pðRjT; hÞ ¼ ln ð pðRjZ; TÞpðZjhÞdZ !E qðZÞ ½ln pðRjZ; TÞ þ ln pðZjhÞ À ln qðZÞ</p><formula>¼ X N n¼1 X M m¼1 / nm ðln pðr n jT m Þ þ ln h m À ln / nm Þ ¼ L 1 ðhÞ;</formula><formula>(8)</formula><p>where the first line follows from Jensen's inequality in a similar fashion to standard VB methods. We have denoted this conditional bound L 1 ðhÞ, which is still a function of h. To generate a bound on the marginal likelihood, pðR j TÞ, we need to remove this dependence on h which we do in a Bayesian fashion, by substituting L 1 ðhÞ into the following Bayesian marginalization:</p><formula>pðRjTÞ ¼ ð pðRjT; hÞpðhÞd h ! ð expfL 1 ðhÞgpðhÞd h :</formula><formula>(9)</formula><p>Solving this integral and taking the logarithm gives us our final bound which equates to</p><formula>ln pðRjTÞ!L ¼ X N n¼1 X M m¼1 / nm ðln pðr n jT m Þ À ln / nm Þ þln Cð^ a o Þ À ln Cð^ a o þ NÞ À X M m¼1 ðln Cða o m Þ À ln Cða o m þ ^ / m ÞÞ;</formula><formula>(10)</formula><p>where ^ / m ¼ P N n¼1 / nm and we also have that the approximate posterior distribution for h is a Dirichlet distribution with parameters</p><formula>a o m þ ^ / m .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Optimization</head><p>Having established the objective function as a lower bound on the marginal likelihood, all that remains is to optimize the variables of the approximating distribution qðZ; hÞ. The dimensionality of this optimization is rather high and potentially rather difficult. Optimization in standard VB is usually performed by an EM like algorithm, which performs a series of convex optimizations in each of the factorized variables alternately. In our formulation of the problem, we only need to optimize the parameters of the distribution qðZÞ, which we do by a gradient-based method. Taking a derivative of (10) with respect to the parameters / gives</p><formula>@L @/ nm ¼ lnpðr n j T m Þ À ln/ nm À 1 þ wða o m þ ^ / m Þ; (11)</formula><p>where w is the digamma function. To avoid constrained optimization we re-parameterize / as c:</p><formula>/ nm ¼ e c nm X M m 0 ¼1 e c nm 0 (12)</formula><p>and it is then possible to optimize the variables c using a standard gradient-based optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Geometry</head><p>Information geometry concerns the interpretation of statistical objects in a geometric fashion. Specifically, a class of probability distributions behaves as a Riemannian manifold with curvature given by the Fisher information.<ref type="bibr" target="#b0">Amari (1998)</ref>showed that the direction of the steepest descent on such a manifold is given by the natural gradient:</p><p>~ rL ¼ G À1 rL ;</p><formula>(13)</formula><p>where G is the Fisher information matrix. Since we are performing optimization of the distribution qðZÞ, we can make use of the natural gradient in computing a search direction (<ref type="bibr" target="#b8">Honkela et al., 2010</ref>). For our problem, we assume that the N Â M matrix Z has been transformed into a NM vector, and the Fisher information corresponding to c nm , c n 0 m 0 is given by</p><formula>G½m; n; m 0 ; n 0  ¼ / nm À / 2 nm ; if n ¼ n 0 and m ¼ m 0 À/ nm / nm 0 ; if n ¼ n 0 but m 6 ¼ m 0 0; otherwise: 8 &gt; &gt; &lt; &gt; &gt; :</formula><formula>(14)</formula><p>We note that this structure is block-diagonal, and that each block can be easily inverted using the Sherman–Morrison identity, giving an analytical expression for G À1 rL, and thus making the natural gradient very fast to compute (see<ref type="bibr" target="#b7">Hensman et al. (2015)</ref>for more details). One can draw comparisons with a Newton method, where G would be replaced with a Hessian, though in the proposed case the system is much cheaper to compute. The optimization of the variational parameters then proceeds as follows. Following random initialization, a unit step is taken in the natural gradient direction. Subsequent steps are subject to conjugate gradients (<ref type="bibr" target="#b8">Honkela et al., 2010</ref>). If the conjugate gradient step should fail to improve the objective we revert to a VBEM update, which is guaranteed to improve the bound. For more details, see Hensman et al. (2012).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Truncation</head><p>The optimization described above has N Â M free parameters for optimization, one to align each read to each transcript. However, for most read-transcript pairs, pðr n j T m Þ will be negligibly small. We follow<ref type="bibr" target="#b5">Glaus et al. (2012)</ref>in truncating the values of pðr n j T m Þ to zero for reads which do not suitably align. Examining the objective function (10) we see that we can also set / nm to zero for these truncated alignments (using the convention that 0lnð0Þ ¼ 0) and thus also c nm ¼ À1 for the same. This truncation dramatically reduces the computational load of our algorithm, reducing the dimensionality of the optimization space as well as reducing the number of operations needed to compute the objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">The approximate posterior</head><p>Having fitted our model, we may wish to propagate the posterior distribution through a second set of processing, for example to identify differentially expressed transcripts as in BitSeq stage 2 (<ref type="bibr" target="#b5">Glaus et al., 2012</ref>). Whilst it may be desirable to solve both stages together in a Bayesian framework, the size of the problem generally forbids this, therefore we propose the use of either a moment-matching or sampling procedure to propagate qðhÞ through further analysis. The approximate posterior qðhÞ is a Dirichlet distribution, whose marginals have the following useful properties:</p><formula>E½h m  ¼ a o m þ ^ / m ^ a o þ N ; (15) var½h m  ¼ ða o m þ ^ / m Þð^ a o þ N À a o m À ^ / m ÞC; (16) cov½h m ; h m 0  ¼ Àða o m þ ^ / m Þða o m 0 þ ^ / m 0 ÞC; (17)</formula><p>with C ¼ ð^ a o þ NÞ À2 ð^ a o þ N þ 1Þ À1. This approximate posterior is somewhat inflexible, in that it cannot express arbitrary covariances between the transcripts. This arises from the factorizing assumption amongst the assignment of reads to transcripts: reads are assigned independently in the variational method and their dependence cannot be modelled. This is reflected in the results section where we show empirically that the VB approximation leads to an underestimation of the variance. Nonetheless, this simplifying assumption leads to very accurate expression estimates much faster than MCMC.For each scenario five replicates are generated according to a Negative Binomial model. Full details of the four scenarios are described in the Supplementary Material. Finally, the resulting reads-per-kilobase (RPK) values were fed into Spanki. Next, the simulated reads were aligned to the reference annotation using Bowtie2 and/or Tophat2. In particular, BitSeq, RSEM, eXpress and Tigar require transcriptomic alignments so Bowtie2 (version 2.0.6) (<ref type="bibr" target="#b12">Langmead and Salzberg, 2012</ref>) was used, while Cufflinks and Casper work with genomic alignments using Tophat2 and Bowtie2. On the other hand, Sailfish and Kallisto produce their own alignments using k-mers mapping and pseudo-alignments, respectively. The corresponding mapping rate for genomic or transcriptomic alignments was 96%. The same amount of reads pseudo-aligned when using Kallisto, whilst Sailfish mapped a smaller portion of k-mers (% 63%).<ref type="figure">Figure 2</ref>displays the mean absolute error (MAE) according to the three criteria, after performing the following normalization:</p><formula>X m2methods MAE ðcÞ m ¼ 1;</formula><p>8c 2 fTheta; WGE À Inter; WGE À Trueg, to make all criteria equally weighted for each scenario. Moreover, the 'Theta' and 'WGE-True' metrics were averaged across the five replicates, while 'WGE-Inter' was averaged across all ten combinations of pairs of replicates. The methods were ranked with respect to their average across the three criteria. RSEM-PME, BitSeqMCMC and BitSeqVB are ranked as best when considering all three criteria. RSEM has similar accuracy in terms of the ground truth expression (Theta</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast and accurate approximate inference of transcript expression</head><p>and WGE-True) but has lower inter-replicate consistency (WGEInter). Conversely, Casper achieves good performance with respect to inter-replicate consistency (WGE-Inter) but is less accurate in comparison to the ground truth values (WGE-True and Theta). The ranking of methods with respect to run-time is shown in<ref type="figure">Figure 3</ref>. Note that the run-time calculation excludes the alignment procedure, but includes all other computations (including computing alignment probabilities in BitSeq's case). An exception is made for Sailfish and Kallisto, where alignment is not required, making these by far the fastest methods. Timings which include the time required for alignment are provided in Supplementary<ref type="figure" target="#fig_1">Figure S12</ref>. The plots of inter-replicate consistency between pairs of replicates are shown in the supplementary material (Figs. 2, 4, 6 and 8). As seen there, Kallisto, RSEM, Sailfish, Tigar2, Cufflinks and eXpress, produce estimates close to the boundary of the parameter space. This is also obtained for RSEM-PME except for scenario 2. This behaviour is avoided when using BitSeqMCMC, BitSeqVB and Casper. The accuracy of BitSeqVB is very close to the two sampling methods BitSeqMCMC and RSEM-PME, but it is consistently faster that these approaches, being about 10 times faster than BitSeqMCMC and 2 times faster than RSEM-PME on average (RSEM-PME is significantly faster than BitSeqMCMC because is uses many fewer iterations of MCMC). BitSeqVB has similar speed to the Cufflinks method in most cases whilst exhibiting much better accuracy. We conclude that the proposed VB algorithm is competitive in speed while exhibiting both high accuracy and good inter-replicate consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Replicate consistency in human data</head><p>A recent study (<ref type="bibr" target="#b22">Rossell et al., 2014</ref>) used the mean absolute error between pairs of replicates of the same ENCODE experiment to assess the accuracy of transcript expression estimation methods. For this purpose, the relative within gene expression estimates are used (WGE-Inter). Here, we provide an extended version of this analysis to benchmark against BitSeqMCMC and six other methods. In total, five ENCODE datasets (<ref type="bibr" target="#b25">Tilgner et al., 2012</ref>) consisting of 2 Â 76 bp reads were selected, corresponding to the following pairs of replicates:Casper, we see that many methods produced estimates close to the boundary of the parameter space, as seen in<ref type="figure">Figure 5</ref>. This means that many transcripts are estimated as weakly or non-expressed in one replicate while being</p><formula>(SRR307897, SRR307898), (SRR307901, SRR307902), (SRR307907, SRR307908), (SRR307911, SRR307912), (</formula><formula>● ● ● ● ● ● ● ● ● ● 0.1 0.2 0.3 0.4</formula><p>Mean Absolute Errorhighly expressed in the other. This problem appears to affect methods using ML estimation (RSEM, Sailfish, Cufflinks, eXpress) or Bayesian methods using a very weak prior (Tigar2). Casper ensures consistency with a strong prior, but this may degrade the accuracy of absolute estimates relative to BitSeq because of stronger regularization. We note that Casper uses MAP parameter estimation, finding the mode of the posterior distribution, while the BitSeq methods estimate the mean of the posterior distribution. Using the posterior mean may avoid spurious values where the mode is a long way from the mass of the posterior without the need for an overly strong prior. Finally, note that the coherency of inter-replicate consistency estimates in our simulation study (Supplementary Figs S2, S4, S6 and S8) with the one reported here. The run-time for each method is displayed in<ref type="figure" target="#fig_3">Figure 4c</ref>. BitSeqVB is comparable to the fastest methods (except for Kallisto which is by far the fastest method) while being ranked as second in terms of the MAE criterion. We conclude that BitSeqVB offers perhaps the best trade-off in accuracy and runtime on these datasets. Finally, we mention that the BitSeqMCMC performance here is in stark contrast with the performance reported in<ref type="bibr" target="#b22">Rossell et al. (2014)</ref>. The reason for this is that in<ref type="bibr" target="#b22">Rossell et al. (2014)</ref>reads were aligned using Bowtie1 whereas we are using Bowtie2. As seen in<ref type="figure" target="#fig_3">Figure 4a</ref>, Bowtie1 can exhibit very low alignment rates for these samples. Interestingly, this behaviour is not present when Bowtie1 is combined with Tophat for genome mapping. The low alignment rates of Bowtie1 means that methods have available only a tiny fraction of the useful data, leading to less accurate results. This explains the weak agreement of same transcript estimates between pairs of replicates reported for BitSeq in<ref type="bibr" target="#b22">Rossell et al. (2014)</ref>and is a reminder that it is very important to check the alignment rates.<ref type="figure">Fig. 5</ref>. Scatterplots of within gene estimates for one pair of replicates (SRR307907 and SRR307908) from the ENCODE data. The blue color corresponds to a smoothed color density representation of the scatterplot</p><formula>● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><formula>● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●</formula><formula>2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><formula>2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><formula>2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><formula>2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 sailfish: MAE = 0.0519 replicate 1 replicate 2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><formula>2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><formula>2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 cufflinks: MAE = 0.0585 replicate 1 replicate 2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 eXpress: MAE = 0.071 replicate 1 replicate 2 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><p>Fast and accurate approximate inference of transcript expression</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of the variational Bayes approximation</head><p>To examine the properties of the variational approximation, we focused on ENCODE dataset SRR307907 (<ref type="bibr" target="#b25">Tilgner et al., 2012</ref>). This contained 30.8 million reads, each 76 bp. The reads were again mapped to the same UCSC/hg19 reference transcriptome resulting in 23.7 million mapped reads. Our main potential concern in using the VB method is the quality of approximation to the posterior.<ref type="figure" target="#fig_11">Figure 6a</ref>shows a comparison of the variational posterior with a ground truth computed by MCMC with a very large sampling time. We conclude that the VB method consistently provides very accurate estimates of the posterior mean across the whole range of expression levels. The estimates of posterior variance are less consistent and for a fraction of transcripts the variances are underestimated (<ref type="figure" target="#fig_11">Fig. 6b</ref>). It appears that VB only estimates the Poisson variance associated with random sampling of reads (<ref type="figure" target="#fig_11">Fig. 6d</ref>), whereas the true posterior variance is larger for some transcripts due to the uncertainty in assigning multimapping reads (<ref type="figure" target="#fig_11">Fig. 6c</ref>). If estimation of the expression level is all that is required, then it would seem that the VB method suffices. However, downstream methods which make use of uncertainty in the transcript quantification [such as the differential expression analysis proposed in BitSeq stage 2 (<ref type="bibr" target="#b5">Glaus et al., 2012)]</ref>may suffer from the poor approximation in terms of posterior variance. This can potentially be addressed by augmenting the VB method with a more accurate approximation as done in a recent study that proposed a new VB algorithm with improved variance estimates and a tighter lower bound on the log-marginal likelihood (<ref type="bibr" target="#b18">Papastamoulis et al., 2014a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Convergence comparison</head><p>We further investigate convergence properties of MCMC and VB in terms of mean expression. RNA-seq data was obtained from ENCODE experiment SRX110318, run SRR387661, generating 124.8 million 76 bp read-pairs. We mapped the reads using Bowtie 2 to a reference transcriptome using 8713 transcripts of chromosome 19 from Ensembl human cDNA, release 70 (<ref type="bibr" target="#b3">Flicek et al., 2013</ref>). As the true expression levels are unknown, we used a long run of MCMC as the ground truth for mean expression estimates. Running the inference methods for a certain number of iterations, we record the run time and calculate Root Mean Square Error (RMSE) of estimated expression. The convergence of our variational method (BitSeqVB) and the original Gibbs sampling procedure (BitSeqMCMC) is shown in<ref type="figure" target="#fig_10">Figure 7</ref>. We also include a standard implementation of VB (similar to<ref type="bibr" target="#b16">Nariai et al. (2013)</ref>) but using the BitSeq model (denoted VBEM). It is straightforward to derive this algorithm from our VB algorithm derivation since standard VBEM is obtained as a special case of steepest descent VB learning (<ref type="bibr" target="#b6">Hensman et al., 2012</ref>). Our implementation of VB converges first in about 2 min. Surprisingly, some runs of collapsed MCMC converge to better estimates even faster than standard VB, which takes around 10 min. However, as MCMC is a stochastic method, an estimate that is consistently better than the results obtain by VB is only obtained after 900 min.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.</head><figDesc>Fig. 1. Graphical model of the RNA-seq mixture problem. Given a known Transcriptome T and some observed reads R, the inference problem is for h through the latent variables Z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1.</head><figDesc>estimated expression levels from real data using BitSeqMCMC (% 56 million reads per replicate) 2. randomly selected expression levels according to a uniform distribution defined on the set (10, 200) (% 7:8 million reads per replicate) 3. a high-dimensional mixture of Poisson Generalized Linear models, which was recently used to model the heterogeneity in RNAseq datasets (Papastamoulis et al., 2014b) (% 5:5 million reads per replicate) 4. estimated expression levels from real data using RSEM (% 18 million reads per replicate)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>SRR307915, SRR307916). All methods were applied assuming the same UCSC/hg19 transcriptome annotation as in the previous section. According to the alignment rates shown in Figure 4a, all methods work with almost the same number of mapped reads when Bowtie2 is used. This is not the case for Bowtie1 which for some reason fails on this dataset. Figure 4b illustrates the ranking of methods in terms of the MAE criterion, averaged across the five datasets. We conclude that BitSeqMCMC has best inter-replicate consistency, closely followed by BitSeqVB, while Casper comes next. Sailfish, RSEM, Tigar2 and Cufflinks exhibit almost two times larger MAE, while eXpress is almost 2.5 times worse according to this measure. Based on these five samples there is a partial order: BitSeqMCMC 1 BitSeqVB 1 fCasper; Kallistog 1 RSEM À PME 1 fRSEM; Sailfishg 1 fCufflinks; Tigar2g 1 eXpress, where 1 denotes 'is better in every experiment'. Excluding BitSeq (MCMC and VB) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. Five ENCODE pairs of replicates. (a) Alignment rates for transcriptome mapping (Bowtie1 and Bowtie2), genome mapping (Tophat 2.0.9 with Bowtie1 and Bowtie2), k-mers mapping (Sailfish) and pseudo-alignments (Kallisto). (b) Ranking of methods in terms of the Mean Absolute Error. (c) Run-time in hours (logscale) with 24.6 M (mapped) reads per sample</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><figDesc>● 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 rsem: MAE = 0.0534 replicate 1 replicate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><figDesc>● 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 tigar2: MAE = 0.0566 replicate 1 replicate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.7.</head><figDesc>Fig. 7. Convergence comparison of Collapsed MCMC with standard VB algorithm and VB with Fletcher-Reeves conjugate gradient optimization. Expression estimates obtained by very long run of MCMC are used as a ground truth and average root mean square error over 10 runs was calculated, two standard deviations are used as error bars. The VB methods with several randomized initial conditions showed negligible differences in convergence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig.6.</head><figDesc>Fig. 6. A comparison of the first two moments of the approximate posterior expression in counts per transcript: (a) posterior mean (R 2 correlation is 0.999) (b) posterior standard deviation: the VB method significantly underestimates the posterior variance (r 2 ). (c), (d) posterior mean-variance relationship in MCMC and VB respectively. Shading represents the number of transcripts in each region</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1.</figDesc><table>Summary of notations 

N 
Number of reads in the dataset 
M 
Number of transcripts in the transcriptome 
r n 
The nth read 
R 
The collection of reads 
T 
The transcriptome 
T m 
The mth transcript 
h m 
Proportion of transcript T m in the sample 
z nm 
Binary: z nm ¼ 1 if read n comes from transcript m 
z n 
Allocation vector of the nth read 
Z 
Collection of all allocation vectors 
/ nm 
Approximate posterior probability of z nm ¼ 1 
c nm 
Re-parameterization of / nm </table></figure>

			<note place="foot">J.Hensman et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3"> Results and discussion The proposed BitSeqVB algorithm was compared with Cufflinks (Trapnell et al., 2010), RSEM as well as the corresponding MCMC sampler RSEM-PME (Li and Dewey, 2011), BitSeqMCMC (Glaus et al., 2012), eXpress (Roberts and Pachter, 2013), Casper (Rossell et al., 2014), Sailfish (Patro et al., 2014), Tigar2 (Nariai et al., 2014) and Kallisto (Bray et al., 2015). We note that both MCMC samplers (RSEM-PME and BitSeqMCMC) use similar collapsed Gibbs algorithms but are initialized differently: RSEM-PME starts from the ML solution found by RSEM while BitSeqMCMC starts from a random initialization and therefore requires more iterations to find a good solution. We used two main ways for benchmarking: analysis on synthetic data allowed comparison with a known ground truth under a variety of generative scenarios; analysis on high-quality replicated human data focused on inter-replicate consistency following the evaluation of Rossell et al. (2014). We find BitSeqVB to have excellent inter-replicate consistency and accuracy, closely approximating the original MCMC algorithm, while also being competitive with other methods in terms of run-time. We subsequently analyze in more detail the approximation to the posterior used in the BitSeqVB method. For comparison with other methods, we used default settings where appropriate: both MCMC sampling methods use 1000 posterior samples as default. However, this number refers to effective samples (Gelman et al., 2003) in BitSeqMCMC and not to single iterations as in RSEM-PME. We turned off creating of unnecessary output files in RSEM. The experiments were conducted on a four core workstation. All the details of the experiments can be found at the aforementioned URL. 3.1 Inference accuracy on synthetic data RNA-seq reads from M ¼ 48 009 transcripts of the UCSC/hg19 transcriptome annotation (Kent et al., 2002) were simulated using the Spanki software (Sturgill et al., 2013). The expression is evaluated in three different measures: transcript expression accuracy (Theta), transcript within-gene relative proportion accuracy (WGE-True) and inter-replicate consistency (WGE-Inter). The first two measures (Theta and WGE-TRUE) compare the resulting estimates against the ground-truth. On the other hand, WGE-Inter compares the consistency of within-gene estimates across independent repetitions of the same experiment. This implies that an algorithm yielding constant estimates independent of any data could achieve WGE-Inter ¼ 0, but it would obviously do very poorly on WGE-True. Thus, a good score on WGE-Inter is necessary but not sufficient for a method to perform well in practice. For further details of the evaluation measures see supplementary material (Section 5). A ground truth was generated using four different models of transcript expression, according to the following scenarios:</note>

			<note place="foot" n="4"> Conclusion We have presented a new Variational Bayes method for inference of transcript expression from RNA-seq data. Building on previous work in BitSeq, we have presented a fast approximate inference method. The mean of the posterior distribution of expression levels was very well estimated in substantially less time than the original MCMC algorithm. The method is therefore suitable when point estimates of expression are sufficient, especially if time and computational resources are limited. We have compared both the original BitSeq algorithm and our new method with the majority of available methods for transcript expression estimation and conclude that BitSeqVB is highly competitive both in terms of expression estimation and run-time. We also note that an existing VBEM algorithm implementation, TIGAR, does not provide a significant improvement over Gibbs sampling in terms of computational time in our examples, as well as having a very high memory requirement. The newest method considered here, Kallisto, is found to be extremely fast and perform with very good accuracy compared with other ML approaches. This speed-up is achieved through avoiding full alignment and simplifying the likelihood computation through using a pseudo-alignment approach. However, the method still produces estimates at the boundary in our between-replicate comparisons similar to all ML methods. It would therefore be very interesting to apply a Bayesian algorithm, such as the fast VB method proposed here, using the same likelihood model as Kallisto. Finally, we suggest some areas for future development. The fast and consistent convergence of the VB method makes it useful for quick examination of the data before the Gibbs sampler is run. Further, since it provides an excellent approximation to the mean</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank three anonymous reviewers for useful comments which have greatly improved the article and Lior Pachter for his blog comments on a preliminary version of this article which led us to include more realistic data simulation scenarios.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Natural gradient works efficiently in learning</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Amari</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="251" to="276" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title level="m" type="main">Pattern Recognition and Machine Learning</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Near-optimal RNA-Seq quantification. arXiv (q-bio</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Bray</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">QM)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Flicek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="48" to="55" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian Data Analysis</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gelman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Texts in Statistical Science</title>
		<meeting><address><addrLine>Florida, US</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press LLC</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>2nd. edn. Chapman &amp; Hall</note>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying differentially expressed transcripts from RNA-seq data with biological variation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Glaus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1721" to="1728" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast variational inference in the conjugate exponential family</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hensman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst. (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast nonparametric clustering of structured timeseries</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hensman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="383" to="393" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Approximate Riemannian conjugate gradient learning for fixed-form variational Bayes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Honkela</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3235" to="3268" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistical inferences for isoform expression in RNA-seq</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">H</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1026" to="1032" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Analysis and design of RNA sequencing experiments for identifying isoform regulation</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Katz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1009" to="1015" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">The human genome browser at UCSC</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Kent</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="996" to="1006" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast gapped-read alignment with Bowtie 2</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Langmead</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Salzberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="357" to="359" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">RSEM: accurate transcript quantification from RNA-Seq data with or without a reference genome</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">N</forename>
				<surname>Dewey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">323</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">RNA-Seq gene expression estimation with read mapping uncertainty</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="493" to="500" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Mapping and quantifying mammalian transcriptomes by RNA-Seq</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mortazavi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="621" to="628" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">TIGAR: transcript isoform abundance estimation method with gapped alignment of RNA-Seq data by variational Bayesian inference</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Nariai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2292" to="2299" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">TIGAR2: sensitive and accurate estimation of transcript isoform expression with longer RNA-Seq reads</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Nariai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved variational Bayes inference for transcript expression estimation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Papastamoulis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="203" to="216" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">On the estimation of mixtures of Poisson regression models with large number of components</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Papastamoulis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="97" to="106" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Sailfish enables alignment-free isoform quantification from RNA-seq reads using lightweight algorithms</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Patro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="462" to="464" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Streaming fragment assignment for realtime analysis of sequencing experiments</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Roberts</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Pachter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="71" to="73" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Quantifying alternative splicing from paired-end RNA-sequencing data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rossell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="309" to="330" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A comprehensive assessment of RNAseq accuracy, reproducibility and information content by the sequencing quality control consortium</title>
		<author>
			<persName>
				<forename type="first">Seqc / Maqc-Iii</forename>
				<surname>Consortium</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="903" to="914" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Design of RNA splicing analysis null models for post hoc filtering of Drosophila head RNA-Seq data with the splicing analysis kit (Spanki)</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sturgill</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">320</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep sequencing of subcellular RNA fractions shows splicing to be predominantly co-transcriptional in the human genome but inefficient for lncRNAs</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Tilgner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1616" to="1625" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Transcript assembly and quantification by RNA-Seq reveals unannotated transcripts and isoform switching during cell differentiation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Trapnell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="516" to="520" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Differential analysis of gene regulation at transcript resolution with RNA-seq</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Trapnell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Haplotype and isoform specific expression estimation using multi-mapping RNA-seq reads</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Turro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">An expectation-maximization algorithm for probabilistic reconstructions of full-length isoforms from splice graphs</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Xing</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3150" to="3160" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<monogr>
		<title level="m" type="main">Fast and accurate approximate inference of transcript expression</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>