
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Quantifying the distribution of probes between subcellular locations using unsupervised pattern unmixing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Luis</forename>
								<forename type="middle">Pedro</forename>
								<surname>Coelho</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Center for Computational Biology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Bioimage informatics</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Joint Carnegie</orgName>
								<orgName type="institution">Mellon University–University of Pittsburgh Ph.D. Program in Computational Biology</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tao</forename>
								<surname>Peng</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Bioimage informatics</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Biomedical Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Robert</forename>
								<forename type="middle">F</forename>
								<surname>Murphy</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Center for Computational Biology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Bioimage informatics</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Joint Carnegie</orgName>
								<orgName type="institution">Mellon University–University of Pittsburgh Ph.D. Program in Computational Biology</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Biomedical Engineering</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Biological Sciences</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Machine Learning</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="institution" key="instit1">Freiburg Institute for Advanced Studies</orgName>
								<orgName type="institution" key="instit2">Albert Ludwig University of Freiburg</orgName>
								<address>
									<postCode>79104</postCode>
									<settlement>Freiburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Quantifying the distribution of probes between subcellular locations using unsupervised pattern unmixing</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="7" to="12"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq220</idno>
					<note>[10:41 12/5/2010 Bioinformatics-btq220.tex] Page: i7 i7–i12 BIOINFORMATICS Availability: http://murphylab.web.cmu.edu/software Contact: murphy@cmu.edu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Proteins exhibit complex subcellular distributions, which may include localizing in more than one organelle and varying in location depending on the cell physiology. Estimating the amount of protein distributed in each subcellular location is essential for quantitative understanding and modeling of protein dynamics and how they affect cell behaviors. We have previously described automated methods using fluorescent microscope images to determine the fractions of protein fluorescence in various subcellular locations when the basic locations in which a protein can be present are known. As this set of basic locations may be unknown (especially for studies on a proteome-wide scale), we here describe unsupervised methods to identify the fundamental patterns from images of mixed patterns and estimate the fractional composition of them. Methods: We developed two approaches to the problem, both based on identifying types of objects present in images and representing patterns by frequencies of those object types. One is a basis pursuit method (which is based on a linear mixture model), and the other is based on latent Dirichlet allocation (LDA). For testing both approaches, we used images previously acquired for testing supervised unmixing methods. These images were of cells labeled with various combinations of two organelle-specific probes that had the same fluorescent properties to simulate mixed patterns of subcellular location. Results: We achieved 0.80 and 0.91 correlation between estimated and underlying fractions of the two probes (fundamental patterns) with basis pursuit and LDA approaches, respectively, indicating that our methods can unmix the complex subcellular distribution with reasonably high accuracy.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To investigate the subcellular localization of proteins at a proteomewide scale, we need to be able to characterize all observed patterns. Identification of subcellular localization patterns from fluorescence images using supervised machine learning methods has become an established method, with excellent results in its field of application. * To whom correspondence should be addressed. † The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors.</p><p>However, this method is, by design, limited to hard assignments to classes predefined by the researcher. Some researchers have explored using unsupervised learning technologies (<ref type="bibr" target="#b7">García Osuna et al., 2007;</ref><ref type="bibr" target="#b8">Hamilton et al., 2009</ref>), which do not require the researcher to specify classes. These methods still result in each protein being assigned a single label. However, not all proteins can be thus characterized. In particular, there are many proteins that exhibit 'mixed patterns', i.e. patterns that are composed of more than one location. For example, while some proteins locate in the nucleus and others locate in the endoplasmic reticulum, there is a third group that locates in both of these locations. A simple class assignment does not adequately represent the relationship between these three possibilities. One alternative is to assign multiple labels to a single pattern. In one large-scale study of the yeast proteome, a third of proteins were annotated with multiple locations, which demonstrates that this is not a problem confined to 'special case' proteins (<ref type="bibr" target="#b4">Chen et al., 2007;</ref><ref type="bibr" target="#b10">Huh et al., 2003</ref>). However, this approach fails to quantify the contribution of each element and shows the need for a system that directly models the mixture phenomenon. We have previously presented some methods that address this pattern unmixing problem in a supervised setting: given images of fundamental patterns (e.g. nuclear and endoplasmic reticulum in the above example) and mixed images, map mixed images into a set of coefficients, one for each fundamental pattern (<ref type="bibr" target="#b13">Peng et al., 2010;</ref><ref type="bibr" target="#b16">Zhao et al., 2005</ref>). These methods were observed to perform well on both synthetic and real data in recovering the underlying mixture coefficients (which had been kept hidden from the algorithm). However, the supervised approach still requires the researcher to specify the fundamental patterns of which other patterns are composed. For example, for the quantitative analysis of translocation experiments as a function of time or drug concentration, the extreme points could be easily identified as the patterns of interest. However, they are still inapplicable to proteome-wide studies where it would be a difficult (and perhaps impossible) task to identify all fundamental patterns that are present. We note that the set of fundamental patterns that can be identified depends both on the specific cell type and the technology used for imaging, highresolution confocal microscopes being able to distinguish patterns that lower resolution systems cannot. Therefore, it is necessary to tackle the unsupervised pattern unmixing problem: given a large collection of images, where none has been tagged as being a representative of a fundamental pattern, map all images into a set of mixture coefficients automatically derived from the data.(a) The algorithms use a collection of images as input in which various concentrations of two probes are present (the concentrations of the Mitotracker and Lysotracker probes are shown by increasing intensity of red and green, respectively). Example images are shown from wells containing only Mitotracker (b), only Lysotracker (c) and a mixture of the two probes (d).In this article, we present and compare methods to address this problem using a test dataset previously created to test supervised unmixing methods (<ref type="bibr" target="#b13">Peng et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.P.Coelho et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Object typing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Overview</head><p>All the methods developed for this problem so far are based on a bag of objects model, where an image is interpreted as a collection of regions of above-background fluorescence. Each object is then characterized by a small set of object features, and objects are clustered into groups (object types). Patterns are then defined as distributions over these groups. This is illustrated in<ref type="figure" target="#fig_0">Figure 1</ref>. The intuition is to capture patterns such as the fact that lysosomes are small mostly circular objects, while mitochondria consist of stringy objects. The methods need to be robust to stochastic variation, however, as mitochondrial patterns are also observed to contain circular objects and agglomerations of lysosomes may appear as a single stringy object. In fact, the algorithms need to capture not only the fact that mitochondrial patterns are composed of stringy objects, but also that the proportions of different types of objects are present in statistically different proportions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Image preprocessing and segmentation</head><p>Images are first preprocessed to remove uneven illumination. The illumination bias is estimated by fitting a plane to the average pixel intensity at each location across the whole collection of images. Every image pixel is then divided by this illumination estimate to regularize across the whole image. Images are segmented by using the model-based method of<ref type="bibr" target="#b12">Lin et al. (2003)</ref>on the nuclear channel, which was previously found to give the best results for images in the unmixing test dataset (<ref type="bibr" target="#b5">Coelho et al., 2009</ref>). The segmentation is extended to the whole field by using the watershed method with the segmented nuclei as seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Object detection</head><p>In our previous supervised unmixing work, objects were simply defined as contiguous pixel regions above a global threshold. In the work described here, we use both a global threshold, using the Ridler– Calvard method (<ref type="bibr" target="#b15">Ridler and Calvard, 1978</ref>), and a local threshold, the mean pixel value of a 15×15 window centered at the pixel. We have found that the global threshold achieves a good separation of the general cell areas from the background, while, inside those regions, local thresholding is better at capturing detail. Objects that are smaller than 5 pixels are filtered out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Object features</head><p>Each object is characterized by a set of features, previously defined as SOF1 (subcellular object features 1). This is a combination of morphological features for describing the shape and size of the object and features which capture the relationship to the nuclear marker (<ref type="bibr" target="#b16">Zhao et al., 2005</ref>):</p><p>(1) Size (in pixels) of the object.</p><p>(2) Distance of object center of fluorescence to DNA center of fluorescence.</p><p>(3) Fraction of object that overlaps with DNA.</p><p>(4) Eccentricity of object hull.</p><p>(5) Euler number of object.Page: i9 i7–i12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i8</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantifying the distribution of probes</head><p>(6) Shape factor of convex hull.</p><p>(7) Size of object skeleton.</p><p>(8) Fraction of overlap between object convex hull and object.</p><p>(9) Fraction of binary object that is skeleton.</p><p>(10) Fraction of fluorescence contained in skeleton.</p><p>(11) Fraction of binary object that constitutes branch points in the skeleton.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">Object clustering</head><p>In order to be able to reason about object types, objects are clustered into groups using k-means on the z-scored feature space. Multiple values of k are tried and the one resulting in the lowest BIC (Bayesian information criterion) score is selected. Based on this clustering, each object can be assigned a numerical identifier, its cluster index, which serves as its type. After this step, the algorithms diverge in how they handle the cluster indices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Basis pursuit</head><p>In this model, each image is represented by a vector xrepresents the fraction of objects in condition i that have type (if there are multiple images for the same condition, a common situation, they are counted together). We have one vector per input condition (i.e. i = 1,...,C, where C is the number of conditions), and the size of this vector is the number of clusters that was automatically identified in the clustering step (i.e. = 1,...,k).</p><formula>x (i) = j b (j) α (i) j +ε (i) ,</formula><formula>(1)</formula><p>where ε (i) encapsulates both the stochastic nature of the mixing process and the measurement noise. Given a set of observations, the task is to identify the bases bWithout additional constraints, principal component analysis (PCA) is the simplest solution to this problem. However, this is unsatisfactory as it could result in negative mixtures, which are not meaningful. Independent component analysis (ICA) suffers from the same problem. Therefore, we add a non-negativity constraint on the vector α and use non-negative matrix factorization (NNMF) possibly with sparsity constraints to solve the problem (<ref type="bibr" target="#b9">Hoyer et al., 2004;</ref><ref type="bibr" target="#b11">Lee and Seung, 1999</ref>). An additional constraint can be helpful to obtain more meaningful results: require the basis vectors to be members of the input dataset (i.e. for all j, there is some i, such that b</p><formula>(j) = x (i)</formula><p>). This condition, which encapsulates the expectation that the input dataset is large enough to contain both fundamental and mixed patterns, requires a search method. Some preliminary results showed that this model was still too sensitive to the trend, i.e. to the average value of x i,j across the dataset (data not shown). If one basis vector was allocated to handle this trend, good fits were obtained but poor interpretability. We found that removing the mean from the data led to more meaningful results. In this detrended dataset, ˆ x</p><p>(i) j may take negative values, but the mixing coefficients α i,j are still constrained to be non-negative. Thus, the final optimization problem is:</p><formula>min b (j) ,α ||ε (i) || 2 (2) ˆ x (i) = x (i) − ¯ x (3) ε (i) = ˆ x (i) − j b (j) α</formula><p>(i) j</p><formula>(4)</formula><p>Subject to the constraint, that for all j, there exists an i, such that b (j) = x (i). In order to find the best basis, we resort to simulated annealing as an optimization method. In this class of methods, the number of fundamental patterns B must be prespecified by the user. PCA and ICA were also performed on detrended data, but NNMF could not be (as the detrended data contains negative numbers, it cannot be the product of two positive matrices). Before applying NNMF, we therefore removed very frequent objects (those that appeared in more than 90% of the images). The intuition is that very frequent objects also correspond to the background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Latent Dirichlet allocation</head><p>Topic modeling in text using latent Dirichlet allocation (LDA) is a popular technique to solve an analogous class of problems (<ref type="bibr" target="#b3">Blei et al., 2003</ref>). In this framework, documents are seen as simple 'bags of words' and topics are distributions over words. Observed bags of words can be generated by choosing mixture coefficients for topics followed by a generation of words according to: pick a topic from which to generate, then pick a word from that topic. In our setting, we view object classes as visual words over which to run LDA. This is similar to work by other researchers in computer vision which use keypoints to define visual words (<ref type="bibr" target="#b6">Csurka et al., 2004;</ref><ref type="bibr" target="#b14">Philbin et al., 2008;</ref><ref type="bibr" target="#b17">Zhu et al., 2009</ref>). The process of generating objects in images to represent mixtures of multiple fundamental patterns follows the Bayesian network in<ref type="figure" target="#fig_5">Figure 2</ref>. The generative process is as follows: for each of M images, a mixture θ i is first sampled (conditioned on the hyper-parameter α). θ i is a vector of fractions of the fundamental pattern distributions b. N i objects are sampled for each image in two steps: select a basis pattern according to θ i and then an object is sampled from the corresponding object type distribution. To invert this generative process, we used the variational EM algorithm of<ref type="bibr" target="#b3">Blei et al. (2003)</ref>to estimate the model parameters of fundamental patterns β and mixture fractions θ. It should be noted that this is an approximation approach liable to getting trapped in local maxima and returning non-optimal results. Therefore, we ran the algorithm multiple times with different random initializations and chose the one with the highest log-likelihood. We choose the number of fundamental patterns B to maximize the log likelihood on a held-out dataset (using cross-validation to obtain more accurate estimate).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i9</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.P.Coelho et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>In order to validate the algorithms, we used a test set that was built to evaluate pattern unmixing algorithms (<ref type="bibr" target="#b13">Peng et al., 2010</ref>). In this dataset, u2os cells were exposed to different concentrations of two fluorescent probes with differing localization profiles (mitochondrial and lysosomal) but similar fluorescence. The probes were image using the same fluorescence filter and therefore could not be distinguished. This simulates the situation in which a fluorophore is present in two different locations. For each probe, eight concentrations were used, for a total of 64 combinations. In parallel to the marker image, a nuclear marker was imaged to serve as a reference point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Computation time</head><p>Most of the computation time is dominated by segmenting the images (∼30 s per image in our implementation) and computing features (∼10 s per image). However, this is an embarrassingly parallel problem and can be computed on multiple machines simultaneously. The clustering takes increasing time for different numbers of clusters, but we limited each clustering run to ∼1 h (while relying on multiple initialization as a guard against local minima). Again, we note that the runs for multiple k can easily be run in parallel. Both basis pursuit and LDA then take only on the order of minutes to run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Basis pursuit</head><p>We measured how well the identified coefficients α</p><p>(i) j correlated with the underlying fractions, which were estimated as linearly proportional to the ratio of the relative concentration of the mitochondrial probe to the sum of the relative concentration of the mitochondrial and lysosomal probes (relative concentration is defined as fraction of the maximum subsaturating concentration). Using PCA, the correlation coefficient between predicted fractions and the underlying relative concentrations was 0.20. NNMF performed better on this metric, achieving a correlation coefficient of 0.65. Independent component analysis performed very poorly, returning correlations on the order of less than 0.10. This is not unexpected as the independence assumptions that underly ICA fail to hold even as an approximation. However, we are also interested in having the basis vectors line up with the underlying fundamental patterns and, in this regard, NNMF performs poorly. One of the patterns corresponded roughly to the total concentration and they did not align well with the fundamental patterns in the data (data not shown). The fully constrained basis pursuit algorithm performed better. It achieved a 0.80 correlation with the underlying relative concentration. It identified as a basis a vector that has the maximal concentration of the mitochondrial probe (and some lysosomal probe, at a relative concentration of 19%) and another that consists of the maximal concentration of the lysosomal probe and 20% mitochondrial probe.<ref type="figure" target="#tab_1">Table 1</ref>shows that the identified pattern 0 matches the mitochondrial probe, while pattern 1 matches the lysosomal probe. The results above were obtained by specifying B = 2 as an input to the algorithm. For different values of B, we obtain decreasing reconstruction error as plotted in<ref type="figure" target="#fig_7">Figure 3</ref>. As it is clear in this figure,For the two fundamental patterns, we display the average coefficient for the inferred fundamental patterns.most of the contribution to the reconstruction comes from the first two or three vectors. Therefore, we can expect that a researcher would be able to estimate B = 2 or B = 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">LDA</head><p>To estimate the number of fundamental patterns using the LDA approach, we measured the log likelihood of the dataset for different numbers of bases using cross-validation. The results are shown in<ref type="figure" target="#fig_9">Figure 4</ref>. We can see that the best result is obtained for B = 3, although the underlying dataset only has two fundamental patterns.<ref type="figure">Table 2</ref>shows the average coefficients inferred for pure pattern inputs after the algorithm had been applied on the whole dataset. Pattern 1 obviously corresponds to the lysosomal component, while pattern 2 corresponds to the mitochondrial component. Pattern 0 appears to be a 'non-significant' pattern capturing the new object types arising in the mixture patterns. The overall correlation coefficient is 0.95 with pattern 0 removed. Using the LDA approach with B = 2, which is the ground truth, the overall correlation coefficient between estimated and actual pattern fractions was found to be 0.91.<ref type="figure">Figure 5</ref>shows the results of one inferred fraction as a function of the underlying concentrations (the plots for the other fraction, not shown, are, of course, symmetric as they sum to 1).<ref type="figure" target="#fig_11">Figure 6</ref>plots all the estimates in a single plot as a function of the underlying concentration fractions. i10Page: i11 i7–i12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Comparisons</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantifying the distribution of probes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>We have described two approaches for performing unsupervised unmixing of subcellular location patterns, and demonstrated good performance with both on a test dataset acquired by high-throughput microscopy and previously used for testing supervised methods. In our supervised work, we had presented two methods, one based on a linear mixture, whose adaptation to the unsupervised case results in the basis pursuit method described here, and another based on multinomial mixtures, which results in the LDA model. The newer LDA model led to slightly better results than the basis pursuit method. This model has the apparent disadvantage that it does not return examples of the underlying patterns, which couldFor the two fundamental patterns, we display the average coefficient for the three discovered fundamental patterns. potentially make interpretation harder. However, we observed that this was, empirically, not a major issue as the identified bases were indeed well aligned with the underlying (hidden) concentrations as opposed to forming a complex mixture with a difficult interpretation. The methods are comparable in terms of computational cost as it is the image processing, feature computation and, particularly, the k-means clustering that has the highest cost (the clustering is done over objects and even this evaluation set of ∼12 K images resulted in ∼750 K objects). Once the clustering is done, both algorithms are very fast. Therefore, in their current forms, the LDA algorithm is superior. It is notable that both unsupervised methods led to higher correlation with the underlying coefficients than the supervised methods. A possible cause of this is the appearance of new object types in the mixture patterns. Under the unsupervised framework, with massive clustering, these objects might be assigned labels different from the ones of the fundamental patterns, while in the<ref type="figure">Fig. 5</ref>. Comparison of results for different unmixing methods. The inferred fraction of pattern 1 is displayed as different intensities of gray (black corresponding to pure pattern 1). The design matrix, which was kept hidden from the algorithms is shown on the top left, for comparison; the other three panels are results of computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.P.Coelho et al.</head><p>supervised version they are forced to be one of the object types present in the fundamental patterns. To prove this conjecture, we assumed that such new types of objects really exist and applied the outlier removal technique of<ref type="bibr" target="#b13">Peng et al. (2010)</ref>to perform supervised unmixing again, in the hope of removing the influence of these objects. The correlations increased to 0.91 and 0.88 with linear and multinomial unmixing approaches, respectively, which are comparable with the unsupervised results. Based on the results presented here, we plan to apply the unsupervised unmixing methods to large-scale image collections with the goal of identifying both the set of all fundamental patterns and of quantitating for the first time the fraction of all proteins that are present in each.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Overview of unmixing methods. (a) The algorithms use a collection of images as input in which various concentrations of two probes are present (the concentrations of the Mitotracker and Lysotracker probes are shown by increasing intensity of red and green, respectively). Example images are shown from wells containing only Mitotracker (b), only Lysotracker (c) and a mixture of the two probes (d). (e) Objects with different size and shapes are extracted and object features are calculated. (f) Objects are clustered into groups in feature space, shown with different colors. (g) Fundamental patterns are identified and the fractions they contribute to each image are estimated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Fig. 1. Overview of unmixing methods. (a) The algorithms use a collection of images as input in which various concentrations of two probes are present (the concentrations of the Mitotracker and Lysotracker probes are shown by increasing intensity of red and green, respectively). Example images are shown from wells containing only Mitotracker (b), only Lysotracker (c) and a mixture of the two probes (d). (e) Objects with different size and shapes are extracted and object features are calculated. (f) Objects are clustered into groups in feature space, shown with different colors. (g) Fundamental patterns are identified and the fractions they contribute to each image are estimated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>(i) such that entry x (i)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Using fractions instead of the direct object counts normalizes for the different number of cells in each image and different cell sizes. In this model, bases (fundamental patterns) are represented as a set of vectors in the same space and a mixture is defined by a set of coefficients α j for each b (j) (j = 1,...,B, where B is the number of basis vectors, and each b (j) is of the same dimension as the x (i) s):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>(j) and coefficients α (i) , which minimize the squared norm of the error terms i ε (i) 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.2.</head><figDesc>Fig. 2. LDA for unmixing. α represents the prior on the topics, θ is the topic mixture parameter (one for each of M images), z represents the particular object topic which is combined with β, the topic distributions to generate an object of type w.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.3.</head><figDesc>Fig. 3. Average squared reconstruction error as a function of the number of patterns B for basis pursuit. This is the value of i ε 2 in (2). For B = 0, we show the total variance, i.e. i ˆ x (i) 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><figDesc>[10:41 12/5/2010 Bioinformatics-btq220.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig.4.</head><figDesc>Fig. 4. Log likelihood as a function of the number of fundamental patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Table2.</head><figDesc>Unmixed coefficients for fundamental patterns and mixed samples for the discovered patterns (using LDA method) Mitochondrial (%) Lysosomal (%) Pattern 0 0.0 0.0 Pattern 1 8.8 99.9 Pattern 2 91.2 0.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig.6.</head><figDesc>Fig. 6. Estimated concentration as a function of the underlying relative probe concentration. Perfect result would be along the dashed diagonal. In LDA unmixing with 3 fundamental patterns, fractions of the two major patterns are normalized and plotted over ground-truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1. Unmixed coefficients for images of fundamental patterns and mixed samples using basis pursuit with B = 2</figDesc><table>Mitochondrial (%) 
Lysosomal (%) 

Pattern 0 
99 
18 
Pattern 1 
1 
82 

</table></figure>

			<note place="foot">© The Author(s) 2010. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/2.5), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:41 12/5/2010 Bioinformatics-btq220.tex] Page: i8 i7–i12</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">i11 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors thank Ghislain Bonami, Sumit Chanda and Daniel Rines for providing images as well as many helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="41" to="53" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq220. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq220. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="12" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Blei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated image analysis of protein localization in budding yeast</title>
		<author>
			<persName>
				<forename type="first">S.-C</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="66" to="71" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Nuclear segmentation in microscope cell images: a handsegmented dataset and comparison of algorithms</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">P</forename>
				<surname>Coelho</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 IEEE International Symposium on Biomedical Imaging</title>
		<meeting>the 2009 IEEE International Symposium on Biomedical Imaging<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="518" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Visual categorization with bags of keypoints</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Csurka</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Statistical Learning in Computer Vision, ECCV, Prague, Czech Republic</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Large-scale automated analysis of location patterns in randomly tagged 3T3 cells</title>
		<author>
			<persName>
				<forename type="first">García</forename>
				<surname>Osuna</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1081" to="1087" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical and visual differentiation of subcellular imaging</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">A</forename>
				<surname>Hamilton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Non-negative matrix factorization with sparseness constraints</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">O</forename>
				<surname>Hoyer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1457" to="1469" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Global analysis of protein localization in budding yeast</title>
		<author>
			<persName>
				<forename type="first">W.-K</forename>
				<surname>Huh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">425</biblScope>
			<biblScope unit="page" from="686" to="691" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by non-negative matrix factorization</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">D</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">S</forename>
				<surname>Seung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A hybrid 3D watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry A</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="23" to="36" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Determining the distribution of probes between different subcellular locations through automated unmixing of subcellular patterns</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2944" to="2949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Geometric LDA: a generative model for particular object discovery</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Philbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference<address><addrLine>Leeds, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Picture thresholding using an iterative selection method</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ridler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Calvard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybernet</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="630" to="632" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Object type recognition for automated analysis of protein subcellular location</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1351" to="1359" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised learning of probabilistic grammar-Markov models for object categories</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Zhu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="114" to="128" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>