
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mixtures of common t-factor analyzers for clustering high-dimensional microarray data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Jangsun</forename>
								<surname>Baek</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Chonnam National University</orgName>
								<address>
									<postCode>500-757</postCode>
									<settlement>Gwangju</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Geoffrey</forename>
								<forename type="middle">J</forename>
								<surname>Mclachlan</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics and Institute for Molecular Bioscience</orgName>
								<orgName type="institution">University of Queensland</orgName>
								<address>
									<postCode>4072</postCode>
									<settlement>Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mixtures of common t-factor analyzers for clustering high-dimensional microarray data</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">9</biblScope>
							<biblScope unit="page" from="1269" to="1276"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr112</idno>
					<note type="submission">Gene expression Advance Access publication March 3, 2011 Received on August 20, 2010; revised on February 10, 2011; accepted on February 27, 2011</note>
					<note>[14:19 7/4/2011 Bioinformatics-btr112.tex] Page: 1269 1269–1276 Associate Editor: Trey Ideker Contact: jbaek@jnu.ac.kr Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Mixtures of factor analyzers enable model-based clustering to be undertaken for high-dimensional microarray data, where the number of observations n is small relative to the number of genes p. Moreover, when the number of clusters is not small, for example, where there are several different types of cancer, there may be the need to reduce further the number of parameters in the specification of the component-covariance matrices. A further reduction can be achieved by using mixtures of factor analyzers with common component-factor loadings (MCFA), which is a more parsimonious model. However, this approach is sensitive to both non-normality and outliers, which are commonly observed in microarray experiments. This sensitivity of the MCFA approach is due to its being based on a mixture model in which the multivariate normal family of distributions is assumed for the component-error and factor distributions. Results: An extension to mixtures of t-factor analyzers with common component-factor loadings is considered, whereby the multivariate t-family is adopted for the component-error and factor distributions. An EM algorithm is developed for the fitting of mixtures of common t-factor analyzers. The model can handle data with tails longer than that of the normal distribution, is robust against outliers and allows the data to be displayed in low-dimensional plots. It is applied here to both synthetic data and some microarray gene expression data for clustering and shows its better performance over several existing methods. Availability: The algorithms were implemented in Matlab. The Matlab code is available at http://blog.naver.com/aggie100.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Model-based methods have been widely used for both clustering and classifying high-dimensional microarray data (<ref type="bibr" target="#b23">McLachlan et al., 2002;</ref><ref type="bibr" target="#b35">Yeung et al., 2001</ref>).<ref type="bibr" target="#b33">Thalamuthu et al. (2006)</ref>compared various clustering techniques and showed that modelbased method performed well for microarray gene clustering. * To whom correspondence should be addressed.</p><p>The finite normal mixture model with unrestricted componentcovariance matrices is a highly parameterized model (<ref type="bibr" target="#b19">McLachlan and Basford, 1988;</ref><ref type="bibr" target="#b20">McLachlan and Peel, 2000a</ref>). Banfield and<ref type="bibr" target="#b2">Raftery (1993)</ref>introduced a parameterization of the componentcovariance matrix based on a variant of the standard spectral decomposition, and its program MCLUST (<ref type="bibr" target="#b9">Fraley and Raftery, 2003</ref>) has been often used. But if the number of genes p is large relative to the sample size n, it may not be possible to use this decomposition to infer an appropriate model for the componentcovariance matrices. Even if it were possible, the results may not be reliable due to potential problems with near-singular estimates of the component-covariance matrices when p is large relative to n. In this case, mixtures of factor analyzers (MFA) is a useful model to reduce the number of parameters by allowing factor-analytic representation of the component-covariance matrices.<ref type="bibr" target="#b13">Hinton et al. (1997)</ref>proposed the MFA adopting a finite mixture of factor analysis models, which was considered for the purposes of clustering by<ref type="bibr">Peel (2000a, 2000b</ref>) and<ref type="bibr" target="#b27">McLachlan et al. (2003</ref><ref type="bibr" target="#b28">McLachlan et al. ( , 2007</ref>).<ref type="bibr" target="#b23">McLachlan et al. (2002</ref><ref type="bibr" target="#b27">McLachlan et al. ( , 2003</ref>) applied MFA to tissue samples with microarray gene expression data for clustering.<ref type="bibr" target="#b18">Martella (2006)</ref>used MFA to classify microarray data successfully. Recently,<ref type="bibr" target="#b34">Xie et al. (2010)</ref>proposed a penalized MFA to allow both selection of effective genes and clustering of high-dimensional data simultaneously.<ref type="bibr" target="#b36">Zhou et al. (2009)</ref>has proposed another penalized model-based clustering method with unconstrained covariance matrices. In practice, for example, where there are several different types of cancer, there is often the need to reduce further the number of parameters in the specification of the componentcovariance matrices by factor-analytic representations.<ref type="bibr" target="#b29">McNicholas and Murphy (2008)</ref>introduced some parsimonious MFA models, which include various MFA models with fewer parameters.<ref type="bibr" target="#b11">Galimberti et al. (2009)</ref>proposed another parsimonious factor mixture model to allow both dimension reduction and variable selection. Baek and McLachlan (2008) and<ref type="bibr" target="#b1">Baek et al. (2010)</ref>proposed the use of mixtures of factor analyzers with common component-factor loadings (MCFA) and applied it to a microarray dataset for clustering. The method considerably reduces further the number of parameters, and allows the data to be displayed in lowdimensional plots in a straightforward manner in contrast to MFA. Several analyses of many real datasets, however, have suggested that the empirical distribution of gene expression levels is approximately log-normal or sometimes with a slightly heavier tailed t-distribution depending on the biological samples under investigation (<ref type="bibr" target="#b16">Li, 2002</ref>). In particular,<ref type="bibr" target="#b12">Giles and Kipling (2003)</ref>applied the Shapiro–Wilks test to Affymetrix microarray expression data and concluded that<ref type="bibr">[14:19 7/4/2011 Bioinformatics-btr112.tex]</ref>Page: 1270 1269–1276</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Baek and G.J.McLachlan</head><p>non-normal distributions are common (up to 46% of probe sets). Lönnstedt and Speed (2002) also noted that outliers occur frequently in microarray experiments. Therefore, the above approaches are sensitive to both non-normality of the data and extreme expression levels as they are based on a mixture model in which the multivariate normal family of distributions is assumed for the component-error and factor distributions.<ref type="bibr" target="#b28">McLachlan et al. (2007)</ref>extended MFA to incorporate the multivariate t-distribution for the component-error and factor distributions. In this article, we propose an extension of MCFA to incorporate the multivariate t-distribution to handle the data with tails longer than that of the normal distribution. In the next section, we review briefly the MCFA approach as proposed by Baek and McLachlan (2008) and considered further in<ref type="bibr" target="#b1">Baek et al. (2010)</ref>. We then describe the mixtures of tfactor analyzers model with common factor loadings (MCtFA) and develop its implementation via the expectation-maximization (EM) algorithm. In Section 3, its application is demonstrated in the clustering of two microarray gene expression datasets. The results so obtained illustrate the improved performance of MCtFA over MCLUST, MFA and MCFA for these two datasets. A short discussion is given in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mixtures of common t-factor analyzers and its EM algorithm</head><p>Finite mixture models are being increasingly used to model the distributions of a wide variety of random phenomena and to cluster datasets; see, for example, McLachlan and Peel (2000a). Let Y = (Y 1 , ..., Y p ) T be a p-dimensional vector of feature variables. For continuous features Y j , the density of Y can be modelled by a mixture of a sufficiently large enough number g of multivariate normal component distributions,</p><formula>f (y; ) = g i=1 π i φ(y; µ i , i ),</formula><formula>(1)</formula><p>where φ(y<ref type="bibr">; µ,)</ref>denotes the p-variate normal density function with mean µ and covariance matrix. Here, the vector of unknown parameters consists of the mixing proportions π i , the elements of the component means µ i and the distinct elements of the component-covariance matrices i (i = 1, ..., g). We focus on the use of mixtures of factor analyzers to reduce the number of parameters in the specification of the component-covariance matrices, as discussed in<ref type="bibr" target="#b13">Hinton et al. (1997)</ref>, McLachlan and Peel (2000a) and<ref type="bibr" target="#b27">McLachlan et al. (2003)</ref>. With the factor-analytic representation of the component-covariance matrices, we have that</p><formula>i = A i A T i +D i (i = 1, ..., g),</formula><formula>(2)</formula><p>where A i is a p×q matrix and D i is a diagonal matrix. To see this, we first note that the MFA approach with the factor-analytic representation (2) on i is equivalent to assuming that the distribution of the difference Y j −µ i can be modelled as</p><formula>Y j −µ i = A i U ij +e ij with prob. π i (i = 1, ..., g)</formula><p>for j = 1, ..., n, where the (unobservable) factors U i1 , ..., U in are distributed independently N(0, I q ), independent of the e ij , which are distributed independently N(0, D i ), where D i is a diagonal matrix (i = 1, ..., g). However, this model may not lead to a sufficiently large enough reduction in the number of parameters, particularly if g is not small. Hence for this case, Baek and McLachlan (2008) and<ref type="bibr" target="#b1">Baek et al. (2010)</ref>proposed the MCFA approach whereby the distribution of Y j is modelled as Y j = AU ij +e ij with prob. π i (i = 1, ..., g)</p><formula>(3)</formula><p>for j = 1, ..., n, where the (unobservable) factors U i1 , .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.., U</head><formula>(4) and i = A i A T +D (i = 1, ..., g),</formula><formula>(5)</formula><p>where A is a p×q matrix, ξ i is a q-dimensional vector, i is a q×q positive definite symmetric matrix, and D is a diagonal p×p matrix. With the restrictions (4) and (5) on the component mean µ i and covariance matrix i , respectively, the MCFA approach provides a greater reduction in the number of parameters compared with MFA (see</p><formula>f (y; ) = g i=1 π i f t (y; µ i , i ,ν i ), (6)</formula><p>wherewhere δ(y,µ;) = (y−µ) T −1 (y−µ), and the vector of unknown parameters consists of the degrees of freedom ν i in addition to the mixing proportions π i and the elements of the ξ i , i , A and D (i = 1,...,g). As in the mixture of common factor analyzers model, A is a p×q matrix and D is a diagonal matrix. In order to fit the model (6) with the restriction (7), it is computationally convenient to exploit its link with factor analysis. Therefore, we assume that the distribution of Y j of MCtFA is modelled as (3), where the joint distribution of the factor U ij and the error e ij needs to be specified so that it is consistent with the t-mixture formulation (6) for the marginal distribution of Y j. In the EM framework, the component label z j associated with the observation y j is introduced as missing data, where z ij = (z j ) i is one or zero according as y j belongs or does not belong to the i-th component of the mixture (i = 1, ..., g; j = 1, ..., n). The unobservable factors u ij are also introduced as missing data in the EM framework. Now we postulate that conditional on membership of the i-th component of the mixture the joint distribution of Y j and its associated factor (vector) U ij is multivariate t-distribution. That is,</p><formula>Y j U ij |z ij = 1 ∼ t p+q (µ * i ,K i ,ν i ) (i = 1,...,g),</formula><formula>(8)</formula><p>where µ</p><formula>* i = (µ i ,ξ i ) = (A T ,I q ) T ξ i and K i = A i A T +D A i i A T i .</formula><p>This specification of the joint distribution of</p><formula>U ij |w j ,z ij = 1 ∼ N q (ξ i , i /w j ) and e ij |w j ,z ij = 1 ∼ N p (0,D/w j )</formula><p>and hence that</p><formula>U ij |z ij = 1 ∼ t q (ξ i , i ,ν i ) and e ij |z ij = 1 ∼ t p (0,D,ν i ).</formula><p>Thus, with this formulation, the error terms e ij and the factors U ij are distributed according to the t-distribution with the same degrees of freedom. However, the factors and error terms are no longer independently distributed as in the normal-based model for common factor analysis, but they are uncorrelated. To see this, we have from</p><p>(9) that conditional on w j , U ij and e ij are uncorrelated, and hence, unconditionally uncorrelated. By adopting a common factor loading matrix and the t-distribution for the factors and error terms, the MCtF model has fewer parameters and is more robust against extreme observations, thus providing a better fit to data with skewed heavy tails. We can obtain the maximum likelihood estimator of the vector of unknown parameters in the mixture of common t-factor analyzers model specified by (6) and (7) as follows. We use a modified version of the AECM algorithm outlined in<ref type="bibr" target="#b28">McLachlan et al. (2007)</ref>for mixtures of t-factor analyzers. We assume that the component-indicators z ij , the factors U ij in (3) and the weights w j in the characterization (9) of the t-distribution for the i-th component distribution of Y j and U ij are all missing. We have from</p><p>(9) that</p><formula>Y j |u ij ,w j ,z ij = 1 ∼ N p (Au ij ,D/w j ) (i = 1, ..., g).</formula><p>Thus in the EM framework for this problem, the complete data consist, in addition to the observed data y j , of the component-indicators z ij , the unobservable weights w j , and the latent factors u ij. The complete-data log likelihood for formed on the basis of the complete data is given by</p><formula>logL c () = g i=1 n j=1 z ij loga ij , where a ij = π i f G (w j ;ν i /2,ν i /2)φ(u ij ;ξ i , i /w j )φ(y j ;Au ij ,D/w j ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">E-step</head><p>In order to carry out the E-step, we need to be able to calculate the conditional expectation of the terms</p><formula>Z ij W j (U ij −ξ i ) and Z ij W j (U ij −ξ i )(U ij −ξ i ) T. From (9)</formula><p>, we have that conditional on y j and w j , the i-th component-conditional distribution of U ij −ξ i is multivariate normal with mean γ T i (y j −Aξ i ) and covariance matrix (</p><formula>I q −γ T i A) i /w j , where γ i = (A i A T +D) −1 A i. Thus, E{U ij −ξ i |(y j ,w j ,z ij = 1)}=γ T i (y j −Aξ i ), and E{(U ij −ξ i )(U ij −ξ i ) T |(y j ,w j ,z ij = 1)}=γ T i (y j −Aξ i )(y j −Aξ i ) T γ i + (I q −γ T i A) i /w j .</formula><p>The conditional expectation of W j given y j and z ij = 1 is given by</p><formula>w i (y j ;) = ν i +p ν i +δ(y j ,Aξ i ;A i A T +D) ,</formula><formula>(10) where δ(y j ,Aξ i ;A i A T +D) = (y j −Aξ i ) T (A i A T +D) −1 (y j −Aξ i</formula><p>). The conditional expectation of Z ij given y j is given by the posterior probability τ i (y j ;) that y j belongs to the i-th component of the mixture;</p><formula>τ i (y j ; ) = π i f t (y j ; Aξ i , A i A T +D,ν i ) g h=1 π h f t (y j ; Aξ h , A h A T +D,ν h )</formula><formula>(11)</formula><p>(i = 1,...,g; j = 1,...,n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">CM-step We use two CM steps</head><p>in the AECM algorithm, which correspond to the partition of into the two subvectors 1 and 2 , where 1 consists of the mixing proportions, the elements of ξ i and the degrees of freedom ν i (i = 1,...,g). The subvector 2 consists of the elements of the common factor loadings matrix A, the i and the diagonal matrix D. On the first cycle, we specify the missing data to be the componentindicator variables Z ij and the weights w j in the characterization (9) of the t-distribution for the component distribution of y j. On the (k +1)-th iteration of the algorithm, we update the estimators of the mixing proportions using</p><formula>π (k+1) i = n j=1 τ i (y j ; (k) )/n,</formula><p>where the posterior probabilities are calculated using (11). The updated estimate of the i-th component factor mean is given by</p><formula>ξ (k+1) i = n j=1 τ i (y j ; (k) )w (k) ij A (k) T y j / n j=1 τ i (y j ; (k) )w (k) ij ,</formula><p>where the current weight w</p><formula>(k) ij = w i (y j ;</formula><p>) is formed using the current value (k) for in (10). In the case where the degrees of freedom ν i in the component t-distributions are not specified but are to be estimated from the data, we have to update the estimate of ν i on the first cycle. The updated estimate ν (k+1) i of ν i does not exist in closed form, but is given as a solution of the equation</p><formula>−ψ( ν i 2 )+log( ν i 2 )+1+ 1 n (k) i n j=1 τ (k) ij (logw (k) ij −w (k) ij ) +ψ( ν (k) i +p 2 )−log( ν (k)</formula><formula>i +p 2 ) = 0, where τ (k)</formula><formula>ij = τ i (y j ; (k) ), n (k) i = n j=1 τ (k) ij</formula><p>(i = 1,...,g), and ψ(·) is the digamma function. The estimate of is updated so that its current value after the first cycle is given by (k+1/2) = (</p><formula>(k+1) T 1 , (k) T 2 ) T .</formula><p>On the second cycle of this iteration, the complete data are expanded to include the unobservable factors U ij associated with the y j. An E-step is performed to calculate Q(; (k+1/2) ), which is the conditional expectation of the complete-data log likelihood given the observed data, using = (k+1/2). Then the new posterior probability,</p><formula>τ i (y j ; (k+1/2) ), is estimated by π (k+1) i f t (y j ; A (k) ξ (k+1) i , A (k) (k) i A (k) T +D (k) ,ν (k+1) i ) g h=1 π (k+1) h f t (y j ; A (k) ξ (k+1) h , A (k) (k) h A (k) T +D (k) ,ν (k+1) h ) .</formula><p>The CM-step on this second cycle is implemented by the maximization of</p><formula>Q(; (k+1/2) ) over with 1 set equal to (k+1) 1 . This yields the updated estimates A (k+1) ,</formula><formula>(k+1) i and D (k+1). Set γ (k) i = (A (k) (k) i A (k) T +D (k) ) −1 A (k) (k) i , w (k+1/2) ij = ν (k+1) i +p ν (k+1) i +δ(y j ,A (k) ξ (k+1) i ;A (k) (k) i A (k) T +D (k) ) , n (k+1/2) i = n j=1 τ i (y j ; (k+1/2) ), S (k+1/2) i = n j=1 τ i (y j ; (k+1/2) )w (k+1/2) ij SE (k+1/2) i n j=1 τ i (y j ; (k+1/2) ) , where SE (k+1/2) i = (y j −A (k) ξ (k+1) i )(y j −A (k) ξ (k+1) i ) T. Then (k+1) i is given by (k+1) i = γ (k+1/2) T i S (k+1/2) i γ (k+1/2) i + (k) i (I q −A (k) T γ (k+1/2) i</formula><p>), Page: 1272 1269–1276</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Baek and G.J.McLachlan</head><p>and the updated estimate D (k+1) is given by</p><formula>D (k+1) = 1 g i=1 n (k+1/2) i g i=1 n (k+1/2) i {(A (k) γ (k+1/2) T i −I p )S (k+1/2) i ·(A (k) γ (k+1/2) T i −I p ) T +A (k) (k) i (I q −A (k) T γ (k+1/2) i )A (k) T }. Let η (k+1/2) ij = γ (k+1/2) T i (y j −A (k) ξ (k+1) i )+ξ (k+1) i</formula><p>. Then the updated estimate A (k+1) is obtained by</p><formula>A (k+1) = ⎛ ⎝ g i=1 n j=1 τ i (y j ; (k+1/2) )w (k+1/2) ij y j η (k+1/2) T ij ⎞ ⎠ ·{ g i=1 ( n j=1 τ i (y j ; (k+1/2) )w (k+1/2) ij η (k+1/2) ij η (k+1/2) T ij +n (k+1/2) i (I q −γ (k+1/2) T i A (k) ) (k) i )} −1 .</formula><p>We have to specify an initial value for the vector of unknown parameters in the application of the EM algorithm. A random start is obtained by first randomly assigning the data into g groups. Using the sample mean and sample covariance matrix of each randomly partitioned data, the initial parameter estimates are obtained as described in the Appendix of<ref type="bibr" target="#b1">Baek et al. (2010)</ref>. We can portray the observed data y j in q-dimensional space by plotting the corresponding value of thê u ij , which are the estimated conditional expectations of the factors U ij , corresponding to the observed data points y j .</p><formula>Note that E(U ij |y j ,z ij = 1) = E{E(U ij |y j ,w j ,z ij = 1)} = ξ i +γ T i (y j −Aξ i ) (12)</formula><p>We letûletˆletû ij denote the value of the right-hand side of (12) evaluated at the maximum likelihood estimates of ξ i , γ i and A. We can define the estimated valuê u j of the j-th factor corresponding to y j asû</p><formula>asˆasû j = g i=1 τ i (y j ; ˆ ) ˆ u ij (j = 1</formula><p>,...,n).</p><formula>(13)</formula><p>An alternative estimate of the posterior expectation of the factor corresponding to the j-th observation y j is defined by replacing τ i (y j ; ˆ ) byˆzbyˆ byˆz ij in (13).<ref type="bibr" target="#b31">Souto et al. (2008)</ref>compared different clustering methods for the analysis of 35 cancer gene expression datasets. For our experiment, we considered 2 of these 35 datasets. We applied MCtFA to cluster each of these two datasets, and compared its performance with other methods. We compare our method with MCLUST, MFA and MCFA. The performance is measured by the Adjusted Rand Index (ARI;<ref type="bibr" target="#b14">Hubert and Arabie, 1985</ref>) and the error rate since the true membership of each observation is known. MCLUST is a software package that implements Gaussian mixture models via EM algorithm and the Bayesian Information Criterion (BIC,<ref type="bibr" target="#b30">Schwarz, 1978</ref>) for model-based clustering (<ref type="bibr" target="#b9">Fraley and Raftery, 2003</ref>). In MCLUST, the component-covariance matrix i is parameterized by eigenvalue decomposition in the form</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><formula>i = ρ i E i i E T</formula><p>i , where ρ i is a constant, E i is the matrix of eigenvectors, i is a diagonal matrix with elements proportional to the eigenvalues of i. Different conditions on ρ i , i and E i characterize the volume, shape and orientation of each component distribution in MCLUST. We deal with the 10 submodels of MCLUST: EII, VII, EEI, VEI, EVI, VVI, EEE, EEV, VEV, VVV(<ref type="bibr" target="#b9">Fraley and Raftery, 2003</ref>,<ref type="figure" target="#tab_1">Table 1</ref>). For MFA, we assumed the covariance matrix of errors is equal for each component. We took advantage of the mclust software for R (<ref type="bibr" target="#b32">Team RDC 2004</ref>) and the EMMIX program (<ref type="bibr" target="#b22">McLachlan et al., 1999</ref>) for MFA, and developed programs for the MCFA and the MCtFA approaches, using the MATLAB language. The first set concerns both breast and colon cancer data (<ref type="bibr" target="#b7">Chowdary et al., 2006</ref>), which consists of 104 gene expressions for 52 matched tissue pairs of two different cancer types (32 pairs of breast tumour and 20 pairs of colon tumour). There are 22 283 genes in the original data, but<ref type="bibr" target="#b31">Souto et al. (2008)</ref>selected 182 genes by filtering uninformative genes. It has been reported in many analyses of real datasets that the empirical distribution of gene expression levels is approximately log-normal or sometimes (on the log scale) with a slightly heavier tailed t-distribution depending on the biological samples under investigation (<ref type="bibr" target="#b16">Li, 2002</ref>). Thus, these data may also have many extreme expressions for each gene.<ref type="figure" target="#fig_0">Figure 1</ref>shows boxplots of the expression levels for the first 10 genes. The distribution of each gene is skewed and has a very long tail. The rest of the genes also have similar shaped distributions. In particular, gene 6 has very high expression levels for six particular tissues.We implemented the MCLUST, MFA, MCFA and MCtFA procedures with g = 2 components with the number of factors q ranging from 1 to 9, using 50 starting values for the parameters. For each value of q, we computed the ARI and the associated error rate. The results are presented in<ref type="figure" target="#tab_1">Table 1</ref>. We have also listed in this table the values of the BIC and the Approximate Weight of Evidence (AWE:<ref type="bibr" target="#b2">Banfield and Raftery, 1993</ref>) for each model with different q. AWE is a model selection criterion based on an approximation to the classification log-likelihood. AWE is defined as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 1273 1269–1276</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixtures of common t-factor analyzers</head><formula>−2logL()+2EN(τ )+2m(3/2+log(n)), (14) where EN(τ ) =− n j=1 g i=1 τ i (y j ;)log(τ i (y j ;))</formula><p>is the entropy of the classification matrix with (i,j)-th element equal to τ i (y j ;) and m is the number of (free) parameters. It penalizes complex models more severely than BIC, and thus selects more parsimonious models than BIC. It would appear that BIC works well at a practical level; see, for example, Fraley and Raftery (1998). Further,<ref type="bibr" target="#b15">Keribin (2000)</ref>proved that BIC provides a consistent estimator of g (<ref type="bibr" target="#b6">Celeux, 2007</ref>). But BIC can lead to too few or too many clusters in practice, depending on the problem at hand. For the present problem of choosing the number of factors q, it would appear from<ref type="figure" target="#tab_1">Table 1</ref>that it leads to too many factors being fitted in the mixtures of factor analyzers model. An apparent explanation for this is that for the present dataset (and the other one to follow), the data are not well represented by the true models of clusters and/or the true clusters are not well separated. As a consequence, BIC leads to too many factors in the mixture model being fitted to the data. The AWE criterion is preferable to BIC here as it leads to fewer factors since it places a higher penalty on more complex model due to the presence of twice of the entropy and the extra constant term (2EN(τ )+3m+mlog(n)) in (14). We also considered the ICL criterion which chooses q to minimize −2logL()+2EN(τ )+mlog(n), which is similar to the AWE criterion. They are the same apart from the additional penalty of 3m+mlog(n) imposed by AWE, which for our present problem leads to a better choice of q. It can be seen that the lowest error rate (0.0288) and highest value (0.8867) of the ARI is obtained by using q = 6 factors with the MCtFA model, which coincides with the choice on the basis of AWE. The lowest error rate (0.1154) of the MFA model is obtained for q = 3 factors. The best result of MCFA model is obtained with its lowest error rate 0.0865 for q = 1 factor (AWE suggests using q = 7). MCLUST chose VVI model as its best and its error rate is 0.3462. It can be seen that the error rate and ARI for MCtFA are better than those for MCLUST, MFA and MCFA. We have also calculated BIC for all models. It can be seen that it failed to select the best modelfor each method. BIC reached its minimum for largest q(q = 9) of each method, so it selected a more complex model than the one with highest ARI and lowest error rate. In the case where the distribution from which the data arose is not in the collection of considered mixture models, BIC criterion tends to overestimate the correct size regardless of the separation of the clusters (<ref type="bibr" target="#b6">Celeux, 2007</ref>). To illustrate the usefulness of the MCtFA approach for portraying the results of a clustering in low-dimensional space, we have plotted in<ref type="figure" target="#fig_1">Figure 2</ref>the estimated factor scoresûscoresˆscoresû j as defined by</p><p>(13) with the implied cluster labels shown. In this plot, we used the third and sixth factors in the fit of the MCtFA model with q = 6 factors. It can be seen that the clusters are represented in this plot with very little overlap. The estimated factor scores were plotted according to the implied clustering labels. The degrees of freedom of the factor t-distributions for both groups were estimated as 1.0 and 1.0, which means their tails of the distributions are very thick and long. We can easily detect 6 distinct extreme tissues as shown in<ref type="figure" target="#fig_1">Figure 2</ref>, which are known to be the 9th–14th colon tumor tissue.<ref type="figure" target="#fig_2">Figure 3</ref>shows the expression levels of all genes for the 6th–17th colon tumor tissues. In<ref type="figure" target="#fig_2">Figure 3</ref>, we observe that all of these 6 outliers are very different from others since they have extremely large expression levels not only of the 6th gene shown in<ref type="figure" target="#fig_0">Figure 1</ref>, but also of other genes. The second dataset to which we applied our method is a lung cancer data (<ref type="bibr" target="#b3">Bhattacherjee et al., 2001</ref>), for which the number of classes is not small (g = 5). It consists of 203 gene expressions partitioned into five subpopulations: four lung cancer types and normal tissues.<ref type="bibr" target="#b31">Souto et al. (2008)</ref>selected 1543 informative genes from the original 12 600 genes. There are big differences among the class sizes of the data. The number of tissues for each class is 139, 17, 6, 21 and 20, respectively.<ref type="figure" target="#fig_3">Figure 4</ref>shows the Page: 1274 1269–1276boxplots of the expressions of a gene plotted for each subpopulation. It can be seen that there exist skewed distributions mixed with symmetric distribution with or without extreme observations for five components in the plot. Since the selected (1543) genes are still too many for the mixture model, we grouped the genes into 50 clusters and selected the centroid from each cluster of genes. That is, we applied the k-means algorithm to the 1543 gene expressions and clustered them into 50 groups of similar characteristics. Then we extracted the centroid from each group to make 50 new features for the mixture models. We implemented the MCLUST, MFA, MCFA, and MCtFA approaches with g = 5 components for the number of factors q ranging from 1 to 10, using 50 starting values for the parameters. For each value of q, we computed the ARI and the error rate. The results are presented in<ref type="figure" target="#tab_2">Table 2</ref>. We have also listed in this table the values of BIC and AWE for each model with different levels of q. MCtFA attains its largest ARI (0.7322) and lowest error rate (0.1133) for q = 6, although AWE suggested the model with q = 7. We notice that there is little difference between the AWE values for q = 6 and for q = 7. The lowest error rate for MCFA is 0.2611 for q = 2 and the largest ARI is 0.4570 for q = 9. The error rate (NA) of MCFA for q = 1 was not able to be calculated since the estimated number of clusters was less than the true value 5. Neither BIC nor AWE indicated the best model for MCFA. MFA reached its best ARI (0.3487) and error rate (0.3498) for q = 7. The minimum BIC and AWE were obtained at q = 6, and at q = 1, respectively. The best model for MCLUST showed similar performance (ARI: 0.3021, error rate: 0.3350) to MFA. MCtFA again performed better than the other methods for this dataset. We display the data using the estimated factor scores of our model in 3D space (<ref type="figure">Figure 5</ref>). In the latter, we used the second, the fourth and the fifth factors in the fit of the MCtFA model with q = 6 factors. The estimated factor scores were plotted according to the implied clustering labels. It can be seen that the five clusters are represented in this plot with very little overlap. The degrees of freedom of the factor t-distributions for the components were estimated as 1.1, 1.3, 7.8, 4.0 and 4.1. There are two distributions with long tails [ν 1 = 1.1(triangle), ν 2 = 1.3(circle)] in the plot. We have also given in<ref type="figure" target="#fig_4">Figure 6</ref>the plot corresponding to that in<ref type="figure">Figure 5</ref>with the true cluster labels shown. There are 23 misallocated tissues which can be seen in other's clusters, but as a whole there is a good agreement between the two plots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Baek and G.J.McLachlan</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>For clustering high-dimensional data such as microarray gene expressions, MFA is a useful technique since it can reduce the number of parameters through its factor-analytic representation of the component-covariance matrices. However, this approach isnot provide a sufficient reduction in the number of parameters, particularly when the number of clusters (subpopulations) is not small. In this article, we proposed a new mixture model which can reduce the number of parameters further in such instances and cluster the data containing outliers simultaneously by introducing a mixture of t-distributions with both component-mean and component covariance represented by common factor loadings. We call this approach mixtures of common t-factor analyzers (MCtFA). We describe the implementation of an EM algorithm for fitting the MCtFA. This approach also has the ability to portray the results of a clustering in low-dimensional space. We can plot the estimated posterior means of the factorsûfactorsˆfactorsû j as defined by</p><p>(13) with the implied cluster labels. On the other hand, the approaches MCLUST, MFA and MtFA cannot project high-dimensional objects in lowdimensional space. The applications of MCtFA to two cancer microarray datasets have demonstrated the usefulness and its relative superiority in clustering performance over MCLUST, MFA and MCFA. It has shown that our method works well for clustering data containing outliers. Moreover, it provides information on the distribution structure of each subpopulation by displaying the estimated factor scores in low-dimensional space. We observed also that the proposed approach fitted the experimental datasets better than the other approaches, and the performance difference between MCtFA and the others becomes even greater when the number of clusters is not small, such as in the case of second dataset (Section 1.1 of Supplementary Material). Often BIC is used to provide a guide to the choice of the number of factors q and the number of components g to be used. However, it did not always lead to the correct choice of the best model. That is, BIC can lead to too simple or too complex model in practice, depending on the problem at hand. Simulation studies reported in<ref type="bibr" target="#b5">Biernacki and</ref><ref type="bibr">Govaert (1997), Biernacki et al. (2000)</ref>and McLachlan and Peel (2000a) show that BIC will overrate the number of clusters under misspecification of the component density, whereas several alternative criteria such as the AWE and ICL criterion are able to identify the correct number of clusters even when the component densities are misspecified (Frühwirth<ref type="bibr" target="#b10">Schnatter and Pyne, 2010</ref>). In both of our real data applications, we observed that BIC did not choose the best q. An apparent explanation for this is that BIC tries to choose more complex model since some of the subpopulations of the datasets have skewed distributions and have several extreme outliers. On the other hand, AWE leads to the best or almost the best model with smallest error rate since it is more robust against misspecification of the component densities for the experimental datasets. Recently, Frühwirth-Schnatter and Pyne (2010) reported that AWE picked the correct model for both skew-t and skew-normal mixture distributions. Also a small simulation study confirms the better performance of the AWE over the BIC when the distribution of the data has skewed heavy tails due to some extreme observations (Section 1.2 of Supplementary Material). In future work, we wish to investigate the use of various model selection criteria on choosing the number of factors q and the number of components g in mixtures of t or skewed distributions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. The boxplots for the first 10 genes in the cancer data of Chowdary et al. (2006).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Plot of the (estimated) posterior mean factor scores via the MCtFA approach based on the implied clustering for the cancer data of Chowdary et al. (2006).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. The boxplots of expression levels of all genes for the 6th–17th colon tumor tissues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. The boxplots for the expressions of a gene by subpopulation: the lung cancer data of Bhattacherjee et al. (2001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.6.</head><figDesc>Fig. 6. Plot of the (estimated) posterior mean factor scores via the MCtFA approach with the true labels shown for the lung cancer data of Bhattacherjee et al. (2001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Funding: Korea Research Foundation Grant funded by the Korean Government (MOEHRD, Basic Research Promotion Fund, KRF2007-521-C00048 to J.B.). Australian Research Council (to G.J.M.). Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>in are distributed independently N(ξ i , i ), independent of the e ij , which are distributed independently N(0, D), where D is a diagonal matrix (i = 1, ..., g). Here A is a p×q matrix of factor loadings, which satisfies A T A = I q. Then MCFA is considered as the normal mixture model (1) with the restrictions µ i = Aξ i (</figDesc><table>i = 1, ..., g) 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1 in Baek et al. 2010).</figDesc><table>The implementation of the EM algorithm to fit this model is described in the 
Appendix of Baek et al. (2010). Another useful feature of the MCFA approach 
is its ability to portray the results of a clustering in low-dimensional space. 
We can plot the estimated posterior meansûmeansˆmeansû j of the factors [as defined by 
Equation (34) of Baek et al. (2010)] in 2D or 3D space, using the implied 
cluster labels. In contrast, MFA does not have the ability to project the high-
dimensional objects in low-dimensional space since the mean vector of the 
factor is assumed to be 0 for each cluster. This is illustrated in McLachlan 
and Peel (2000a, Chapter 8). 
Now we assume that y 1 ,...,y n are an observed random sample from the 
t-mixture density 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>µ i = Aξ i and i = A i A T +D</figDesc><table>(i = 1,...,g), 
(7) 

and where the multivariate t-probability density function 
f t (y; µ,,ν) is defined as 

f t (y; µ,,ν) = 
((ν+p)/2)|| −1/2 

(πν) p/2 (ν/2){1+δ(y,µ;)/ν} (ν+p)/2 , 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Y j and its associated factors in (3) will imply the t-mixture model (6) for the marginal distribution of Y j with</figDesc><table>the restriction (7). Using the characterization of the t-distribution related to 
the normal distribution, it follows that we can express (8) alternatively as 

Y j 
U ij [14:19 7/4/2011 Bioinformatics-btr112.tex] 

Page: 1271 1269–1276 

Mixtures of common t-factor analyzers 

f G (w;α,β) ={β α w α−1 / /(α)}exp(−βw)I [0,∞) (w)(α,β&gt;0). 
Therefore, 
it can be established from (9) that 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 1. Comparison of MCLUST, MFA, MCFA and MCtFA models for implied clustering versus the true membership of Chowdary's 104 cancer tissues</figDesc><table>Model 
Factors 
BIC 
AWE 
ARI 
Error rate 

MCLUST 
VVI 
242 872 
0.0657 
0.3462 

MFA 
1 
250 841 
257 805 
0.0296 
0.3750 
2 
241 124 
250 855 
0.0296 
0.3750 
3 
234 888 
247 371 
0.5858 
0.1154 
4 
232 917 
248 137 
0.0386 
0.3750 
5 
230 485 
248 426 
0.0657 
0.3462 
6 
230 326 
250 974 
0.4726 
0.1538 
7 
230 461 
253 800 
0.2790 
0.2308 
8 
229 825 
255 839 
0.1431 
0.2981 
9 
229 433 
258 107 
0.1696 
0.2885 

MCFA 
1 
261 337 
264 164 
0.6800 
0.0865 
2 
253 301 
257 532 
0.0464 
0.3654 
3 
246 291 
251 934 
0.1282 
0.3077 
4 
243 084 
250 139 
0.0657 
0.3462 
5 
240 297 
248 767 
0.1587 
0.2885 
6 
236 654 
246 539 
0.0657 
0.3462 
7 
233 076 
244 374 
0.0657 
0.3462 
8 
232 083 
244 795 
0.2128 
0.2596 
9 
231 226 
245 354 
0.1240 
0.3077 

MCtFA 
1 
234 450 
237 278 
0 
0.4038 
2 
229 677 
233 920 
0.8505 
0.0385 
3 
228 106 
233 764 
0.8505 
0.0385 
4 
226 891 
233 976 
0.0675 
0.3558 
5 
225 387 
233 876 
0.5564 
0.1250 
6 
223 518 
233 419 
0.8867 
0.0288 
7 
222 455 
233 772 
0.6808 
0.0865 
8 
222 156 
234 884 
0.7465 
0.0673 
9 
221 134 
235 276 
0.4742 
0.1538 

The bold numbers are the optimal values of BIC, AWE, ARI and Error rate for each 
model. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 2. Comparison of MCLUST, MFA, MCFA and MCtFA models for implied clustering versus the true membership of Bhattacharjee's 203 lung cancer tissues</figDesc><table>Model 
Factors 
BIC 
AWE 
ARI 
Error rate 

MCLUST 
VVI 
135 023 
0.3021 
0.3350 

MFA 
1 
140 710 
145 324 
0.3100 
0.4286 
2 
139 479 
146 125 
0.3219 
0.3941 
3 
139 313 
147 955 
0.3156 
0.4089 
4 
139 016 
149 611 
0.3013 
0.4039 
5 
139 068 
151 573 
0.3368 
0.3645 
6 
138 870 
153 244 
0.2445 
0.4236 
7 
139 358 
155 561 
0.3487 
0.3498 
8 
139 747 
157 738 
0.2616 
0.4335 
9 
140 207 
159 943 
0.2571 
0.4433 
10 
140 414 
161 854 
0.2368 
0.4680 

MCFA 
1 
148 255 
149 674 
0.0721 
NA 
2 
144 994 
146 585 
0.3348 
0.2611 
3 
142 978 
145 042 
0.3090 
0.3300 
4 
141 826 
144 453 
0.4376 
0.2759 
5 
140 943 
144 139 
0.3703 
0.3153 
6 
140 123 
143 943 
0.3269 
0.3251 
7 
139 362 
143 800 
0.3692 
0.3153 
8 
138 921 
144 015 
0.3775 
0.3153 
9 
138 420 
144 194 
0.4570 
0.2709 
10 
138 134 
144 633 
0.2418 
0.4335 

MCtFA 
1 
144 424 
145 607 
−0.1269 
0.4384 
2 
142 708 
144 294 
0.3619 
0.2413 
3 
141 155 
143 236 
0.4735 
0.2266 
4 
139 683 
142 334 
0.6179 
0.1527 
5 
138 937 
142 154 
0.6657 
0.1379 
6 
138 194 
142 025 
0.7322 
0.1133 
7 
137 538 
142 009 
0.5875 
0.1675 
8 
136 973 
142 105 
0.6417 
0.1773 
9 
136 660 
142 474 
0.4408 
0.2365 
10 
136 431 
142 967 
0.3215 
0.3153 

The bold numbers are the optimal values of BIC, AWE, ARI and Error rate for each 
model. NA means Not Available. 

Fig. 5. Plot of the (estimated) posterior mean factor scores via the MCtFA 
approach based on the implied clustering for the lung cancer data of 
Bhattacherjee et al. (2001). 

sensitive to outliers as it is based on a mixture model in which 
the multivariate normal family of distributions is assumed for the 
component factor and error distributions. McLachlan et al. (2007) 
extended MFA to incorporate t-distributions for the component 
factor and error in the mixture model for dealing with unusual 
extreme observations (MtFA). These methods, however, may </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">|w j ,z ij = 1 ∼ N p+q (µ * i ,K i /w j ), (9) where w j is a value of the weight variable W j taken to have the gamma distribution f G (w j ;ν i /2,ν i /2), where</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixtures of factor analyzers with common factor loadings for the clustering and visualisation of high-dimensional data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Baek</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Preprint Series of the Isaac Newton Institute for Mathematical Sciences</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixtures of factor analyzers with common factor loadings: applications to the clustering and visualisation of high-dimensional data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Baek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intel</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1298" to="1309" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Model-based Gaussian and non-Gaussian clustering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Banfield</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Raftery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="803" to="821" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Classification of human lung carcinomas by mRNA expression profiling reveals distinct adenocarcinoma subclasses</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bhattacherjee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 98</title>
		<meeting>. Natl Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="13790" to="13795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Using the classification likelihood to choose the number of clusters</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Biernacki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Govaert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Stat</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="451" to="457" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Assessing a mixture model for clustering with the integrated completed likelihood</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Biernacki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intel</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="719" to="725" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Mixture models for classification Advances in Data Analysis</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Celeux</surname>
			</persName>
		</author>
		<editor>Decker,R. et al.</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Prognostic gene expression signatures can be measured in tissues collected in RNAlater preservative</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Chowdary</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Diagn</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="31" to="39" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">How many clusters? Which clustering methods? Answers via model-based cluster analysis</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Fraley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Raftery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput.J</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="578" to="588" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Enhanced model-based clustering, density estimation, and discriminant analysis software: MCLUST</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Fraley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Raftery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Classific</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="263" to="286" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Bayesian inference for finite mixtures of univariate and multivariate skew-normal and skew-t distributions</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Frühwirth-Schnatter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pyne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="317" to="336" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Penalized factor mixture analysis for variable selection in Clustered Data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Galimberti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="4301" to="4310" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Normality of oligonucleotide microarray data and implications for parametric statistical analyses</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Giles</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kipling</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2254" to="2262" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling the manifolds of images of handwritten digits</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="65" to="73" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hubert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Arabie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Classific</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Consistent estimation of the order of mixture models</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Keribin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sankhya Ser. A</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="49" to="66" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Genome-wide coexpression dynamics: theory and application</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="16875" to="16880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Lönnstedt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Speed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sinica</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="31" to="46" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Replicated. microarray data</note>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Classification of microarray data with factor mixture models</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Martella</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="202" to="208" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Mixture Models: Inference and Applications to Clustering</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">E</forename>
				<surname>Basford</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Marcel Dekker Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Finite Mixture Models</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Peel</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Mixtures of factor analyzers</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Peel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Machine Learning</title>
		<editor>Langley, P.</editor>
		<meeting>the Seventeenth International Conference on Machine Learning<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="599" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">The EMMIX software for the fitting of mixtures of normal and t-components</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Mixture model-based approach to the clustering of microarray expression data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="413" to="422" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">1419</biblScope>
			<biblScope unit="issue">74</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1276" to="1269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Baek</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Modelling high-dimensional data by mixtures of factor analyzers</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="379" to="388" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Extension of the mixture of factor analyzers model to incorporate the multivariate t distribution</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="5327" to="5338" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Parsimonious Gaussian mixture models</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Mcnicholas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">B</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="285" to="296" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Schwarz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Clustering cancer gene expression data: a comparative study</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Souto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">497</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName>
				<forename type="first">Rdc</forename>
				<surname>Team</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Evaluation and comparison of gene clustering methods in microarray analysis</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Thalamuthu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2405" to="2412" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Penalized mixtures of factor analyzers with application to clustering high dimensional microarray data</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Xie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="501" to="508" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Model-based clustering and data transformations for gene expression data</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">Y</forename>
				<surname>Yeung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="977" to="987" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Penalized model-based clustering with unconstrained covariance matrices</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. J. Stat</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1473" to="1496" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>