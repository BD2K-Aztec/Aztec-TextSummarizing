
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prediction of human functional genetic networks from heterogeneous data using RVM-based ensemble learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Chia-Chin</forename>
								<surname>Wu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Shahab</forename>
								<surname>Asgharzadeh</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="institution">Children&apos;s Hospital Los Angeles</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Keck School of Medicine</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Timothy</forename>
								<forename type="middle">J</forename>
								<surname>Triche</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Children&apos;s Hospital Los Angeles</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Keck School of Medicine</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<forename type="middle">Z</forename>
								<surname>D &apos;argenio</surname>
							</persName>
						</author>
						<title level="a" type="main">Prediction of human functional genetic networks from heterogeneous data using RVM-based ensemble learning</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="issue">6</biblScope>
							<biblScope unit="page" from="807" to="813"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq044</idno>
					<note type="submission">Systems biology Advance Access publication February 4, 2010 Received on October 19, 2009; revised on January 27, 2010; accepted on January 28, 2010</note>
					<note>[15:12 19/2/2010 Bioinformatics-btq044.tex] Page: 807 807–813 Associate Editor: John Quackenbush Contact: dargenio@bmsr.usc.edu Supplementary information: Supplementary material is available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Three major problems confront the construction of a human genetic network from heterogeneous genomics data using kernel-based approaches: definition of a robust gold-standard negative set, large-scale learning and massive missing data values. Results: The proposed graph-based approach generates a robust GSN for the training process of genetic network construction. The RVM-based ensemble model that combines AdaBoost and reduced-feature yields improved performance on large-scale learning problems with massive missing values in comparison to Naïve Bayes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Biological pathways that organize functional associations between different genes, proteins and small molecules are central to understanding cellular function. A variety of high-throughput experimental data, such as DNA microarray, ChIP-chip technology and systematic two-hybrid analysis (<ref type="bibr" target="#b21">Lee et al., 2002;</ref><ref type="bibr" target="#b34">Rual et al., 2005;</ref><ref type="bibr" target="#b37">Stears et al., 2003</ref>), have the potential to provide a systemlevel perspective of cellular processes and may contribute to systematic drug discovery (<ref type="bibr" target="#b38">Stoughton and Friend, 2005</ref>). Moreover, the broad availability of indirect biological data sources, such as Gene Ontology and protein localization information, also contain information that can be used to understand cellular processes (<ref type="bibr" target="#b24">Loging et al., 2007</ref>). Understanding biological pathways at the whole-genome level, however, remains a major challenge. Several computational approaches have been applied to construct biological networks using different individual data sources (<ref type="bibr" target="#b1">Basso et al., 2005;</ref><ref type="bibr" target="#b28">Papin et al., 2005</ref>). However, the results are often contradictory and not super imposable in any obvious way due to the intrinsic error rate of each data set and limited coverage (<ref type="bibr" target="#b46">Zhong and Sternberg, 2006</ref>). This limitation has motivated more recent work addressing the problems of integrating heterogeneous functional genomic and proteomic data to construct biological network. Results from these studies suggest that the combination of multiple sources can provide a more unified view of prediction with large coverage and high reliability. Several rigorous statistical models and machine * To whom correspondence should be addressed. learning approaches have been applied to generate reliable integrated predictions, such as Bayesian modeling, Decision Tree and Random Forest (<ref type="bibr" target="#b16">Jansen et al., 2003;</ref><ref type="bibr" target="#b20">Lee et al., 2004</ref><ref type="bibr" target="#b31">, Qi et al., 2006</ref>). Bayesian modeling (Naïve Bayes and Fully Connected Bayes) is the most popular method used to predict protein–protein and genetic interactions (<ref type="bibr" target="#b16">Jansen et al., 2003;</ref><ref type="bibr" target="#b41">Troyanskaya et al., 2003;</ref><ref type="bibr" target="#b33">Rhodes et al., 2005</ref>). Correlation among data sets, however, can cause prediction bias in Naïve Bayes models. Fully Connected Bayes models (<ref type="bibr" target="#b16">Jansen et al., 2003</ref>), in contrast, can capture the interdependence among data sources by directly calculating joint probabilities; however, it results in higher computational costs and requires bin size adjustment of each data dimension to obtain reasonable results, especially for high-dimension data. Moreover, the model prior is generally arbitrarily set to be the proportion of total number of positive and negative examples in the chosen benchmarks (<ref type="bibr" target="#b16">Jansen et al., 2003;</ref><ref type="bibr" target="#b33">Rhodes et al., 2005</ref>). Kernel-based models have demonstrated very competitive computational performance due to their ability to model non-linear systems and high-dimension data. The Support Vector Machine (SVM) has recently been successfully applied to predict protein– protein interactions and protein complex relationships in Yeast and Escherichia coli using heterogeneous data (Ben<ref type="bibr" target="#b2">Hur and Noble, 2005;</ref><ref type="bibr" target="#b32">Qiu and Noble, 2008;</ref><ref type="bibr" target="#b45">Yellaboina et al., 2007</ref>). The Relevance Vector Machine (RVM) approach (<ref type="bibr" target="#b39">Tipping, 2001</ref>), another powerful kernel-based model, uses a Bayesian learning framework to produce sparse decision models. RVM is similar to SVM in many respects and has been reported to yield nearly identical performance, but surpasses SVM in several aspects, including automatic prevention of over fitting and generation of much sparser models (<ref type="bibr" target="#b4">Bowd et al., 2005;</ref><ref type="bibr" target="#b39">Tipping, 2001</ref>). The RVM has been applied to several biological tasks including the classification and diagnosis of cancers (<ref type="bibr" target="#b19">Krishnapuram et al., 2004;</ref><ref type="bibr" target="#b44">Van Holsbeke et al., 2007</ref>) and the identification of non-coding regions in genomes (<ref type="bibr" target="#b9">Down and Hubbard, 2004</ref>). Thus, RVM may be a useful approach for integrating multiple heterogeneous data for constructing genetic networks. Three major problems, however, confront the use of RVM in constructing a human genetic network from diverse genomic data. First, a robust gold-standard negative (GSN) set is needed for training. A noisy gold-standard will impair training and cause prediction bias. Major methods reported in previous protein interaction studies to define GSN (Ben<ref type="bibr" target="#b3">Hur and Noble, 2006</ref>;<ref type="bibr" target="#b15">Jansen and Gerstein, 2004;</ref><ref type="bibr" target="#b16">Jansen et al., 2003;</ref><ref type="bibr" target="#b31">Qi et al., 2006</ref>) are not suitable for defining GSN for construction of a functional genetic network, which is not only composed of physical interactions but<ref type="bibr">[15:12 19/2/2010 Bioinformatics-btq044.tex]</ref>Page: 808 807–813</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.-C.Wu et al.</head><p>broader functional gene–gene relationships in pathways. Second, the size of the training data derived from human KEGG pathways is large. As with most of the kernel-based approaches, the computational cost associated with RVM for large-scale problems is a challenge (<ref type="bibr" target="#b40">Tipping and Faul, 2003</ref>). Third, most biological datasets contain many missing data values and the number will dramatically increase as more data types are included. The work reported herein addresses each of the three aforementioned challenges and is organized as follows. A graphbased method to define an accurate GSN is first presented to reduce noise in our negative training set (Section 2.1). Next, Sections 2.2 and 2.3 present the proposed RVM-based approach that combines two ensemble models, AdaBoost and reduced-feature to simultaneously address the other two problems of large-scale learning and massive missing data values. The data features and performance evaluation are presented in Section 2.4. Finally, all the results of experiments for the proposed approach are presented in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gold-standard datasets for training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Gold-standard positive</head><p>In order to construct a genetic network to reveal the tendency for genes to operate in the same pathways, we derive the gold-standard positive (GSP) set from the KEGG pathway, as has been reported in previous studies (<ref type="bibr" target="#b12">Franke et al., 2006;</ref><ref type="bibr" target="#b20">Lee et al., 2004</ref>). Two genes can be considered to constitute a positive pair if they have at least one KEGG pathway membership. Using the version of the KEGG pathway on DEC 2008, 498 989 positive interactions among 4882 genes are generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">GSN via a graph-based approach</head><p>Unlike GSP, identification of a GSN set for training and testing is challenging because of the difficulty in specifying gene pairs that do not function together in the same pathway. Three methods have been reported to generate a GSN. In the first method, two genes are defined as a negative pair if they do not function together in any KEGG pathway (<ref type="bibr" target="#b12">Franke et al., 2006;</ref><ref type="bibr" target="#b20">Lee et al., 2004</ref>). This method will generate a large number of negative interactions (in our case, 11 415 704 negative interactions), but most of them represent potentially positive interactions. For instance, if two genes are defined as a negative pair but share the same positive interacting partners (i.e. they share same pathway partners), it is possible that they may function together in some unknown pathway (<ref type="figure" target="#fig_0">Fig. 1a</ref>). In the second approach, which is often used to predict protein– protein interactions, a random set of protein pairs (after filtering the positive examples) can be defined as the GSN. This method is justified becausethe fraction of the positive pairs in the total set of protein pairs is small (Ben<ref type="bibr" target="#b2">Hur and Noble, 2005;</ref><ref type="bibr" target="#b31">Qi et al., 2006</ref>). However, this method is not suitable for defining the GSN for predicting a functional genetic network, which is not only composed of protein–protein interactions but also broader functional genetic relationships in pathways. The third approach generates negative examples based on different cellular compartments (Jansen and<ref type="bibr" target="#b15">Gerstein, 2004;</ref><ref type="bibr" target="#b16">Jansen et al., 2003</ref>). This strategy is also often applied to predict protein–protein interactions, but is not applicable to construction of a genetic network because a pathway is composed of proteins located in different compartments. To overcome these limitations, we present a graph-based approach to define the GSN. The central concept is to find the most distant functional relationship between any two genes based on the defined GSP. A network is first derived based on the GSP, in which any two genes which share at least one KEGG pathway are linked together. It is then further assumed that two genes are increasingly less likely to function together in the same pathway as the topological distance between them increases in this network (<ref type="figure" target="#fig_0">Fig. 1b</ref>). Here, Dijkstra's algorithm (<ref type="bibr" target="#b7">Dijkstra, 1959</ref>) is used to calculate the shortest topological distance between any gene pair in the network. The topological distance between a gene pair is then used to represent their functional relationship in the KEGG pathways. The N most distant gene pairs in the network (excluding an infinite relationship) can be defined as our robust GSN. For a balanced learning process, N is taken equal to the size of the GSP. Some newly discovered pathways are now isolated (i.e. genes in these pathways are infinite-distant from other genes in the KEGG network), but these could be potentially found to connect to other existing pathways in the future (the result in the Section 3.1 illustrates this point). Therefore, infinite-distant gene pairs are excluded from the GSN.</p><formula>(a) ( b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">RVM and kernels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">RVM</head><p>Assume that a genetic network is developed based on a set of N training examples, {x n ,t n } N n=1 , where x n ∈ R d (d is the number of features,<ref type="figure" target="#tab_1">Table 1</ref>) represents a vector of gene pair scores for the nth training example, and t n ∈ {0,1} is a label vector indicating the classes to which the nth example belongs (1 and 0 denote interacting and non-interacting pairs). Correspondingly, X = {x n } N n=1 and T = {t n } N n=1 denote the training and label set. A RVM classification model can take the form of a linear combination of basis functions, formed by a kernel function centered at the different training points.</p><formula>Y (X ) = N n=1 w n k (X,x n ) = W K,</formula><formula>(1) where W =[w 1 ,w 2 ,..., w N ]</formula><p>is a vector consisting of the linear combination weights, and K is a design matrix whose i-th column is formed with the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction of functional genetic networks</head><p>value of the kernel function, k(x i ,x n ), at the nth training point. Moreover, Y = {y n } N n=1 is the output prediction vector corresponded to the label vector T. Given an input x i , a gene pair is assigned as interacting (i.e. t * i =1) if y i (x i ) ≥ 0 and as non-interacting (i.e. t * i = 0) otherwise. Then, RVM uses a sparse Bayesian learning framework in which an a priori parameter structure is based on the automatic relevance determination theory for removing irrelevant data points. Hence, the number of kernel linear combinations in Equation (1) will be reduced to M (M N) and a sparse model for decision is produced. This advantage of RVM (<ref type="bibr" target="#b4">Bowd et al., 2005;</ref><ref type="bibr" target="#b39">Tipping, 2001</ref>) can greatly reduce the prediction time of the proposed ensemble framework in Section 2.3. A more extensive explanation of RVM is provided in the work of Tipping (<ref type="bibr" target="#b39">Tipping, 2001</ref>), and its MATLAB implementation is also available from http://www.relevancevector.com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Kernel used</head><p>The radial basis kernel, denoted K RB , is used as a pair wise kernel to present the similarity between any gene pair and any other gene pair, given a dataset that has been assigned a measure between any two genes (such as Pearson correlation of gene expression and cocitation score). However, for graph-structure datasets (genetic interaction, protein–protein interactions and protein phosphorylation), we first employ the diffusion kernel (<ref type="bibr" target="#b18">Kondor and Lafferty, 2002</ref>), denoted K D , to capture in-directed gene–gene relationships before applying the radial basis kernel to calculate pair–pair similarities (<ref type="bibr" target="#b32">Qiu and Noble, 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Kernel combinations Heterogeneous datasets, {D</head><formula>1 ,D 2 , ...,D n }</formula><p>, are to be integrated and m datasets among them are graph-structure data features, while the remaining n–m are from other heterogeneous data. In this work, we consider four kernel combinations in the RVM-based model, denoted KC1–KC4. In KC1, the graph-structure data features are first pre-computed using the diffusion kernel, and then the pairwise kernel values of each data set are calculated using the radial basis kernel separately before they are added together. The final summed kernel matrix, which is the input to the RVM model, is as follows:</p><formula>K KC1 = m i=1 K RB K D D i + n j=m+1 K RB D j (2)</formula><p>KC2 concatenates all the data sets together to form a single data matrix after applying the diffusion kernel to the graph structure data. The pairwise kernel values are later directly computed based on the data matrix.</p><formula>K KC2 = K RB K D D 1 : K D D 2 ··· : K D D m : D m+2 ··· : D n .</formula><formula>(3)</formula><p>In KC3, the kernel matrix of each data feature is used to train an individual model, and the resulting values from all the models are averaged to generate a final result. Finally, to evaluate the performance of diffusion kernel in RVM-based model, we also consider a KC4 scenario, in which the diffusion kernel is not applied to the graph-structure data features. The gene pairwise kernel values of all data are directly calculated using the radial basis kernel separately before summing.</p><formula>K KC4 = n i=1 K RB [D i ] (4)</formula><p>In Section 3.3, the performance of all combination approaches using the RVM-based model is evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The RVM-based ensemble framework</head><p>Ensemble methods that attempt to build up highly accurate models by combining many diverse base models represent a major development in machine learning in the past decade (<ref type="bibr" target="#b27">Opitz et al., 1999;</ref><ref type="bibr" target="#b30">Polikar, 2006</ref>). A diversity of base models is typically achieved by using different training data sets, which allows each base model to be able to generate different discriminant boundaries. The combination of these base models is expected to improve the learning performance and the generalization performance. More recently, numerous ensemble-based approaches have been proposedto address missing value and large-scale problems (<ref type="bibr" target="#b30">Polikar, 2006</ref>). We now focus on how the ensemble framework can address the two remaining problems for prediction of human genetic networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">AadaBoost for large-scale learning</head><p>AdaBoost (<ref type="bibr">Freund and Schapire, 1999</ref>), a popular ensemble method, is first combined with RVM to address the problem of large-scale learning. The main concept of RVMAdaBoost (as detailed in the Supplementary Data S3) is to sample many small training sets from the original large training set (<ref type="figure" target="#fig_1">Fig. 2a</ref>). Each RVM base model, which is trained from each small training set with low computational cost, is much weaker than it would be if it were trained with the whole data set. As a sufficient number of base models are generated, most of the distinct aspects of the complete training set can be captured and represented in the final combined model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Reduced-feature model for missing values</head><p>There are two major causes for missing values in our data. First, no individual dataset covers all gene pairs since different types of data contain complementary pathway information (<ref type="figure" target="#tab_1">Table 1</ref>). Second, most biological datasets are corrupted and noisy, as is the case with gene expression data. Therefore, missing values are common in heterogeneous biological data, and more gene pairs will have missing data as more datasets are integrated. When using RVM to build a prediction system, proper treatment of biological datasets with a large number of missing values is a critical issue for classification learning since missing data values in both training and testing set can affect prediction accuracy. Missing data problems have been well-studied in machine learning. Widely used approaches such as data deletion, which results in information lose, and simple imputation methods, which are problematic for large-scale missing data sets, would not be appropriate for our application. An alternative method, namely the reduced-feature model, is an ensemble based approach that combines many base models corresponding to various patterns of data features. These base models are trained only using a subset of all the data features. This reduced-feature modeling has been shown to be more robust to missing data than other imputation approaches (Saar<ref type="bibr" target="#b35">Tsechansky and Provost, 2007</ref>), and it also reduces computational costs because of its lower-dimensional learning than the complete modeling. Thus, we will adopt reduce-feature modeling for the problem of massive missing values in our application. Additional investigation of missing values problems will be illustrated in the Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">The RVM-based double ensemble</head><p>In this work, AdaBoost and reduced-feature are combined as outlined below and illustrated in<ref type="figure" target="#fig_1">Figure 2</ref>:</p><p>Page: 810 807–813</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.-C.Wu et al.</head><p>(1) Generate M feature sets by sampling m features M times from the complete set of data features without replacement.</p><p>(2) Train M base models (SF models in<ref type="figure" target="#fig_1">Fig. 2b</ref>) with these M feature sets using RVM-AdaBoost, which is the first level ensemble.</p><p>(3) An ensemble of all base models is then generated through averaging of the outputs from all base models. This is the second level ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The data features and performance evaluation</head><p>Fourteen datasets, as summarized in<ref type="figure" target="#tab_1">Table 1</ref>, are integrated in our study. Overall, these data sets can be divided into eight categories. The Supplementary Data S1 describes the source of these data sets and presents preprocessing details. As shown in the Table 1, different data features contain significantly varying degrees of coverage. These biological datasets present different types of pathway information and thus yield massive missing values in our training and prediction phase. Ten-fold cross-validation testing is used to access performance of models to be presented in Sections 3.2 and 3.3 based on precision–recall curve and the area under ROC curve (AUC). Other measures of prediction performance, including classification error, F-measure and G-mean, are detailed in the Supplementary Data S2. However, the gold-standard set in our work consists of many replicated data points (i.e. many interactions with same data feature scores). This produces dependence between testing and training data in crossvalidation. Cross-validation testing is not able to reveal much difference in the generalization performance of different models. Therefore, two curated pathway datasets, Biocarta and NCI-nature pathways are used to serve as independent testing examples. Biocarta and NCI-nature pathway contain 18 574 and 69 123 interactions different from the KEGG pathways. The classification errors of the two independent testing sets are calculated for all cases to evaluate the generalization performance. Finally, average values and standard derivations of all the performance measures are reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance of the graph-based GSN approach</head><p>The negative gold-standards generated by existing methods (<ref type="bibr" target="#b12">Franke et al., 2006;</ref><ref type="bibr" target="#b20">Lee et al., 2004</ref>) for genetic network prediction contains a significant portion of potential positive interactions. To illustrate this, an old version of the KEGG pathways (downloaded on<ref type="bibr">July, 2007</ref>) is compared with the new KEGG pathways (downloaded on<ref type="bibr">Dec, 2008</ref>). We first define a GSP and GSN based on the old KEGG pathways; that is, the GSP is composed of gene pairs that share at least one old KEGG pathway, and the GSN is composed of any two genes that do not share any old KEGG pathways but both of them are involved in at least one KEGG pathways. The result is that 19 285 gene pairs included in the GSN are found to appear in some new KEGG pathways. In order to determine if the graph-based approach presented in the Section 2.1 can define a more robust GSN, a network composed of all interactions in the old KEGG pathway is derived first. The shortest topological distance of those gene pairs without any linkage between them in the network is determined using Dijkstra's algorithm (<ref type="bibr" target="#b7">Dijkstra, 1959</ref>). Then, we calculate the portion of gene pairs with specific topologic distances (≤ 2) that do not function together in the old KEGG pathways, but are found to function together in the new KEGG pathways. The results presented in<ref type="figure" target="#fig_3">Figure 3a</ref>show that more gene pairs with lower topological distances in the network are included in new KEGG pathways. Genes in isolated pathways (newly discovered pathways) are indicated as having an infinitedistant from other genes in the KEGG network, but these newly discovered pathways may be found to connect to other pathways in). This approach was also evaluated using the two independent data sets, the NCI-nature pathways and Biocarta pathways, with similar results to those shown in<ref type="figure" target="#fig_3">Figure 3a</ref>. To evaluate whether any two genes with a more distant KEGG relationship have a lower functional relationship, the Gene Ontology functional information was mapped to each gene pair. The GO functional relationship score of a gene pair is determined by identifying the shared GO process or function term as described in the Supplemental Data S1. A higher score represents a closer functional relationship.<ref type="figure" target="#fig_3">Figure 3b</ref>confirms that the greater distance between any two genes in this network, the lower the functional relationship between them (they have a lower chance to function together in the same pathway). It should be emphasized that the Gene Ontology was not used to determine the GSN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Combining heterogeneous data</head><p>The RVM-Adaboost (<ref type="figure" target="#fig_1">Fig. 2a</ref>) is the first level ensemble model embedded in our framework (<ref type="figure" target="#fig_1">Fig. 2b</ref>) for training the gold-standard set (GSP and GSN defined in the Section 2.1) with the size of almost 1 million. Based on analysis of synthetic data (Supplementary Tables S1 and S2), RVM-AdaBoost is able to reduce the run-time relative to RVM alone. At a data set size of 1000, the computation time for RVM-AdaBoost is ∼2.5-fold less than that of RVM alone. As the data set size is increased to 3000, the runtime of RVMAdaBoost is ∼20-fold less than RVM alone. Based on these synthetic data results, therefore, we expect the reduction in computation time of RVM-AdaBoost relative to RVM alone to become greater as N increases. RVM-AdaBoost can approach the result achieved from the complete data set with reduced computation cost both in the<ref type="bibr">[15:12 19/2/2010 Bioinformatics-btq044.tex]</ref>Page: 811 807–813in the Supplementary Data S4). To evaluate the performance of RVM-AdaBoost in the construction of a genetic network, it is necessary to first determine which of the kernel combination approaches introduced in the Section 2.2 should be incorporated. Hence, the prediction performance of models with several different kernel combinations has been evaluated. To accommodate missing values in data features in kernel combination methods KC1, KC3 and KC4, the element values of each kernel matrix are replaced with zeros corresponding to row or column with missing values to indicate no similarity measure among them. In KC2, the missing values in each dataset have to be first imputed with the average value of each data feature before concatenating all the data sets to form a single data matrix. The pairwise kernel values are later directly computed based the imputed data matrix before the training process. The work of Pavlidis (<ref type="bibr" target="#b29">Pavlidis et al., 2001</ref>) investigated the kernel combination approaches denoted here as KC1–KC3 for use with SVM models, while the following presents our evaluation of the methods for use with RVM-based models.<ref type="figure" target="#fig_4">Figure 4</ref>presents the performance based on 10-fold cross validation of the three kernel combination methods using precision–recall curves, while<ref type="figure" target="#tab_2">Table 2</ref>lists the classification errors for the two independent testing sets for the models. Based on the 10-fold cross-validation testing, the results indicate that the KC1 combination method outperforms the other methods. Pavlidis (<ref type="bibr" target="#b29">Pavlidis et al., 2001</ref>) also concluded that the KC1 method (their intermediate combination approach) when incorporated in a SVM model perform better than the other two combination methods in predicting yeast protein function. The KC2 and KC3 methods can not preserve the different semantic associations within data type as well as KC1, and hence produce inferior prediction performance. Moreover, the imputation implemented in KC2 may cause biased results (the effect of imputation will be illustrated in Section 3.3). In contrast, the KC1 method can subsequently sum up the kernel values of each data feature to represent different semantic association, and hence improve the performance progressively. However, we also find that KC3 has better generalization performance based on the classification error of the two independent sets. This latter point is not discussed in the work by Pavlidis (<ref type="bibr" target="#b29">Pavlidis et al., 2001</ref>). The KC3 method is a type of reduced-feature ensemble model (the number of sub feature set is 1) that trains a base model using a subset of all the data features. The reduced-feature ensemble model can generate better generalization performance than models trained by whole data features. The reduced-feature models are investigated further in Section 3.3. Next, to demonstrate the performance of the diffusion kernel in RVM-based model, we also compare results of KC1 to those of KC4, which does not employ a diffusion kernel to the graph-structure data features. The results in<ref type="figure" target="#tab_2">Table 2</ref>and<ref type="figure" target="#fig_4">Figure 4</ref>taken together show that KC1 outperforms KC4, indicating that the diffusion kernel can capture indirect gene–gene relationships from graph structure-data features to improve the prediction of pathway relationship. Therefore, the KC1 kernel combination approach incorporated in the RVM-based model will be used in all the results shown below. With this method, the model performance increases progressively as more datasets are integrated, thus allowing the model to include complementary pathway information, such as protein–protein interactions, protein phophorylation and transcription regulation (Supplementary<ref type="figure" target="#fig_3">Figure S3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction of functional genetic networks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Performance of RVM-based double ensemble model with missing values</head><p>Several additional approaches for dealing with missing values using RVM-based models are considered here using the kernel combination method KC1 (see Section 2.2). In the first scenario, denoted M1, the element values of kernel matrices are replaced with zeros corresponding to a row or column with missing values to indicate no similarity measure among them (methods denoted KC1 in Section 3.3). This scenario attempts to keep the data structure of complementary pathway information, but does not impute a value on the original missing data feature. In the second scenario (denoted M2), the missing values in each dataset are first imputed with the average value of each data feature. The kernel matrices are then computed based on the imputed data features. In the M1 and M2 model scenarios, RVM-AdaBoost (<ref type="figure" target="#fig_1">Fig. 2a</ref>) is applied to generate the discriminant result. The third scenario (M3) is the double ensemble model (<ref type="figure" target="#fig_1">Fig. 2b</ref>) that combines RVM, AdaBoost and the reducedfeature approach. The method of dealing missing values in the base model of M3 is same as the M1. The number of reduced-feature models in the M3 ensemble structure is set at 14, equal to the number of total data features, in order to allow comparison with the M1 model. The number of randomly chosen features in each base</p><p>Page: 812 807–813model is set to m = log 2 (k +1) ≈ 4 as in Random Forest (a threebased ensemble approach) (<ref type="bibr" target="#b6">Breiman, 2001</ref>), where k = 14 is the total number of our data features. (The results in the Supplementary Data S6 show that this rule is also applicable to the RVM-based model.) To further evaluate the performances of the RVM-based models in all the scenarios, we compare them with the baseline model, Naïve Bayes (denoted as NB in the<ref type="figure" target="#tab_3">Table 3</ref>), which is also the most popular approach used in prediction of genetic and protein interactions (<ref type="bibr" target="#b12">Franke et al., 2006;</ref><ref type="bibr" target="#b16">Jansen et al., 2003;</ref><ref type="bibr" target="#b33">Rhodes et al., 2005;</ref><ref type="bibr" target="#b41">Troyanskaya et al., 2003</ref>). The prior odds of the Naïve Bayes model is set to one, which is determined based on the proportion of total number of positive and negative examples in the benchmarks (<ref type="bibr" target="#b16">Jansen et al., 2003;</ref><ref type="bibr" target="#b33">Rhodes et al., 2005</ref>). In<ref type="figure" target="#fig_5">Figure 5</ref>, the performance based on 10-fold cross-validation of all the models is also presented using precision–recall curves.<ref type="figure" target="#tab_3">Table 3</ref>lists the average values and standard derivations of the performance measures of independent testing for all three approaches. Performances of the RVM-based models all surpass Naïve Bayes in the 10-fold validation testing. This indicates that RVM-based ensemble model can yield significant learning performance even as the data contain massive missing vales. Among the three scenarios, M2 is inferior to the other scenarios, especially based on its poor independent testing error. M2 differs from M1 and M3 mainly due to its imputation of missing values. Most imputation methods are based on the assumption of missing at random and missing completely at random, however, the assumption is not applicable to genetic network construction. Many missing values are actually caused by data complementariness due to different molecular relationships in pathways. For this reason, imputation may cause bias in the result. The M1 method shows comparable performance to M3 in 10-fold cross-validation testing, but results in a higher independent testing error. Both of M1 and M3 use the same method for handling the missing values. However, the reduce-feature structure of M3 can include base-models corresponding to training data with different patterns of missing values, and thus generate better performance. In addition, M3 may benefit from its double ensemble structure. The model diversity in M3 not only comes from sampling subsets of data points, but also from sampling subsets of data features. The higher variety of base models in M3 can help yield much lower generalization errors (details are in the Supplementary Data S6). We also find the number of vectors increases when applying the reduced-feature model (M3). However, the reduced-feature model has an important advantage: it is a lower-dimensional learning problem compared to the complete-feature learning, and thus can reduce computation costs both in the training and testing phases. Although more base models are included in the M3 ensemble structure, the number of vectors is still small compared to the total number of the training data points. The sparseness of RVM plays an important role on the reduction of the number of vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.-C.Wu et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>In this work, a graph-based approach is first presented to construct a more robust GSN than previous methods. Through validations using old and new KEGG pathways as well as the Gene Ontology, it has been shown that a robust GSN can be constructed by choosing the N most distant KEGG pathway relationships. The high values of F-measure and G-Mean (supplementary material S5) in all our results also indicate that our models can yield good classification performance on both positive and negative examples. This suggests that the proposed graph-based GSN is sufficiently robust that the overlap between GSP and GSN is small. With moderate sampling size, the RVM-based model with only a few vectors is able to significantly reduce both training and prediction time. It will be of interest to compare the performance of RVM-AdaBoost with SVM-AdaBoost (<ref type="bibr" target="#b8">Do and Fekete, 2007;</ref><ref type="bibr" target="#b22">Li et al., 2005</ref>) in future applications, especially with respect to prediction time that is dominated by the number of vectors in the final assembled model. This can clarify the advantage of RVMbased ensemble models on sparseness. The KC1 kernel combination approach in Section 2.2 has been shown to be an effective kernel integration approach in RVM-based model, which can retain the semantic association within each dataset and subsequently sum up kernel values of each dataset to improve the performance progressively. Through this method, it is observed that the model performance increases progressively as more datasets are integrated (Supplementary Data S5), thus allowing the model to predict complementary pathway information. We have also addressed the ability of the RVM-based models to classify the biological dataset with a large number of missing values. We find that the RVM-based model can yield significant performance even with massive missing data values, as shown by comparison with the Naïve Bayes baseline model. Among the three model scenarios, the double ensemble model (M3) can generate a much lower generalization error than the others because it includes base-models corresponding to training data with different patterns Page: 813 807–813</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction of functional genetic networks</head><p>of missing values. Our results also indicate that naïve imputation may not be suitable for complementary pathway data since each gene pair is only able to be presented in some types of genomic and proteomic data. In summary, the graph-based approach presented can generate robust GSN for the training process of genetic network construction. The RVM-based ensemble model also yields significant performance improvement even if it does not achieve the optimal results generated by the RVM model trained from the complete dataset. Finally, based on the results presented, the RVM-based ensemble model is a computationally practical and effective approach that can be used on large-scale and high-dimension problems even with massive missing data values..</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Two genes are linked together with solid lines if they function together in the present KEGG pathways (positive examples) while those connected with dotted lines do not function together. (a) illustrates potential positive examples. It would be more likely that genes 7 and 2 function together in some unknown pathways than genes 1 and 2, because the former pair shares more pathway partners. The width of the dotted line reflects the probability that a linkage exists. (b) Illustrates ideal negative examples. It would be less likely for genes 2 and 5 to function together in some unknown pathways than genes 2 and 3 or genes 2 and 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. (a) RVM-AdaBoost. (b) RVM-based double ensemble model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. (a) Proportion of gene pairs with specific topologic distances in the old KEGG network that function together in the new KEGG pathways. (b) GO scores of gene pairs with specific topologic distances in the old KEGG network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Precision–recall curves of models with different kernel combinations based on 10-fold cross-validation testing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Precision–recall curves of models with different ways for dealing with missing values based 10-fold cross-validation testing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>Funding: National Institute of Health grant P41-EB001978, US Department of Defense grant W81XWH-07-1-0580, and National Institute of Health's Child Health Research Career Development Award Program K12-CA60104. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1.</figDesc><table>Data features 

Data type 
No. of genes 
Data source 

Literature 
26 475 
Entrez gene 
Functional annotation 
14 667 
Ashburner et al. (2000) 
16 015 
16 507 
Protein domain 
15 565 
Ng et al. (2003) 
Protein–protein 
interaction and 
genetic interaction 

8787 
Entrez Gene 
2166 
Vastrik et al. (2007) 
6982 
Gary et al. (2003) 
9295 
Keshava Prasad et al. (2009) 
6279 
Shannon et al. (2003) 
Gene context 
11 303 
Bowers et al. (2004) 
Protein phosphorylation 
5490 
Linding et al. (2008) 
Gene expression profile 
19 777 
Obayashi et al. (2008) 
Transcription regulation 
937 
Ferretti et al. (2007) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. Performances of models with different kernel combinations using independent testing sets</figDesc><table>Combination 
Number of 
vectors 

Biocarta error (%) 
NCI_nature 
error (%) 

KC1 
121. ± 39.2 
2 3 .6 ± 2.44 
24.6 ± 2.83 
KC2 
981. ± 153. 
47.2 ± 3.47 
53.7 ± 2.16 
KC3 
40.6 ± 5.19 
15.2 ± 9.73 
16.0 ± 10.8 
KC4 
92.8 ± 20.35 
33.3 ± 2.15 
35.4 ± 2.40 

training and prediction phase (i.e. fewer vectors will be included in 
the final model) by choosing a moderate sampling size. We selected 
a sampling size of 500 and a maximum number of boosting iterations 
of 20 for the RVM-AdaBoost models as sufficient for genetic 
network construction in this work (details </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 3.</figDesc><table>Performances of different models with missing values using 
independent testing sets 

Model Number of vectors Biocarta error (%) NCI_nature error (%) 

NB 
– 
41.5 ± 0.08 
48.6 ± 0.08 
M1 
121. ± 39.2 
2 3 .6 ± 2.44 
24.6 ± 2.83 
M2 
104. ± 19.7 
3 4 .7 ± 2.22 
38.1 ± 2.53 
M3 
366. ± 34.2 
1 4 .3 ± 4.01 
13.9 ± 4.54 

</table></figure>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Gene Ontology: tool for the unification of biology</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ashburner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Reverse engineering of regulatory networks in human B cells</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Basso</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="382" to="390" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Kernel methods for predicting protein–protein interactions</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ben-Hur</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Noble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="38" to="46" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. 1</note>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Choosing negative examples for the prediction of protein-protein interactions</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ben-Hur</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Noble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Suppl. 1</note>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Relevance vector machine and support vector machine classifier analysis of scanning laser polarimetry retinal nerve fiber layer measurements</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bowd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1322" to="1329" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Prolinks: a database of protein functional linkages derived from coevolution</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">M</forename>
				<surname>Bowers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Random forests. Machine Learn</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A note on two problems in connexion with graphs</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Dijkstra</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische Math</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Large scale classification with support vector machine algorithms</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">N</forename>
				<surname>Do</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Fekete</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth Intl. Conf. Machine Learn. Appl</title>
		<meeting>. Sixth Intl. Conf. Machine Learn. Appl</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">What can we learn from noncoding regions of similarity between genomes?</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">A</forename>
				<surname>Down</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">J</forename>
				<surname>Hubbard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">131</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Entrez</forename>
				<surname>Gene Database</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>last. accessed date December</note>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">PReMod: a database of genome-wide mammalian cis-regulatory module predictions</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Ferretti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="122" to="126" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Database. issue</note>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Reconstruction of a functional human gene network, with an application for prioritizing positional candidate genes</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Franke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1011" to="1025" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Freund</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">E</forename>
				<surname>Schapire</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. &amp; Sys. Sci</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">BIND: the biomolecular interaction network database</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gary</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="248" to="250" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Analyzing protein function on a genomic scale: the importance of gold-standard positives and negatives for network prediction</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Jansen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gerstein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Microbiol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="535" to="545" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">A Bayesian network approach for predicting protein-protein interactions from genomic data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Jansen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">302</biblScope>
			<biblScope unit="page" from="449" to="453" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Human protein reference database-2009 update</title>
		<author>
			<persName>
				<forename type="first">Keshava</forename>
				<surname>Prasad</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">S</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="767" to="772" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Diffusion kernels on graphs and other discrete structures</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">I</forename>
				<surname>Kondor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lafferty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 19th Intl. Conf. Machine Learn</title>
		<meeting>. 19th Intl. Conf. Machine Learn</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="315" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint classifier and feature optimization for comprehensive cancer diagnosis using gene expression data</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Krishnapuram</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="227" to="242" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A probabilistic functional network of yeast genes</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="page" from="1555" to="1558" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">I</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transcriptional regulatory networks in Saccharomyces cerevisiae</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="799" to="804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">AdaBoost with SVM-based component classifiers</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Appl. Artificial Intell</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="785" to="795" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">NetworKIN: a resource for exploring cellular phosphorylation networks</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Linding</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="695" to="699" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">High-throughput electronic biology: mining information for drug discovery</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Loging</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Drug Discov</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="220" to="230" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">InterDom: a database of putative interacting protein domains for validating predicted protein interactions and complexes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Ng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="251" to="254" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">COXPRESdb: a database of coexpressed gene networks in mammals</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Obayashi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="77" to="82" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Popular ensemble methods: an empirical study</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">W</forename>
				<surname>Opitz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artificial Intell. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="169" to="198" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Reconstruction of cellular signaling networks and analysis of their properties</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Papin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Mol. Cell Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">Gene functional classification from heterogeneous data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Pavlidis</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>RECOMB</publisher>
			<biblScope unit="page" from="249" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Ensemble based systems in decision making</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Polikar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Circuits &amp; Systems Mag</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="21" to="45" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Evaluation of different biological data and computational classification methods for use in protein interaction prediction</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Qi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="490" to="500" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Predicting co-complexed protein pairs from heterogeneous data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Qiu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Noble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic model of the human protein-protein interaction network</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Rhodes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="951" to="959" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Towards a proteome-scale map of the human protein-protein interaction network</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">F</forename>
				<surname>Rual</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">437</biblScope>
			<biblScope unit="page" from="1173" to="1178" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Handling missing values when applying classification models</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Saar-Tsechansky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Provost</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1625" to="1657" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Cytoscape: a software environment for integrated models of biomolecular interaction networks</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Shannon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2498" to="24504" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Trends in microarray analysis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">L</forename>
				<surname>Stears</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Med</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="140" to="145" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">How molecular profiling could revolutionize drug discovery</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">B</forename>
				<surname>Stoughton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">H</forename>
				<surname>Friend</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Drug Discov</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="345" to="350" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Sparse Bayesian learning and the Relevance Vector Machine</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Tipping</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="211" to="244" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast marginal likelihood maximization for sparse Bayesian models</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Tipping</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Faul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nineth Artificial Intell. &amp; Stat</title>
		<imprint>
			<biblScope unit="page" from="3" to="6" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">A Bayesian framework for combining heterogeneous data sources for gene function prediction (in Saccharomyces cerevisiae)</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">G</forename>
				<surname>Troyanskaya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="8348" to="8353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<monogr>
		<title level="m" type="main">Reactome: a knowledge base of biologic pathways and processes</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Vastrik</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">External validation of mathematical models to distinguish between benign and malignant adnexal tumors: a multicenter study by the International Ovarian Tumor Analysis Group</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Van Holsbeke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">1315</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4440" to="447" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">Inferring genome-wide functional linkages in E. coli by combining improved genome context methods: comparison with high-throughput experimental data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Yellaboina</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="527" to="535" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">Genome-wide prediction of C. elegans genetic interactions</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Zhong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">W</forename>
				<surname>Sternberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="page" from="311" to="1481" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>