
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Logic Forest: an ensemble classifier for discovering logical combinations of binary markers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Bethany</forename>
								<forename type="middle">J</forename>
								<surname>Wolf</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Biostatistics and Epidemiology</orgName>
								<orgName type="institution">Medical University of South Carolina</orgName>
								<address>
									<addrLine>135 Cannon St</addrLine>
									<settlement>Charleston</settlement>
									<region>SC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Elizabeth</forename>
								<forename type="middle">G</forename>
								<surname>Hill</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Biostatistics and Epidemiology</orgName>
								<orgName type="institution">Medical University of South Carolina</orgName>
								<address>
									<addrLine>135 Cannon St</addrLine>
									<settlement>Charleston</settlement>
									<region>SC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Elizabeth</forename>
								<forename type="middle">H</forename>
								<surname>Slate</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Biostatistics and Epidemiology</orgName>
								<orgName type="institution">Medical University of South Carolina</orgName>
								<address>
									<addrLine>135 Cannon St</addrLine>
									<settlement>Charleston</settlement>
									<region>SC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Logic Forest: an ensemble classifier for discovering logical combinations of binary markers</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="issue">17</biblScope>
							<biblScope unit="page" from="2183" to="2189"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq354</idno>
					<note type="submission">Received on March 25, 2010; revised on June 4, 2010; accepted on June 28, 2010</note>
					<note>[15:28 30/7/2010 Bioinformatics-btq354.tex] Page: 2183 2183–2189 Associate Editor: Jonathan Wren Contact: wolfb@musc.edu Supplementary information : Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Highly sensitive and specific screening tools may reduce disease-related mortality by enabling physicians to diagnose diseases in asymptomatic patients or at-risk individuals. Diagnostic tests based on multiple biomarkers may achieve the needed sensitivity and specificity to realize this clinical gain. Results: Logic regression, a multivariable regression method predicting an outcome using logical combinations of binary predictors, yields interpretable models of the complex interactions in biologic systems. However, its performance degrades in noisy data. We extend logic regression for classification to an ensemble of logic trees (Logic Forest, LF). We conduct simulation studies comparing the ability of logic regression and LF to identify variable interactions predictive of disease status. Our findings indicate LF is superior to logic regression for identifying important predictors. We apply our method to single nucleotide polymorphism data to determine associations of genetic and health factors with periodontal disease. Availability: LF code is publicly available on CRAN, http://cran.r-project.org/.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Diseases often stem from complex gene–gene and gene–environment interactions and single biomarkers typically perform poorly with respect to sensitivity and specificity (Alvarez<ref type="bibr" target="#b5">Castro and Carlborg, 2007;</ref><ref type="bibr" target="#b22">Kotti et al., 2007;</ref><ref type="bibr" target="#b23">Kumar et al., 2006</ref>).<ref type="bibr" target="#b24">Lo and Zhang (2002)</ref>note that common statistical methods for screening high-dimensional biomarker data focus on only main effects and do not capture interactions that lead to disease. Failure to recognize interactions among genes leads to the inability to replicate study results in human populations (<ref type="bibr" target="#b9">Carlborg and Haley, 2004</ref>). Many authors suggest that a panel of biomarkers rather than a single marker has the potential to provide improvements in sensitivity and specificity required to replace traditional diagnosis (see, e.g.<ref type="bibr" target="#b23">Kumar et al., 2006;</ref><ref type="bibr" target="#b25">Manne et al., 2005;</ref><ref type="bibr" target="#b32">Srivastava, 2005</ref>). Diseases for which panels of markers demonstrate improved sensitivity and specificity over single markers include prostate, * To whom correspondence should be addressed. ovarian and bladder cancer and heart disease (<ref type="bibr" target="#b25">Manne et al., 2005;</ref><ref type="bibr" target="#b27">Negm et al., 2002;</ref><ref type="bibr" target="#b34">Wagner et al., 2004;</ref><ref type="bibr" target="#b35">Zethelius et al., 2008</ref>). Non-parametric tree-based methods are easily interpretable and have flexibility to identify relationships among predictor variables (<ref type="bibr" target="#b7">Austin, 2007</ref>). Logic regression (LR;<ref type="bibr" target="#b28">Ruczinski et al., 2003</ref>) is a tree-based method capable of modeling a binary, continuous or survival response with higher order interactions among binary predictors. In this article, we focus on classification of a binary response. LR generates classification rules by constructing Boolean ('and'= ∧, 'or'= ∨, and 'not'= !) combinations of binary predictors for classification of a binary outcome. An LR model is represented as a tree with connecting nodes as the logical operators and terminal nodes (called leaves) as the predictors. LR has been used in the development of screening and diagnostic tools for several diseases and has shown modest improvements in sensitivity and specificity compared with traditional approaches such as logistic regression and CART (<ref type="bibr" target="#b11">Etzioni et al., 2003</ref><ref type="bibr" target="#b12">Etzioni et al., , 2004</ref><ref type="bibr" target="#b16">Janes et al., 2005;</ref><ref type="bibr" target="#b19">Kooperberg et al., 2007;</ref><ref type="bibr" target="#b33">Vermeulen et al., 2007</ref>). LR can be unstable when data are noisy. In the context of identifying interacting genetic loci, performance was poor for frequently occurring interactions only weakly associated with the response (<ref type="bibr" target="#b33">Vermeulen et al., 2007</ref>). A study designed to identify regulatory motifs confirmed that increasing noise in data severely limited the ability of LR to correctly identify the true model in simulated data (<ref type="bibr" target="#b17">Keles et al., 2004</ref>). Ensemble extensions of tree-based methods demonstrate improved predictive accuracy (<ref type="bibr" target="#b8">Breiman, 1996;</ref><ref type="bibr" target="#b10">Dietterich, 2000;</ref><ref type="bibr" target="#b14">Friedman, 2001</ref>). Two ensemble adaptations of LR are available. Monte Carlo LR (MCLR) builds a series of models from the training dataset using Monte Carlo methods and identifies groups of predictors that co-occur across all models (<ref type="bibr" target="#b18">Kooperberg and Ruczinski, 2005</ref>). However, the relationship among predictors (∧, ∨ and !) is unclear. LogicFS, a bagging version of LR, constructs an ensemble by drawing repeated bootstrap samples and building LR models from each (<ref type="bibr" target="#b8">Breiman, 1996;</ref><ref type="bibr" target="#b30">Schwender and Ickstadt, 2008</ref>). In contrast to MCLR, logicFS identifies explicit predictor interactions [referred to as prime implicants (<ref type="bibr">PIs)]</ref>. Additionally, logicFS provides a measure of variable interaction importance. In Section 2, we present a new ensemble of logic trees approach called Logic Forest (LF), and introduce a new permutation-based measure of predictor importance. We also develop the idea of subset matching as an additional means of identifying important interactions. We present a simulation study in Section 3 comparing the performance of LR and logicFS with LF considering data with noise in the predictors, latent predictors and varying true model<ref type="bibr">[</ref>complexity. We apply LF to periodontal disease data in Section 4 and discuss the results of our simulation studies in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DEFINITIONS AND NOTATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LF</head><p>Given observed data W = y,x recorded on n subjects consisting of a binary response y = y 1 ,...,y n and p binary predictors</p><formula>x i = x i1 ,...,x ip , i = 1</formula><p>,...,n, LR constructs a tree T describing</p><p>Boolean combinations of predictors that best classify the response. For example, LR might produce the expression</p><formula>y * = y * 1 ,...,y * m for x * ,</formula><p>we calculate the misclassification rate as:</p><formula>MC T b ,y * ,x * = 1 m m =1 y * − y {T b },x * 2. (2)</formula><p>Associated with tree b in the forest is an out-of-bag dataset, OOB (T b ), comprising observations not included in the bootstrap sample used to construct T b. If test data are not available, we can use OOB (T b ) to obtain an unbiased estimate of the forest's misclassification rate. Let W i = (y i ,x i ) ∈ W, and let O (W i ,T b ) = I (W i ∈ OOB (T b ) ) indicate the i-th observation's membership in OOB (T b ). The LF OOB prediction is</p><formula>y OOB i T b ,x i = ⎧ ⎨ ⎩ 1 if B</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Variable importance measures</head><p>Let X be a predictor or, more generally, a PI occurring in the tree. The importance of X in an LR model, VIMP.LR X , is determined by X's presence or absence in a fitted tree, T , providing a crude assessment of association with response. An advantage of LF over LR is the availability of many trees for identifying important predictors and PIs. Our LF importance measure for predictor X j ,j = 1,...,p, is based on the misclassification rates for each tree in the forest. Denote the OOB misclassification rate for T b by</p><formula>MC OOB T b ,y,x = n i=1 y i − y i T b ,x i 2 O W i ,T b n</formula><formula>(6)</formula><p>Values range between −1 and 1, with positive values suggesting a positive association between response, Y, and predictor X j. More generally, (6) can be computed with X j being a PI. An algorithm similar to LF, called logicFS, was introduced by<ref type="bibr" target="#b30">Schwender and Ickstadt (2008)</ref>. Unlike logicFS, LF randomly selects the maximum size when building each tree in the ensemble. Although tree size can vary in logicFS, flexibility in the upper bound for the maximum number of leaves in a tree enhances the probability that the forest will discover smaller PIs. Additionally, Schwender and Ickstadt provide a different measure of PI importance obtained by replacing the permutation step in (6) with addition or removal of the PI in tree T b , which we will refer to as VIMP.FS (<ref type="bibr" target="#b30">Schwender and Ickstadt, 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Subset matching</head><p>Let F be the set of unique PIs identified in a LF consisting of B trees. When a given PI, P for example, is an element of F, we say P is an 'exact match'. We say P is a 'subset match' for a forest if P is an exact match or P ∧Q is an element of F for some PI, Q. For example, LF might identify PI 1 =X 4 ∧X 5 and PI 2 =X 4 ∧X 5 ∧X 6. The PI X 4 ∧X 5 is an exact match to PI 1 and a subset match to PI 2. The concept of subset matching enables us to fully detect contributions of PIs to the fitted trees in LF W,B . Also, if a PI has multiple subset matches to increasingly larger PIs in F, then that PI is said to persist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SIMULATIONS</head><p>We compare the performance of LR and logicFS with LF using eight simulation studies. Each simulation is characterized by an underlying logical relation L and predictor noise level. A training dataset W = (y,x) used to construct LRmodels, FS W,B , is generated by simulating error-free Bernoulli predictors z and obtaining the observed response y = L(z). Observed predictors x are constructed such that x j = 1−z j with probability π and otherwise x j = z j where π is a prespecified noise level. We focus on the effects of predictor noise, the complexity of L and an omitted predictor, the last motivated by our experience that complexity of biological networks prohibits observation of all related variables.<ref type="figure" target="#tab_1">Table 1</ref>(i) mean model error rate, defined as the misclassification rate of the fitted model for the test dataset (2); (ii) identification of PIs in L according to VIMP.LR and inclusion in K for LF; and (iii) identification of PIs in L according to subset matching as described in Section 2.3 for LR and according to subset matching to K for LF and logicFS. We use the LogicReg package (<ref type="bibr" target="#b19">Kooperberg and Ruczinski, 2007</ref>) in R v. 2.7.1 (R Development Core Team, 2009) with simulated annealing optimization to fit all LR models. Maximum model size for LR models is selected using the cross-validation procedure suggested by<ref type="bibr" target="#b28">Ruczinski et al. (2003)</ref>. Cross-validation improves LR model performance by reducing the likelihood of over-fitting. LogicFS models are constructed using the logicFS package (<ref type="bibr" target="#b31">Schwender, 2007</ref>) available at www.bioconductor.org. The LF algorithm (Section 2.1) is used to generate all ensemble models. LogicFS and LF models include B = 100 logic regression trees. The same starting and ending annealing temperatures are selected for LR, logicFS and LF. The starting temperature of 2 is selected such that ∼90% of 'new' models are accepted. The final temperature of −1 is set to achieve a score where &gt;5% of new models are accepted. The cooling schedule is set so that 50 000 iterations are required to get from start to end temperature. Increasing the number of iterations to 250 000 did not affect our findings. With these settings, an ensemble is constructed in less than a minute on a Windows 2.26 GHz machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Predictor noise</head><p>Cases 1 and 2 (<ref type="figure" target="#tab_1">Table 1</ref>) examine the effects of noisy predictors on LR, logicFS and LF performance. The results for the mean model error rates for samples sizes 25, 200 and 1000 are shown in<ref type="figure" target="#tab_2">Table 2</ref>. Model error rates are similar at all sample sizes for all three methods for Cases 1 and 2.<ref type="figure">Figure 1</ref>shows the proportion of times each method recovered the PI X 4 ∧X 5 using exact and subset matching by sample size for each noise level. Error bars in the figure represent 95% confidence intervals for the proportions.<ref type="figure">Figure 1</ref>shows that LF is significantly more likely to exactly identify the PI X 4 ∧X 5 than LR for sample sizes n = 25 to 100 in data with 5% noise and for n = 25 to 300 in data with 15% noise. The performance of LF and logicFS is similar in data with 5% noise although LF more frequently exactly identifies the PIs forsample sizes n ≤ 50. LF exactly identifies X 4 ∧X 5 significantly more frequently than logicFS in data with 15% noise for sample sizes from n = 35 to 200. The results for PI X 5 ∧X 11 were similar to those of X 4 ∧X 5 (results not shown). The performance of the three methods does not improve significantly with subset matching in data with 5% noise. However, in data with 15% noise, the ability of all three methods is enhanced under subset matching. Although the performance of LR and logicFS is closer to LF when subset matching is used, LF still identifies the PIs more frequently than logic FS for 50 ≤ n ≤ 150 and more frequently that LR for 25 ≤ n ≤ 300. Both LR and logicFS identify the relationship between X 4 and X 5 and between X 5 and X 11 , but the tendency is to add spurious components to the PI. We also consider a null scenario in which there is no association between predictors and the response. The predictors follow the distribution for Cases 1 and 2 (<ref type="figure" target="#tab_1">Table 1</ref>) and the response is L iid</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model complexity</head><p>Cases 3–6 (<ref type="figure" target="#tab_1">Table 1</ref>) examine the effect of model complexity on the ability of each method to correctly identify PIs truly associated with the response and on the error rate of the fitted model. Cases 3 and 4 investigate a simple logic expression, L 1 , describing the response using two PIs of size 2. Cases 5 and 6 investigate a more complex model, L 2 , containing three PIs, two of Size 4 and one of Size 5. These models also have a lower probability of an observed response value of 1 relative to Cases 1 and 2, which has been shown to reduce the ability of LR to identify interactions known to be important (<ref type="bibr" target="#b33">Vermeulen et al., 2007</ref>).of LF is significantly smaller than both LR and logic for n = 25 in Cases 3 through 5. However, logicFS has smaller mean model error rate than LF and LR in Cases 3 and 5 for n ≥ 200. The difference in mean model error rates for logicFS and LF is significant for n ≥ 500 for Case 3 and for n ≥ 300 for Case 5. From<ref type="figure" target="#fig_1">Figure 2</ref>, for data with a simple underlying model L 1 and 5% noise in the predictors LF is significantly more likely to exactly identify the true PI, X 4 ∧X 5 , than LR and logicFS for n ≥ 35 and for 35 ≤ n ≤ 500, respectively. The results for recovery of X 5 ∧X 11 are similar in data with 5% predictor noise. In data with 15% noise, LR</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 2187 2183–2189</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logic Forest</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and logicFS exactly identify these PIs X 4 ∧X 5 and X 5 ∧X</head><p>11 in &lt;5% of models at all sample sizes. However, LF exactly identifies the PIs in &gt;60% of all models once n = 150 (see<ref type="figure">Fig. 1</ref>, Section 1 of the Supplementary Material). A comparison of the performance of both methods for Cases 1 and 2 versus Cases 3 and 4, which consider the same simple model but with P</p><formula>L 1 = 1 = 0.375 compared with P L 1 = 1 = 0.09375</formula><p>, respectively, indicate that all three methods are less likely to recover the true PIs if there is reduced probability of a response being 1 (Figs 1 and 2). In the complex model, L 2 , LF and logicFS exactly identify the two PIs of Size 4 with greater frequency than LR at sample sizes n ≥ 150 for both noise levels. LF and logicFS identify all PIs in L 2 equally well with the exception of the two PIs of Size 4 at n = 75 and the largest PI at n = 1000 where logicFS exactly identifies these PIs more frequently than LF. All three methods have difficulty in identifying the largest PI in L 2 (<ref type="figure">Fig. 3</ref>). This is likely due to the fact that the largest PI explains only a small proportion of variation in the response. In data with 15% noise, the proportion of times the two Size 4 PIs are recovered is greatly reduced for all three methods. However, LF exactly identifies the two Size 4 PIs more frequently than LR for n ≥ 150 and than logicFS for n ≥ 300. LF achieves a maximum of 23% of models containing exact matches compared with 15% for logicFS and 2% for LR. In data with 15% noise, none of the methods is able to recover the largest PI exactly. LR, logicFS and LF all demonstrate improved performance for true underlying model L 1 when evaluated by subset matching. However, LF identifies the two PIs from model L 1 more often than LR and logicFS for sample sizes between n = 75 and n = 200 in data with 5% noise and between n = 75 and n = 300 for data with 15% noise. Use of subset matching for identifying PIs in the complex model L 2 only significantly improves the performance of the three methods in data with 15% predictor noise (see<ref type="figure" target="#fig_1">Fig. 2</ref>, Section 1 in the Supplementary Material). LogicFS and LF both identify the PIs of Size 4 more frequently than LR as subset matches for n ≥ 300. LogicFS identifies these two PIs more frequently as subset matches than LF for n ≥ 750. Even using subset matching, all three methods have difficulty identifying the Size 5 PI in the complex model at both noise levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Latent predictors</head><p>In Cases 7 and 8 (<ref type="figure" target="#tab_1">Table 1</ref>), we consider models in which a latent variable directly affects one or more PIs explanatory of the response. The true response for Case 7, L 3 , has two PIs but only Z 5 ∧Z 11 ∧Z 21 contains the latent predictor Z 21. In Case 8, the response, L 4 , has similar PIs and both PIs are affected by the latent predictor. Corresponding to the latency of Z 21 , predictor X 21 is not observed and therefore not available when constructing the models; thus we cannot identify the true PIs. For these cases, we determine the proportion of times each method identifies X 4 ∧X 5 and X 5 ∧X 11 , the observed components of the true PIs. The mean model error rate was not statistically different at a majority of sample sizes (results not shown). The only exception occurs at n = 25 where LF and logicFS have significantly smaller mean error rates than LR.<ref type="figure" target="#fig_3">Figure 4</ref>shows the proportion of times each method recovers the two partial PIs by sample size for L 3. The ability of each method to recover the partial PIs X 4 ∧X 5 or X 5 ∧X 11 depends on the model. For L 3 , where only the relationshipbetween X 5 and X 11 is strongly affected by the absence of X 21 , X 4 ∧X 5 is exactly recovered in 100% of models for n &gt; 150 for all three methods, while exact recovery of X 5 ∧X 11 occurs much less frequently (<ref type="figure" target="#fig_3">Fig. 4</ref>). LF is more adept at exactly recovering X 5 ∧X 11 than LR and logicFS at all sample sizes. LR and logicFS rarely recover the exact PI X 5 ∧X 11 for data generated under L 3 (<ref type="figure" target="#fig_3">Fig. 4</ref>). In L 4 , LR and logicFS rarely exactly recover either PI even with increasing sample size. However, LF is able to exactly identify both PIs in L 4 in up to 60% of models (see<ref type="figure">Fig. 3</ref>, Section 2 in the Supplementary Material). For X 5 ∧X 11 for L 3 and for both X 4 ∧X 5 and X 5 ∧X 11 for L 4 , the performance of LR and logicFS improves greatly with subset matching. Despite improvement in the performance of LR with subset matching, LF performs significantly better than LR in both models and for all sample sizes n ≥ 35 (<ref type="figure" target="#fig_3">Fig. 4</ref>). However, logicFS identifies the PI X 5 ∧X 11 in L 3 significantly more frequently as subset matches than LF for sample sizes ranging between n = 75 and n = 200. LogicFS also identifies both PIs in L 4 as subset matches more frequently than LF for n ≥ 500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PERIODONTAL DISEASE IN AFRICAN AMERICANS WITH DIABETES</head><p>We examine the association of genetic and health factors with prevalence of generalized adult periodontitis using data from a study conducted at the Center for Oral Health Research at the Medical University of South Carolina. Here, generalized adult periodontitis is defined as ≥3 mm clinical attachment loss and &gt;30% of sites affected. These data are drawn from 244 African American adults with diabetes. Information on each subject includes the binary health indicators total cholesterol (&gt;200 mg/dl),HDL(&gt; 40mg/dl), triglycerides (&gt;150mg/dl), C-reactive protein levels (&gt;1mg/l), HbA1c levels (&gt;7%), smoking status (current versus former and never, former versus current and never) and genotype data for nine single nucleotide polymorphisms (SNPs) believed to play a role in inflammation and/or bone resorption. Among the 244 participants in the study, 95 have generalized adult periodontitis. Seven of the SNPs are coded by two dummy variables for the LF analysis. The first dummy variable takes value 1 if the subject has a SNP genotype with at least one copy of the minor allele (dominant effect of the minor allele) and the second takes value 1 if the subject has two copies of the minor allele (recessive effect of the minor allele). This coding allows for consideration of both dominant andrecessive genetic effects in the model. The remaining two SNPs for which no subjects have two copies of the minor allele are coded for the dominant genetic effect only. The final dataset includes 23 binary predictors composed of these 16 SNP dummy variables and seven health indicators. Two LF models, each with B = 100 trees, are constructed from the data. The first LF model includes all SNPs and health indicators as predictors. The second model is constructed with only the SNPs as predictors. The top five PIs for both models, as determined by VIMP.LF magnitude, are shown in<ref type="figure" target="#fig_5">Figure 5</ref>. VIMP.LF scores are normalized so the largest is 1. The most important single predictor identified by the models is the recessive genetic effect for the IL1α −889 minor allele (IL1A1.22). Previous studies suggest that the minor allele of IL-1α −889 is associated with advanced periodontitis, though these studies considered only the dominant genetic effect (<ref type="bibr" target="#b15">Gore et al., 1998;</ref><ref type="bibr" target="#b21">Kornman et al., 1997;</ref><ref type="bibr" target="#b26">Moreira et al., 2007</ref>). Also two PIs selected among the top five by VIMP.LF magnitude appear in both models: (i) IL1B.12 ∧ IL1A1.22 and (ii) IL1A1.22 ∧ !MMP3.12 (<ref type="figure" target="#fig_5">Fig. 5</ref>). IL1A1.22 represents the recessive genetic effect for the IL-1α −889 minor allele, IL1B.12 represents the dominant genetic effect for the IL-1β +3954 minor allele and !MMP3.12 represents the recessive genetic effect for the MMP3 major allele. PI(a), IL1B.12 ∧ IL1A1.22, suggests an association consistent with previous reports (<ref type="bibr" target="#b15">Gore et al., 1998;</ref><ref type="bibr" target="#b21">Kornman et al., 1997</ref>). The recessive genetic effect for the MMP3 minor allele is implicated in chronic periodontitis in a Brazilian population (<ref type="bibr" target="#b6">Astolfi et al., 2006</ref>), but the interaction described by PI(b) has not been noted previously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>LR has the ability to model complex interactions such as those that might describe a disease state. To improve identification of important PIs, Schwender and Ickstadt (2008) presented a bagged version of LR called logicFS. Unlike their approach, our method randomly selects a maximum size when building each tree in the ensemble, thereby enhancing the probability that the forest will discover smaller PIs. We also introduce a permutation measure to quantify PI importance. Additionally, we present the notion of subset matching to enhance sensitivity to PI contributions. We extend simulations in previous studies evaluating the performance of LR, logicFS and our ensemble of LR trees, LF, by including larger sample sizes, noise in the predictors and smaller probabilities of the response variable taking value 1. Our results show that LF and logicFS are better able identify important PIs than LR. LF also demonstrates improved ability to recover PIs relative to logicFS at smaller sample sizes in a majority of the simulation scenarios. We also show that forced inclusion of smaller trees in the forest is beneficial for PI identification, particularly in data with latent variables or noisy predictors. Using the permutation-based measure of variable importance, LF is more adept at identifying informative PIs in noisy data, in data with a latent variable and in more complex true models than LR and logicFS. The greatest improvement from LF occurs in scenarios where PIs are smaller and more weakly associated with a response or in situations where there is failure to observe a predictor truly associated with the response. LF also exhibits greater improvement relative to LR as sample size increases, while the largest improvements in performance of LF relative to logicFS occurs at smaller sample sizes (35 ≤ n ≤ 200). The main exception occurs for data following a complex underlying model where the performance of LF and logicFS is similar for recovery of the three PIs in L 2 (<ref type="figure">Fig. 3</ref>). LR, logicFS and LF all demonstrate limited ability to recover large PIs weakly associated with the outcome in the presence of smaller PIs with stronger associations. We also introduce the idea of subset matching. If a PI persists in increasingly larger PIs, then that PI may represent a true association. For example, discovery of the PIs P, P ∧Q 1 and P ∧Q 2 ∧Q 3 suggests a true association of the PI P with the response. In LF, as opposed to LR, we have the richness of the forest in which to evaluate this persistence of predictors and PIs. Especially in a latent variable setting, where not all components of a predictive PI are observed, persistence throughout the forest facilitates identification of the observed components of that PI. LF, LR and logicFS were also compared with Random Forest (RF) and MCLR. The mean model error rate for RF was larger than all three methods for a majority of sample sizes for simulation Cases 1, 2, 3, 5 and 7 and comparable with LF for Cases 4 and 8. RF is designed to identify important individual predictors from among all predictors in the data and concerning identification of individual predictors, RF performed comparably with LF. However, RF provides no direct mechanism for quantifying associations among predictor interactions and response. MCLR is designed to identify predictors that co-occur with the greatest frequency. MCLR identified predictor combinations from true PIs in &lt;5% of all models for all simulation scenarios (results are not shown). The simulations presented in this article are by no means an exhaustive study of all scenarios one might encounter in biologic data. However, this study provides insight into the effectiveness of ensemble methods, LF in particular, in improving the identification of PIs in scenarios likely in biological studies. LF is not designed to handle data with a larger number of predictors than observations. Based on simulations examining the performance of LF, data should have at least twice as many observations as predictors for the best performance. The methods and measures presented in this study were restricted to classification trees. LR has the ability to build trees as predictors in linear and logistic regression models by altering the scoring functions used in constructing the LR model (sums of squares and deviance, respectively). Further studies are necessary to assess the performance of LF with such alternative scoring functions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>describes these three scenarios encompassing eight simulation cases. We consider sample sizes ranging from 25 to 1000. For each combination of simulation case and sample size, we generate 500 datasets. We evaluate the performance of LR W , FS W,B and LF W,B using a test dataset of 100 observations generated in the same way as the training data. For model evaluation, let K (K ⊂ F) be the set of five PIs in LF W,B or FS W,B with maximum absolute VIMP.LF or VIMP.FS values, respectively. Evaluation criteria are:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Recovery of the PI X 4 ∧X 5 for L 1 (Case 3) with P L = 1 = 0.09375, in data with 5% noise in all predictors. N = 500 replications for each sample size. Error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig</head><figDesc>Fig. 3. Recovery of the PIs X 4 ∧X 5 ∧X 21 ∧!X 45 and X 5 ∧X 16 ∧X 21 ∧ X 33 ∧!X 45 for the complex model, L 2 (Case 5), in data with 5% noise in all predictors. N = 500 replications for each sample size. Error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. Recovery of exact and subset matches for observed components of the PI X 5 ∧X 11 ∧X 21 for L 3 (Case 7). N = 500 replications for each sample size. Error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Normalized VIMP.LF for model including SNPs and health indicators (LF1) and model including only SNPs (LF2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>T = X 4 ∨X 11 ∧ X 5. T 2 = X 3 ∧X 4 ∧X 5 ∨ X 3 ∧X 5 ∧X 11 ∨ X 3 ∧!X 3 ∧X 5 is the DNF of the expression T 1 = X 4 ∨X 11 ∨!X 3 ∧ X 5 ∧X 3 . T 2 , however, is not in reduced DNF as its third term can be further simplified yielding the three PI reduced DNF form, T 3 = X 3 ∧X 4 ∧X 5 ∨ X 3 ∧X bootstrap samples, W b , from W. For each b, a positive integer M b is selected limiting the size of tree T b in the ensemble by specifying the maximum number of terminal nodes (leaves); thus, random selection of M b from within specified ranges ensures variability of tree sizes within LF. Given values for the p predictors for m new observations, x * (an m×p matrix), and a forest of B trees</figDesc><table>A logic expression (i.e. tree) can be expressed in reduced 
disjunctive normal form (DNF), defined as a series of PIs joined 
by ∨ operators (Fleisher et al., 1983). PIs capture predictor 
interactions as ∧ combinations that cannot be further reduced 
(Schwender and Ickstadt, 2008). For example 5 ∧X 11 
∨X 5 . Henceforth, 

all logic expressions will be in reduced DNF. The complexity of a 
tree is defined by the size and number of PIs. A PI's size is defined as 
the number of predictors in the PI. Given an LR model, LR 

W 
= T , 

and a new observation consisting of predictors x with dimension 
1×p, the prediction made by T is y 

T ,x 

taking values 0 or 1. 
The LF of B trees, denoted LF 

W,B 
={T 1 ,...,T B }={T b },b = 

1,...,B, is an ensemble of LR trees constructed from B LF 

W,B 

, the predicted values, 
y 

{T b },x  *  

, are based on a majority vote so that 

y 

T b 


,x  *  


= 


1 if 1 

B 

B 
b=1 y 


T b ,x  *  


≥ 0.5 

0 otherwise 
(1) 

where x  *  
is the th row of x  *  . Given response </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>− y OOB i {T b },x i 2. (4)</figDesc><table>b=1 y i 


T b ,x i 

O 

W i ,T b 
B 

b=1 O 


W i ,T b 


≥ 0.5 

0 else. 

(3) 

The LF OOB misclassification rate is 

MC OOB 


T b 


,y,x 

= 1 

n 

n 

i=1 


y i </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>denote the matrix of predictors with X j randomly permuted. We define the variable importance measure for X j by VIMP.LF X j =</figDesc><table>i=1 O 


W i ,T b 

. (5) 

Let x 


j 


1 
B 

B 

b=1 


MC OOB 


T b ,y,x 


j 


−MC OOB 

T b ,y,x 


. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>Table 1. 1 ,z 2 ,...,z 20 iid ∼ Bern 0.5 L 1 = Z 4 ∧Z z 1 ,z 2 ,...,z 50 iid ∼ Bern 0.5 Z 5 ∧Z 11 ∧Z 21 ∧!Z 45 ∨ 1 ,z 2 ,...,z 21 iid ∼ Bern 0.5 L 3 = Z 4 ∧Z 5 ∨ Z 5 ∧Z</figDesc><table>Simulation scenarios for all eight cases 

Case 
Scenario 
True predictors 
True response 

L 

P 

L = 1 

Predictor 
noise (π) 

1 
Predictor noise 
z 5 
∨ 

Z 5 ∧Z 11 

0.3750 
0.05 
2 
0.3750 
0.15 

3 
Model complexity 
z i ,i = 1,2,...,50 

iid 

∼ Bern 

0.50 

if i = 4,5,11 
L 1 = 

Z 4 ∧Z 5 
∨ 

Z 5 ∧Z 11 

0.09375 
0.05 

4 
z i 

iid 

∼ Bern 

0.23015 

if i = 4,5,11 
0.09375 
0.15 

5 
L 2 = 

Z 4 ∧Z 5 ∧Z 21 ∧!Z 45 
∨ 
0.10156 
0.05 

6 

Z 5 ∧Z 16 ∧Z 21 ∧Z 33 ∧!Z 45 

0.10156 
0.15 

7 
Latent predictor a 
z 11 ∧Z 21 

0.3125 
0.025 
8 
L 4 = 

Z 4 ∧Z 5 ∧Z 21 
∨ 

Z 5 ∧Z 11 ∧Z 21 

0.1875 
0.025 

For the latent predictor scenario a , Z 21 represents a latent predictor and is not observed in the data used to construct LR, logicFS, and LF models. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 2. Mean model error rate for simulation Cases 1–6 (Table 1)</figDesc><table>Case 
Predictor 
Sample 
LR mean 
logicFS mean 
LF mean 
noise (%) 
size 
error rate 
error rate 
error rate 

1 
5 
25 
0.190 
0.190 
0.184 
200 
0.070 
0.060 
0.061 
1000 
0.062 
0.060 
0.060 

2 
15 
25 
0.320 
0.314 
0.310 
200 
0.200 
0.201 
0.199 
1000 
0.174 
0.173 
0.173 

3 
5 
25 
0.135 
0.124 
0.104 
200 
0.062 
0.063 
0.064 
1000 
0.055 
0.048 
0.053 

4 
15 
25 
0.136 
0.127 
0.108 
200 
0.107 
0.103 
0.103 
1000 
0.102 
0.102 
0.101 

5 
5 
25 
0.130 
0.124 
0.102 
200 
0.081 
0.079 
0.082 
1000 
0.063 
0.049 
0.080 

6 
15 
25 
0.125 
0.116 
0.105 
200 
0.104 
0.102 
0.100 
1000 
0.100 
0.098 
0.100 

Error rate variance ranges between 1.1×10 −4 and 1.4×10 −7 . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Page: 2186 2183–2189 B.J.Wolf et al. Proportion of Times Recovered</figDesc><table>Exact Match, 5% Noise 
Subset Match, 5% Noise 

Exact Match, 15% Noise 
Subset Match, 15% Noise 

Sample Size 

Fig. 1. Recovery of the PI X 4 ∧X 5 for model L 1 (Cases 1 and 2) in data with 
5 or 15% noise in all predictors. N = 500 replications for each sample size. 
Error bars represent 95% confidence intervals. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>∼ Bern 0.375 . We simulate 500 datasets for sample sizes ranging from 25 to 1000 and examine the proportion of times each method recovers the PIs X 4 ∧X 5 and X 5 ∧X 11 according to the criteria defined for these simulations. All three methods recover these PIs in &lt;2% of all simulation runs at all sample sizes.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><figDesc>. 3. Recovery of the PIs X 4 ∧X 5 ∧X 21 ∧!X 45 and X 5 ∧X 16 ∧X 21 ∧ X 33 ∧!X 45 for the complex model, L 2 (Case 5), in data with 5% noise in all predictors. N = 500 replications for each sample size. Error bars represent 95% confidence intervals. Results for average model error rates for sample sizes 25, 200 and 1000 (5 and 15% noise) for Cases 3–6 are shown in Table 2. Figure 2 represents the proportion of times each method recovers L 1 's PI X 4 ∧X 5 , exactly and by subset matching, for 5% predictor noise. Figure 3 represents the proportion of times each method recovers L 2 's PIs X 4 ∧X 5 ∧X 21 ∧!X 45 and X 5 ∧X 16 ∧X 21 ∧X 33 ∧!X 45 for 5% noise. The mean model error rate</figDesc><table></table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2183 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This manuscript has been significantly improved based on comments from the reviewers and the associate editor. The authors thank the South Carolina COBRE for Oral Health and Dr J. Fernandes for the use of the periodontal SNP data.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page" from="28" to="30" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq354. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2189" to="2183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Logic Forest Funding: National Institute of General Medicine (grant T32GM074934, partially); National Cancer Institute (grant R03CA137805, partially); National Institute of Dental and Craniofacial Research (grant K25DE016863, partially); National Institute of Dental and Craniofacial Research (grant P20RR017696, partially)</title>
	</analytic>
	<monogr>
		<title level="j">National Science Foundation Division of Mathematical Sciences</title>
		<imprint/>
	</monogr>
	<note>grant. 0604666, partially</note>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Conflict of Interest: none declared</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">REFERENCES</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">A unified model for functional and statistical epistasis and its application in quantitative trait loci analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Alvarez-Castro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Carlborg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="1151" to="1167" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Genetic polymorphisms in the MMP-1 and MMP-3 gene may contribute to chronic periodontitis in a brazilian population</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Astolfi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Periodontol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="699" to="703" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A comparison of regression trees, logistic regression, generalized additive models, and multivariate adaptive regression splines for predicting AMI mortality</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">C</forename>
				<surname>Austin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2937" to="2957" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Bagging Predictors</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Epistasis: too often neglected in complex trait studies?</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Carlborg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">S</forename>
				<surname>Haley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="618" to="625" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">An experimental comparison of three methods for constructing ensembles of decision trees: bagging, boosting, and randomization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">G</forename>
				<surname>Dietterich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="139" to="157" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining biomarkers to detect disease with application to prostate cancer</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Etzioni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="523" to="538" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Prostate-specific antigen and free prostate-specific antigen in the early detection of prostate cancer: do combination tests improve detection? Cancer Epidemiol</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Etzioni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomarkers Prev</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1640" to="1645" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Exclusive-OR representation of Boolean functions</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Fleisher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Dev</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="412" to="416" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1189" to="1202" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Interleukin-1β +3953 allele 2: association with disease status in adult periodontitis</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">A</forename>
				<surname>Gore</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Periodontol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="781" to="785" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Identifying target populations for screening or not screening using logic regression</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Janes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1321" to="1338" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Regulatory motif finding by logic regression</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Keles</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2799" to="2811" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Identifying interacting SNPs using Monte Carlo logic regression</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kooperberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ruczinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="157" to="170" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">LogicReg: Logic Regression. R package version 1.4.9. Available at: http://cran.r-project.org</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kooperberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ruczinski</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007-04-04" />
		</imprint>
	</monogr>
	<note>last. accessed date</note>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Logic regression for analysis of the association between genetic variation in the renin-angiotensin system and myocardial infarction or stroke</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kooperberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="334" to="343" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">The interleukin-1 genotype as a severity factor in adult periodontal disease</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">S</forename>
				<surname>Kornman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Periodontol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="72" to="77" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Strategy for detecting susceptibility genes with weak or no marginal effects</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kotti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Hered</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="85" to="92" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Biomarkers in cancer screening, research and detection: present and future: a review</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomarkers</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="385" to="405" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Backward haplotype transmission association (BHTA) algorithm-a fast multiple-marker screening method</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">H</forename>
				<surname>Lo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Hered</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="197" to="215" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Recent advances in biomarkers for cancer diagnosis and treatment</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Manne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discov. Today</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="965" to="976" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">The IL-1α −889 gene polymorphism is associated with chronic periodontal disease in a sample of brazilian individuals</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">R</forename>
				<surname>Moreira</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Periodont. Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="23" to="30" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">The promise of biomarkers in cancer screening and detection</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">S</forename>
				<surname>Negm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Mol. Med</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="288" to="293" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Logic regression</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ruczinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="475" to="511" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing. R Foundation for Statistical Computing Available at: http://www.r-project.org (last accessed date</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Development</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Core</forename>
				<surname>Team</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009-04-04" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Identification of SNP interactions using logic regression</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Schwender</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ickstadt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="187" to="198" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<monogr>
		<title level="m" type="main">logicFS: Identifying interesting SNP interactions with logicFS</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Schwender</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Bioconductor. package</note>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Cancer biomarkers: an emerging means of detecting, diagnosing and treating cancer</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Srivastava</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Biomark</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Application of multi-locus analytical methods to identify interacting loci in case-control studies</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">H</forename>
				<surname>Vermeulen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="689" to="700" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Challenges for biomarkers in cancer detection</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Wagner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. N. Y. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">1022</biblScope>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Use of multiple biomarkers to improve the prediction of death from cardiovascular causes</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zethelius</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="2107" to="2116" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>