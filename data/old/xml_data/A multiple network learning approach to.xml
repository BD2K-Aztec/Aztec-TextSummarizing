
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A multiple network learning approach to capture system-wide condition-specific responses</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Sushmita</forename>
								<surname>Roy</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of New Mexico</orgName>
								<address>
									<postCode>87131</postCode>
									<settlement>Albuquerque</settlement>
									<region>NM</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Broad Institute of MIT and Harvard</orgName>
								<address>
									<postCode>02141</postCode>
									<settlement>Cambridge</settlement>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Margaret</forename>
								<surname>Werner-Washburne</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Biology</orgName>
								<orgName type="institution">University of New Mexico</orgName>
								<address>
									<postCode>87131</postCode>
									<settlement>Albuquerque</settlement>
									<region>NM</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Terran</forename>
								<surname>Lane</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of New Mexico</orgName>
								<address>
									<postCode>87131</postCode>
									<settlement>Albuquerque</settlement>
									<region>NM</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Olga</forename>
								<surname>Troyanskaya</surname>
							</persName>
						</author>
						<title level="a" type="main">A multiple network learning approach to capture system-wide condition-specific responses</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">13</biblScope>
							<biblScope unit="page" from="1832" to="1838"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr270</idno>
					<note type="submission">Systems biology Advance Access publication May 5, 2011 Received on September 27, 2010; revised on April 1, 2011; accepted on April 20, 2011</note>
					<note>[14:59 8/6/2011 Bioinformatics-btr270.tex] Page: 1832 1832–1838 Associate Editor: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Condition-specific networks capture system-wide behavior under varying conditions such as environmental stresses, cell types or tissues. These networks frequently comprise parts that are unique to each condition, and parts that are shared among related conditions. Existing approaches for learning condition-specific networks typically identify either only differences or only similarities across conditions. Most of these approaches first learn networks per condition independently, and then identify similarities and differences in a post-learning step. Such approaches do not exploit the shared information across conditions during network learning. Results: We describe an approach for learning condition-specific networks that identifies the shared and unique subgraphs during network learning simultaneously, rather than as a post-processing step. Our approach learns networks across condition sets, shares data from different conditions and produces high-quality networks that capture biologically meaningful information. On simulated data, our approach outperformed an existing approach that learns networks independently for each condition, especially for small training datasets. On microarray data of hundreds of deletion mutants in two, yeast stationary-phase cell populations, the inferred network structure identified several common and population-specific effects of these deletion mutants and several high-confidence cases of double-deletion pairs, which can be experimentally tested. Our results are consistent with and extend the existing knowledge base of differentiated cell populations in yeast stationary phase. Availability and Implementation: C++ code can be accessed from</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>All cells on earth have the potential to sense and respond to different extracellular conditions defined by different environmental stresses, growth factors or cellular differentiation signals. Response to different conditions or condition-specific response is orchestrated * To whom correspondence should be addressed. by changes in the concentration of cellular components (mRNAs, proteins and metabolites) as well as the interactions among these components. Condition-specific networks capture the interactions among cellular components under different conditions, providing a system-wide view of condition-specific behavior. Understanding these networks can provide important insight into how organisms function, adapt and evolve. Although technological advances are allowing us to capture the concentrations of the system components, our ability to quantify the condition-specific interactions is still limited. Fortunately, network inference algorithms based on probabilistic graphical models that have been used successfully to infer a functional network from one gene expression (mRNA concentration) dataset (<ref type="bibr" target="#b6">Friedman et al., 2000;</ref><ref type="bibr" target="#b18">Pe'er et al., 2006;</ref><ref type="bibr" target="#b25">Segal et al., 2003</ref><ref type="bibr" target="#b26">Segal et al., , 2005</ref><ref type="bibr">Werhli et al., 2006;</ref><ref type="bibr">Yu et al., 2004</ref>), provide a starting point for inferring conditionspecific networks. In principle, a probabilistic network for each condition could be inferred separately from each condition. In practice, however, such an approach is limited because it fails to recognize an important aspect of condition-specific network learning: this is a multiple-network learning problem, where the networks for each condition are related (with both shared and unique subnetworks). To extend existing network inference methods to infer conditionspecific networks, it is important to explicitly capture and exploit the shared information during network learning. In this article, we develop a novel approach, Network Inference with Pooling Data (NIPD), based on probabilistic graphical models that explicitly incorporates the shared information across conditions by simultaneously learning multiple, high-quality networks across a small number of conditions. NIPD treats the condition as an additional random variable, different values of which induce different network structures (<ref type="figure" target="#fig_0">Fig. 1</ref>). Edges in NIPD are statistical dependencies that abstract the true condition-specific, physical network (protein–protein, protein–DNA interactions) and are inferred from condition-specific mRNA concentrations. Modeling the condition variable within the learning framework allows the condition information to directly influence which edges occur in the final inferred networks, and also the condition-specific roles of the edges. Existing network-based approaches for condition-specific responses can be grouped into module-centric and gene-centric approaches. Module-centric approaches identify transcription modules (set of transcription factors regulating a set of target genes) that are coexpressed in a condition-specific manner (Kimconditions, A and B. C represents conditions in NIPD. NIPD learns dependencies that are shared between A and B, as well as those unique to A or to<ref type="bibr">B. et al., 2006;</ref><ref type="bibr" target="#b26">Segal et al., 2005;</ref><ref type="bibr">Tuck et al., 2006</ref>). However, these approaches assume identical behavior for all genes within a module, and do not provide fine-grained interaction structure that explains the condition-specific behavior of individual genes. Further, condition-specific patterns are identified via a post-learning gene set enrichment analysis. Gene-centric approaches identify the set of condition-specific edges on a per-gene basis. Such approaches have been developed for capturing condition-specific behavior in diseases (<ref type="bibr" target="#b4">Chuang et al., 2007</ref>), in yeast stress responses (<ref type="bibr" target="#b20">Rokhlenko et al., 2007;</ref><ref type="bibr" target="#b21">Roy et al., 2009</ref>) and also in different species (<ref type="bibr" target="#b1">Bergmann et al., 2004;</ref><ref type="bibr" target="#b27">Stuart et al., 2003</ref>). However, these approaches are not probabilistic in nature (<ref type="bibr" target="#b4">Chuang et al., 2007;</ref><ref type="bibr" target="#b20">Rokhlenko et al., 2007</ref>), often rely on the network being known (<ref type="bibr" target="#b4">Chuang et al., 2007</ref>) and are restricted to pairwise coexpression relationships rather than general statistical dependencies (<ref type="bibr" target="#b1">Bergmann et al., 2004;</ref><ref type="bibr" target="#b27">Stuart et al., 2003</ref>). Most of these approaches infer a network for each condition separately, and then compare the networks from different conditions to identify the edges unique or shared across conditions. The approach in<ref type="bibr">Myers et al.</ref>does integrate context more directly within a Bayesian network, but relies on an initial training set to learn model parameters (<ref type="bibr" target="#b16">Myers and Troyanskaya, 2007</ref>). Other approaches such as differential dependency networks (<ref type="bibr">Zhang et al., 2008</ref>) and mixture of subgraphs (<ref type="bibr" target="#b23">Sanguinetti et al., 2008</ref>) construct probabilistic models, but focus on differences rather than both differences and similarities. The NIPD approach is a gene-centric approach with the following benefits: (i) infers general statistical dependencies including pairwise and higher order dependencies (dependencies among more than two genes); (ii) does not rely on the network being known; (iii) is probabilistic in nature, providing a system-wide description of the condition-specific behavior as a probabilistic network; (iv) simultaneously learns networks across multiple conditions allowing the learning procedure to be informed by the shared information across conditions; and (v) does not bias the networks toward only differences or similarities, thus identifying both conserved and unique aspects of condition-specific responses. Results on simulated data from known ground truth networks suggested that networks inferred by NIPD were of significantly higher quality than networks learned separately for each condition. Results on microarray compendia from two yeast cell populations, quiescent and non-quiescent, both under glucose stress (<ref type="bibr" target="#b0">Aragon et al., 2008</ref>), demonstrated that NIPD identified dependencies capturing shared processes (respiration) that agree with the global starvation stress experienced by these cells, as well as populationspecific processes (chromatin modeling in quiescent), that are consistent with the physiological state of these cells. Finally, NIPD networks were used to extract candidates of double deletion experiments, that can lead to insight into this important stage in the life cycle of yeast, and for processes such as cancer and aging (<ref type="bibr" target="#b7">Gray et al., 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning multiple networks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Probabilistic graphical models for functional networks</head><p>NIPD is based on the framework of probabilistic graphical models (<ref type="bibr" target="#b13">Lauritzen, 1996</ref>). These models have been widely used for modeling biological networks (<ref type="bibr" target="#b6">Friedman et al., 2000;</ref><ref type="bibr" target="#b18">Pe'er et al., 2006;</ref><ref type="bibr" target="#b26">Segal et al., 2005;</ref><ref type="bibr">Yu et al., 2004</ref>), because they can represent complex interaction patterns and also model noisy data, both typical of biological systems. A probabilistic graphical model has two components: a graph G and a set of potentials functions ={ψ 1 ,...,ψ || } (<ref type="bibr" target="#b13">Lauritzen, 1996</ref>). The nodes of G represent random variables, X ={X 1 ,...,X n }, encoding the mRNA expression level of genes. The edges of G represent pairwise and higher order (among &gt;2 genes) statistical dependencies among random variables. Each ψ i specifies the mathematical form of the dependency between X i and its neighbors. The graph can have directed edges as in Bayesian networks (<ref type="bibr" target="#b10">Heckerman, 1999</ref>) or undirected edges as in Markov random fields (<ref type="bibr" target="#b13">Lauritzen, 1996</ref>). We focus on undirected models, because they can represent cyclic dependencies, which arise in biological networks and are difficult to represent in directed models. Learning in these models typically optimizes a likelihood-based score by greedily searching the space of candidate graphs (<ref type="bibr" target="#b10">Heckerman, 1999</ref>). In undirected models, because likelihood cannot be exactly computed, we use pseudo-likelihood to learn the structure (<ref type="bibr" target="#b2">Besag, 1977</ref>). Briefly, pseudo-likelihood decomposes as a product over conditional distributions per variable, P(X i |M i ), where M i denotes the immediate neighborhood or Markov Blanket of X i. To learn G, we need to find the best M i for each X i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning multiple condition-specific networks</head><p>Assume we have a set of k conditions, C. Let |D c |={x c1 ,...,x c|Dc| } denote the dataset for the c-th condition, 1 ≤ c ≤ k. x cd ,1 ≤ d ≤|D c |, denotes the mRNA expression values in the d-th microarray in condition c. The problem of condition-specific network learning is defined as: given k datasets,</p><formula>{D 1 ,...,D k }, learn k graphs, {G 1 ,...,G k }, one for each condition.</formula><p>A simple approach for learning multiple networks is to learn each graph G c , independent of all G c ,c = c, using dataset D c only. We refer to this approach as the independent learner (INDEP). INDEP is a generalization of several existing approaches (<ref type="bibr" target="#b1">Bergmann et al., 2004;</ref><ref type="bibr" target="#b20">Rokhlenko et al., 2007;</ref><ref type="bibr" target="#b27">Stuart et al., 2003</ref>), which can all be considered as instances of INDEP with a specific network learning algorithm. We use the Markov blanket search algorithm as the learning algorithm for INDEP, which finds the best Markov blanket of every node using a greedy search of edge additions (<ref type="bibr" target="#b21">Roy et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Exploiting shared information for learning multiple networks</head><p>(NIPD): To motivate NIPD, let us first consider the 'condition' semantics of an edge for the two condition case C ={A,B}. An edge between two variables, X i and X j , can occur only in condition A but not in B, only in condition B but not in A, or in both A and B. Thus, edges in condition A's network are the union of edges that occur in the singleton set {A}, and the edges that occur in the set {A,B}. Our goal is to explicitly capture these condition subset semantics of each edge. Such information can be useful to characterize transcription factors that regulate overlapping target sets in different conditions (<ref type="bibr" target="#b8">Harbison et al., 2004</ref>). An edge that occurs in a nonsingleton condition subset is a shared edge, and its parameters can be learned by pooling the data from all the conditions in the subset. Of course, both</p><p>Page: 1834 1832–1838</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Roy et al.</head><p>the edges and their condition-specific semantics are unknowns and must be inferred automatically from the data. NIPD uses a novel formulation of the conditional distribution,). The proportionality sign can be eliminated by dividing by a normalization constant. However, we work with the unnormalized product because it decomposes over condition subsets (Supplementary Material). Other formulations of P(X i |M ci ), such as a weighted sum of mixtures (<ref type="bibr" target="#b9">Hastie et al., 2001</ref>), are not decomposable over condition subsets and did not have significant advantages in our preliminary experiments. θ Ei is estimated by pooling the data for all non-singleton E, which in turn makes more data available for estimating these parameters. This enables NIPD to robustly estimate parameters, especially those of higher order dependencies, which are harder to estimate relative to pairwise dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Structure learning algorithm of NIPD in detail:</head><p>Our structure learning algorithm maintains a conditional distribution for every variable, X i for every set E ∈ powerset(C) and computes score improvement of adding an edge {X i ,X k } in every set E. This addition will affect the conditionals of X i and X j in all conditions e ∈ E. The net score improvement of adding an edge {X i ,X j } to a condition set E is given by:</p><formula>Score {X i ,X j },E = e∈E PLLV(X i ,M ei ∪{X j },e)−PLLV(X i ,M ei ,e) +PLLV(X j ,M ej ∪{X i },e)−PLLV(X j ,M ej ,e) ,</formula><formula>(1)</formula><p>where</p><formula>to PLLV(X i ,M ei ,e) decomposes as F s.t: e∈F PLLV(X i ,M * Fi ,e).</formula><p>Because the edge {X i ,X j } is being added to M * E , all terms not involving E remain unchanged producing the score improvement:</p><formula>Score {X i ,X j },E = PLLV(X i ,M * Ei ∪X j ,E)−PLLV(X i ,M * Ei ,E) +PLLV(X j ,M * Ej ∪X i ,E)−PLLV(X j ,M * Ej ,E)</formula><p>This score allows us to score an edge in condition sets in a decomposable manner. Our structure learning algorithm begins with k empty graphs and proposes edge additions for all variables, for all subsets of the condition set C (Algorithm 1). The outermost for loop (Steps 4–14 ) iterates over variables X i to identify new candidate MB variables, X j , in a condition set E. We iterate over all candidate MBs X j (<ref type="bibr">Steps 5</ref>–12) and condition sets E (Steps 6–11) and compute the score improvement for each pair {X j ,E} (Step 10). If the current condition set under consideration has more than one condition, data from these conditions are pooled and parameters for the new distribution P(X i |M * Ei ) are estimated using the pooled dataset (Steps 7–9). A candidate move for a variable X i is composed of a pair {X j ,E } with the maximal score improvement over all variables and conditions (<ref type="bibr">Step 13</ref>). After all candidate moves have been identified, moves are attempted in the order of decreasing score improvement (Step 15), to enable moves with the highest score improvements to be attempted first. A move connecting two variables, X i and X j , can fail if a previous move updated the neighborhoods of either X i or X j. The algorithm converges when no edge addition improves the score of the k graphs. Although we implement NIPD with undirected, probabilistic graphical models, the NIPD framework is applicable to directed graphs as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dataset description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Microarray data from yeast stationary phase:</head><p>Each microarray measures the mRNA expression of all yeast (Saccharomyces cerevisiae) genes in response to ≈100 genetic deletions from quiescent and nonquiescent populations, isolated from glucose-starved stationary phase cultures (<ref type="bibr" target="#b0">Aragon et al., 2008</ref>), We first filtered the microarray data to exclude genes with &gt; 80% missing values. We then considered only those genes whose expression changed significantly (|z|-score ≥ 4) compared with wild type, in either quiescent or non-quiescent populations. This resulted in a final dataset of 2639 genes exhibiting downstream knockout effects of 1 of the 88 deletions. Although we selected genes that were significantly affected by at least by one deletion, neither NIPD nor INDEP knew which genes were affected by which deletion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Simulated data:</head><p>We simulated data from six networks, one network per condition. One of these was a subnetwork of 99 nodes from the Escherichia coli regulatory network (<ref type="bibr" target="#b22">Salgado et al., 2006</ref>). The other five were generated by flipping 10, 30, 50, 70 and 100% of the edges of the first network. A simulated dataset was generated per network, using a differential</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning multiple networks</head><p>equation-based simulator, by perturbing all transcription factor nodes and measuring the steady state of all genes (<ref type="bibr" target="#b15">Mendes et al., 2003</ref>). This was repeated 1000 times per network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Validation of network structure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Inferred from simulated data:</head><p>We used three methods to infer networks on simulated data: NIPD, INDEP with a Markov blanket search algorithm (<ref type="bibr" target="#b21">Roy et al., 2009</ref>) and GeneNet (<ref type="bibr" target="#b24">Schäfer and Strimmer, 2005</ref>). GeneNet also infers a network per condition independently by learning a shrinkage-based partial correlations graph, and is well-suited for sparse data situations. Note the GeneNet algorithm outputs a weight for every edge corresponding to the statistical significance of an edge. To obtain a network, one needs to specify an input number of edges. We used the number of edges from NIPD because this was when GeneNet had the highest performance. We compared the structure of the networks inferred by these algorithms to the true network structure using standard precision and recall of edge match, and also the neighborhood match of every node (Supplementary Material). For edge match, we report the F-score, which is the harmonic mean of precision and recall. We evaluate neighborhood structure quality by obtaining the number of nodes on which one approach was significantly better than another approach (t-test P &lt; 0.05) in capturing node neighborhood as a function of training data size (See Supplementary Material). This comparison captures a more localized picture of the types of random variables that may be contributing most to errors. We partitioned each dataset into q equal partitions, where q ∈ {3,4,5,6,7,8,9,10}. The training data size for each partition is N q and decreases with increasing q. For each q, we learned a network for each partition and report the average F-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Inferred from microarray data:</head><p>Network inference from microarray data is known to be a notoriously difficult problem because of the relatively few samples (microarrays) compared with the number of genes. A concern that arises in this situation is distinguishing true from spurious dependencies. We took several measures to ensure the dependencies captured by our networks represented meaningful dependencies: (i) we use an MDL-based score that penalizes complex structures, (ii) genes were connected to only the 88 genes for which we had single deletion strains (this was done uniformly for both NIPD and INDEP), (iii) genes without deletions were not allowed to have more than eight neighbors (the 88 genes with deletion mutants were unconstrained), (iv) edges inferred by INDEP or NIPD were assigned a confidence score based on a well-known bootstrap analysis (<ref type="bibr" target="#b6">Friedman et al., 2000;</ref><ref type="bibr" target="#b17">Pe'er et al., 2001</ref>), where we subsampled the data 20 times. We considered only those edges that had a confidence ≥ τ, which in turn was determined based on the probability of observing an edge with this confidence by random (Supplementary<ref type="figure" target="#fig_0">Fig. S1</ref>). We selected τ = 0.3 because this represented the point of most dramatic change in the probability for random edges. All GO Process enrichments were performed in Genatomy (http://www.c2b2.columbia.edu/danapeerlab/html/genatomy.html).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>The goals of our experiments were as follows: (i) to compare our approach against independent network learning approaches, on simulated data from known ground-truth networks and (ii) to assess the value of our approach on real microarray data. For (i) we used two independent learners, INDEP with a Markov blanket search algorithm and GeneNet (<ref type="bibr" target="#b24">Schäfer and Strimmer, 2005</ref>). Experiments on simulated data allowed us to systematically compare the quality of the inferred networks and, therefore, assess the benefit of pooling data and sharing information across conditions versus learning networks independently. To address (ii) we applied NIPD and INDEP on microarray data from two yeast cell populations isolated from glucose-starved stationary phase cultures (<ref type="bibr" target="#b0">Aragon et al., 2008</ref>). These data are good case studies for condition-specific network learning (hundreds of samples per condition), and the inferred quiescent and non-quiescent networks can provide potentially new insight into stationary phase, a process known to be intricately related to cancer and aging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NIPD had superior performance on networks with known ground truth</head><p>We first evaluated overall network structure using two sets of networks, HIGHSIM and LOWSIM. Networks in HIGHSIM shared a large portion (75%) of the edges, and networks in LOWSIM shared a small (20%) portion of the edges. On HIGHSIM, NIPD performed significantly better than INDEP and GeneNet for all training data sizes (<ref type="figure" target="#fig_2">Fig. 2</ref>). On LOWSIM, NIPD was significantly better than INDEP, and comparable to GeneNet performing better on one network and at par on the second network. In addition to standard F-score, we also compared the algorithms based on how well neighborhoods of individual variables were identified (Supplementary Figs S5–S8). These 'per-variable' scores provide a more granular understanding of algorithm performance. In particular, nodes with high degree may be contributing to the majority of the errors, but standard precision–recall values will not be able to capture this. NIPD consistently outperformed other algorithms, especially when there is some sharing of structure between conditions. To demonstrate that NIPD is not specific to two conditions, we varied the number of conditions from two to six. We found that NIPD and GeneNet were generally better than INDEP, which does not handle sparse data conditions, and the performance margin between NIPD and GeneNet decreased with increasing number of networks (<ref type="figure" target="#fig_3">Fig. 3</ref>, Supplementary Figs S2–S4). NIPD seemed to suffer most on networks with the fewest number of shared edges, whereas GeneNet suffered most when there were more shared edges. However, GeneNet did not significantly outperform NIPD in any case. Overall, our results show that when the individual condition-specific networks are similar, NIPD has a significantly better performance than other algorithms. When the underlying networks are different, NIPD performs at par with methods suited for small training data sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Application to yeast quiescence</head><p>We applied NIPD to microarray datasets from yeast quiescent and non-quiescent cell populations separated from stationary phase cultures (<ref type="bibr" target="#b0">Aragon et al., 2008</ref>). The cell populations have experienced the same glucose starvation stress, but have differentiated physiologically (<ref type="bibr" target="#b5">Davidson et al., 2011</ref>), suggesting that each population responds to starvation stress differently. Each microarray within each dataset measures the expression profile of 1 of 88 deletion mutants, selected based on existing knowledge of yeast stationary phase. We applied NIPD and INDEP approaches to learn quiescent and non-quiescent-specific networks, treating each cell population as a condition. One of the goals of our study was to further characterize these deletion mutants, many of which have no known phenotype. Hence, we constrained the networks such that only Page: 1836 1832–1838, 1 q , where 3 ≤ q ≤ 10. Top is for HIGHSIM (75% edges shared) and bottom is for LOWSIM (20% edges shared). The top and bottom graphs are for networks from the individual conditions. Higher is better.genes with deletion mutants are connected to the remaining genes. 1 The neighborhood of each deletion mutant determined by the network topology was analyzed for Gene Ontology (GO) process enrichment (FDR &lt; 0.05), and the network quality was considered proportional to the number of unique GO processes enriched within a neighborhood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Roy et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">NIPD captures both common response as well as populationspecific starvation responses:</head><p>To determine if one method was superior than another, we examined the GO process categories enriched in the neighborhood of every deletion mutant in the inferred networks. On quiescent, 21 of the deletion mutants were enriched in 68 different biological processes using the NIPD-inferred network, whereas using INDEP only 2 mutants were associated with a biological process, all of which were identified by the NIPD algorithm already (Supplementary Material 1). Similar behavior was observed on non-quiescent. To identify similarities and differences between the two populations, we asked which deletion mutants affect the same processes in both populations, and which mutants affect different processes (Supplementary<ref type="figure" target="#fig_0">Fig. S10</ref>). We found several processes that were affected by the same deletion in quiescent and non-quiescent populations, suggesting a conserved, starvation stress response (response to stimulus, cellular respiration). Both these processes were previously identified to be associated with quiescent cells (<ref type="bibr" target="#b0">Aragon et al., 2008</ref>). NIPD also identified several processes that were associated exclusively with quiescent cells (purine metabolic process, cellular aging, chromatin modification). Although respiration was present in both populations, quiescent was associated with more processes related to respiration, consistent with our recent finding that quiescent cells exhibit higher rates of respiration (<ref type="bibr" target="#b5">Davidson et al., 2011</ref>). The only process that we did not recover was signal transduction. This may be because of our per-mutant analysis, whereas previous work considered upregulated genes in the entire compendium of quiescent cells. In contrast, INDEP did not identify any shared process, and identified a small subset of these population-specific processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">NIPD identified several deletion combinations:</head><p>We next analyzed neighborhood genes of individual deletion mutants to identify pairs of deletion mutants that had more overlapping neighbors (Hypergeometric P&lt;1E-3). Such combinations represent candidates for double deletion analysis, that are generally harder to experimentally test, but are necessary to identify genetic interactions and cross-talk between pathways. We found 18 and 21 deletion pairs in quiescent and non-quiescent populations, respectively. These numbers are significantly higher than in random networks with identical degree distributions (z-test, P &lt; 1E-4, Supplementary<ref type="figure" target="#tab_1">Table  ST1</ref>). In quiescent cells, we found several deletion pairs likely to affect TCA cycle and aerobic respiration. In non-quiescent cells, several knock-out combinations involved fatty acid metabolism and aerobic respiration. Our predictions included genes either with known phenotypes in stationary phase or related to genes with such phenotypes. For example, QCR7, QCR8 and QCR10 are subunits of ubiqunol-cytochrome c oxidoreductase complex; QCR7 is essential for viability in stationary phase (<ref type="bibr" target="#b0">Aragon et al., 2008;</ref><ref type="bibr" target="#b14">Martinez et al., 2004</ref>), and both QCR8 and QCR10 were in our predictions. Our predictions also included ALD4 and ADH2, both dehydrogenases, which may affect population heterogeneity of non-quiescent cells and reproductive capacity of both cell types (A. Dodson, personal communication). Overall, 17 of the 39 genes in our predicted deletion combinations are required for viability and survival in stationary phase, which suggests these combinations are likely to have significant phenotypes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning multiple networks</head><p>of condition-specific responses. The crux of our approach is to recognize that condition-specific network learning poses a multiple network learning problem where the networks are related and, therefore, share information among them. NIPD solves this problem by simultaneously learning networks across all conditions using a novel score that allows the learning process to be aware of the shared information across conditions. Small training datasets, which are common for biological data, present significant challenges for any network learning approach. In particular, standard approaches that infer networks for each condition independently (<ref type="bibr" target="#b21">Roy et al., 2009</ref>) suffer from low sensitivity because they miss shared dependencies that are too weak within individual datasets. In contrast, NIPD is able to recover these shared dependencies because by pooling data across conditions during network learning, NIPD effectively has more data for estimating parameters for the shared parts of the network. This allows NIPD to have more discovery power than INDEP, and our results confirmed that the additional dependencies inferred by NIPD represent shared, biologically meaningful dependencies. One of the strengths of NIPD was its ability to identify networks with the most biologically meaningful structure. This allowed us to characterize deletion mutants based on their affects on quiescent and non-quiescent cells, and also to predict combinations of such individual gene deletions. Several of these predictions are supported by literature, including genes that are known to have a phenotypic effect on stationary phase cultures (<ref type="bibr" target="#b0">Aragon et al., 2008;</ref><ref type="bibr" target="#b14">Martinez et al., 2004</ref>). Importantly, these predictions are a drastic reduction of the possible double deletion combinations of 88 single gene deletions and provide directions for future experiments. The probabilistic framework of NIPD can be easily extended to automatically infer the condition variable to handle situations with uncertainty about conditions. The run time of NIPD scales exponentially with the number of conditions (Supplementary<ref type="figure">Fig. S9</ref>) which makes the algorithm prohibitively slow for higher number of conditions. Another direction of future research is to incorporate condition hierarchies or temporally related conditions, to focus on a few, instead of all, condition subsets. NIPD can also be extended to integrate data from other levels of cellular organization such as the proteome, metabolome (<ref type="bibr" target="#b3">Bradley et al., 2009</ref>) and the epigenome (<ref type="bibr" target="#b11">Kaplan et al., 2008</ref>). An important feature of NIPD is that it is gene centric, allowing us to derive condition specificity of individual pairwise and higher order dependencies, which is feasible for conditions with enough samples for such a fine-grained analysis. While module-centric approaches have had much success in dissecting the regulatory program across diverse conditions, such approaches are amenable to situations where a fine-grained analysis is not possible. Thus, both approaches have their merits and the suitability of each approach is dependent upon the data at hand. Next-generation technologies are making large-scale transcript data per cell type and condition a near possibility. We expect our approach to be beneficial for interrogating these datasets and deciphering mechanisms of cell type and tissue specificity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. NIPD framework for two conditions, A and B. C represents conditions in NIPD. NIPD learns dependencies that are shared between A and B, as well as those unique to A or to B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Performance comparison using F-score of NIPD, INDEP and GeneNet on simulated data of two networks. Shown are mean and SDs of F-scores estimated from partitions of different sizes, 1 q , where 3 ≤ q ≤ 10. Top is for HIGHSIM (75% edges shared) and bottom is for LOWSIM (20% edges shared). The top and bottom graphs are for networks from the individual conditions. Higher is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Performance comparison INDEP, NIPD and GeneNet as a function of decreasing training data for six networks. Shown are mean and SD of F-score of inferred network structure from each partition size. Higher is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>We have introduced a novel, probabilistic graphical modeling approach, NIPD, for learning fine-grained interaction patterns Page: 1837 1832–1838</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Tuck,D.P. et al. (2006) Characterizing disease states from topological properties of transcriptional regulatory networks. BMC Bioinformatics, 7. Werhli,A.V. et al. (2006) Comparative evaluation of reverse engineering gene regulatory networks with relevance networks, graphical gaussian models and Bayesian networks. Bioinformatics, 22, 2523–2531. Yu,J. et al. (2004) Advances to Bayesian network inference for generating causal networks from observational biological data. Bioinformatics, 20, 3594–3603. Zhang,B. et al. (2008) Differential dependency network analysis to identify conditionspecific topological changes in biological networks. Bioinformatics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>P(X i |M ci ), where M ci is the Markov blanket (MB) of X i in condition c, such that shared edges impose a cross-condition dependence in the MBs and their parameters. NIPD incorporates this formulation within the pseudo-likelihood score and evaluates candidate networks with respect to data from any subset of conditions. This enables NIPD to identify the condition-subset semantics of MBs and also exploit shared information across conditions. Let θ ci denote the parameters of P(X i |M ci ). M ci in turn is determined by all neighbors of X i in any subset of C that includes c. Let E ⊆ C be a subset of condition. Let M * Ei be the set of variables that are connected to X i only in condition set E and θ * Ei denote the parameters associated with M * Ei. For example, if C ={A,B}, then M * {A}i denotes the set of variables that are connected to X i in A only and not B, M * {A,B}i denotes the set of variables that are connected to X i in both A and B and so on. The overall MB of X i in condition A is M Ai = M * Ai ∪M * {A,B}i. Similarly, overall MB of X i in condition B is M Bi = M * {B}i ∪M * {A,B}i. θ Ai and θ Bi are therefore concatenations of θ * {A}i and θ * {A,B}i. Here, the shared component θ * {A,B}i associated with M * {A,B}i enforces cross-condition dependence among the θ Ai and θ Bi. More generally, for any c ∈ C, M ci = E∈powerset(C) : c∈E M * Ei , where M * Ei denotes the neighbors of X i only in condition set E. We assume P(X i |M * i ) to be conditional Gaussians. We now need to define P(X i |M ci ) such that it takes into account all subsets E, c ∈ E. We use a product formulation: P(X i |M ci ) ∝ E∈powerset(C) : c∈E P(X i |M * Ei</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>PLLV(X i ,M ei ,e) is the conditional log likelihood of X i given its neighbors, and is defined as |De| d=1 logP(X i = x di |M ei = m di )− |θ ei |log(|De|) 2 , where the second term is MDL penalty. x di and m di are assignments to X i and M ei , respectively, from the d-th data point x d in dataset D e. Because of our product formulation of P(X i |M ei ), the pseudo-likelihood contribution of each D e</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>|X| } Set of conditions C Datasets for c ∈ C, {D |M * Ei ∪{X j }) using pooled dataset D E obtained from merging all D e s.} as candidate move for X i , where {X j ,E }= argmax j,E Score {X i X j }E</figDesc><table>Algorithm 1 NIPD structure learning 

1. Input: 
Random variable set, X ={X 1 ,...,X 1 ,...,D |C| } 
2. Output: 
Inferred graphs G 1 ,...,G |C| 
3. while Score(G 1 ,...,G |C| ) does not stabilize do 
4. 
for X i ∈ X do {/ *Propose moves*/} 
5. 
for X j ∈ (X \{X i }) do 
6. 
for E ∈ powerset(C) do 
7. 
if |E| &gt; 1 then 
8. 
Estimate parameters for new conditional P(X i t. 
e ∈ E. 
9. 
end if 
10. 
compute Score {X i X j }E . 
11. 
end for 
12. 
end for 
13. 
Store {X i ,X 
j ,E 14. 
end for 
15. 
Make candidate moves {X i ,X 
j ,E } in order of decreasing score 
improvement /*Attempt moves*/ 
16. end while 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [14:59 8/6/2011 Bioinformatics-btr270.tex]</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> This is not a bi-partite graph because the genes with deletion mutants are allowed to connect to each other.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Characterization of differentiated quiescent and non-quiescent cells in yeast stationary-phase cultures</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">D</forename>
				<surname>Aragon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Cell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1271" to="1280" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Similarities and differences in genome-wide expression data of six organisms</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bergmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficiency of pseudolikelihood estimation for simple gaussian fields</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Besag</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="616" to="618" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Coordinated concentration changes of transcripts and metabolites in Saccharomyces cerevisiae</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">H</forename>
				<surname>Bradley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Network-based classification of breast cancer metastasis</title>
		<author>
			<persName>
				<forename type="first">H.-Y</forename>
				<surname>Chuang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">The proteomics of quiescent and non-quiescent cell differentiation in yeast stationary-phase cultures</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">S</forename>
				<surname>Davidson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Cell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="988" to="998" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Using bayesian networks to analyze expression data</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="601" to="620" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">sleeping beauty&apos;: Quiescence in Saccharomyces cerevisiae</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">V</forename>
				<surname>Gray</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microbiol. Mol. Biol. Rev</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="187" to="206" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Transcriptional regulatory code of a eukaryotic genome</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">T</forename>
				<surname>Harbison</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">431</biblScope>
			<biblScope unit="page" from="99" to="104" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A Tutorial on Learning with Bayesian Networks</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Heckerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning in Graphical Models</title>
		<editor>Jordan,M.</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">The DNA-encoded nucleosome organization of a eukaryotic genome</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Kaplan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">458</biblScope>
			<biblScope unit="page" from="362" to="366" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Unraveling condition specific gene transcriptional regulatory networks in saccharomyces cerevisiae</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">Graphical Models. Oxford Statistical Science Series</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Lauritzen</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Genomic analysis of stationary-phase and exit in Saccharomyces cerevisiae: gene expression and identification of novel essential genes</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Martinez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Cell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="5295" to="5305" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Artificial gene networks for objective comparison of analysis algorithms</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Mendes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="122" to="129" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Context-sensitive data integration and prediction of biological networks</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Myers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">G</forename>
				<surname>Troyanskaya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2322" to="2330" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Inferring subnetworks from perturbed expression profiles</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Pe &apos;er</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="215" to="224" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Minreg: a scalable algorithm for learning parsimonious regulatory networks in yeast and mammals</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Pe &apos;er</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="167" to="189" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">O</forename>
				<surname>Rhein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Similarities and differences of gene expression in yeast stress conditions</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Rokhlenko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="184" to="190" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Inference of functional networks of condition-specific response– a case study of quiescence in yeast</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Roy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Pacific Symposium on Biocomputing</title>
		<editor>Roy et al.</editor>
		<meeting>Pacific Symposium on Biocomputing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="51" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Regulondb (version 5.0): Escherichia coli k-12 transcriptional regulatory network, operon organization, and growth conditions</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Salgado</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">394</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Mmg: a probabilistic tool to identify submodules of metabolic pathways</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Sanguinetti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1078" to="1084" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">An empirical bayes approach to inferring large-scale gene association networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schäfer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="754" to="764" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Module networks: identifying regulatory modules and their condition-specific regulators from gene expression data</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Segal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="166" to="176" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning module networks</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Segal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="557" to="588" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">A gene-coexpression network for global discovery of conserved genetic modules</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Stuart</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">302</biblScope>
			<biblScope unit="page" from="249" to="255" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>