
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome assembly from synthetic long read clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Volodymyr</forename>
								<surname>Kuleshov</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Genetics</orgName>
								<orgName type="institution">Stanford University School of Medicine</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Michael</forename>
								<forename type="middle">P</forename>
								<surname>Snyder</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Genetics</orgName>
								<orgName type="institution">Stanford University School of Medicine</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Serafim</forename>
								<surname>Batzoglou</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Genome assembly from synthetic long read clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw267</idno>
					<note>*To whom correspondence should be addressed. Contact: kuleshov@stanford.edu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Despite rapid progress in sequencing technology, assembling de novo the genomes of new species as well as reconstructing complex metagenomes remains major technological challenges. New synthetic long read (SLR) technologies promise significant advances towards these goals; however, their applicability is limited by high sequencing requirements and the inability of current assembly paradigms to cope with combinations of short and long reads. Results: Here, we introduce Architect, a new de novo scaffolder aimed at SLR technologies. Unlike previous assembly strategies, Architect does not require a costly subassembly step; instead it assembles genomes directly from the SLR&apos;s underlying short reads, which we refer to as read clouds. This enables a 4-to 20-fold reduction in sequencing requirements and a 5-fold increase in assembly contiguity on both genomic and metagenomic datasets relative to state-of-the-art assembly strategies aimed directly at fully subassembled long reads. Availability and Implementation: Our source code is freely available at https://github.com/kule shov/architect.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Genome sequencing technology has had an enormous impact on modern science and medicine. Information gleaned from the genome has become a crucial ingredient in numerous industrial and medical applications, such as breeding disease-resistant crops, identifying infectious microbes or diagnosing human health problems. Yet, despite rapid progress in sequencing technology, fully reconstructing de novo the genomes of new organisms or complex metagenomes still remains a major technological challenge. The main obstacle in de novo genome assembly remains sequencing read length. Current technologies can only read short hundredbase substrings of the genome; recovering the original sequence from these substrings is impossible, as they fundamentally cannot resolve the true position of repetitive sequences that are longer than their own length. This results in highly fragmented assemblies that need to be further improved with more sophisticated and expensive techniques. Recently, new synthetic long read (SLR) technologies have offered great promise towards making inexpensive and accurate de novo assembly a reality. These technologies exhibit read lengths in the tens of kilobases and theoretically have the power to reconstruct a large fraction of an organism's genome. Nonetheless, SLRs have not yet realized their full potential. Most existing approaches involve a two-stage process in which long fragments are first assembled from short reads, and then the genome is assembled from the long fragments. Such strategies typically require prohibitively large amounts of short-read sequencing for each long fragment; in some cases, attaining this high level of coverage may not even be feasible. In addition, long reads often must be complemented by short reads (e.g. to compensate for sequencing bias); yet, there are currently very few assemblers that can effectively handle both types of data. Here, we introduce Architect, a new de novo scaffolder for SLR technologies that aims to address these shortcomings. Unlike previous assembly strategies, Architect does not require a costly subassembly step; instead it assembles genomes directly from the SLR's underlying short reads. Moreover, by dealing only with short reads, it avoids difficulties that arise from jointly assembling reads of highly differing lengths. In practice, Architect leads to a 4-to 20-fold reduction in sequencing requirements and up to a 5-fold increase in assembly contiguity compared with current state-of-the-art assembly strategies aimed directly at fully subassembled long reads. We demonstrate the improvements offered by Architect on the genomes of Drosophila melanogaster and Caenorhabditis elegans as well as on two metagenomic samples: the synthetic mock community from the human microbiome project, and a bona fide human gut metagenome from a healthy male individual. Our results suggest that Architect may lower the cost of accurate de novo assembly and facilitate the V C The Author 2016. Published by Oxford University Press.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i216</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</p><p>Bioinformatics, 32, 2016, i216â€“i224 doi: 10.1093/bioinformatics/btw267 ISMB 2016 analysis of long-range genomic features in metagenomic samples, for example long operons or strain haplotypes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">De novo assembly</head><p>The goal of de novo assembly is to reconstruct a target genome (viewed as a string of up to several billion letters) from sequencing reads, which can be viewed as random substrings of the genome. Assembly paradigms. There exist two main approaches to de novo assembly and each is best suited to a particular type of data. The Ovelap-Layout-Consensus (OLC) paradigm (<ref type="bibr" target="#b22">Myers et al., 2000</ref>) works best with long reads (&gt; 1 kp); it involves computing overlaps between all pairs of reads and simplifying the resulting overlap graph until we obtain long, contiguous subsequences of the genome called contigs. Contigs may be further assembled into scaffolds using paired-end or mate-pair read data. The main shortcomings of OLC assemblers are high computational requirements for computing overlaps between a very large number of short-read pairs (&lt; 200 bp). The alternative De Brujn graph (DBG) paradigm (<ref type="bibr" target="#b24">Pevzner et al., 2001</ref>) addresses this problem by first breaking reads into k-mers (with k &lt; 127) and then linking them in a graph. This reduces the number of vertices to consider, but loses important contiguity signal encoded in longer reads. Finally, when using paired-end or mate-pair reads, it is common to further extend the de novo assembly via a scaffolding process. The term 'scaffold' refers to a genomic sequence containing subsequences of unknown nucleotides (usually denoted by N) of potentially uncertain lengths. Many assemblers include a scaffolding module that produces such sequences from paired-end reads (see e.g.<ref type="bibr" target="#b30">Zerbino et al., 2009</ref>); in addition, there exist many standalone scaffolding tools, whose performance can often match or exceed that of more complex assemblers (<ref type="bibr" target="#b14">Hunt et al., 2014</ref>). The importance of read length. The main difficulty faced by either paradigm is genomic repeats (<ref type="bibr" target="#b22">Myers et al., 2000</ref>). If a genome contains subsequences ARB and CRD (meaning that R is a repeat occurring twice; A; B; C; D are unique sequences), and if the length of sequencing reads is smaller than R, then we cannot determine whether ARB or ARD is the correct contig ordering. In such cases, we must report A; B; C; D; R as individual contigs. Thus, read length is one of the most important factors determining the quality of de novo assemblies (<ref type="bibr" target="#b8">Chaisson et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">SLR technologies</head><p>This work introduces tools targeted at two closely related types of sequencing technologies: SLRs and read clouds; both types of methods share a common protocol, which we illustrate in<ref type="figure" target="#fig_0">Figure 1</ref>. Synthetic long reads. The first set of technologies aims to produce 'virtual' long reads on standard short-read sequencers via a specialized library preparation method (<ref type="figure" target="#fig_0">Fig. 1</ref>). At a high level, input DNA is first sheared into kilobase-long fragments, which are then randomly distributed across a small number of containers. The fragments are typically diluted such that each container holds a small fraction (%0.1â€“2%) of the target genome. The contents of each container are then sheared further into shorter fragments and are assigned a unique barcode before being pooled together for sequencing. After sequencing, reads are demultiplexed into their containers of origin using the barcodes. Each container may be assembled separately with a short-read assembler, which produces multiple kilobase-long sequences in each well; this approach is referred to as subassembly. The resulting sequences correspond to the original long fragments. In the last step, the target genome is assembled from the long fragments using an OLC-based method. There exist multiple instantiations of the protocol described above. Techniques that produce fully assembled SLRs include fosmid pooling (<ref type="bibr" target="#b11">Duitama et al., 2012</ref>), long fragment reads (<ref type="bibr" target="#b23">Peters et al., 2012</ref>) and Tru-seq SLRs (<ref type="bibr" target="#b29">Voskoboynik et al., 2013</ref>) (TSLR), which is also one of the few technologies to be commercially available. SLRs have been applied to a wide range of problems, including genome phasing (), read alignment (<ref type="bibr" target="#b4">Bishara et al., 2015</ref>) and metagenomic analysis (<ref type="bibr" target="#b18">Kuleshov et al., 2015;</ref><ref type="bibr" target="#b26">Sharon et al., 2015</ref>). Repeat reduction. The key process that makes subassembly possible is a reduction in the repeat content of the genome within each container. Because each container holds only a small fraction (%0.1â€“2%) of the target genome, the probability of two copies of the same repeat R finding themselves in the same container is very low. Thus, each container can be seen as containing a genome with no repeats and that is therefore relatively easy to assemble. Once each container has been assembled separately, we may merge the resulting long fragments into a final genome assembly. Read cloud technologies. Alternatively, the contents of each container may be sequenced at a relatively low coverage, either to lower, which are then diluted and placed into multiple containers, typically with 0.1â€“2% of the genome per container (3). Within each container, fragments may be amplified before being cut into short fragments, and barcoded (4). The barcoded fragments are finally pooled together and sequenced (5); reads can be demultiplexed on a computer into their original compartment via the barcodes in order to form read clouds or SLRs Genome assembly from read clouds i217 sequencing requirements, or because the laboratory protocol may not permit high-coverage sequencing for technical reasons. In such cases, we only obtain clusters of short reads that originate from long fragments. We refer to such clusters as read clouds. The term 'cloud' comes from the appearance of such reads when aligned to a reference genome and visualized in a genome browser: they typically form isolated clusters with an imprecise shape (<ref type="figure" target="#fig_1">Fig. 2</ref>, top). Although they do not output long contiguous sequences, read cloud technologies contain signal which may be used for resolving genomic repeats; the focus of this work is precisely to extract this signal. Examples of read cloud methods include contiguity preserving transposase sequencing (CPT-seq;<ref type="bibr" target="#b1">Amini et al., 2014</ref>), which produces very thin clouds, and the 10X GemCode platform, which features an adjustable cloud depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Related work</head><p>Most applications of SLR and read cloud technologies to de novo assembly have used a subassembly-based strategy. These methods were used to assemble the genomes of Botryllus schlosseri (<ref type="bibr" target="#b29">Voskoboynik et al., 2013</ref>), D.melanogaster (<ref type="bibr" target="#b21">McCoy et al., 2014</ref>), C.elegans (<ref type="bibr" target="#b19">Li et al., 2015</ref>) as well as metagenomic samples from the human gut (<ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>) and from the environment (<ref type="bibr" target="#b26">Sharon et al., 2015</ref>). In all cases, assemblies achieved N50 lengths below 100 kb, highlighting limitations of subassembly-based strategies. Currently, only one method is able to use read clouds for de novo assembly, and that is FragScaff (<ref type="bibr" target="#b0">Adey et al., 2014</ref>), a scaffolder aimed at extremely low-internal-coverage read clouds obtained via the contiguity preserving transposase sequencing (CPT-seq) technology. FragScaff produces orderings of contigs by leveraging the same signal as Architect; it differs mainly in its scaffolding algorithm, which is optimized for CPT-seq. In particular, FragScaff formulates the scaffolding problem as finding the maximum-weight spanning tree (MST) on the scaffold graph. This formulation was shown to be highly effective at scaffolding large genomes form CPT-seq data; however, it is less effective when scaffolding metagenomic data as well as read clouds obtained from alternative technologies such as TSLR, long fragment reads or fosmid clones. We further discuss differences between FragScaff and Architect in Section 5. There also exist multiple de novo assembly methodologies that provide an alternative to read clouds.<ref type="bibr" target="#b6">Burton et al. (2013)</ref>showed that contigs can be effectively scaffolded using chromatin-level contact probability maps generated by the high-throughput chromosome conformation capture (Hi-C) technology; however, Hi-C has high input-DNA requirements and its ability to scaffold highcomplexity metagenomes remains relatively limited (<ref type="bibr" target="#b7">Burton et al., 2014</ref>). An alternative technology, single-molecule real-time (SMRT) sequencing, has been shown to be highly effective at assembling bacterial genomes (<ref type="bibr" target="#b15">Koren et al., 2012;</ref><ref type="bibr" target="#b10">Chin et al., 2013</ref>) and was recently scaled to handle entire human genomes (<ref type="bibr" target="#b9">Chaisson et al., 2015</ref>). Its shortcomings include requiring specialized sequencing instruments as well as significant reagent costs relative to the more standard Illumina platform; also, SMRT technologies may exhibit lower accuracy when assembling highly heterozygous genomic regions, especially in the context of metagenomics (<ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>). We further compare SMRT and read cloud technologies in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">High-level overview of Architect</head><p>Current SLR-based approaches to de novo assembly have several important shortcomings. First, subassembly requires very deep sequencing, since each long fragment must be covered to a sufficiently high depth in order to be assembled; in some cases, attaining this high level of coverage may not even be feasible due to inherent technical limitations of the library preparation protocol. Secondly, long reads often work best in combination with standard shotgun reads; however, neither the OCL nor the DBG assembly paradigm is effective at assembling the two types of data jointly. Below, we introduce the Architect scaffolder, which implements a solution to both of these limitations. Read clouds. Rather than adopting a two-stage subassembly approach, Architect attempts to scaffold the genome using low internal coverage read clouds. Recall that we use the term read cloud to denote the set of short reads derived from shearing a long fragment within a given container (<ref type="figure" target="#fig_1">Fig. 2</ref>, top). Local and global coverage. To better explain how our approach differs from subassembly, we introduce the concepts of local and global coverage. Local coverage refers to the average coverage of a long fragment with short reads; it is formally defined as the total number of base pairs in short reads obtained from sequencing a given container, divided by the number of total number of base pairs of genomic content originally placed in the container. Global coverage refers to the coverage of the original genome with long fragments. It is obtained by dividing the number of base pairs placed in all containers by the size of the target genome. Read cloud-based scaffolding. The high-level intuition for how low-local coverage read clouds may be used for scaffolding genomes is illustrated in<ref type="figure" target="#fig_1">Figure 2</ref>. Consider a genome with a repeat R flanked by unique sequences (A, B) and (C, D) (<ref type="figure" target="#fig_1">Fig. 2</ref>, top). If the length ofR is longer than the read length, the assembly graph will contain a characteristic X-shaped structure that cannot be resolved (<ref type="figure" target="#fig_1">Fig. 2</ref>, middle). However, if there are two read clouds that map to ARB and CRD in different containers, we can align the clouds to the contigs and observe that read clouds from the same container align to A and B. This indicates how the contigs should be scaffolded. Contig orderings. A crucial distinction between Architect and regular scaffolders is that read clouds provide relatively little signal about the distance between adjacent contigs. This is partly due to the greatly varying lengths of read clouds previously reported for certain technologies. Another cause is the relatively shallow internal coverage of read clouds, which makes it difficult to estimate where the cloud starts and ends. Because of these complications, Architect reports orderings of contigs instead of scaffolds. The main difference between the two is that orderings offer no guarantees about the relative distance of two consecutive contigs. Although the contiguity of assemblies provided by Architect significantly exceeds that of alternative approaches, the reader should still keep in mind this important distinction when evaluating our results. Algorithm overview. The Architect scaffolder takes as input preassembled scaffolds or contigs from a standard short-read assembler as well as an alignment of read clouds to these scaffolds. In addition to read clouds, Architect is also able to leverage paired-end are mate-pair reads to guide scaffolding in cases where the original assembly is ambiguous. Architect uses alignment of read clouds and paired-end reads to form a scaffold graph; this graph is then simplified to produce orderings of scaffolds. The simplification process is guided by an algorithm which is explained in detail in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Datasets</head><p>We evaluated Architect on four publicly available genomic datasets produced using the commercially available Tru-Seq SLR sequencing technology from Illumina. We obtained datasets for two genomes and two metagenomes; in each case, we had access to the subassembled long reads and their underlying raw short reads. We subsampled these to various percentages (from 5% to 25%), and used them as our 'read cloud' dataset. All read cloud datasets were complemented with standard shotgun libraries. Drosophila melanogaster. We used a dataset previously published by<ref type="bibr" target="#b21">McCoy et al. (2014)</ref>(SRX447481). We library mol-32281c for our analysis (the library contained 212M read pairs, each read being 100 bp in length), in addition to two short-read datasets published in an independent study (SRX543254). Caenorhabditis elegans. We used a dataset made available by Illumina as part of its TSLR technology demonstration (data are available on BaseSpace). We used TSLR library no. 1 (out of 2) for our experiments; we complemented this with a standard shotgun read dataset used in benchmarking genomic assemblers (<ref type="bibr" target="#b27">Simpson and Durbin, 2011</ref>). Mock gut metagenome. We tested our ability to assess the accuracy of our metagenomic assemblies on the human microbiome project staggered mock community (<ref type="bibr">Human Microbiome Project Consortium, 2012</ref>). This synthetic community contains 20 organisms with known reference genomes and is widely used for validation. We used a recent TSLR dataset (library 1) in addition to the accompanying short reads. In addition to helping validate the robustness of Architect to different coverages, this dataset also provides an indication of the ability of long read clouds to scaffold bacterial genomes. Bona fide gut metagenome. Finally, we assemble a bona fide sample from the gut of a healthy male adult individual (<ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>). This dataset was previously assembled from TSLRs and was found to be extremely diverse and complex, making it a realistic and challenging benchmark dataset for Architect. We again used TSLR libraries 1â€“3 from the previous study as well as the entirety of the accompanying short reads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Assembly strategies</head><p>We compared Architect to four alternative assembly strategies. Shotgun reads were assembled using a standard short-read assembler into contigs or scaffolds. In our experiments, we used SPAdes 3.5.0 (<ref type="bibr" target="#b2">Bankevich et al., 2012</ref>) on the D.melanogaster dataset and Soapdenovo2 rc240 (<ref type="bibr" target="#b20">Luo et al., 2012</ref>) on the other three datasets (we found this choice to produce the highest quality contigs). Overall, these two assemblers have been shown in previous studies to achieve state-of-the-art performance on a variety of genomes (<ref type="bibr" target="#b25">Salzberg et al., 2012</ref>). Long reads. Next, we used the Celera assembler (<ref type="bibr" target="#b22">Myers et al., 2000</ref>) directly on subassembled SLRs. The Celera assembler has been previously used to obtain high-quality assemblies from TSLRs on both genomes and metagenomes (<ref type="bibr" target="#b29">Voskoboynik et al., 2013</ref>). Shotgun and long reads were jointly assembled using SPAdes 3.5.0 for the D.melanogaster and C.elegans datasets and Minimus2 (<ref type="bibr" target="#b28">Sommer et al., 2007</ref>) for the metagenomic datasets. Minimus2 is a tool that merges independent shotgun and long read assemblies in a post-processing stage; we found that it assembled two times more sequence that SPAdes on both metagenomic datasets. Shotgun reads and read clouds were assembled with Architect. We aligned shotgun and raw TSLR short-read libraries to contigs assembled from shotgun reads (using the first strategy above); Architect used this data to produce long scaffold orderings. FragScaff. Finally, we compared Architect with an alternative scaffolding program that uses a different algorithm to perform scaffolding based on the same type of data (<ref type="bibr" target="#b0">Adey et al., 2014</ref>). We ran FragScaff multiple times varying the two parameters specified in the documentation to have the largest effect on assembly quality; we report the best results obtained across these runs. The exact scripts used for running our experiments are available in the GitHub repository of Architect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation metrics</head><p>We evaluated performance using standard metrics reported by Quast 3.1, a popular tool for assessing the quality of genome and metagenome assemblies (<ref type="bibr" target="#b12">Gurevich et al., 2013</ref>). The N50 length of a set of contigs is a measure of assembly contiguity: we say that contigs have an N50 of x if at least 50% of the total assembled sequence is in contigs of length x or longer. The genome NA50 is defined as the N50 of scaffolds that have been broken at every major misassembly. Major misassemblies are said to occur when a contig substring aligns 1 kb away or further from its neighbouring sequence. We refer the reader to the documentation of Quast for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results</head><p>3.5.1 Assembly quality A summary of our results can be found in<ref type="figure" target="#tab_1">Table 1</ref>. At a high level, Architect outperforms alternative assembly strategies and produces genome assemblies that are up to five times longer than approaches based on shotgun and subassembled SLRs. Moreover, Architect achieves this performance with only 25% of the sequencing requirements of standard long read-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Genome assembly from read clouds i219</head><p>As an example, on the Drosophila dataset, Architect produces scaffolds of 253 kb in length, compared with a 124 kb SPAdes assembly of shotgun and long reads. Relative to subassembled long read sequencing, the output of Architect contains about 23% more errors; this indicates that assembling short reads separately in each container is less error-prone than assembling them jointly. However, note that the number of misassemblies produced by Architect is essentially the same as that of the purely short-read assembly (Â¡4% difference), indicating that the errors are primarily introduced during the initial short-read assembly stage, rather than during Architect scaffolding. Similar observations can be made for other genomes as well. On the mock metagenomic data, we observed a 5-fold increase in N50 from 35 kb to more than 170. This suggests that Architect is robust to variation in coverage across scaffolds. Our approach also improved performance on the bona fide gut metagenome, with Architect matching the performance of the strategies involving full subassembly. Although the resulting scaffolds are still much shorter than ones obtained on the mock metagenome data, they are of a sufficient length to capture many interesting long-range genomic features such as operons or strain haplotypes. All of the above findings suggest that the potential of SLRs is not fully realized using existing joint assembly strategies. Architect is able to use the signal from read clouds more efficiently, as it sidesteps the difficulties of working with different classes of read data. Another advantage of our approach relative is that it can leverage fragments that could not be subassembled (e.g. due to sequencing biases introducing gaps in internal coverage). More generally, it is applicable to read cloud technologies that subsequence long fragments to very shallow depths, and where subassembly cannot be performed in principle. Another observation to be made is that subassembled long reads by themselves do not outperform shotgun reads on multiple datasets. Past work has attributed this to sequencing biases in the Truseq technology (<ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>). This again motivates the need for an assembly approach like Architect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Sensitivity to coverage</head><p>Next, we measured the effects of internal read cloud coverage on the quality of assemblies produced by Architect. More specifically, we subsampled the read cloud library for the D.melanogaster genome to 5%, 10% and 15% of the original coverage, in addition to the 25% subsampled dataset examined above.<ref type="figure" target="#tab_2">Table 2</ref>shows the results of our subsampling procedure. Even at very low coverages, accuracy and N50 length do not degrade significantly. This indicates that users may trade off internal coverage for increased external coverage of the genome in applications where this is necessary, for example when dealing with larger genomes. Moreover, these results suggest that Architect should scale to alternative read cloud technologies whose internal coverage is relatively sparse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.3">Running times</head><p>Overall, the main computational bottlenecks in our scaffolding process are the preprocessing stages: the de novo assembly of the input contigs and the alignment of reads back to these contigs. For largergenomes, these may take on the order of days to run. The Architect algorithm itself runs on the order of tens of minutes; on our machine, its running times on D.melanogaster, C.elegans, the mock and the bona fide metagenomes were 7, 6, 13 and 24 min, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>We now proceed to explain the details of the scaffolding algorithm implemented in Architect. The algorithm takes as input preassembled contigs or scaffolds from a standard shotgun assembler, as well as alignments between the scaffolds and two sets of reads: paired-end shotgun sequences and read clouds. Then, it follows a three-stage protocol whose final output is accurate orderings of the input scaffolds. At the first stage, Architect uses the input alignments to build a scaffold graph. Nodes in the graph correspond to scaffolds; links are placed between scaffolds whenever there appears to be evidence that they might be in close proximity in the target genome. Then, the graph is iteratively pruned in order to remove spurious edges. Pruning occurs in three steps: first, we use paired-end link information to identify the highest-confidence connections; next, we use read cloud alignments to resolve cases where paired-links could not be pruned with sufficient confidence; finally, we use information contained solely in read clouds to make decisions about edges which have no evidence from paired-end reads. These decisions are made using a model that determines the probability of a spurious assignment given observed read cloud evidence. Finally, in the third and last step, we use the remaining unpruned edges to order the scaffolds. We now give more details about each procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Scaffolding algorithm</head><p>We now give a high-level overview of our scaffolding strategy. The input to our procedure is a set of scaffolds S and two sets of alignments (in BAM format): a paired-end read alignment and a read cloud alignment. We also let K denote the total number of read cloud containers; for the TSLR data used in our experiments, K Â¼ 384 per library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Graph construction</head><p>We start by forming the scaffold graph G Â¼ Ã°V; EÃž. The vertices V Â¼ fs c js 2 S; c 2 fh; tgg of G correspond to scaffolds augmented with indicators c that represent either the head (c Â¼ h) or tail (c Â¼ t) of the node. The edge set E is restricted to 'consistent' pairs s i;ci ; s j;cj where Ã°c i ; c j Ãž Â¼ Ã°h; tÃž or (t, h). Edges are constructed from the paired-end and read cloud alignments as follows. Paired-end link detection. We introduce an edge between s i ; s j 2 S if there are at least three paired-end links connecting them. Each paired-end read must have a mapping score of ! 30; also, the average inter-scaffold distance over all read pairs in a link must fall within three standard deviations of the average library insert size. We will use linksÃ°s i;ci ; s j;cj Ãž to denote the number of paired-end links between the corresponding scaffolds. Container hit detection. We say that a 'hit' for container k occurs in scaffold s i when a read cloud from that container maps to s i. If two s i , s j are close to each other in the target genome, we expect to observe multiple hits from the same containers in both of them. To avoid false positives due to incorrect read alignments, we call a hit when at least h min reads from a container map to s i (h min &gt; 40 by default for TSLR data). Also, when there is a hit from container k to scaffold s i , we associate that hit with an intervalsi;k ) as the start (respectively, the end) position of the 10-th short-read aligning to s i from container k, starting from the left (respectively, from the right). This again encourages robustness to read misalignments. We will use hitsÃ°s i;ci Ãž f1;. .. ; Kg to denote the set of hits in s i at endpoint c i ; we also use commonÃ°s i;ci ; s j;cj Ãž Â¼ jhitsÃ°s i;ci Ãž \ hitsÃ°s j;cj Ãžj jhitsÃ°s i;ci Ãž [ hitsÃ°s j;cj Ãžj to denote the fraction of hits shared between s i;ci ; s j;cj. New edges in G are created whenever jhitsÃ°s i;ci Ãž \ hitsÃ°s j;cj Ãžj ! 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Pruning</head><p>Paired-end pruning. First, we determine edges that have strong support from paired-end reads and prune ones that don't. Specifically, we identify edges e Â¼ Ã°s i;ci ; s j;cj Ãž that have stronger support than all alternatives E alt Â¼ fÃ°s 1 ; s 2 Ãžjs 1 2 e or s 2 2 eg in the sense that</p><formula>8e 0 2 E alt. linksÃ°eÃž Ã€ linksÃ°e 0 Ãž ! s 1 and linksÃ°e 0 Ãž linksÃ°eÃž s 2 ;</formula><p>where s 1 Â¼ 3 and s 2 Â¼ 0:7 by default. In such cases, we identify e as a correct and prune away E alt from the graph. Note that this stage is meant to emulate of SSPACE (<ref type="bibr" target="#b5">Boetzer et al., 2011</ref>), a popular and widely used standalone scaffolder. Although the algorithm we use is very simpleâ€”especially compared with more complex, multi-stage scaffolding procedures implemented in the Celera (<ref type="bibr" target="#b22">Myers et al., 2000</ref>) or Velvet (<ref type="bibr" target="#b30">Zerbino et al., 2009</ref>) assemblersâ€”it has been shown to be one of the best overall scaffolding methods in a recent empirical study (<ref type="bibr" target="#b14">Hunt et al., 2014</ref>).where q 1 ! 0 is a user-specified parameter. In such cases, we identify e as correct and prune away E alt from the graph. This step attempts to resolve paired-end link ambiguities via read clouds; it considers links with insufficient cloud support to be spurious. Read-cloud pruning. Finally, we discard all link data, and prune away edges that have insufficient support from read clouds. In particular we prune all edges E for which</p><formula>commonÃ°eÃž &lt; q 2 :</formula><p>Again, q 2 ! 0 is a user-specified parameter. The parameters Ã°q 1 ; q 2 Ãž are set by default to (0.2, 0.33); we found that these values produced the best NA50 in our experiments. Decreasing these values (i.e. increasing the recall), did not result in any improvements in NA50, while increasing them by more than 25% (thus increasing precision), produced a considerable decrease in assembly contiguity at the cost of a relatively modest improvement in accuracy. The default parameters for Ã°s 1 ; s 2 Ãž were chosen to match those of SSPACE (<ref type="bibr" target="#b5">Boetzer et al., 2011</ref>); in our experiments, performance was relatively robust relative to these parameters, mainly because most edges from paired-end links were unambiguous. Finally, we specified some parameters directly as constants (e.g.Comparison to SMRT sequencing. Multiple authors have shown that SMRT sequencing is highly effective at assembling bacterial (<ref type="bibr" target="#b15">Koren et al., 2012;</ref><ref type="bibr" target="#b10">Chin et al., 2013</ref>), eukaryotic (<ref type="bibr" target="#b3">Berlin et al., 2015</ref>) and even human (<ref type="bibr" target="#b9">Chaisson et al., 2015</ref>) genomes. The SMRT technology produces reads of up to a dozen of kilobases in length which exhibit very low sequence bias; these may probe genomic regions that are difficult to access even with standard shotgun sequencing reads (<ref type="bibr" target="#b9">Chaisson et al., 2015</ref>). The same cannot be said for SLRs, which often involve an amplification step (based on e.g. PCR), which may result in highly non-uniform genomic coverage (<ref type="bibr" target="#b23">Peters et al., 2012;</ref><ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>). The SMRT technology is also more effective at assembling tandem repeat regions, which may confuse subassembly-based approaches. The main shortcomings of SMRT include specialized sequencing instruments and increased reagent costs relative to the Illumina platform. Moreover, SMRT technologies typically exhibit lower accuracy; although this can often be mitigated by error-correction algorithms, such algorithms may inadvertently correct real genomic variation, especially in the context of heterozygous genomes or multiple closely related metagenomic strains (<ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>). Drosophila melanogaster assembly analysis. To further analyze the differences between the two technologies, we compared the SMRT assembly of D.melanogaster by<ref type="bibr" target="#b3">Berlin et al. (2015)</ref>with our assembly based on Tru-seq SLR clouds whose local coverage was subsampled to 25% of the original data. The SMRT assembly was substantially more contiguous than ours (21 Mbp versus 252 kb N50); furthermore, SMRT produced contiguous genomic sequences, whereas the output of our method consists of contig orderings. The difference in performance between the two methods can be attributed to a significantly higher coverage of the target genome (90x versus 17x global coverage) and substantially longer read lengths (average length of 9317 kb versus 4800 kb; the latter number refers to the average length of subassembled long reads, which we use as a proxy for the average length of useful long fragments). Most importantly, Tru-seq SLRs exhibit important sequencing bias (<ref type="bibr" target="#b18">Kuleshov et al., 2015</ref>), which leaves many genomic regions uncovered; this is partly evidenced by the fact that standard shotgun assemblies match the contiguity of assemblies based on fully subassembled long reads, even though the latter are $100Ã‚ longer. In fact, we observed that regions in the Drosophila reference genome to which orderings produced by Architect could be aligned with MUMmer (v. 3.0 with default parameters) had an average GC content of 47%, compared with 38% for other regions. The average GC content in D.melanogaster was 42.23%. In addition, we reproduced the analysis of<ref type="bibr" target="#b3">Berlin et al. (2015)</ref>and found that our assembly placed 4690 (86%) of 5425 annotated transposable element repeats in a single contig ordering, compared with 5274 (97%) for the SMRT assembly. This difference can be attributed to the difficulty of SLRs in handling tandem and nested repeats, as well as to the shorter fragment length used in our assembly. Although, our assembly of D.melanogaster was less complete than that based on SMRT reads, we want to emphasize that alternative technologies (e.g. the 10X platform) may yield substantially longer read clouds with less sequencing bias than ones we used for our assembly. Since our technique is applicable to such technologies, we expect it to produce competitive assemblies when the underlying read cloud technologies become more mature. Alternative technologies and larger genomes. Although we used Architect to assemble small-and medium-sized genomes, our highlevel approach extends naturally to larger genomes. Larger genomes typically have longer repeats, and resolving them requires longer read clouds. While commercial technologies enabling such read clouds are starting to become commercially available, there are yet few publicly available read cloud datasets, which motivates us to focus our evaluation on TSLR data. Our approach may also be complementary to alternative technologies such as chromatin-level contact probability maps or SMRT sequencing. The latter technology could be used to generate substantially longer initial contigs, which could then be further scaffolded with long read clouds. Chromatin-level contact probability maps could be used to further scaffold the ordered contigs produced by Architect into chromosome-long maps. This idea was shown to be highly effective in combination with the output of FragScaff and should be expected to work with the output of Architect as well. Finally, an important advantage of our subassembly approach is its modularity: the base contigs can be produced using any shotgun assembler, and as a consequence our methodology can be improved by better assemblers and by additional sequencing data such as mate-pair reads.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. High-level overview of SLR and read cloud technologies. DNA (1) is sheared into kilobase-long fragments (2), which are then diluted and placed into multiple containers, typically with 0.1â€“2% of the genome per container (3). Within each container, fragments may be amplified before being cut into short fragments, and barcoded (4). The barcoded fragments are finally pooled together and sequenced (5); reads can be demultiplexed on a computer into their original compartment via the barcodes in order to form read clouds or SLRs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Scaffolding using read clouds. A genome contains a repeat R flanked by unique sequences (A, B) and (C, D) (top). With short reads, the correct assembly is ambiguous (middle). If two read clouds (marked as red and orange) map, respectively, to ARB and CRD, this provides signal that may be used to correctly resolve the repeat structure (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>through vertices v 2 V in decreasing order of length. For each e 2 E incident to v, let E alt Ã°eÃž Â¼ fÃ°s 1 ; s 2 Ãžjs 1 2 e or s 2 2 eg. If 8e 0 2 E alt Ã°eÃž; linksÃ°eÃž Ã€ linksÃ°e 0 Ãž ! s 1 and linksÃ°e 0 Ãž linksÃ°eÃž s 2 , then select e as being the correct edge and prune E alt Ã°eÃž from the graph. @BULLET Joint read cloud and paired-end pruning. Go again through vertices v 2 V in decreasing order of length. For each e 2 E incident to v such that linksÃ°eÃž ! 3; commonÃ°eÃž ! q 1 , let E alt Ã°eÃž Â¼ fÃ°s 1 ; s 2 Ãžjs 1 2 e or s 2 2 eg. If 8e 0 2 E alt Ã°eÃž; commonÃ°e 0 Ãž &lt; q 1 or linksÃ°e 0 Ãž Â¼ 0, then prune E alt Ã°eÃž from the graph. @BULLET Read-cloud pruning. Prune e 2 E for which commonÃ°eÃž &lt; q 2 : 3. Determine scaffold orderings O via edge contraction in G. Output: Set of orderings O. Genome assembly from read clouds i221 Joint paired-end and read-cloud pruning. Next, we find edges with support from both paired-end reads and read clouds, and eliminate alternatives. In particular, we find all edges e 2 E such that</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Assembly evaluation of Architect on four de novo assembly datasets.</figDesc><table>Genome Ã¾ sequencing method 
Scaffolds 
Largest scaffold (kb) 
Mb assembled 
% assembled 
N50 (kb) 
NA50 (kb) 
Misassemblies 

Drosophila melanogaster 
Shotgun reads 
65 510 
314.5 
143.7 
100.0 
44.8 
43.1 
2265 
Long reads 
5064 
341.5 
127.5 
88.7 
45.3 
43.2 
1742 
Shotgun and long reads 
29 809 
649.4 
117.4 
81.7 
123.9 
115.1 
2024 
FragScaff  â€  
63 018 
567.8 
55.3 
38.6 
56.8 
55.2 
2289 
Shotgun and read clouds  â€  
57 567 
1767.4 
143.7 
100.0 
262.8 
252.2 
2341 
Caenorhabditis elegans 
Shotgun reads 
32 092 
383.1 
100.1 
99.9 
35.6 
31.9 
307 
Long reads 
2345 
555.0 
96.3 
96.4 
81.2 
76.0 
363 
Shotgun and long reads 
2423 
569.0 
83.3 
83.5 
95.6 
68.7 
771 
FragScaff  â€  
29 320 
510.2 
40.3 
40.4 
51.1 
50.2 
321 
Shotgun and read clouds  â€  
4235 
630.9 
99.6 
99.7 
120.2 
113.4 
331 
Mock metagenome 
Shotgun reads 
36 081 
414.0 
34.0 
41.1 
19.1 
18.8 
34 
Long reads 
914 
405.1 
17.6 
21.2 
24.6 
24.2 
29 
Shotgun and long reads 
22 562 
553.3 
42.5 
51.2 
35.1 
34.3 
113 
FragScaff  â€  
33 180 
510.1 
10.2 
12.3 
33.2 
31.1 
37 
Shotgun and read clouds  â€  
17 688 
743.4 
34.0 
41.1 
173.7 
173.7 
39 
Bona fide metagenome 
Shotgun reads 
128 131 
34.1 
230.1 
â€” 
5.3 
â€” 
â€” 
Long reads 
12 432 
89.2 
170.2 
â€” 
8.2 
â€” 
â€” 
Shotgun and long reads 
121 319 
101.9 
289.5 
â€” 
15.3 
â€” 
â€” 
FragScaff  â€  
127 943 
40.2 
100.3 
â€” 
6.2 
â€” 
â€” 
Shotgun and read clouds  â€  
123 975 
91.4 
288.1 
â€” 
13.3 
â€” 

Note: Note that metrics reported for FragScaff and Architect correspond to orderings of contigs rather than scaffolds (this is indicated by a â€ ) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2.</figDesc><table>Effect cloud sparsity on assembly quality 

Subsample 
Number 
of reads (M) 

N50 
(kb) 

NA50 
(kb) 

Size 
(Mb) 

Max 
(kb) 

25% 
53.1 
262.8 
252.2 
143.7 
1767.4 
15% 
31.9 
261.4 
250.8 
143.7 
1340.2 
10% 
21.2 
242.2 
224.5 
143.7 
961.3 
5% 
10.6 
178.8 
160.4 
143.7 
611.3 

Note: Results are reported for orderings of Drosophila input scaffolds pro-
duced by Architect. 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3"> minimum paired-end links to form an edge); we found that tweaking these parameters led to little improvements, and in some cases resulted in a large degradation of performance. 4.1.3 Ordering Once we have pruned the graph G, we proceed to order and orient scaffolds. Two scaffolds s i;ci ; s j;cj can be oriented relative to each other if they are connected by an edge e, and there is no other edge that touches s i;ci or s j;cj. In such cases, we can contract e and merge s i;ci ; s j;cj into a new scaffold. We repeat this procedure for all edges that can be contracted and output the sequences of the scaffold in the final, simplified graph. 4.2 Evaluation methodology We use the standard metrics of Quast (Gurevich et al., 2013) to measure misassemblies. Quast determines true contig positions by mapping them to the reference via MUMmer; it defines a major miassembly as an alignment in which a contig subsequence maps 1 kb or further from its neighbouring subsequences. We define the genome NA50 as the N50 of scaffolds that have been broken at every major misassembly. In order to evaluate the quality of the output of Architect, we developed our own evaluation script, which is available on Github. In brief, we first map to the reference the scaffolds provided as input to Architect. Then, given a set of output orderings, we determine the number of misassemblies in the orderings as a sum (1) the number of misassemblies in the input contigs and (2) the number of misorderings introduced by Architect. The latter is defined as follows. Given two scaffolds a, b mapping to intervals (a 1 , a 2 ), (b 1 , b 2 ) in the reference, we say that b follows a if a, b map to the same strand of the same chromosome and the following two criteria hold: a 1 &lt; b 1 and jb 1 Ã€ a 2 j &lt; 5000. Given an ordering c 1 ; c 2 ;. .. ; c n of contigs (each c i corresponding to an interval), we determine the number of misorderings as the number of consecutive pairs i; i Ã¾ 1 that are not adjacent. We consider both left-to-right and right-to-left orderings, and take the correct one to be the one with the fewest errors. Note that this procedure generalizes the methodology used in Quast. 5 Discussion Comparison to FragScaff. FragScaff and Architect leverage the same read cloud signal to perform scaffolding; they mainly differ in their scaffolding algorithm. FragScaff generally adopts a top-to-bottom approach: it determines edge scores by fitting a normal distribution to hitsÃ°s i ; s j Ãž across the entire graph. Users specify a z-score as a cutoff for pruning edges; true connections are then determined using a greedy MST algorithm. Architect on the other hand combines scaffolds from the bottom up: it computes a local score for each edge, which depends only on local signal between s i and s j. Architect then prunes edges locally: it discards edges within a neighbourhood if that neighbourhood contains a single best connection. Unlike FragScaff, it does not attempt to resolve the remaining edges via a MST. We believe the latter approach has several advantages in the context of metagenomes and high-coverage low-dilution technologies like TSLR. First, the cutoff for pruning reads ought to depend on the neighbourhood: a correct edge e Ãƒ may have low support, but if alternative edges are even less supported, we may still choose to select e Ãƒ and discard the alternatives. This is especially true for read cloud technologies that exhibit coverage biases across different regions of the genome. Conversely, the greedy MST approach must select a connected tree in the scaffold graph. Thus, if two edges are equally good candidates, it must choose one over the other. Finally, Architect is able to leverage standard paired-end links to improve scaffold contiguity. These links are particularly helpful when initial short-read assemblies are fragmented; generally, we want the initial shotgun-based scaffolds to be sufficiently long, so that a sufficient number of read clouds may align to them. Pairedend links may help bootstrap scaffolding with read clouds when the starting contigs are too short. Comparison to SLR subassembly. Architect produced in most cases assemblies that were longer than ones obtained from subassembled long reads, even though it required substantially less sequencing. This in part due to the fact that the TSLRs used in our experiments did not adequately cover the entirety of the target genome, owing primarily to sequencing biases. In fact, high-coverage shotgun reads typically produced assemblies with comparable N50 lengths to the SLR assemblies, indicating that repeats were not the bottleneck factor limiting the effectiveness of the long reads. This hypothesis is further supported by the fact that jointly assembling the long read and shotgun datasets produced substantially better results than with either technology by itself. However, jointly assembling read clouds and shotgun reads produced significantly longer assemblies that even this latter approach. We believe there are two explanations behind this. First, current assembly paradigms are targeted at either short or long reads, and there are currently no effective tools for combining both types of assemblies. Architect side-steps this issue by using the read clouds only as an indirect signals during the scaffolding process. Furthermore, read cloud technologies such as TSLR often exhibit biases in their internal coverage, and as a consequence some clouds may not subassemble into long reads. By side-stepping subassembly, our approach is able to leverage these low-quality clouds. i222 V.Kuleshov et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="6"> Conclusion In conclusion, we have shown that shallow read clouds can be used to effectively produce long-range scaffolds on both genomic and metagenomic data without actually forming subassembled long reads. This produces 5-to 20-fold savings in sequencing requirements while at the same time increasing the N50 length of scaffolds by up to five times compared with current state-of-the-art methods. Furthermore, our tool Architect improves over an existing scaffolder, FragScaff, by being able to handle read clouds produced from other technologies besides CPT-seq as well as by handling metagenomic datasets. These were noted as important limitations of the read cloud scaffolding approach in the original FragScaff paper. Our results suggest that Architect may lower the cost of accurate de novo assembly and facilitate the analysis of metagenomic samples. Scaffolds on the order of tens of kilobases are sufficient to capture many interesting long-range genomic features in metagenomes, for example long operons or strain haplotypes. Lowering the sequencing requirements needed to access these features is particularly important, since high coverage is needed to capture low abundance strains. By reducing by 10-fold the internal coverage of read clouds, we may correspondingly increase external coverage by 10fold, which in turns let us sample species whose level of abundance is 10 times smaller than what was previously accessible. Finally, we would like to note the fact that our approach is highly modular and can be expected to lead to improvements when combined with better shotgun read assemblers as well as alternative sequencing methods such as chromatin-level contact probability maps, SMRT sequencing or mate pairs. Funding This work was supported by US National Institutes of Health/National Human Genome Research Institute (NIH/NHGRI) grant T32 HG000044. V.K. was supported by a Natural Sciences and Engineering Research Council of Canada (NSERC) post-graduate fellowship. We thank Illumina, Inc. for their assistance in providing some of the datasets used in this work. Conflict of Interest: V.K. is a consultant for Illumina Inc. S.B. is a co-founder of DNAnexus and a member of the scientific advisory boards of 23 and Me and Eve Biomedical. M.S. is a co-founder of Personalis and a member of the scientific advisory boards of Personalis, AxioMx and Genapsys. Genome assembly from read clouds i223 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">In vitro, long-range sequence information for de novo genome assembly via transposase contiguity</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Adey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2041" to="2049" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Haplotype-resolved whole-genome sequencing by contiguity-preserving transposition and combinatorial indexing</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Amini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1343" to="1349" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Spades: A new genome assembly algorithm and its applications to single-cell sequencing</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bankevich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="455" to="477" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Assembling large genomes with single-molecule sequencing and locality-sensitive hashing</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Berlin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="623" to="630" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Read clouds uncover variation in complex regions of the human genome</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bishara</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1570" to="1580" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Scaffolding pre-assembled contigs using S SPACE</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Boetzer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="578" to="579" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Chromosome-scale scaffolding of de novo genome assemblies based on chromatin interactions</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">N</forename>
				<surname>Burton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1119" to="1125" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Species-level deconvolution of metagenome assemblies with hi-c-based contact probability maps</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">N</forename>
				<surname>Burton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">G3</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1339" to="1346" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">De novo fragment assembly with short mate-paired reads: Does the read length matter?</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chaisson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">336</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Resolving the complexity of the human genome using single-molecule sequencing</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J P</forename>
				<surname>Chaisson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">517</biblScope>
			<biblScope unit="page" from="608" to="611" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonhybrid, finished microbial genome assemblies from long-read SMRT sequencing data</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">S</forename>
				<surname>Chin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="563" to="569" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Fosmid-based whole genome haplotyping of a HapMap trio child: Evaluation of single individual haplotyping techniques</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Duitama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2041" to="2053" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">QUAST: Quality assessment tool for genome assemblies</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gurevich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1072" to="1075" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A framework for human microbiome research</title>
	</analytic>
	<monogr>
		<title level="j">Human Microbiome Project Consortium. Nature</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="page" from="215" to="221" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">A comprehensive evaluation of assembly scaffolding tools</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hunt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Hybrid error correction and de novo assembly of singlemolecule sequencing reads</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Koren</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="693" to="700" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic single-individual haplotyping</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kuleshov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="379" to="385" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Whole-genome haplotyping using long reads and statistical methods</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kuleshov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Synthetic long-read sequencing reveals intraspecies diversity in the human microbiome</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kuleshov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotech</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="64" to="69" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Illumina synthetic long read sequencing allows recovery of missing sequences even in the finished C. elegans genome</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">10814</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Soapdenovo2: An empirically improved memory-efficient short-read de novo assembler</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Luo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GigaScience</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Illumina truseq synthetic long-reads empower de novo assembly and resolve complex, highly repetitive transposable elements</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">C</forename>
				<surname>Mccoy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">106689</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A whole-genome assembly of drosophila</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">287</biblScope>
			<biblScope unit="page" from="2196" to="2204" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Accurate whole-genome sequencing and haplotyping from 10 to 20 human cells</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">A</forename>
				<surname>Peters</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">487</biblScope>
			<biblScope unit="page" from="190" to="195" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">An Eulerian path approach to DNA fragment assembly</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Pevzner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA, 98</title>
		<meeting>. Natl. Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="9748" to="9753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">GAGE: A critical evaluation of genome assemblies and assembly algorithms</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Salzberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="557" to="567" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Accurate, multi-kb reads resolve complex populations and detect rare microorganisms</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Sharon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="534" to="543" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient de novo assembly of large genomes using compressed data structures</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="111" to="126556" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Minimus: A fast, lightweight genome assembler</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">D</forename>
				<surname>Sommer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">The genome sequence of the colonial chordate, Botryllus schlosseri</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Voskoboynik</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">569</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Pebble and rock band: Heuristic resolution of repeats and scaffolding in the velvet short-read de novo assembler</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Zerbino</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>