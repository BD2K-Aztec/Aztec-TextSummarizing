
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics Automated annotation of developmental stages of Drosophila embryos in images containing spatial patterns of expression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Lei</forename>
								<surname>Yuan</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computing, Informatics</orgName>
								<orgName type="department" key="dep2">Decision Systems Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Cheng</forename>
								<surname>Pan</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computing, Informatics</orgName>
								<orgName type="department" key="dep2">Decision Systems Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Shuiwang</forename>
								<surname>Ji</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computing, Informatics</orgName>
								<orgName type="department" key="dep2">Decision Systems Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Michael</forename>
								<surname>Mccutchan</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Zhi-Hua</forename>
								<surname>Zhou</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="laboratory">National Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing, China</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Stuart</forename>
								<forename type="middle">J</forename>
								<surname>Newfeld</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Life Sciences</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Sudhir</forename>
								<surname>Kumar</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Life Sciences</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Center of Excellence in Genomic Medicine Research</orgName>
								<orgName type="institution">King Abdulaziz University</orgName>
								<address>
									<settlement>Jeddah</settlement>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jieping</forename>
								<surname>Ye</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computing, Informatics</orgName>
								<orgName type="department" key="dep2">Decision Systems Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Evolutionary Medicine and Informatics</orgName>
								<orgName type="institution" key="instit1">The Biodesign Institute</orgName>
								<orgName type="institution" key="instit2">Arizona State University</orgName>
								<address>
									<postCode>85287</postCode>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimage informatics Automated annotation of developmental stages of Drosophila embryos in images containing spatial patterns of expression</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="266" to="273"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt648</idno>
					<note type="submission">Received on June 3, 2013; revised on September 8, 2013; accepted on November 4, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren for download at: http://www.public.asu.edu/*jye02/Software/Fly-Project/. Contact: jieping.ye@asu.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Drosophila melanogaster is a major model organism for investigating the function and interconnection of animal genes in the earliest stages of embryogenesis. Today, images capturing Drosophila gene expression patterns are being produced at a higher throughput than ever before. The analysis of spatial patterns of gene expression is most biologically meaningful when images from a similar time point during development are compared. Thus, the critical first step is to determine the developmental stage of an embryo. This information is also needed to observe and analyze expression changes over developmental time. Currently, developmental stages (time) of embryos in images capturing spatial expression pattern are annotated manually, which is time-and labor-intensive. Embryos are often designated into stage ranges, making the information on developmental time course. This makes downstream analyses inefficient and biological interpretations of similarities and differences in spatial expression patterns challenging, particularly when using automated tools for analyzing expression patterns of large number of images. Results: Here, we present a new computational approach to annotate developmental stage for Drosophila embryos in the gene expression images. In an analysis of 3724 images, the new approach shows high accuracy in predicting the developmental stage correctly (79%). In addition, it provides a stage score that enables one to more finely annotate each embryo so that they are divided into early and late periods of development within standard stage demarcations. Stage scores for all images containing expression patterns of the same gene enable a direct way to view expression changes over developmental time for any gene. We show that the genomewide-expression-maps generated using images from embryos in refined stages illuminate global gene activities and changes much better, and more refined stage annotations improve our ability to better interpret results when expression pattern matches are discovered between genes. Availability and implementation: The software package is available</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Increasingly higher throughput bio-imaging technologies are enabling scientists to capture the spatiotemporal patterns of gene expression, which promises to generate a more comprehensive picture of genome function and interaction (<ref type="bibr" target="#b3">Cardona and Tomancak, 2012;</ref><ref type="bibr" target="#b25">Peng et al., 2007;</ref><ref type="bibr" target="#b31">Walter et al., 2010;</ref><ref type="bibr" target="#b34">Yakoby et al., 2008</ref>). Today, gene expression and protein localization patterns are being captured with unprecedented spatial resolution in numerous model organisms. For example, more than one hundred thousand images of gene expression patterns from early embryogenesis are available for Drosophila melanogaster (fruit fly) (<ref type="bibr" target="#b18">Le´cuyerLe´cuyer et al., 2007;</ref><ref type="bibr" target="#b28">Tomancak et al., 2002</ref>). These images are a treasure trove for identifying co-expressed and coregulated genes and for tracing the changes in a gene's expression over time (<ref type="bibr" target="#b18">Le´cuyerLe´cuyer et al., 2007;</ref><ref type="bibr" target="#b28">Tomancak et al., 2002</ref>). Knowledge gained from analyses of these Drosophila expression patterns is widely important because a large number of genes involved in fruit fly development are commonly found in animal kingdom (<ref type="bibr" target="#b19">Levine and Davidson, 2005;</ref><ref type="bibr" target="#b26">Simpson, 2002;</ref><ref type="bibr" target="#b32">Weiss, 2005</ref>). Consequently, many of the inferences made from studies of fruit flies have been shown to apply to humans and other species (<ref type="bibr" target="#b4">Chen and Crowther, 2012;</ref><ref type="bibr" target="#b14">Kumar, 2001;</ref><ref type="bibr" target="#b19">Levine and Davidson, 2005;</ref><ref type="bibr" target="#b23">Miller et al., 2013;</ref><ref type="bibr" target="#b26">Simpson, 2002;</ref><ref type="bibr" target="#b32">Weiss, 2005;</ref><ref type="bibr" target="#b33">Williams et al., 2012</ref>). Overall, research efforts into the spatial and temporal characteristics of gene expression patterns of Drosophila have been at the leading edge of scientific investigations into the fundamental principles of animal development (<ref type="bibr" target="#b12">Kalinka et al., 2010;</ref><ref type="bibr" target="#b13">Konikoff et al., 2012;</ref><ref type="bibr" target="#b24">Osterfield et al., 2013;</ref><ref type="bibr" target="#b28">Tomancak et al., 2002;</ref><ref type="bibr" target="#b31">Walter et al., 2010</ref>). The comparative analysis of gene expression patterns is most biologically meaningful when images from a similar time point are compared (Campos<ref type="bibr" target="#b2">Ortega and Hartenstein, 1997</ref>). Based on morphological landmarks, the continuous process of Drosophila embryogenesis is traditionally divided into a series of Stages (1, 2, Á Á Á, 17) (<ref type="bibr" target="#b15">Kumar et al., 2002</ref>). However, the standard practice of manually inspecting images containing spatial patterns is a ratelimiting step, especially when it has to be done for large number *To whom correspondence should be addressed. ß The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. of images produced by high-throughput techniques. Images generated in some high-throughput experiments are currently given stage range assignments (e.g. 4–6) rather than individual stages (<ref type="figure">Fig. 1</ref>). As the original developmental stage delineations are based on major morphological events in the fruit fly development, it is, in principle, possible to distinguish embryos in images at the level of individual stages (<ref type="bibr" target="#b11">Ji et al., 2008;</ref><ref type="bibr" target="#b36">Ye et al., 2006</ref><ref type="bibr" target="#b37">Ye et al., , 2008</ref>). However, previous methods (<ref type="bibr" target="#b1">Cai et al., 2012;</ref><ref type="bibr" target="#b22">Meng and Shyu, 2011</ref>) only predict stage ranges, and no methods currently exist to provide specific stage annotations for Drosophila embryos. Furthermore, no approach currently exists to annotate developmental stage for an embryo on a continuous numerical basis, which would be more biologically realistic because development is a continuous process that is reflected in the output of the high-throughput experiments. Visually, it is possible to scan a set of embryonic expressions and arrange them into a progression of gene expression, which informs us about the change and direction of spatial expression over time. This indicates need for a system that has the ability to assign more finely graded stage information that enables one to conduct biological discovery using images with higher resolution of stage similarity. In this article, we report one such computational system and show how it enhances visualization and scientific discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MATERIALS AND METHODS</head><p>To develop an automated annotation system, we began by building a comprehensive training set, in which development experts identified images that were exemplar for each developmental stage defined in (Campos<ref type="bibr" target="#b2">Ortega and Hartenstein, 1997</ref>). This constituted our initial training/testing set and contained 3724 images (all in lateral view) such that there were 4200 images for each stage considered (<ref type="figure" target="#tab_1">Table 1</ref>). We applied machine learning (<ref type="bibr" target="#b0">Bishop et al., 2006</ref>) to develop a pool of 1050 classification models to discriminate among stages. For any image, all 1050 models are applied to generate a stage prediction, which produces the voting histogram (<ref type="figure">Fig. 2</ref>). This histogram is used to generate estimates of embryo stage annotation at various levels of granularity. In the simplest case, we classify an embryo to be of stage S if a majority of models designated the image to be in Stage S. For example, Stage 10 gets the highest number of votes, and thus it is assigned to the embryo in the image under consideration (<ref type="figure">Fig. 2</ref>). This histogram also shows that the number of votes for Stage 9 is higher than that for Stage 11, which enables a finer stage designation (early Stage 10, 10E) for this embryo. We also generate a stage score (SS) using the frequencies in the voting histogram to incorporate non-symmetry of the distribution and relative size of the most frequent peaks. For the example in<ref type="figure">Figure 2</ref>, SS ¼ 6:8. These stage scores can be used to order images based on embryonic developmental time or produce finer grade stage annotations. The rest of this section is organized as follows. In Section 2.1, we discuss the training set we built as 'ground truth' for our system. We then present the various machine learning methods used to create a big pool of models in Section 2.2. Finally, we introduce the annotation of previously unseen images in Section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training set acquisition</head><p>To develop an automated annotation system, a key component is to build a comprehensive training set, in which each entity (in our case, images of gene expression in Drosophila embryo) is associated with the 'accurate' annotation (in our case, the corresponding stage). By learning from the training set, a system will extract critical information from the images that discriminates the developmental stages from each other and uses the extracted knowledge to build classifiers for predicting the stage of previously unseen images. We have manually annotated a collection of images with precise stage labels for 3724 standardized Berkeley Drosophila Genome Project (BDGP) images (in lateral view) in FlyExpress. The detailed numbers of labeled images are listed in<ref type="figure" target="#tab_1">Table 1</ref>. Embryogenesis in Drosophila starts with 13 rapid nuclear divisions after fertilization. Thus, the only morphological difference across the first stage range (Stages 1–3) is the number of nuclei, a feature not visible with the microscopy used by the BDGP consortium. Therefore, they are considered as a single stage (Stage 3) in this work. The alignment and orientation of all images in this study are standardized using a semi-automated pipeline, and the size is scaled to 128 by 320 pixels (<ref type="bibr" target="#b13">Konikoff et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model pool construction</head><p>The key of a successful voting system is to build a pool of diverse classification models, each with reasonably good performance. In this section, we will first introduce the feature extraction process and then present different ways of building classification models by using the underlying structure of the features.<ref type="figure">Fig. 1</ref>. Sample images from the BDGP. It has the largest collection of images for early as well as late stages. The images in BDGP are grouped into six stage ranges: 1–3, 4–6, 7–8, 9–10, 11–12 and 13–17 (<ref type="bibr" target="#b28">Tomancak et al., 2002</ref><ref type="bibr" target="#b29">Tomancak et al., , 2007</ref>easier for computational models to distinguish, appropriate feature extraction is critical. Log Gabor filters (<ref type="bibr" target="#b5">Daugman, 1980;</ref><ref type="bibr" target="#b7">Field, 1987</ref>) have been shown to offer the best simultaneous localization of spatial and frequency information with an arbitrary bandwidth. They are particularly suitable for our study, as the features distinguishing between different stages should focus on the general morphology of the embryo as well as subtle textures. In the frequency domain, the log Gabor function with respect to radius (r) and angle () can be described by:</p><formula>G r, ð Þ ¼ exp À log r=f 0 ð Þ ð Þ 2 2 2 r exp À À 0 ð Þ 2 2 2</formula><p>where f 0 is the filter's center frequency, 0 is the filter's orientation and r and are the corresponding standard deviations. By choosing different values of f 0 and 0 , one can construct filters with different wavelet scales and orientations. The procedure of our feature construction is illustrated in<ref type="figure" target="#fig_0">Figure 3</ref>. First, we converted the color image to gray scale. We then used log Gabor filters with four different wavelet scales and six different filter orientations to extract the texture information. Hence, 24 Gabor images were obtained from the filtering operation. Next, we divided each of the Gabor images into 640 sub-blocks of size 8 by 8, and the mean values were used to represent each of the sub-blocks. The 24 sub-sampled Gabor images were then converted to vectors, which were concatenated together as the feature vector for the original image. Thus, the dimension of the final feature vector is 24 Â 640 ¼ 1530.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Preliminary on linear classifiers</head><p>The feature construction step maps the images into a feature space, with each dimension corresponding to a specific Gabor feature. We can then denote the training set as D ¼ X, Yg f , where X ¼ fx 1 ,. .. , x n g is the feature vector of the annotated images, Y ¼ y 1 , :::, y n É È is the corresponding stage and n is the number of training samples. In our study, we apply linear classifiers on this high-dimensional classification problem, and apply the one-versusthe-rest (<ref type="bibr" target="#b0">Bishop et al., 2006</ref>) method to convert the multiclass classification problem into a series of binary class problems. Therefore, only binary linear classifiers will be discussed in the rest of this section. Specifically, a binary linear classifier takes the linear combination of the feature vector x of a sample to make the prediction:</p><formula>y ¼ sgn w T x À Á , ð1Þ</formula><p>where y 2 À1, 1g f is the decision or the predicted 'label' of x 2 R d , w 2 R d is the weight vector of the classifier that needs to be learned from the training data, and sgn Á ð Þ is the sign function.</p><p>Learning a linear classifier is to pursuit the optimal weight vector w on the training set, which can be formulated as the following optimization problem:</p><formula>w Ã ¼ arg min w 'ðw, X, YÞ þ RegðwÞ, ð2Þ</formula><p>where 'ðw, X, YÞ is the loss function measuring the discrepancy between the prediction and the ground truth for the training samples, and RegðwÞ is a regularization term designed to improve the generalization performance of the classifier. The regularization term can be used to impose specific structures on the weight vector; and it will be discussed in detail in the following subsection. Three common loss functions are used in this study:</p><p>Least square loss (<ref type="bibr" target="#b0">Bishop et al., 2006;</ref><ref type="bibr" target="#b10">Hastie et al., 2009</ref>) (e.g. ridge regression):</p><formula>'ðw, X, YÞ ¼ 1 2 X n i¼1 w T x i À y i À Á 2</formula><p>Logistic loss (<ref type="bibr" target="#b0">Bishop et al., 2006;</ref><ref type="bibr" target="#b10">Hastie et al., 2009</ref>) (e.g. logistic regression):</p><formula>'ðw, X, YÞ ¼ X n i¼1 log 1 þ exp Ày i w T x i À Á À Á</formula><p>Hinge loss (<ref type="bibr" target="#b0">Bishop et al., 2006;</ref><ref type="bibr" target="#b30">Vapnik, 2000</ref>) (e.g. support vector machine or SVM):<ref type="figure">Fig. 2</ref>. Overview of our stage annotation system. By learning from a training dataset with manually labeled stage information, we build a pool of 1050 classification models. We then apply this pool to the unlabeled images in our FlyExpress database, providing a histogram of voting values for each image. The histogram is then used to annotate the image with a specific stage, as well as a more refined 'sub-stage' and numerical-based 'stage score'An alternative way of addressing the high-dimensional problem is feature selection. In the rest of this subsection, we will discuss 3 variants of sparsity-inducing regularizations (' 1 norm, ' 2, 1 norm and ' 2, 1 À ' 1 norm) that can impose different types of sparsity patterns on the solution of Equation (2) and lead to simultaneous classification and feature selection (<ref type="bibr" target="#b35">Ye and Liu, 2012</ref>). From Equation (1), one characteristic of a linear classifier is that if we set a certain entry of w to be 0, it is equivalent to removing the corresponding feature. This motivates us to introduce the ' 1 regularization (<ref type="bibr" target="#b27">Tibshirani, 1996</ref>):</p><formula>'ðw, X, YÞ ¼ X n i¼1 max 0, 1 À y i w T x i È É</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Exploiting the underlying sparse structure</head><formula>RegðwÞ ¼ X d j¼1 w j ¼ w k k 1 :</formula><p>The ' 1 regularization (also called Lasso) performs feature selection and classification in a unified formulation. It has been applied successfully in various applications (<ref type="bibr" target="#b21">Liu et al., 2009</ref>). However, Lasso does not make full use of the underlying structure of our data. Specifically, as shown in our feature extraction process illustrated in<ref type="figure" target="#fig_0">Figure 3</ref>, each region of the image is associated with 24 features, one for each of the 24 different log-Gabor filters. Thus, the features can be naturally partitioned into distinct groups, one for each region of the image. It is then natural to apply group Lasso (<ref type="bibr" target="#b38">Yuan and Lin, 2006</ref>), which can be applied to select feature groups, i.e. image regions. Assume that we partition the index of the features into S disjoint groups fG 1 ,. .. , G S g, one for each region, such that</p><formula>G 1 [ G 2 [ Á Á Á [ G S ¼</formula><p>f1, 2,. .. , dg. We can then obtain the ' 2, 1 norm (also called group Lasso) regularization as follows:</p><formula>RegðwÞ ¼ X S i¼1 w Gi 2 ,</formula><p>where w Gi is the weight vector restricted to the i-th group of features, and is the parameter that controls the group sparsity. When we use the ' 2, 1 norm regularization to perform feature selection, all features from the same group will be selected simultaneously. Thus, only the 'between-group sparsity' is considered. However, some features from a selected group may be irrelevant to our prediction. In this case, the ' 2, 1 À ' 1 norm regularization (called sparse group Lasso) (<ref type="bibr" target="#b8">Friedman et al., 2010;</ref><ref type="bibr" target="#b20">Liu and Ye, 2010</ref>) can be applied, which simultaneously achieves the 'between-group' sparsity based on the ' 2, 1 norm and the 'within-group' sparsity based on the ' 1 norm as follows:</p><formula>RegðwÞ ¼ 1 w k k 1 þ 2 X S i¼1 w Gi 2 :</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Constructing a pool of diverse classifiers</head><p>The key idea of a successful voting system is to have a large and diverse pool of models, each of them with reasonable prediction power. In this study, we applied SVM with linear kernels from the LIBLINEAR (<ref type="bibr" target="#b6">Fan et al., 2008</ref>) package and six sparse learning algorithms (Lasso, group Lasso and sparse group Lasso with least square and logistic loss) from the SLEP (<ref type="bibr" target="#b21">Liu et al., 2009</ref>) package. We then partition the annotated dataset into two disjoint sets, namely, the 'training set' where linear classifiers are learned and the 'validation set' where the performance of the learned classifiers can be evaluated. Five different training set ratios (from 50 to 90%) are used to partition the dataset and for each ratio, 30 random partitions are generated. Each combination of classification algorithm and training set partition results in a distinct classification model. In terms of classification algorithms, we find that all seven algorithms perform comparably with the three sparse learning methods using logistic loss achieving slightly better performance. The best cross-validation accuracy is 79.82 AE 1.67%, which is achieved by sparse logistic regression with logistic loss and 90% of data as training. For our 15-class (Stages 3–17) classification problem, an accuracy of 80% is reasonably good. We also find that the validation accuracy generally increases as more samples are used in training, but the increase is not that significant after 70% of the annotated data (about 2600 images) are used for training. This indicates that the annotated dataset has an adequate size. In addition to obtaining a collection of 'reasonable' models, we also need the models to be diverse such that the majority voting of the pool will provide robust results for unseen subjects. We calculate the average rate that at least one of the algorithms does not agree with the others, and find that the disagreement rate varies from 30 to 20% as the training ratio increases (refer to Supplementary Materials for detailed results on individual classifier performance as well as disagreement rate). Therefore, we have built a pool of 1050 (7 algorithms times, 5 training ratios times, 30 random partitions) diverse models, each of which achieves reasonably good classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Voting for stage annotation and beyond</head><p>In this subsection, we will discuss in detail the voting scheme we designed for annotating the remaining BDGP images in our FlyExpress database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Stage annotation by majority voting For a given unlabeled</head><p>image, we denote the prediction vector for this image based on the i-th model as y i 2 f0, 1g 15 , where y i is a 15D binary vector indicating the stage prediction of the i-th model. Specifically, y i ½j ¼ 1 indicates that the i-th model determines that this image belongs to the j-th stage. We also assign a 'confidence level' of the current model as a i , which is set to be the classification accuracy of this model on the validation set. We then summarize all the predictions from the 1050 models and obtain a prediction histogram defined as h ¼ P 1050 i¼1 a i y i. Then, the entry with the highest voting will be the stage assigned by the ensemble of the pool of models. That is, the final annotation is defined as S ¼ arg max i h i ½ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Sub-stage annotation and decimal-based embryo ordering</head><p>To illustrate our method of refining stage annotation to sub-stages and the decimal-based embryo ordering scheme, we first provide an example of the prediction histogram for a specific image in<ref type="figure">Figure 2</ref>. In our current system, only images assigned to Stages 4–16 have refined stage annotation. As expected, Stage 10 gets the most votes among all 15 stages, and therefore this image will be annotated as Stage 10. We then compare the voting scores for the two adjacent Stages 9 and 11 and observe that h 9 ½ 4h 11 ½ . Therefore, according to our system, this Stage 10 image is more similar to Stage 9 compared with Stage 11. Thus, we will annotate this image as Stage 10E (early 10). In addition to the order information of the prediction histogram, we can assign a continuous stage value for the image. Using<ref type="figure">Figure 2</ref>as an example, we calculate the 'stage score' for this image as:</p><formula>SS ¼ 10 À h 9 ½  h 9 ½  þ h 10 ½ </formula><p>The intuition is as follows: the higher value of h½9 with respect to h½10 is, the 'earlier' this embryo is among all the Stage 10E images. This decimal stage value can only be used to suggest a relative order within each substage. For example, in terms of developmental time, a Stage 7.9 image is not necessarily closer to Stage 8 than a Stage 6.7 image is to Stage 7. With the help of the embryo ordering scheme, we can obtain even more refined stages. For example, we can further divide Stage 10E into three sub-sub-stages as follows: first, we sort all the decimal stage values of all the images assigned to Stage 10E. We then evenly split the sorted images into three groups, with the first group annotated as Stage 10E-a, second as 10E-b and third as 10E-c.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head><p>We estimated the cross-validation performance of the annotation system in correctly assigning a specific stage (S) for the 3724 annotated images first. This produced an accuracy of 79%, with the highest accuracy observed for Stage 7 (89%) and the lowest accuracy for Stage 10 (44%). This may attribute to the fact that the differences between Stages 9 and 10 are small as they correspond to the slow phase of germ band movement. For evaluating the performance of our method on independent data at a large scale, we generated the annotation S for 36 802 images (lateral views) obtained from the FlyExpress database (<ref type="bibr" target="#b16">Kumar et al., 2011</ref>). A stage assignment was deemed to be correct if S was within the stage range provided by the source BDGP (<ref type="bibr" target="#b28">Tomancak et al., 2002</ref><ref type="bibr" target="#b29">Tomancak et al., , 2007</ref>). That is, if an image was annotated as Stage 7 by our system (S ¼ 7) and BDGP annotated it as stage range 7–8, then the annotation was considered to be correct. In this case, the accuracy of our annotations was 86.6%, with the highest accuracy seen for stage range 4–6 (96.. Of these, manual annotations were not provided by experts for 23 images because they were too out-of-focus to annotate or not lateral (mislabeled in the database). For the remaining 117 images, computational and manual annotations matched 81% of the times, which is similar to the accuracy observed for the training set. At the level of sub-stages, manual and computational annotations matched 73.5% of the time. Overall, we found that the computational prediction is within one sub-stage of the expert developmental biologists' annotation for 93% of the images tested. Therefore, the computational predictions can provide an excellent set of initial annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Improving similar expression pattern retrieval</head><p>Within the FlyExpress database, we provide a tool for identifying similar gene expression patterns for a given query image (<ref type="bibr" target="#b15">Kumar et al., 2002</ref>). As the images in FlyExpress are assigned to a stage range, the search can only be done within a particular stage range. However, the comparison of gene expression is most biologically meaningful when the embryos are from similar developmental time points, which means that the use of specific stage would be useful to improving the interpretation of matches. We present two example cases where the use of specific and refined stages leads to better biological insights (<ref type="figure" target="#fig_2">Fig. 4</ref>). In<ref type="figure" target="#fig_2">Figure 4A</ref>, an expression profile of srp gene from stage range 4–6 is used to query for the best matching patterns. It produces results from many different genes within the same stage range. A view of the specific stage enables one to quickly realize that the query image was from Stage 6 and that many of the resulting patterns are from earlier stages (e.g. 4 and 5). So, by incorporating specific stage information, the user would have received results from Stage 6 only, which would have been more relevant. A similar situation exists for the second case (<ref type="figure" target="#fig_2">Fig. 4B</ref>), where the expression of Gasp from stage range 13–17 is used to query the database. Results in this case show spurious overlaps with many much earlier stage images (e.g. 13, 14), which have been included simply because of rather coarse stage annotations available. Therefore, we plan to provide users with an option in FlyExpress to view results that potentially represent the best matches that come from the closest predicted stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Genomewide-expression-maps with refined stage information</head><p>Using the predicted stage information for 36 802 images (lateral views) obtained from the FlyExpress database (<ref type="bibr" target="#b16">Kumar et al., 2011</ref>), we created genomewide-expression-maps (GEMs) that are generated by aggregating and normalizing all spatial gene expression patterns from the same stage (<ref type="bibr" target="#b13">Konikoff et al., 2012;</ref><ref type="bibr" target="#b16">Kumar et al., 2011</ref>). In<ref type="figure" target="#fig_3">Figure 5</ref>, we demonstrate how the use of increasingly refined stage information makes the global views of gene activities increasingly more informative. The results are arranged from top to bottom for images classified by BDGP in Stages 7–8, 9–10 and 11–12 (see Supplementary Materials for other stage ranges). In<ref type="figure" target="#fig_3">Figure 5A</ref>, GEMS for stage range 7–8 lack the information that the germ band is initially more posterior in position and moves toward the anterior, which is easily revealed when images from stage range 7–8 are separated into Stages 7 and 8. This trend is further illuminated when the stages are further refined into early and late parts (<ref type="figure" target="#fig_3">Fig. 5C</ref>). Comparing the Hartenstein (1993) images side by side with these GEMs confirms this trend (<ref type="figure" target="#fig_4">Fig. 6</ref>). Increasingly more refined trend is seen for Stages 9–10 and 11–12 as shown in<ref type="figure" target="#fig_3">Figure 5</ref>(top to bottom in the right column), such that one quickly gets a sense of the developmental progression illuminated by gene expression patterns. These results indicate that the automated stage annotations work well and that refined stages will enable scientists to identify better sets of co-expressed genes. We also predicted stage score for each image and then build GEMs at an even higher resolution than those in<ref type="figure" target="#fig_3">Figure 5</ref>, whichshows how global gene activities vary over developmental time. In our supplemental materials, we provide a short video made by dividing each stage into 8 sub-sub-stages ('BDGP_GEMs.avi'). In addition to categorizing embryo images into finer sub-stages, our stage score can help to sort all embryo images based on their estimated developmental time (refer to Supplementary Materials for more results on embryo sorting). This will add great functionalities to our current FlyExpress database, and a preliminary version is already included in our iPhone app (<ref type="bibr" target="#b17">Kumar et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">More on model ensemble</head><p>In our final annotation system, all 1050 models are used to form the ensemble. One interesting question to ask is: is it truly beneficial to include all of them? In this subsection, we use the aforementioned independent evaluation dataset to validate our choice of large number of models. First, we show that combining different classification algorithms is essential for the success of model ensemble. We predict the stages of the images from the evaluation set using the ensemble of different subset of methods, and the results are summarized in<ref type="figure" target="#tab_2">Table 2</ref>. Apart from the ensemble of all methods, we test three other scenarios: SVM models alone, sparse models alone and SVM models plus sparse models with logistic loss. Formally, we define the criteria as follows:</p><p>Sub-stage Accuracy (Acc 0.5 ). Only the images that are annotated with the correct sub-stage are considered accurate. For example, if an 'early stage 7' image is annotated as Stage 7E by our system, then the annotation is considered correct Stage Accuracy (Acc Stage). The images that are annotated with the correct stage are considered accurate. For example, if an 'early stage 7' image is annotated as Stage 7E or Stage 7L by our system, then the annotation is considered correct Plus-Minus-Sub-stage Accuracy (Acc AE0.5 ). The images that are annotated with a sub-stage which is at most 'a sub-stage away' from the manually annotated sub-stage are considered accurate. For example, if an 'early stage 7' image is annotated as Stage 6L, Stage 7E or Stage 7L by our system, then the annotation is considered correct. As we can see from<ref type="figure" target="#tab_2">Table 2</ref>, neither SVM models nor sparse models yield competitive results, while the best performance is achieved by combining all of them together. This is especially true for the side-stage accuracy, where a large number of diverse models are essential for accurately predicting if an image is from the early or late part of a certain stage. Additional discussions such as the effects of ensemble pruning (<ref type="bibr" target="#b39">Zhou, 2012</ref>) can be found in the Supplementary Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>In this article, we propose an automated system for the developmental stage annotation of Drosophila embryo gene expression images. A pool of 1050 classification models is constructed using a variety of state-of-the-art sparse learning algorithms. Based on this model pool, we design a voting scheme which not only produces accurate stage annotation but also a stage score for each embryo. This stage score can be used to more finely annotate each embryo into early and late periods of developmental stage. We use this system to annotate 36 802 images (lateral view) from the FlyExpress database, and show that the refined stage and sub-stage annotations greatly improve our ability to view global gene activities and to interpret matching expression patterns. Our current system is designed for size and orientation standardized images in the FlyExpress database. To extend our system for annotating non-standardized images (e.g. disoriented ones) will be an interesting future direction.Three evaluation criteria are used, namely, the sub-stage accuracy (Acc 0.5 ), the stage accuracy (Acc Stage) and the plus-minus-half accuracy (Acc AE0.5 ).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.3.</head><figDesc>Fig. 3. Illustration of the feature extraction process. The standardized image is first processed by a series of log-Gabor filters, resulting in 24 Gabor images. These Gabor images are then down-sampled and concatenated into a single feature vector, which is the final representation of the original image. As indicated by the cross in the figure, one sub-block of the original image corresponds to 24 features in the feature vector, one for each Gabor image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>9%) and the lowest for stage range 9–10 (74.9%). Visual inspection of mistakes revealed that a handful of images were not lateral views. Cai et al. (2012) reported an 85.2% cross-validation accuracy using 5414 images, whereas Ye et al. (2008) achieved 87.8% for just the 3 early stage ranges. Compared with previous results, our system is accurate in terms of predicting the stage ranges for all 36 802 images. We also performed another independent evaluation by randomly selecting 140 images from Stages 4–17. We asked a domain expert to manually annotate these randomly selected images with specific stages (S) and more refined stages [e.g. Early Stage 10 (10E), late Stage 7 (7L)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.4.</head><figDesc>Fig. 4. Examples of refining image retrieval results using stage annotation. Two example query images are used, with the left one (A) from the Kr gene and right one (B) from Gasp. The top matches from the FlyExpress lateral BDGP images are listed, with corresponding pattern as well as similarity values. The annotated stage from our system is presented on the left of each expression image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.5.</head><figDesc>Fig. 5. Stages 7–12 GEMs generated by using only the stage range information [(A), left column], the predicted stage information [(B), middle column] and the sub-stage information [(C), right column]. The total number of images involved for creating each individual GEM is also reported</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.6.</head><figDesc>Fig. 6. GEMs obtained from automatically annotated lateral BDGP images (Stages 7–12) compared with previously published overview images of stage development</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Number of annotated BDGP images for each developmental stage</figDesc><table>Stage 
No. of images 
Stage 
No. of images 

1–3 
250 
11 
246 
4 
251 
12 
255 
5 
274 
13 
251 
6 
224 
14 
252 
7 
236 
15 
232 
8 
260 
16 
243 
9 
248 
17 
254 
10 
248 
Total 
3724 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. Performance evaluation of model ensemble using different subsets of the learning algorithms when stage range information is not available</figDesc><table>Methods 
Acc 0.5 (%) 
Acc Stage (%) 
Acc AE0.5 (%) 

SVM þ sparse algorithms 
73.50 
81.20 
93.16 
SVM 
52.99 
76.07 
91.45 
Sparse algorithms 
68.38 
82.05 
94.02 
SVM þ logistic algorithms 
65.81 
80.34 
94.02 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">This collection of images is manually annotated with precise stage labels. The orientation of all images in this study is standardized, and the size is scaled to 128 by 320 pixels. 267 Automated annotation of developmental stages of Drosophila embryos at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="269"> Automated annotation of developmental stages of Drosophila embryos at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">L.Yuan et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="273"> Automated annotation of developmental stages of Drosophila embryos at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors thank Charlotte Konikoff for assistance in reading the manuscript and providing feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint stage recognition and anatomical annotation of Drosophila gene expression patterns</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Cai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="16" to="24" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">The Embryonic Development of Drosophila Melanogaster</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Campos-Ortega</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Hartenstein</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin, DE</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Current challenges in open-source bioimage informatics</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cardona</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tomancak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="661" to="665" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Functional genomics in Drosophila models of human disease</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">F</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">C</forename>
				<surname>Crowther</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Funct. Genomics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="405" to="415" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Two-dimensional spectral analysis of cortical receptive field profiles</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">G</forename>
				<surname>Daugman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="847" to="856" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Liblinear: a library for large linear classification</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Fan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Relations between the statistics of natural images and the response properties of cortical cells</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Field</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Am. A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2379" to="2394" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title level="m" type="main">A note on the group lasso and a sparse group lasso</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">Atlas of Drosophila Development</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Hartenstein</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cold Spring Harbor Laboratory Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Automated annotation of Drosophila gene expression patterns using a controlled vocabulary</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1881" to="1888" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Gene expression divergence recapitulates the developmental hourglass model</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">T</forename>
				<surname>Kalinka</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">468</biblScope>
			<biblScope unit="page" from="811" to="814" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparison of embryonic expression within multigene families using the flyexpress discovery platform reveals more spatial than temporal divergence</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">E</forename>
				<surname>Konikoff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Dyn</title>
		<imprint>
			<biblScope unit="volume">241</biblScope>
			<biblScope unit="page" from="150" to="160" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Signalling pathways in Drosophila and vertebrate retinal development</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">P</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="846" to="857" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">BEST: a novel computational approach for comparing gene expression patterns from early stages of Drosophila melanogaster development</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="2037" to="2047" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Flyexpress: visual mining of spatiotemporal patterns for genes and publications in Drosophila embryogenesis</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3319" to="3320" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Exploring spatial patterns of gene expression from fruit fly embryogenesis on the iphone</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2847" to="2848" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Global analysis of mRNA localization reveals a prominent role in organizing cellular architecture and function</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Le´cuyerle´cuyer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="174" to="187" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Gene regulatory networks for development</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Levine</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">H</forename>
				<surname>Davidson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="4936" to="4942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Moreau-yosida regularization for grouped tree structure learning</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ye</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1459" to="1467" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">SLEP: Sparse Learning with Efficient Projections</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Tempe, AZ, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic annotation of Drosophila developmental stages using association classification and information integration</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Meng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Shyu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Reuse and Integration (IRI), 2011 IEEE International Conference on</title>
		<meeting><address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Drosophila melanogaster as an emerging translational model of human nephrolithiasis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Miller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Urol</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="page" from="1648" to="1656" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Three-dimensional epithelial morphogenesis in the developing Drosophila egg</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Osterfield</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Cell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="400" to="410" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic image analysis for gene expression patterns of fly embryos</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cell Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Evolution of development in closely related species of flies and worms</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="907" to="907" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Series B (Methodol)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Systematic determination of patterns of gene expression during Drosophila embryogenesis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tomancak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="88" to="89" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Global analysis of patterns of gene expression during Drosophila embryogenesis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tomancak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<monogr>
		<title level="m" type="main">The Nature of Statistical Learning Theory</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Vapnik</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>SpringerVerlag</publisher>
			<pubPlace>New York Inc</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualization of image data from cells to organisms</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Walter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Suppl. .</note>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">The phenogenetic logic of life</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">M</forename>
				<surname>Weiss</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="36" to="45" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">What model organisms and interactomics can reveal about the genetics of human obesity</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Williams</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell. Mol. Life Sci</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="3819" to="3834" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">A combinatorial code for pattern formation in Drosophila oogenesis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Yakoby</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Cell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="725" to="737" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Sparse methods for biomedical data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ye</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="4" to="15" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Classification of Drosophila embryonic developmental stage range based on gene expression pattern images</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ye</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Computational Systems Bioinformatics Conference</title>
		<meeting>the Computational Systems Bioinformatics Conference</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="293" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Developmental stage annotation of Drosophila gene expression pattern images via an entire solution path for LDA</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ye</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Model selection and estimation in regression with grouped variables</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Yuan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Series B. Stat. Methodol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="49" to="67" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<monogr>
		<title level="m" type="main">Ensemble Methods: Foundations and Algorithms</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<forename type="middle">H</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>Boca Raton, FL, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>