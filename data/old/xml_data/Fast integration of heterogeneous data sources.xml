
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Fast integration of heterogeneous data sources for predicting gene function with limited annotation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Sara</forename>
								<surname>Mostafavi</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Cellular and Biomolecular Research</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Quaid</forename>
								<surname>Morris</surname>
							</persName>
							<email>quaid.morris@utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Cellular and Biomolecular Research</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Fast integration of heterogeneous data sources for predicting gene function with limited annotation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="issue">14</biblScope>
							<biblScope unit="page" from="1759" to="1765"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq262</idno>
					<note type="submission">Received on March 5, 2010; revised on April 25, 2010; accepted on May 16, 2010</note>
					<note>[10:47 16/6/2010 Bioinformatics-btq262.tex] Page: 1759 1759â€“1765 Associate Editor: Jonathan Wren Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Many algorithms that integrate multiple functional association networks for predicting gene function construct a composite network as a weighted sum of the individual networks and then use the composite network to predict gene function. The weight assigned to an individual network represents the usefulness of that network in predicting a given gene function. However, because many categories of gene function have a small number of annotations, the process of assigning these network weights is prone to overfitting. Results: Here, we address this problem by proposing a novel approach to combining multiple functional association networks. In particular, we present a method where network weights are simultaneously optimized on sets of related function categories. The method is simpler and faster than existing approaches. Further, we show that it produces composite networks with improved function prediction accuracy using five example species (yeast, mouse, fly, Esherichia coli and human). Availability: Networks and code are available from:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The past decade has seen a dramatic increase in the quantity and variety of publicly available genomic and proteomic data, and a parallel increase in the number of computational methods to integrate these heterogeneous data in generating predictions about protein and gene function [see Noble and Ben-Hur (2007) for a review]. Many of these methods, often called gene (or protein) function prediction algorithms, use the same basic framework: first, they generate so-called functional association networks that capture information about shared gene (or protein) function implicit in each dataset, then they integrate these networks to generate a single composite network which they input, along with a set of labels that describe gene function, to a kernel-or network-based classification algorithm (e.g.<ref type="bibr" target="#b13">Lanckriet et al., 2004;</ref><ref type="bibr" target="#b14">Marcotte et al., 1999;</ref><ref type="bibr" target="#b16">Mostafavi et al., 2008;</ref><ref type="bibr" target="#b17">Myers and Troyanskaya, 2007;</ref><ref type="bibr" target="#b27">Tsuda et al., 2005</ref>). Once trained, these classification algorithms assign * To whom correspondence should be addressed. discriminant values to each gene that can then be thresholded to generate hypotheses about the function of unlabeled genes. The functional association network is a natural and widely used representation for capturing information about shared gene function from high-throughput data sources. In this representation, nodes correspond to genes or proteins and the edges are weighted according to the evidence implied by a given data source for shared function of the connected nodes. These edge weights are calculated using a similarity metric matched to a given data type; for example, the Pearson's correlation coefficient (PCC) is often used to measure pairwise similarities between gene expression profiles. Once calculated, it is relatively easy to translate these networks into kernels for kernel-based learning methods [e.g. by using a diffusion kernel (<ref type="bibr" target="#b12">Kondor and Lafferty, 2002;</ref><ref type="bibr" target="#b24">Qi et al., 2008)]</ref>. An important step in predicting gene function is the construction of a composite network from multiple functional association networks. A common approach is to construct a function-specific composite network as a weighted sum of the individual networks such that the weight of each network is determined based on the network's predictiveness of a set of positively labeled genes that are deemed to have the same specific function (<ref type="bibr" target="#b13">Lanckriet et al., 2004;</ref><ref type="bibr" target="#b16">Mostafavi et al., 2008;</ref><ref type="bibr" target="#b27">Tsuda et al., 2005</ref>). The positive gene labels are derived from online databases such as Gene Ontology (GO;<ref type="bibr" target="#b0">Ashburner et al., 2000</ref>), KEGG (<ref type="bibr" target="#b9">Kanehisa and Goto, 2000</ref>) and Enzyme Commission (EC;<ref type="bibr" target="#b1">Bairoch, 2000</ref>). These databases provide a controlled vocabulary describing categories of gene function and curated lists of genes annotated to these functions. There are two challenges in constructing function-specific composite networks. First, because many functional categories have only a few annotations, it is difficult to assign network weights without overfitting. Second, for an algorithm to be widely applicable it must be fast and scalable to combine dozens of networks with over 10 000 nodes (genes) each. Here, we investigate a number of network weighting schemes to avoid overfitting. In particular, we propose a new approach that we refer to as Simultaneous Weights (SWs). SW is based on our previous algorithm, GeneMANIA (<ref type="bibr" target="#b16">Mostafavi et al., 2008</ref>), which constructs function-specific composite network by solving a constrained linear regression problem. However, instead of assigning function-specific network weights, we simultaneously optimize the weights on a group of related function categories by solving a single-constrained linear regression problem. We evaluate the impact of several regularization schemes such as LASSO (<ref type="bibr" target="#b26">Tibshirani, 1996</ref>), elastic net (<ref type="bibr" target="#b31">Zou and Hastie, 2005</ref>), ridge regularization on our previous weighting scheme (<ref type="bibr" target="#b16">Mostafavi et al., 2008</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Mostafavi and Q.Morris</head><p>state-of-the-art methods in gene function prediction, SW results in a drastic improvement in performance while reducing the computation time requirement of gene function prediction on five example species (yeast, fly, mouse, human and Escherichia coli).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There are large number of algorithms that extend simple guilt-byassociation when predicting gene function from a single network including (<ref type="bibr" target="#b10">Karaoz et al., 2003;</ref><ref type="bibr" target="#b18">Nabieva et al., 2005;</ref><ref type="bibr" target="#b28">Vazquez et al., 2003</ref>). The approaches closest to those presented in this article are methods for integrating multiple functional association networks into one composite network with the goal of predicting gene function from the composite network. In the seminal work of<ref type="bibr" target="#b14">Marcotte et al. (1999)</ref>, a composite network is constructed with an edge between two genes if the two genes are linked together in the majority of the underlying functional association networks. Similarly, in<ref type="bibr" target="#b20">Pavlidis et al. (2002)</ref>a composite network is constructed as an unweigted sum of several functional association networks, each derived from a different data source. More recently, in<ref type="bibr" target="#b13">Lanckriet et al. (2004)</ref>;<ref type="bibr" target="#b27">Tsuda et al. (2005) and</ref><ref type="bibr" target="#b16">Mostafavi et al. (2008)</ref>, function-specific composite networks are constructed as a weighted sum where the weight of each network is determined based on the function being predicted. In<ref type="bibr" target="#b13">Lanckriet et al. (2004) and</ref><ref type="bibr" target="#b27">Tsuda et al. (2005)</ref>, the network weights are assigned to optimize the performance of support vector machine (SVM) and Gaussian random fields (GRFs), respectively, which use the composite network to predict gene function. In<ref type="bibr" target="#b16">Mostafavi et al. (2008)</ref>, we use linear regression to optimize an objective function inspired by the kernel target alignment (<ref type="bibr" target="#b2">Cristianini et al., 2002</ref>) of the composite network and the class labels. Another method for combining multiple association network was presented in<ref type="bibr" target="#b17">Myers and Troyanskaya (2007)</ref>where a combined network was constructed using a naive Bayes classifier. The new approach that we present here, SW, extends GeneMANIA algorithm (<ref type="bibr" target="#b16">Mostafavi et al., 2008</ref>) that was previously shown to have the state-of-art performance on yeast and mouse benchmark datasets (<ref type="bibr" target="#b16">Mostafavi et al., 2008;</ref><ref type="bibr" target="#b22">Pena-Castillo et al., 2008</ref>). However, achieving good performance with the GeneMANIA algorithm in categories with a small number of annotations required a time-consuming regularization procedure. Here, we investigate how to improve the performance for function categories with few annotations without increasing computation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>Following the framework of<ref type="bibr" target="#b16">Mostafavi et al. (2008)</ref>, our approach for predicting gene function from multiple networks consists of two steps: (i) it constructs a composite network from multiple functional association networks and (ii) it predicts gene function from a single composite network. Below, we first review the constrained linear regression problem solved by the GeneMANIA algorithm for assigning network weights; next we describe SW, our new approach for assigning network weights using related categories of gene function. Finally, we briefly review how gene function is predicted from a single composite network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Combining networks with linear regression</head><p>We assume that we are given as input m networks, which we index by d, W d âˆˆ R nÃ—n , W d = W d T , where the (i,j)-th element of W d , w d ij â‰¥ 0 for all i and j. We interpret w d ij as the strength of the evidence of cofunctionality between genes i and j as derived from dataset d. Using annotation databases such as GO, for each GO term that describes a given category of gene function c, positive genes are defined as genes that are annotated to c and we consider all other genes as negatives: that is, we define a label vector y âˆˆ{+1,âˆ’1} n , where positive and negative genes are labeled as +1, âˆ’1, respectively. Our goal is to construct a composite network as a weighted sum of the m networks</p><formula>W * = m d Âµ d W d ,</formula><p>where Âµ d is the weight assigned to network d, such that W * can be used to predict other positive genes. To assign the network weights, GeneMANIA solves a constrained linear regression problem by minimizing the least squares error between the composite network and the target network T which represents the pairwise functional relationships implied by the label vector:</p><formula>Âµ * = argmin Âµ trace((T âˆ’W * ) T (T âˆ’W * )), (1) s.t. W * = m d=1 Âµ d W d , Âµ d â‰¥ 0 d ={1,.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..,m}</head><p>where the target network T has elements T ij taking one of the two values: ( n âˆ’ n ) 2 if genes i and j are both positive and âˆ’ n + n âˆ’ n 2 if genes i and j have opposite signs, where n + and n âˆ’ are the number of positives and negatives in y. Since the negativeâ€“negative pairs of genes typically do not form a coherent class, it is more appropriate to solve a one-class problem: in GeneMANIA this is addressed by removing the entries in T and each network W d that correspond to negative pairs of genes (i.e. T ij and w d ij with i and j both negative). The non-negative constraint in Equation (1) ensures that the Laplacian matrix L which is derived from W * , L = Dâˆ’W * (where D is a diagonal matrix of the row sums of W * , i.e.</p><formula>D ii = n j=1 w * ij</formula><p>) is positive semi-definite. As we will show later, we need this condition to use W * for making predictions about gene function. By using the fact that trace(WT ) = vec(W ) T vec(T ), where vec(W ) is an operator that stacks the columns of matrix W atop of each other, we can write (1) as a non-negative linear regression problem:</p><p>Page: 1761 1759â€“1765</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast integration of heterogeneous data sources</head><p>that improves the performance without increasing the computational time and show that it performs better than previous approaches. In particular, in SW, instead of assigning network weights for each category separately, we fit the network weights to a set of related function categories. To do so, we assign the network weights by solving the following problem:</p><formula>Âµ * = argmin Âµ h c=1 ( t c âˆ’ Âµ) T ( t c âˆ’ Âµ), Âµ d â‰¥ 0</formula><p>where t c for c = 1,...,h are constructed from h positively labeled genes sets (categories) that are related to each other. Once we obtain Âµ * , we construct W * and use it to predict all h categories. If we include all entries of (i.e. not excluding negativeâ€“negative pairs of genes for each category h as described above), we can then write the above problem as:</p><formula>Âµ * = argmin Âµ âˆ’2 Âµ T TËœtTËœt +h Âµ T T Âµ whereËœtwhereËœ whereËœt = h c=1 t c and</formula><p>so we only need to solve the regression problem once to get the SWs. As such, for each category, T c ij takes on one of the three possible values: (</p><formula>n + c n ) 2 ,( n âˆ’ c n ) 2 ,âˆ’ n âˆ’ c n + c n 2 when</formula><p>i,j are both negative, both positive and have the opposite signs, respectively, and n + c (n âˆ’ c ) is the number of positives (negatives) in category c. As we will show, including the negativeâ€“negative pairs of genes in t c and does not degrade the performance of the constructed composite network. In our experiments, constructingËœtconstructingËœ constructingËœt takes &lt;5 s with h = 1000 on a standard computer (2.4 GHz Intel Core 2 Duo, 4 GB RAM). Further, for a given set of networks, we can always precompute T and thus only need to calculate TËœtTËœt for a group of categories of interest. As we will show in Section 5, combining weights by SWs results in an improvement in the performance of the composite networks in predicting the relevant h gene categories while it reduces the computation time (as now we are only required to solve for the network weights once when predicting h categories).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Predicting protein function from a single network</head><p>We evaluate a composite network, W * , by its ability to predict a given gene function. As done in<ref type="bibr" target="#b16">Mostafavi et al. (2008)</ref>, we use the GRFs algorithm (<ref type="bibr" target="#b29">Zhou et al., 2004;</ref><ref type="bibr" target="#b30">Zhu et al., 2003</ref>) to predict gene function from a single composite network. In particular, given a label vector y where y i represents the prior evidence for gene i having the function of interest, the GRF algorithm assigns a discriminant score f i âˆˆ<ref type="bibr">[âˆ’1,1]</ref>to each node (gene) i in the network which we can then threshold to classify the genes. In particular, y i ={âˆ’1,k,+1} where known negative and positive genes are assigned âˆ’1 and +1, respectively, and the unlabeled genes (i.e. the possibility set) are assigned a value âˆ’1 â‰¤ k â‰¤+1, for example, k can be adjusted based on a gene's annotations in GO (<ref type="bibr" target="#b15">Mostafavi and Morris, 2009</ref>). We can write the GRFs algorithm in the following general form:</p><formula>f * = argmin f n i=1 Ïƒ i (y i âˆ’f i ) 2 + n i,j=1 w * ij (f i âˆ’f j ) 2 (3) = argmin f ( f âˆ’âˆ’ y) T ( f âˆ’âˆ’ y)+ f L f = (+L) âˆ’1 y where [Ïƒ 1 ,...,Ïƒ n ]</formula><formula>k = n + âˆ’n âˆ’ n + +n âˆ’ ,</formula><p>the mean of the labels of the labeled nodes; this modification results in considerable performance improvement in unbalanced classification problems such as gene function prediction. Setting Ïƒ i &gt; 0, ensures that +L is invertible because +L is diagonally dominant; in our experiments, we set = I (the identity matrix). To solve for f , we only need to solve a linear system of equations M y = f , where M = (I +L), which we can do with various existing fast iterative solvers (<ref type="bibr" target="#b20">Nocedal and Wright, 2006</ref>). We use conjugate gradient (CG). CG is guaranteed to terminate in n steps, the most time-consuming operation at each step being a matrixvector product with a computational complexity proportional to the number of non-zero elements in L; in our setting L is very sparse, with O(n) non-zero elements, and CG terminates in fewer than 20 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODS</head><p>In this section, we describe our benchmark datasets, how we construct functional association networks, our evaluation criterion and how we group function categories in SW (see the Supplementary Material for more detailed information).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Yeast, fly, mouse, human and E.Coli datasets</head><p>We evaluate our methodology on benchmark networks in five species: yeast, fly, mouse, human and E.coli. For yeast, we constructed 44 networks that include interactions derived from gene expression, protein and genetic interaction [downloaded from BIOGRD (<ref type="bibr" target="#b25">Stark et al., 2006</ref>)] and protein localization. For mouse, we use the MouseFunc benchmark (<ref type="bibr" target="#b22">Pena-Castillo et al., 2008</ref>), which consists of 10 networks and covers 21 603 mouse genes. For fly, we have constructed 38 networks from various gene expression data [downloaded from GEO (<ref type="bibr" target="#b3">Edgar et al., 2002)]</ref>, protein interaction (downloaded from BioGRID) and domain composition [downloaded from BioMART (<ref type="bibr" target="#b11">Kasprzyk et al., 2004)</ref>] that cover 13 562 fly genes. For E.coli, we use seven networks from<ref type="bibr" target="#b8">Hu et al. (2009)</ref>that include coinheritance and protein interactions for 4175 E.coli genes. Similarly, our human benchmark consists of eight networks constructed from various gene expression, protein interaction, domain composition and phenotype data and covers 13 281 human genes obtained from HPRD (<ref type="bibr" target="#b23">Prasad et al., 2006</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Functional association networks</head><p>We construct networks from each profile-based high-throughput data source using the PCC. For network-based data (e.g. protein interaction), we use both a direct interaction network and a correlation-based network using the PCC on the frequency-corrected data [as done in<ref type="bibr" target="#b16">Mostafavi et al. (2008)]</ref>. For efficiency, we sparsify our correlation-based networks by setting by keeping the top K interactions for each gene and setting the rest to zero. See the Supplementary Material for more details. We then normalized all our networks by:</p><formula>Ëœ W d = D âˆ’1/2 d W d D âˆ’1/2 d</formula><p>where D d is the diagonal row sum matrix of W d. Similarly, we also normalize the combined network W * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>To evaluate gene function prediction, we use the GO biological process (BP) function categories (<ref type="bibr" target="#b0">Ashburner et al., 2000</ref>) for Saccharomyces cerevisiae</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Mostafavi and Q.Morris</head><p>(<ref type="bibr">June 2006</ref>), Mus musculus [downloaded from MouseFunc data (<ref type="bibr">PenaCastillo et al., 2008)]</ref>, Drosophila melanogaster (<ref type="bibr">July 2009</ref>), Homo sapiens (July 2009) and E.coli (<ref type="bibr">April 2010</ref>). Following common practice, we have removed Inferred from Electronic Annotation (IEA) annotations. These annotations, which constitute the majority of GO annotations, are not reviewed by a curator and, as such, are believed to be less accurate. Furthermore, doing so helps us to avoid circularity because IEAs are themselves computationally predicted using some of the data that we make available to our algorithms. We evaluate each method's composite networks by using them as input to the GRF algorithm (the second step in GeneMANIA). We report the performance in terms of both average area under the receiver operating characteristic (ROC) curve (AUC of ROC) and average precision at 10% recall over all BP GO categories with 3â€“300 annotations using 3-fold crossvalidation (CV). We focus on BP categories because they make up the majority of functions in the GO hierarchy. Our results for cellular component (CC) and molecular function (MF) categories are similar and are described in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Grouping GO categories for simultaneous weights</head><p>We have examined several methods for grouping GO categories when assigning SWs including grouping by (i) GO hierarchy (i.e. BP, CC and MF) (ii) GO hierarchy and number of annotations (iii) clustering of GO categories based on annotations and (iv) ancestor and descendant terms with ancestors having a maximum category size (300 annotations). We only report results for the grouping of GO categories by GO hierarchy and number of annotations (e.g. all categories with less than 300 annotations) as we found it to have the best performance (Supplementary Material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>Here, we first evaluate SW and compare its performance to several other approaches: various regularized linear regression methods, the TSS algorithm and a simpler correlation-based method (described below), using the yeast benchmark networks. We then show analogous results using mouse, fly, human and E.coli benchmark data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Performance on yeast networks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Comparison of performance of SW with various functionspecific linear regression methods</head><p>We first extensively compare the performance of SW in predicting gene function in yeast to that of GeneMANIA. In particular, as discussed in Section 4, one way to improve the performance of function-specific constrained linear regression in GeneMANIA is to use regularization; in fact,<ref type="bibr" target="#b16">Mostafavi et al. (2008)</ref>showed that ridge regression (i.e. 2 norm regularization) to a mean weight prior, where the mean weights refer to the average weight assigned to each network in a large number of function predictions, considerably improves the performance with the drawback of increasing the computation time to estimate the mean weights. Here, we investigate the effect of several forms of regularization on the performance of GeneMANIA algorithm where we find the network weights by solving the following problem:</p><formula>Âµ * = argmin Âµ ( t âˆ’ Âµ) T ( t âˆ’ Âµ)+J( Âµ) , Âµ â‰¥ 0</formula><p>where J â‰¥ 0 is the regularization function. In particular, we investigated the performance of four different regularizations:</p><p>(i) ridge with uniform prior, (ii) ridge with mean prior, (iii) LASSO and (iv) elastic net. In LASSO (<ref type="bibr" target="#b26">Tibshirani, 1996</ref>), J(, it was shown that the elastic net results in a sparse solution and often performs better than the LASSO. For ridge with a prior, we define J(</p><formula>Âµ) = Î± 1 m d=1 |Âµ d |,</formula><formula>Âµ) = m d=1 (Âµ d âˆ’v d ) 2 s d ,</formula><p>where v is a prior weight vector and s d determines the strength of the regularization on Âµ d. In<ref type="bibr" target="#b16">Mostafavi et al. (2008)</ref>, the mean weight prior was obtained as the average weight assigned to each category (using unregularized regression) in predicting all categories in the same GO hierarchy (we will refer to this method as ridge with mean prior). In addition, if we set v d = 1 the network weights are shrunk to a uniform value, we call this second method ridge with uniform prior. In our experiments, we set s d = 1/ ij w d ij ; thus, the strength of the regularizer is higher on sparser networks.<ref type="bibr">Efron et al., 2004</ref>) algorithm to solve for the LASSO and elastic net solutions; we set the number of positive coefficients using F-statistics (<ref type="bibr" target="#b7">Hastie et al., 2001</ref>). For elastic net, we set Î± 2 =1e-6 using CV. 1 For SW, we used all 1188 BP GO categories to fit the networks weights. In Uniform, the network weights are all set to 1/m where m is the number of networks.<ref type="figure">Figure 1a</ref>shows that SW significantly outperforms ridge regression with mean prior overall in terms of ROC (P = 4.368Ã— 10 âˆ’23 , Wilcoxon signed rank test) and slightly improves on the performance in terms of precision (P = 0.0437, Wilcoxon signed rank test) with the advantage that it only requires solving one linear regression problem to predict all 1188 GO categories (instead of 1188 for the function-specific network weighting methods). In addition, this figure shows that unregularized linear regression performs as well as or better than LASSO, ridge or elastic net regularization whereas ridge with a prior results in a better performance in all evaluation categories. However, as expected, we see that the performance of unregularized regression improves with increasing number of positives and thus it is more appropriate to use function-specific weighting in such instances. One explanation for the observed trend in<ref type="figure">Figure 1a</ref>is that regularization methods that shrink the network weights toward zero are too selective and often identify only a few relevant networks. For example, on average 45% (20/44), 54% (24/44) and 95% (42/44), 97% (43/44) of the networks are assigned a non-zero weight using LASSO, unregularized linear regression and ridge with mean prior, and SW, respectively (see Supplementary<ref type="figure">Fig. S1</ref>). Note that the best performing networks on their own are significantly worse than the combined data (<ref type="figure">Fig. 1b</ref>). SW results in a better measure of network relevancy and with the current available genomics and proteomics datasets, one integrated composite functional association network can sufficiently and accurately predict a broad range of functional relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 1763 1759â€“1765</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast integration of heterogeneous data sources</head><p>(</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Comparison of SW with TSS and correlation-based network weights</head><p>We also compared the performance of SW with two other methods: TSS algorithm (<ref type="bibr" target="#b27">Tsuda et al., 2005</ref>) and a simpler correlation-based network weighting method (<ref type="figure" target="#fig_2">Fig. 2</ref>). In the correlation network weighting, each network is assigned a weight that is inspired by the Kernel Target Alignment scoreâ€”we set</p><formula>Âµ d = y T W d y W d ,W d = ij w d ij y i y j ij (w 2 ij )</formula><p>. Unlike the linear regression methods, correlation-based weighting does not account for the redundancy between the networks. The TSS algorithm (<ref type="bibr" target="#b27">Tsuda et al., 2005</ref>) assigns the network weights by optimizing the performance of the GRFs algorithm with the resulting composite network. In our experiments, we set the regularization parameters of the TSS algorithm by CV to c 0 = 0.5 and c = 1. As done in code provided in<ref type="bibr" target="#b27">Tsuda et al. (2005)</ref>, we also set a lower bound of 0.01 on Âµ d. We note that the absence of the lower bound results in a decrease in the performance of the TSS algorithms. As shown in<ref type="figure" target="#fig_2">Figure 2</ref>, SW significantly outperforms correlation-based network weights and TSS in all evaluation categories. To further understand the differences between these various approaches, we compare the network weights that were assigned to individual networks. As shown in<ref type="figure" target="#fig_3">Figure 3</ref>, we observed that the TSS algorithm tends to be very selective, often assigning large weights to a few networks and a very low weight (the weight lower bound) to the rest. The correlation weights are similar to the linear regression weights; however, the redundancy between the networksis not accounted for. For example, the protein interaction networks (shown as cyan and green) drawn from separate publications tend to include similar information and the average of weights assigned to these networks by correlation weights is higher than that of linear regression. As expected, the mean weight assigned by linear regression to individual networks is similar to SW for that network. In general, consistent with previous studies (<ref type="bibr" target="#b14">Marcotte et al., 1999</ref>), we observed that all methods assign a high proportion of the network weights to the networks derived from gene expression datasets and the protein localization dataset.(n = 1101 for fly, 952 for mouse, for 1188 for human, 528 for E.coli)<ref type="bibr">[11]</ref><ref type="bibr">[12]</ref><ref type="bibr">[13]</ref><ref type="bibr">[14]</ref><ref type="bibr">[15]</ref><ref type="bibr">[16]</ref><ref type="bibr">[17]</ref><ref type="bibr">[18]</ref><ref type="bibr">[19]</ref><ref type="bibr">[20]</ref><ref type="bibr">[21]</ref><ref type="bibr">[22]</ref><ref type="bibr">[23]</ref><ref type="bibr">[24]</ref><ref type="bibr">[25]</ref><ref type="bibr">[26]</ref><ref type="bibr">[27]</ref><ref type="bibr">[28]</ref><ref type="bibr">[29]</ref><ref type="bibr">[30]</ref>(n = 668 for fly, 435 for mouse, 510 for human and 177 for E.coli),(n = 426 for fly, 239 for mouse, 254 for human and 104 for E.coli) and(overall). Error bars show the standard error. Asterisk indicate significant difference in overall performance (category size range) using paired Wilcoxon signed rank test with a Bonferroni correction: double asterisk indicate SW performs significantly better than both of the other methods, asterisk indicates that the differences were significant only between SW and unregularized. and unregularized linear regression in terms of precision in fly and human. In mouse, SW significantly outperforms unregularized linear regression in terms of precision. We note that the human networks are sparser than the other organisms, which makes it hard to assign accurate network weights (mean number of interactions is 391 240 in human networks compared with 1 011 400 in mouse), which may explain the smaller (but significant) improvements of SW compared with uniform weights. As well, we note that the performance of uniform weights tends to degrade as the number of networks increasesâ€”this is because of the abundance of gene expression datasets and thus the number of co-expression networks. For example, out of the 38 networks for fly, 32 are co-expression networks. By not accounting for redundancy, the performance of uniform weights is significantly worse than that of SW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Mostafavi and Q.Morris</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have introduced a new network weighting scheme for combining multiple networks that are derived from genomic and proteomic data in order to construct a composite network that is predictive of gene function. We have shown that by fitting network weights that are simultaneously optimized on a group of functions from the same branch of GO, we greatly improve prediction performance. We have shown that we can obtain these SWs by solving a constrained linear regression problem. In our experiments, the SW method results in a significant improvement in predicting gene function in yeast, mouse and fly. In human and E.coli, SWs performs only slightly better than a uniform network combination; this is because these networks tend to be sparser than the other networks making it hard to assign accurate network weights. In our experiments, we have observed that adding a small amount of ridge regularization to SW results in a slight performance improvement; the regularization parameter can be set using CV; alternatively, we have observed good performance by setting it to âˆ¼ 0.001 n 2 (nâˆ’1) (i.e. 0.1% of the total number of observations).</p><p>Our results show that fitting the SWs to GO categories in the same hierarchy with a broad range of specificities (those withannotations) outperform more specific groupings of the GO categories. Note that, because we adjust the target vector t c to balance the number of positives and negatives in each category c, the larger GO categories contribute more to the overall target vectorËœt vectorËœ vectorËœt ; on the other hand, there are many more categories with<ref type="bibr">[3]</ref><ref type="bibr">[4]</ref><ref type="bibr">[5]</ref><ref type="bibr">[6]</ref><ref type="bibr">[7]</ref><ref type="bibr">[8]</ref><ref type="bibr">[9]</ref><ref type="bibr">[10]</ref>annotations. In summary, we have demonstrated the feasibility and the utility of constructing a single composite network with SWs for predicting various GO categories. Unlike a fixed network combination with uniform weights, SWs account for noisy and redundant networks. This observation can in turn speed up gene function prediction from multiple networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[10:47 16/6/2010 Bioinformatics-btq262.tex] Page: 1762 1759â€“1765</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Figure 1a summarizes the performance of each method in five evaluation categories: predicting gene functions which have [3â€“10], [11â€“30], [31â€“100], [101â€“300] positive annotations and [3â€“300] (i.e. overall) positive annotations. In ridge with mean prior, we set the prior on each network's weight to the average weight that network received in predicting all 1188 GO BP categories with 3â€“300 annotations. We used the LARS (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Performance of SW, TSS and correlation in predicting gene function in yeast according to BP categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Each colored bar represents the average weight assigned to each network while predicting 1188 gene functions. Networks are divided into four types (i) co-localization (network 1), (ii) gene expressions (networks 2â€“7), (iii) protein interaction (networks 8â€“25) and genetic interactions (networks 26â€“44).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Comparison of performance of unregularized linear regression (Unreg), SW and a fixed uniform combination of networks in predicting gene function in fly (a and e), mouse (b and f), human (c and g) and E.coli (d and h). The bars show average performance in BP categories with [3â€“10] (n = 1101 for fly, 952 for mouse, for 1188 for human, 528 for E.coli) [11â€“30](n = 668 for fly, 435 for mouse, 510 for human and 177 for E.coli), [31â€“100] (n = 426 for fly, 239 for mouse, 254 for human and 104 for E.coli) and [3â€“100] (overall). Error bars show the standard error. Asterisk indicate significant difference in overall performance ([3â€“100] category size range) using paired Wilcoxon signed rank test with a Bonferroni correction: double asterisk indicate SW performs significantly better than both of the other methods, asterisk indicates that the differences were significant only between SW and unregularized.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>T are model parameters, is a diagonal matrix with ii = Ïƒ i , L = Dâˆ’W is the graph Laplacian and D is a diagonal matrix with D ii = j w * ij. The above objective ensures that the discriminant scores remain close to their initial labels [first term in (3)] and that the discriminant scores of genes likely to share a function (measured by high w * ij ) are similar to each other [second term in (3)]. As done in Mostafavi et al. (2008), we set</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>whereas in standard ridge regression J( Âµ) = Î± 2 m d=1 Âµ 2 d where Î± 1 and Î± 2 are regularization constants and determine the strength of the regularization. The elastic net regularization (Zou and Hastie, 2005) combines l 2-and l 1-norm penalties: Î± 1 m d=1 |Âµ d |+Î± 2 m d=2 Âµ 2 d. In Zou and Hastie (2005)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>on fly, mouse, human and E.coli benchmarks</figDesc><table>We also investigated the performance of unregularized linear 
regression, SW and uniform network weights on fly, mouse, human 
and E.coli networks in all GO categories that have between 3 and 100 
annotations (2195 for fly, 1626 for mouse, 1952 for human, and 809 
for E. coli). Figure 4 summarizes the performance in terms of AUC of 
ROC curve and precision at 10% recall in the four species. As shown, 
SW is significantly better than unregularized linear regression in 
the overall category in fly, mouse, human and E.coli in terms of 
AUC of ROC. As well, SW is significantly better than uniform Page: 1764 1759â€“1765 

</table></figure>

			<note place="foot">Âµ * = argmin Âµ ( t âˆ’ Âµ) T ( t âˆ’ Âµ), Âµ d â‰¥ 0,d ={1,...,m} (2) where t = vec(T ), =[vec(W 1 ),...,vec(W m )] and Âµ = [Âµ 1 ,...,Âµ m ] T. In practice, we include a column of ones in and calculate a bias Âµ 0 that we discard when constructing W * . Unlike the other values of Âµ d , Âµ 0 is not constrained to be positive. Solving Equation (2) requires at most m iterations (though in practice the number of iterations is much smaller), each iteration involves solving a system of linear equations with m variables and a matrix-vector product. As m (the number of networks) tends to be smaller than 100, we can compute the network weights very fast (e.g. in seconds on a standard computer). 3.2 Combining networks with SWs Although the above approach is fast, it often performs poorly in predicting categories that have a small number of annotations (as discussed in Section 5). In Mostafavi et al. (2008), it was shown that an 2 norm regularization (also known as ridge regression) to a mean weight prior, improves performance in such categories (Section 5.1.1). However, assessing this prior requires solving several regression problems. Here, we define a simple modification 1760 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> We picked Î± 2 from the set [1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1] by examining the mean ROC using 3-fold CV.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thank Khalid Zuberi, Quentin Shao and Javier Diaz for their help with collecting the networks.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Gene ontology: tool for unification of biology</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ashburner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">The enzyme database in</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bairoch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="304" to="305" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">On kernel target alignment</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Cristianini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteen Conference on Advances in Neural Information Processing Systems</title>
		<meeting>the Fourteen Conference on Advances in Neural Information Processing Systems<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="367" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Gene expression omnibus: NCBI gene expression and hybridization array data repository</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Edgar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="207" to="210" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="47" to="63" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq262. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1765" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Least angle regression</title>
		<author>
			<persName>
				<forename type="first">B</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="407" to="499" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Fast. integration of heterogeneous data sources Efron,</note>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer</publisher>
			<pubPlace>NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Global functional atlas of escherichia coli encompassing previously uncharacterized proteins</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">96</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">KEGG: Kyoto encyclopedia of genes and genome</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kanehisa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Goto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="27" to="30" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Whole-genome annotation by using evidence integration in functional-linkage networks</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Karaoz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="2888" to="2893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Ensmart: a generic system for fast and flexible access to biological data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kasprzyk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="160" to="169" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Diffusion kernels on graphs and other discrete structures</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kondor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lafferty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Conf. Mach. Learn. (ICML)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="463" to="475" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A statistical framework for genomic data fusion</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lanckriet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2626" to="2635" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">A combined algorithm for genome-wide prediction of protein function</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Marcotte</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="83" to="86" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Using the gene ontology hierarchy when predicting gene function</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mostafavi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Morris</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence<address><addrLine>Montreal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Genemania: a real-time multiple association network integration algorithm for predicting gene function</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mostafavi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Context-sensitive data integration and prediction of biological networks</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Myers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Troyanskaya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2322" to="2330" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Whole-proteome prediction of protein function via graphtheoretic analysis of interaction maps</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Nabieva</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Integrating Information for Protein Function Prediction Bioinformatics-From Genomes to Therapies</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Noble</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ben-Hur</surname>
			</persName>
		</author>
		<editor>Lengauer,T.</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>WileyVCH Verlag GmbH &amp; Co KGaA</publisher>
			<pubPlace>Weinheim, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Numerical Optimization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Nocedal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wright</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Usa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Pavlidis</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer</publisher>
			<pubPlace>NY</pubPlace>
		</imprint>
	</monogr>
	<note>Learning. gene functional classification from multiple data types</note>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="401" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A critical assessment of Mus musculus gene function prediction using integrated genomic evidence</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Pena-Castillo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Human protein reference database â€“ 2006 update</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">K</forename>
				<surname>Prasad</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="411" to="414" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Finding friends and enemies in an enemies-only network: a graph diffusion kernel for predicting novel genetic interactions and co-complex membership from yeast genetic intearctions</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Qi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">BioGRID: a general repository for interaction datasets</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Stark</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast protein classification with multiple networks</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Tsuda</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="59" to="65" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Global protein function prediction from protein-protein interaction networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Vazquez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="697" to="700" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="328" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Semi-supervised learning using Gaussian fields and harmonic functions</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Zhu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth International Conference on Machine Learning</title>
		<meeting>the Twentieth International Conference on Machine Learning<address><addrLine>Washington DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>